{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "95878a73",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6478c6ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading CSV file with proper dtype to preserve leading zeros...\n",
      "Total rows in 2024 before filtering: 5205065\n",
      "Total rows after removing NA values in Units/Prescriptions: 2599748\n",
      "Rows removed by NA filter: 2605317\n",
      "Total rows after filtering out State='XX': 2362630\n",
      "Rows removed by State filter: 237118\n",
      "Unique NDCs 33397\n"
     ]
    }
   ],
   "source": [
    "# Read the CSV file with NDC column as string to preserve leading zeros\n",
    "year = 2024\n",
    "csv_file = fr\"c:\\Users\\lholguin\\OneDrive - purdue.edu\\VS code\\Data\\SDUD\\SDUD{year}.csv\"\n",
    "\n",
    "#Personal pc path: r\"c:\\Users\\asus\\OneDrive - purdue.edu\\VS code\\Data\\SDUD\\SDUD{year}.csv\"\n",
    "#Office path: \"C:\\Users\\lholguin\\OneDrive - purdue.edu\\VS code\\Data\\SDUD\\SDUD{year}.csv\"\n",
    "\n",
    "#personal pc: r\"c:\\Users\\asus\\OneDrive - purdue.edu\\VS code\\Data\\SDUD\\SDUD2024.csv\"\n",
    "print(\"Reading CSV file with proper dtype to preserve leading zeros...\")\n",
    "\n",
    "# Force NDC column to be read as string/object to preserve leading zeros\n",
    "df = pd.read_csv(csv_file, dtype={'NDC': 'object'})\n",
    "\n",
    "# Filter out rows with NA values in 'Units Reimbursed' or 'Number of Prescriptions' first\n",
    "print(rf\"Total rows in {year} before filtering: {len(df)}\")\n",
    "df_filtered = df.dropna(subset=['Units Reimbursed', 'Number of Prescriptions'])\n",
    "print(f\"Total rows after removing NA values in Units/Prescriptions: {len(df_filtered)}\")\n",
    "print(f\"Rows removed by NA filter: {len(df) - len(df_filtered)}\")\n",
    "\n",
    "# Then filter out rows where State column equals 'XX'\n",
    "before_state_filter = len(df_filtered)\n",
    "df_filtered = df_filtered[df_filtered['State'] != 'XX']\n",
    "print(f\"Total rows after filtering out State='XX': {len(df_filtered)}\")\n",
    "print(f\"Rows removed by State filter: {before_state_filter - len(df_filtered)}\")\n",
    "print(\"Unique NDCs\", df_filtered['NDC'].nunique())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fcf539d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting 2348980 NDC values with leading zeros preserved (excluding State='XX' and NA values)...\n",
      "Successfully saved 2348980 NDC values to NDCf_2021.txt (State != 'XX', no NA values)\n",
      "Unique NDC values: 32417\n",
      "First 10 NDC values (with leading zeros):\n",
      "['00002143380', '00002143480', '00002143611', '00002144511', '00002223680', '00002318280', '00002614511', '00002614527', '00002751001', '00002751659']\n"
     ]
    }
   ],
   "source": [
    "#Generating the txt file with the NDC values\n",
    "# Save to text file\n",
    "\n",
    "# Extract NDC column from filtered data - it's already in string format now\n",
    "ndc_values = df_filtered['NDC']\n",
    "output_file = rf\"C:\\Users\\lholguin\\OneDrive - purdue.edu\\VS code\\Data\\ATC\\text_files\\NDCf_{year}.txt\"\n",
    "print(f\"Extracting {len(ndc_values)} NDC codes (All) with leading zeros preserved (excluding State='XX' and NA values)...\")\n",
    "\n",
    "with open(output_file, 'w') as f:\n",
    "    for ndc in ndc_values:\n",
    "        f.write(str(ndc) + '\\n')\n",
    "\n",
    "print(f\"Successfully saved {len(ndc_values)} NDC values to NDCf_{year}.txt (State != 'XX', no NA values)\")\n",
    "print(f\"Unique NDC values: {ndc_values.nunique()}\")\n",
    "print(\"First 10 NDC values (with leading zeros):\")\n",
    "print(ndc_values.head(10).tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4d9c8a17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique ATC4 Classes in ATC4 mapping file: 612\n",
      "Index(['NDC', 'ATC4 Class'], dtype='object')\n",
      "Unique NDCs of ATC csv 2024: 32204\n",
      "Total rows 61470\n",
      "ATC4 Class\n",
      "H02AB    894\n",
      "N06BA    762\n",
      "S01BA    757\n",
      "N06AX    746\n",
      "C05AA    746\n",
      "B05XA    723\n",
      "R01AD    718\n",
      "N03AX    702\n",
      "S01AA    698\n",
      "C10AA    655\n",
      "Name: count, dtype: int64\n",
      "Filtered dataset has 2362630 rows\n",
      "Merged dataframe has 4360194 rows\n",
      "Unique NDCs in merged dataframe: 33397\n",
      "count\n",
      "1     21590\n",
      "2      4098\n",
      "3      3168\n",
      "4       911\n",
      "5       718\n",
      "7       523\n",
      "11      270\n",
      "8       267\n",
      "6       241\n",
      "9       179\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#Once you have run the code n2c.py then you'll have the ATC4 csv file to read in\n",
    "\n",
    "# read ATC4 mapping, ensure NDC is read as string and zero-padded to 11 digits\n",
    "file_path=rf'C:\\Users\\lholguin\\OneDrive - purdue.edu\\VS code\\Data\\ATC\\NDCf_{year}_ATC4_classes.csv'\n",
    "#Personal pc path r'C:\\Users\\asus\\OneDrive - purdue.edu\\VS code\\Data\\ATC\\NDCf_{year}_ATC4_classes.csv'\n",
    "#office path: r\"C:\\Users\\lholguin\\OneDrive - purdue.edu\\VS code\\Data\\ATC\\NDCf_{year}_ATC4_classes.csv\"\n",
    "\n",
    "df_atc4 = pd.read_csv(file_path, dtype={'NDC': 'object'})\n",
    "df_atc4['NDC'] = df_atc4['NDC'].str.zfill(11)\n",
    "#How many unique atc4 classes are there in the mapping file?\n",
    "print(f\"Unique ATC4 Classes in ATC4 mapping file: {df_atc4['ATC4 Class'].nunique()}\")\n",
    "\n",
    "print(df_atc4.columns)\n",
    "print( rf\"Unique NDCs of ATC csv {year}:\", df_atc4['NDC'].nunique())\n",
    "print(\"Total rows\", len(df_atc4))\n",
    "top_classes = df_atc4['ATC4 Class'].value_counts()\n",
    "print(top_classes.head(10))\n",
    "print(f\"Filtered dataset has {len(df_filtered)} rows\")\n",
    "\n",
    "# Merge filtered SDUD data with ATC4 mapping on NDC\n",
    "\n",
    "merged_df=pd.merge(df_filtered, df_atc4, on='NDC', how='left')\n",
    "print(f\"Merged dataframe has {len(merged_df)} rows\")\n",
    "print(f\"Unique NDCs in merged dataframe: {merged_df['NDC'].nunique()}\")\n",
    "atc_counts = df_atc4['NDC'].value_counts()\n",
    "print(atc_counts.value_counts().head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0933b97a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NDCs without ATC4 Class in 2024 df: 1193\n",
      "['00069034405', '00069246510', '00264785000', '00469650189', '00527143501', '00536408501', '00574030216', '00574030316', '00591292754', '13811052501']\n",
      "Saved missing NDCs to C:\\Users\\asus\\OneDrive - purdue.edu\\VS code\\Data\\ATC\\text_files\\NDC_missing_2024.txt\n",
      "Unique ATC4 Classes in 2024 merged dataframe: 612\n"
     ]
    }
   ],
   "source": [
    "# Looking at the unique ndc codes that does not have an atc4 class\n",
    "missing_atc = merged_df[merged_df['ATC4 Class'].isna()]\n",
    "print(rf\"NDCs without ATC4 Class in {year} df: {missing_atc['NDC'].nunique()}\")\n",
    "print(missing_atc['NDC'].head(10).tolist())\n",
    "\n",
    "#Let's print those NDC codes to a text file to see if they have atc5 classes\n",
    "missing_ndc_file = rf\"C:\\Users\\asus\\OneDrive - purdue.edu\\VS code\\Data\\ATC\\text_files\\NDC_missing_{year}.txt\"\n",
    "with open(missing_ndc_file, 'w') as f:\n",
    "    for ndc in missing_atc['NDC'].unique():\n",
    "        f.write(str(ndc) + '\\n')\n",
    "print(f\"Saved missing NDCs to {missing_ndc_file}\")\n",
    "\n",
    "#Looking at the unique atc4 classes in the merged dataframe\n",
    "print(rf\"Unique ATC4 Classes in {year} merged dataframe: {merged_df['ATC4 Class'].nunique()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d6217936",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           NDC            ATC5 Class\n",
      "0  50419032513        No RxCUI Found\n",
      "1     26394825  No ATC Mapping Found\n",
      "2  65219028102        No RxCUI Found\n",
      "3    990799009        No RxCUI Found\n",
      "4  51645073099        No RxCUI Found\n",
      "Unique RxCUI in missing NDC mapping: 908\n",
      "Unique ATC5 Class in missing NDC mapping: 285\n"
     ]
    }
   ],
   "source": [
    "#Note that using the mapping atc5 for missing ndc is a little bit more detailed. Let's analyze it\n",
    "miss_path=rf'C:\\Users\\asus\\OneDrive - purdue.edu\\VS code\\Data\\ATC\\NDC_missing_{year}_ATC5_classes.csv'\n",
    "# C:\\Users\\lholguin\\OneDrive - purdue.edu\\VS code\\Data\\ATC\\NDC_missing_2024_ATC5_classes.csv\n",
    "df_miss=pd.read_csv(miss_path)\n",
    "print(df_miss.head())\n",
    "Rxcui_no = df_miss[df_miss['ATC5 Class'] == 'No RxCUI Found'].shape[0]\n",
    "ATClass_no = df_miss[df_miss['ATC5 Class'] == 'No ATC Mapping Found'].shape[0]\n",
    "print(f\"Unique RxCUI in missing NDC mapping: {Rxcui_no}\")\n",
    "print(f\"Unique ATC5 Class in missing NDC mapping: {ATClass_no}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eb34233",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      ATC4 Class ATC3 Class ATC2 Class\n",
      "0          N01BA       N01B        N01\n",
      "1          A01AC       A01A        A01\n",
      "2          A16AX       A16A        A16\n",
      "3          R06AX       R06A        R06\n",
      "4          S02BA       S02B        S02\n",
      "...          ...        ...        ...\n",
      "61465      M02AA       M02A        M02\n",
      "61466      D07XB       D07X        D07\n",
      "61467      H03AA       H03A        H03\n",
      "61468      C10AC       C10A        C10\n",
      "61469      A07AA       A07A        A07\n",
      "\n",
      "[61470 rows x 3 columns]\n",
      "Unique ATC4 Classes in 2024: 612\n",
      "Unique ATC3 Classes in 2024: 212\n",
      "Unique ATC2 Classes in 2024: 89\n",
      "               NDC ATC4 Class ATC3 Class ATC2 Class\n",
      "0      63323047637      N01BA       N01B        N01\n",
      "1      63323050601      A01AC       A01A        A01\n",
      "2      66658020490      A16AX       A16A        A16\n",
      "3      00904719260      R06AX       R06A        R06\n",
      "4      66993073080      S02BA       S02B        S02\n",
      "...            ...        ...        ...        ...\n",
      "61465  46122064654      M02AA       M02A        M02\n",
      "61466  70121165701      D07XB       D07X        D07\n",
      "61467  68180097103      H03AA       H03A        H03\n",
      "61468  27241013451      C10AC       C10A        C10\n",
      "61469  00121086816      A07AA       A07A        A07\n",
      "\n",
      "[61470 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "#Going from atc4 to atc2 and atc3 groups (filtering)\n",
    "df_atc4['ATC3 Class'] = df_atc4['ATC4 Class'].str[:4]\n",
    "df_atc4['ATC2 Class'] = df_atc4['ATC4 Class'].str[:3]\n",
    "print(df_atc4[['ATC4 Class', 'ATC3 Class', 'ATC2 Class']])\n",
    "\n",
    "#printing unique counts for each class\n",
    "print(rf\"Unique ATC4 Classes in {year}: {df_atc4['ATC4 Class'].nunique()}\")\n",
    "print(rf\"Unique ATC3 Classes in {year}: {df_atc4['ATC3 Class'].nunique()}\")\n",
    "print(rf\"Unique ATC2 Classes in {year}: {df_atc4['ATC2 Class'].nunique()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "894dd361",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cache: C:\\Users\\lholguin\\OneDrive - purdue.edu\\VS code\\Data\\ATC\\cache_files\\atc_names_cache\n",
      "Reading C:\\Users\\lholguin\\OneDrive - purdue.edu\\VS code\\Data\\ATC\\NDCf_2024_ATC4_classes.csv...\n",
      "Total rows: 61470\n",
      "Original columns: ['NDC', 'ATC4 Class']\n",
      "\n",
      "Creating ATC3 and ATC2 columns from ATC4...\n",
      "  ATC4 Class ATC3 Class ATC2 Class\n",
      "0      N01BA       N01B        N01\n",
      "1      A01AC       A01A        A01\n",
      "2      A16AX       A16A        A16\n",
      "3      R06AX       R06A        R06\n",
      "4      S02BA       S02B        S02\n",
      "5      B03BA       B03B        B03\n",
      "6      D11AX       D11A        D11\n",
      "7      C07AB       C07A        C07\n",
      "8      C01BB       C01B        C01\n",
      "9      B01AB       B01A        B01\n",
      "\n",
      "Unique codes to fetch:\n",
      "  ATC4: 612\n",
      "  ATC3: 212\n",
      "  ATC2: 89\n",
      "\n",
      "Unique ATC4 Classes: 612\n",
      "Unique ATC3 Classes: 212\n",
      "Unique ATC2 Classes: 89\n",
      "\n",
      "Fetching ATC4 names...\n",
      "Progress: 10/913 (1.1%) - Rate: 2.1 codes/sec - ETA: 7.2 min\n",
      "Progress: 20/913 (2.2%) - Rate: 2.1 codes/sec - ETA: 7.3 min\n",
      "Progress: 30/913 (3.3%) - Rate: 2.0 codes/sec - ETA: 7.2 min\n",
      "Progress: 40/913 (4.4%) - Rate: 2.0 codes/sec - ETA: 7.2 min\n",
      "Progress: 50/913 (5.5%) - Rate: 2.0 codes/sec - ETA: 7.2 min\n",
      "Progress: 60/913 (6.6%) - Rate: 2.0 codes/sec - ETA: 7.1 min\n",
      "Progress: 70/913 (7.7%) - Rate: 2.0 codes/sec - ETA: 7.0 min\n",
      "Progress: 80/913 (8.8%) - Rate: 2.0 codes/sec - ETA: 7.0 min\n",
      "Progress: 90/913 (9.9%) - Rate: 2.0 codes/sec - ETA: 6.9 min\n",
      "Progress: 100/913 (11.0%) - Rate: 2.0 codes/sec - ETA: 6.8 min\n",
      "Progress: 110/913 (12.0%) - Rate: 2.0 codes/sec - ETA: 6.7 min\n",
      "Progress: 120/913 (13.1%) - Rate: 2.0 codes/sec - ETA: 6.7 min\n",
      "Progress: 130/913 (14.2%) - Rate: 2.0 codes/sec - ETA: 6.6 min\n",
      "Progress: 140/913 (15.3%) - Rate: 2.0 codes/sec - ETA: 6.5 min\n",
      "Progress: 150/913 (16.4%) - Rate: 2.0 codes/sec - ETA: 6.4 min\n",
      "Progress: 160/913 (17.5%) - Rate: 2.0 codes/sec - ETA: 6.3 min\n",
      "Progress: 170/913 (18.6%) - Rate: 2.0 codes/sec - ETA: 6.3 min\n",
      "Progress: 180/913 (19.7%) - Rate: 2.0 codes/sec - ETA: 6.2 min\n",
      "Progress: 190/913 (20.8%) - Rate: 2.0 codes/sec - ETA: 6.1 min\n",
      "Progress: 200/913 (21.9%) - Rate: 2.0 codes/sec - ETA: 6.0 min\n",
      "Progress: 210/913 (23.0%) - Rate: 2.0 codes/sec - ETA: 5.9 min\n",
      "Progress: 220/913 (24.1%) - Rate: 2.0 codes/sec - ETA: 5.8 min\n",
      "Progress: 230/913 (25.2%) - Rate: 2.0 codes/sec - ETA: 5.7 min\n",
      "Progress: 240/913 (26.3%) - Rate: 2.0 codes/sec - ETA: 5.7 min\n",
      "Progress: 250/913 (27.4%) - Rate: 2.0 codes/sec - ETA: 5.6 min\n",
      "Progress: 260/913 (28.5%) - Rate: 2.0 codes/sec - ETA: 5.5 min\n",
      "Progress: 270/913 (29.6%) - Rate: 2.0 codes/sec - ETA: 5.4 min\n",
      "Progress: 280/913 (30.7%) - Rate: 2.0 codes/sec - ETA: 5.3 min\n",
      "Progress: 290/913 (31.8%) - Rate: 2.0 codes/sec - ETA: 5.2 min\n",
      "Progress: 300/913 (32.9%) - Rate: 2.0 codes/sec - ETA: 5.1 min\n",
      "Progress: 310/913 (34.0%) - Rate: 2.0 codes/sec - ETA: 5.1 min\n",
      "Progress: 320/913 (35.0%) - Rate: 2.0 codes/sec - ETA: 5.0 min\n",
      "Progress: 330/913 (36.1%) - Rate: 2.0 codes/sec - ETA: 4.9 min\n",
      "Progress: 340/913 (37.2%) - Rate: 2.0 codes/sec - ETA: 4.8 min\n",
      "Progress: 350/913 (38.3%) - Rate: 2.0 codes/sec - ETA: 4.7 min\n",
      "Progress: 360/913 (39.4%) - Rate: 2.0 codes/sec - ETA: 4.6 min\n",
      "Progress: 370/913 (40.5%) - Rate: 2.0 codes/sec - ETA: 4.6 min\n",
      "Progress: 380/913 (41.6%) - Rate: 2.0 codes/sec - ETA: 4.5 min\n",
      "Progress: 390/913 (42.7%) - Rate: 2.0 codes/sec - ETA: 4.4 min\n",
      "Progress: 400/913 (43.8%) - Rate: 2.0 codes/sec - ETA: 4.3 min\n",
      "Progress: 410/913 (44.9%) - Rate: 2.0 codes/sec - ETA: 4.2 min\n",
      "Progress: 420/913 (46.0%) - Rate: 2.0 codes/sec - ETA: 4.1 min\n",
      "Progress: 430/913 (47.1%) - Rate: 2.0 codes/sec - ETA: 4.1 min\n",
      "Progress: 440/913 (48.2%) - Rate: 2.0 codes/sec - ETA: 4.0 min\n",
      "Progress: 450/913 (49.3%) - Rate: 2.0 codes/sec - ETA: 3.9 min\n",
      "Progress: 460/913 (50.4%) - Rate: 2.0 codes/sec - ETA: 3.8 min\n",
      "Progress: 470/913 (51.5%) - Rate: 2.0 codes/sec - ETA: 3.7 min\n",
      "Progress: 480/913 (52.6%) - Rate: 2.0 codes/sec - ETA: 3.6 min\n",
      "Progress: 490/913 (53.7%) - Rate: 2.0 codes/sec - ETA: 3.5 min\n",
      "Progress: 500/913 (54.8%) - Rate: 2.0 codes/sec - ETA: 3.5 min\n",
      "Progress: 510/913 (55.9%) - Rate: 2.0 codes/sec - ETA: 3.4 min\n",
      "Progress: 520/913 (57.0%) - Rate: 2.0 codes/sec - ETA: 3.3 min\n",
      "Progress: 530/913 (58.1%) - Rate: 2.0 codes/sec - ETA: 3.2 min\n",
      "Progress: 540/913 (59.1%) - Rate: 2.0 codes/sec - ETA: 3.1 min\n",
      "Progress: 550/913 (60.2%) - Rate: 2.0 codes/sec - ETA: 3.0 min\n",
      "Progress: 560/913 (61.3%) - Rate: 2.0 codes/sec - ETA: 3.0 min\n",
      "Progress: 570/913 (62.4%) - Rate: 2.0 codes/sec - ETA: 2.9 min\n",
      "Progress: 580/913 (63.5%) - Rate: 2.0 codes/sec - ETA: 2.8 min\n",
      "Progress: 590/913 (64.6%) - Rate: 2.0 codes/sec - ETA: 2.7 min\n",
      "Progress: 600/913 (65.7%) - Rate: 2.0 codes/sec - ETA: 2.6 min\n",
      "Progress: 610/913 (66.8%) - Rate: 2.0 codes/sec - ETA: 2.5 min\n",
      "\n",
      "Fetching ATC3 names...\n",
      "Progress: 620/913 (67.9%) - Rate: 2.0 codes/sec - ETA: 2.5 min\n",
      "Progress: 630/913 (69.0%) - Rate: 2.0 codes/sec - ETA: 2.4 min\n",
      "Progress: 640/913 (70.1%) - Rate: 2.0 codes/sec - ETA: 2.3 min\n",
      "Progress: 650/913 (71.2%) - Rate: 2.0 codes/sec - ETA: 2.2 min\n",
      "Progress: 660/913 (72.3%) - Rate: 2.0 codes/sec - ETA: 2.1 min\n",
      "Progress: 670/913 (73.4%) - Rate: 2.0 codes/sec - ETA: 2.0 min\n",
      "Progress: 680/913 (74.5%) - Rate: 2.0 codes/sec - ETA: 2.0 min\n",
      "Progress: 690/913 (75.6%) - Rate: 2.0 codes/sec - ETA: 1.9 min\n",
      "Progress: 700/913 (76.7%) - Rate: 2.0 codes/sec - ETA: 1.8 min\n",
      "Progress: 710/913 (77.8%) - Rate: 2.0 codes/sec - ETA: 1.7 min\n",
      "Progress: 720/913 (78.9%) - Rate: 2.0 codes/sec - ETA: 1.6 min\n",
      "Progress: 730/913 (80.0%) - Rate: 2.0 codes/sec - ETA: 1.5 min\n",
      "Progress: 740/913 (81.1%) - Rate: 2.0 codes/sec - ETA: 1.5 min\n",
      "Progress: 750/913 (82.1%) - Rate: 2.0 codes/sec - ETA: 1.4 min\n",
      "Progress: 760/913 (83.2%) - Rate: 2.0 codes/sec - ETA: 1.3 min\n",
      "Progress: 770/913 (84.3%) - Rate: 2.0 codes/sec - ETA: 1.2 min\n",
      "Progress: 780/913 (85.4%) - Rate: 2.0 codes/sec - ETA: 1.1 min\n",
      "Progress: 790/913 (86.5%) - Rate: 2.0 codes/sec - ETA: 1.0 min\n",
      "Progress: 800/913 (87.6%) - Rate: 2.0 codes/sec - ETA: 0.9 min\n",
      "Progress: 810/913 (88.7%) - Rate: 2.0 codes/sec - ETA: 0.9 min\n",
      "Progress: 820/913 (89.8%) - Rate: 2.0 codes/sec - ETA: 0.8 min\n",
      "\n",
      "Fetching ATC2 names...\n",
      "Progress: 830/913 (90.9%) - Rate: 2.0 codes/sec - ETA: 0.7 min\n",
      "Progress: 840/913 (92.0%) - Rate: 2.0 codes/sec - ETA: 0.6 min\n",
      "Progress: 850/913 (93.1%) - Rate: 2.0 codes/sec - ETA: 0.5 min\n",
      "Progress: 860/913 (94.2%) - Rate: 2.0 codes/sec - ETA: 0.4 min\n",
      "Progress: 870/913 (95.3%) - Rate: 2.0 codes/sec - ETA: 0.4 min\n",
      "Progress: 880/913 (96.4%) - Rate: 2.0 codes/sec - ETA: 0.3 min\n",
      "Progress: 890/913 (97.5%) - Rate: 2.0 codes/sec - ETA: 0.2 min\n",
      "Progress: 900/913 (98.6%) - Rate: 2.0 codes/sec - ETA: 0.1 min\n",
      "Progress: 910/913 (99.7%) - Rate: 2.0 codes/sec - ETA: 0.0 min\n",
      "\n",
      "Total processing time: 7.6 minutes\n",
      "\n",
      "Applying names to dataframe...\n",
      "\n",
      "Saving to C:\\Users\\lholguin\\OneDrive - purdue.edu\\VS code\\Data\\ATC\\NDCf_2024_ATC4_classes_with_names.csv...\n",
      "\n",
      "Complete! Output saved to: C:\\Users\\lholguin\\OneDrive - purdue.edu\\VS code\\Data\\ATC\\NDCf_2024_ATC4_classes_with_names.csv\n",
      "Total rows: 61470\n",
      "\n",
      "Sample output:\n",
      "  ATC4 Class                                         ATC4_Name ATC3 Class  \\\n",
      "0      N01BA                       Esters of aminobenzoic acid       N01B   \n",
      "1      A01AC          Corticosteroids for local oral treatment       A01A   \n",
      "2      A16AX  Various alimentary tract and metabolism products       A16A   \n",
      "3      R06AX             Other antihistamines for systemic use       R06A   \n",
      "4      S02BA                                   Corticosteroids       S02B   \n",
      "5      B03BA        Vitamin B12 (cyanocobalamin and analogues)       B03B   \n",
      "6      D11AX                             Other dermatologicals       D11A   \n",
      "7      C07AB                   Beta blocking agents, selective       C07A   \n",
      "8      C01BB                         Antiarrhythmics, class Ib       C01B   \n",
      "9      B01AB                                     Heparin group       B01A   \n",
      "\n",
      "                                        ATC3_Name ATC2 Class  \\\n",
      "0                              ANESTHETICS, LOCAL        N01   \n",
      "1                     STOMATOLOGICAL PREPARATIONS        A01   \n",
      "2  OTHER ALIMENTARY TRACT AND METABOLISM PRODUCTS        A16   \n",
      "3                 ANTIHISTAMINES FOR SYSTEMIC USE        R06   \n",
      "4                                 CORTICOSTEROIDS        S02   \n",
      "5                      VITAMIN B12 AND FOLIC ACID        B03   \n",
      "6               OTHER DERMATOLOGICAL PREPARATIONS        D11   \n",
      "7                            BETA BLOCKING AGENTS        C07   \n",
      "8                ANTIARRHYTHMICS, CLASS I AND III        C01   \n",
      "9                           ANTITHROMBOTIC AGENTS        B01   \n",
      "\n",
      "                                        ATC2_Name  \n",
      "0                                     ANESTHETICS  \n",
      "1                     STOMATOLOGICAL PREPARATIONS  \n",
      "2  OTHER ALIMENTARY TRACT AND METABOLISM PRODUCTS  \n",
      "3                 ANTIHISTAMINES FOR SYSTEMIC USE  \n",
      "4                                     OTOLOGICALS  \n",
      "5                         ANTIANEMIC PREPARATIONS  \n",
      "6               OTHER DERMATOLOGICAL PREPARATIONS  \n",
      "7                            BETA BLOCKING AGENTS  \n",
      "8                                 CARDIAC THERAPY  \n",
      "9                           ANTITHROMBOTIC AGENTS  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import shelve\n",
    "from datetime import datetime\n",
    "import os\n",
    "\n",
    "def get_atc_name(atc_code, cache):\n",
    "    \"\"\"Get ATC class name from code, using cache.\"\"\"\n",
    "    cache_key = f\"atc_name:{atc_code}\"\n",
    "    if cache_key in cache:\n",
    "        return cache[cache_key]\n",
    "    \n",
    "    try:\n",
    "        url = f\"https://rxnav.nlm.nih.gov/REST/rxclass/class/byId.json?classId={atc_code}\"\n",
    "        response = requests.get(url)\n",
    "        response.raise_for_status()\n",
    "        data = response.json()\n",
    "        \n",
    "        # Get class name\n",
    "        if 'rxclassMinConceptList' in data and 'rxclassMinConcept' in data['rxclassMinConceptList']:\n",
    "            concepts = data['rxclassMinConceptList']['rxclassMinConcept']\n",
    "            if concepts:\n",
    "                name = concepts[0].get('className', '')\n",
    "                cache[cache_key] = name\n",
    "                return name\n",
    "        \n",
    "        cache[cache_key] = ''\n",
    "        return ''\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error retrieving name for {atc_code}: {e}\")\n",
    "        cache[cache_key] = ''\n",
    "        return ''\n",
    "\n",
    "def add_all_atc_names(input_file, output_file=None, cache_path=None):\n",
    "    \"\"\"Add ATC class names for all levels (ATC2, ATC3, ATC4).\"\"\"\n",
    "    \n",
    "    # Set up cache path\n",
    "    if cache_path is None:\n",
    "        cache_dir = os.path.join(os.path.dirname(input_file), 'cache_files')\n",
    "        os.makedirs(cache_dir, exist_ok=True)\n",
    "        cache_path = os.path.join(cache_dir, 'atc_names_cache')\n",
    "    \n",
    "    print(f\"Using cache: {cache_path}\")\n",
    "    \n",
    "    # Read CSV\n",
    "    print(f\"Reading {input_file}...\")\n",
    "    df = pd.read_csv(input_file, dtype={'NDC': 'object'})\n",
    "    \n",
    "    print(f\"Total rows: {len(df)}\")\n",
    "    print(f\"Original columns: {df.columns.tolist()}\")\n",
    "    \n",
    "    # Create ATC3 and ATC2 columns from ATC4\n",
    "    print(\"\\nCreating ATC3 and ATC2 columns from ATC4...\")\n",
    "    df['ATC3 Class'] = df['ATC4 Class'].str[:4]\n",
    "    df['ATC2 Class'] = df['ATC4 Class'].str[:3]\n",
    "    \n",
    "    print(df[['ATC4 Class', 'ATC3 Class', 'ATC2 Class']].head(10))\n",
    "    \n",
    "    # Add name columns\n",
    "    df['ATC4_Name'] = ''\n",
    "    df['ATC3_Name'] = ''\n",
    "    df['ATC2_Name'] = ''\n",
    "    \n",
    "    # Get unique codes for each level\n",
    "    unique_atc4 = df['ATC4 Class'].dropna().unique()\n",
    "    unique_atc3 = df['ATC3 Class'].dropna().unique()\n",
    "    unique_atc2 = df['ATC2 Class'].dropna().unique()\n",
    "    \n",
    "    # Filter out invalid codes\n",
    "    unique_atc4 = [c for c in unique_atc4 if c not in ['No ATC Mapping Found', 'No RxCUI Found', '']]\n",
    "    unique_atc3 = [c for c in unique_atc3 if c not in ['No ATC Mapping Found', 'No RxCUI Found', '', 'No ', 'No']]\n",
    "    unique_atc2 = [c for c in unique_atc2 if c not in ['No ATC Mapping Found', 'No RxCUI Found', '', 'No ', 'No']]\n",
    "    \n",
    "    print(f\"\\nUnique codes to fetch:\")\n",
    "    print(f\"  ATC4: {len(unique_atc4)}\")\n",
    "    print(f\"  ATC3: {len(unique_atc3)}\")\n",
    "    print(f\"  ATC2: {len(unique_atc2)}\")\n",
    "    \n",
    "    # Print unique counts\n",
    "    print(f\"\\nUnique ATC4 Classes: {len(unique_atc4)}\")\n",
    "    print(f\"Unique ATC3 Classes: {len(unique_atc3)}\")\n",
    "    print(f\"Unique ATC2 Classes: {len(unique_atc2)}\")\n",
    "    \n",
    "    total_codes = len(unique_atc4) + len(unique_atc3) + len(unique_atc2)\n",
    "    \n",
    "    # Build mappings\n",
    "    atc4_names = {}\n",
    "    atc3_names = {}\n",
    "    atc2_names = {}\n",
    "    \n",
    "    with shelve.open(cache_path) as cache:\n",
    "        start_time = datetime.now()\n",
    "        processed = 0\n",
    "        \n",
    "        # Process ATC4\n",
    "        print(\"\\nFetching ATC4 names...\")\n",
    "        for code in unique_atc4:\n",
    "            processed += 1\n",
    "            if processed % 10 == 0:\n",
    "                elapsed = (datetime.now() - start_time).total_seconds()\n",
    "                rate = processed / elapsed if elapsed > 0 else 0\n",
    "                remaining = (total_codes - processed) / rate if rate > 0 else 0\n",
    "                print(f\"Progress: {processed}/{total_codes} ({processed/total_codes*100:.1f}%) - \"\n",
    "                      f\"Rate: {rate:.1f} codes/sec - ETA: {remaining/60:.1f} min\")\n",
    "                cache.sync()\n",
    "            \n",
    "            atc4_names[code] = get_atc_name(code, cache)\n",
    "        \n",
    "        # Process ATC3\n",
    "        print(\"\\nFetching ATC3 names...\")\n",
    "        for code in unique_atc3:\n",
    "            processed += 1\n",
    "            if processed % 10 == 0:\n",
    "                elapsed = (datetime.now() - start_time).total_seconds()\n",
    "                rate = processed / elapsed if elapsed > 0 else 0\n",
    "                remaining = (total_codes - processed) / rate if rate > 0 else 0\n",
    "                print(f\"Progress: {processed}/{total_codes} ({processed/total_codes*100:.1f}%) - \"\n",
    "                      f\"Rate: {rate:.1f} codes/sec - ETA: {remaining/60:.1f} min\")\n",
    "                cache.sync()\n",
    "            \n",
    "            atc3_names[code] = get_atc_name(code, cache)\n",
    "        \n",
    "        # Process ATC2\n",
    "        print(\"\\nFetching ATC2 names...\")\n",
    "        for code in unique_atc2:\n",
    "            processed += 1\n",
    "            if processed % 10 == 0:\n",
    "                elapsed = (datetime.now() - start_time).total_seconds()\n",
    "                rate = processed / elapsed if elapsed > 0 else 0\n",
    "                remaining = (total_codes - processed) / rate if rate > 0 else 0\n",
    "                print(f\"Progress: {processed}/{total_codes} ({processed/total_codes*100:.1f}%) - \"\n",
    "                      f\"Rate: {rate:.1f} codes/sec - ETA: {remaining/60:.1f} min\")\n",
    "                cache.sync()\n",
    "            \n",
    "            atc2_names[code] = get_atc_name(code, cache)\n",
    "        \n",
    "        print(f\"\\nTotal processing time: {(datetime.now() - start_time).total_seconds()/60:.1f} minutes\")\n",
    "    \n",
    "    # Apply mappings to dataframe\n",
    "    print(\"\\nApplying names to dataframe...\")\n",
    "    df['ATC4_Name'] = df['ATC4 Class'].map(atc4_names).fillna('')\n",
    "    df['ATC3_Name'] = df['ATC3 Class'].map(atc3_names).fillna('')\n",
    "    df['ATC2_Name'] = df['ATC2 Class'].map(atc2_names).fillna('')\n",
    "    \n",
    "    # Reorder columns to group code and name together\n",
    "    column_order = ['NDC', \n",
    "                    'ATC4 Class', 'ATC4_Name',\n",
    "                    'ATC3 Class', 'ATC3_Name',\n",
    "                    'ATC2 Class', 'ATC2_Name']\n",
    "    df = df[column_order]\n",
    "    \n",
    "    # Save output\n",
    "    if output_file is None:\n",
    "        output_file = input_file.replace('.csv', '_with_names.csv')\n",
    "    \n",
    "    print(f\"\\nSaving to {output_file}...\")\n",
    "    df.to_csv(output_file, index=False)\n",
    "    \n",
    "    print(f\"\\nComplete! Output saved to: {output_file}\")\n",
    "    print(f\"Total rows: {len(df)}\")\n",
    "    print(\"\\nSample output:\")\n",
    "    print(df[['ATC4 Class', 'ATC4_Name', 'ATC3 Class', 'ATC3_Name', 'ATC2 Class', 'ATC2_Name']].head(10))\n",
    "    \n",
    "    return df\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Configure paths\n",
    "    year = 2024\n",
    "    cache_path = r\"C:\\Users\\lholguin\\OneDrive - purdue.edu\\VS code\\Data\\ATC\\cache_files\\atc_names_cache\"\n",
    "    input_file = rf\"C:\\Users\\lholguin\\OneDrive - purdue.edu\\VS code\\Data\\ATC\\NDCf_{year}_ATC4_classes.csv\"\n",
    "    output_file = rf\"C:\\Users\\lholguin\\OneDrive - purdue.edu\\VS code\\Data\\ATC\\NDCf_{year}_ATC4_classes_with_names.csv\"\n",
    "    \n",
    "    df = add_all_atc_names(input_file, output_file, cache_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
