{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Statistical Models vs Machine Learning Models Comparison\n",
    "## Comprehensive MAE-based Performance Analysis\n",
    "\n",
    "This notebook compares the performance of statistical forecasting models (StatsForecast) against machine learning models (MLForecast) using Mean Absolute Error (MAE) as the primary metric.\n",
    "\n",
    "### Gray Zone Threshold:\n",
    "- **5% threshold**: If the MAE difference between approaches is less than 5%, the difference is considered **not significant**\n",
    "- This creates three categories: ML wins, Stats wins, and No Significant Difference\n",
    "\n",
    "### Analysis Components:\n",
    "1. **Data Loading and Merging**: Combine ML and Stats results by unique_id\n",
    "2. **Best Model Frequency Analysis**: Which models are selected most often\n",
    "3. **Comparison Levels**: Individual, State, Metric, and Overall comparisons\n",
    "4. **Visualizations**: Comprehensive dashboards for each analysis level\n",
    "5. **Export Results**: Excel files with detailed analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Libraries imported successfully\n"
     ]
    }
   ],
   "source": [
    "# Import required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "import seaborn as sns\n",
    "from matplotlib.gridspec import GridSpec\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"✓ Libraries imported successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Configuration complete\n",
      "  Gray zone threshold: 5.0%\n",
      "  States: MI, IN, IL, OH\n",
      "  Metrics: Units Reimbursed (UR), Number of Prescriptions (NoP)\n"
     ]
    }
   ],
   "source": [
    "# Configuration and Style\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "plt.rcParams.update({\n",
    "    'font.family': 'sans-serif',\n",
    "    'font.sans-serif': ['Arial', 'DejaVu Sans'],\n",
    "    'font.size': 11,\n",
    "    'axes.titlesize': 13,\n",
    "    'axes.titleweight': 'bold',\n",
    "    'axes.labelsize': 11,\n",
    "    'xtick.labelsize': 10,\n",
    "    'ytick.labelsize': 10,\n",
    "    'legend.fontsize': 10,\n",
    "    'figure.titlesize': 16,\n",
    "    'figure.titleweight': 'bold',\n",
    "    'axes.spines.top': False,\n",
    "    'axes.spines.right': False,\n",
    "})\n",
    "\n",
    "# Display options\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 100)\n",
    "pd.set_option('display.float_format', '{:.2f}'.format)\n",
    "\n",
    "# Gray zone threshold\n",
    "GRAY_ZONE_THRESHOLD = 5.0  # If MAE difference is less than 5%, it's not significant\n",
    "\n",
    "# Color schemes\n",
    "ML_COLOR = '#1f77b4'      # Blue for ML\n",
    "STATS_COLOR = '#ff7f0e'   # Orange for Stats\n",
    "GRAY_COLOR = '#CCCCCC'    # Gray for no significant difference\n",
    "\n",
    "# States and metrics\n",
    "STATES = ['MI', 'IN', 'IL', 'OH']\n",
    "METRICS = ['UR', 'NoP']  # Units Reimbursed, Number of Prescriptions\n",
    "\n",
    "print(f\"✓ Configuration complete\")\n",
    "print(f\"  Gray zone threshold: {GRAY_ZONE_THRESHOLD}%\")\n",
    "print(f\"  States: {', '.join(STATES)}\")\n",
    "print(f\"  Metrics: Units Reimbursed (UR), Number of Prescriptions (NoP)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load and Merge Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ ML file sheets: ['MI_ml_UR', 'MI_ml_NoP', 'IN_ml_UR', 'IN_ml_NoP', 'IL_ml_UR', 'IL_ml_NoP', 'OH_ml_UR', 'OH_ml_NoP']\n",
      "✓ Stats file sheets: ['IN_stats_UR', 'IN_stats_NoP', 'IL_stats_UR', 'IL_stats_NoP', 'MI_stats_NoP', 'MI_stats_UR', 'OH_stats_UR', 'OH_stats_NoP']\n"
     ]
    }
   ],
   "source": [
    "# Load ML and Stats models results\n",
    "user=\"Lilian\"\n",
    "\n",
    "path_ml=rf\"C:\\Users\\{user}\\OneDrive - purdue.edu\\VS code\\Data\\ATC\\Comparison\\ML_general.xlsx\"\n",
    "path_stats=rf\"C:\\Users\\{user}\\OneDrive - purdue.edu\\VS code\\Data\\ATC\\Comparison\\Stats_General.xlsx\"\n",
    "\n",
    "ml_file = pd.ExcelFile(path_ml)\n",
    "stats_file = pd.ExcelFile(path_stats)\n",
    "\n",
    "print(f\"✓ ML file sheets: {ml_file.sheet_names}\")\n",
    "print(f\"✓ Stats file sheets: {stats_file.sheet_names}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Loaded 8 ML sheets\n",
      "✓ Loaded 8 Stats sheets\n"
     ]
    }
   ],
   "source": [
    "# Load all sheets into dictionaries\n",
    "ml_data = {}\n",
    "stats_data = {}\n",
    "\n",
    "for state in STATES:\n",
    "    for metric in METRICS:\n",
    "        ml_sheet = f\"{state}_ml_{metric}\"\n",
    "        stats_sheet = f\"{state}_stats_{metric}\"\n",
    "        \n",
    "        ml_data[ml_sheet] = pd.read_excel(ml_file, sheet_name=ml_sheet)\n",
    "        stats_data[stats_sheet] = pd.read_excel(stats_file, sheet_name=stats_sheet)\n",
    "\n",
    "print(f\"✓ Loaded {len(ml_data)} ML sheets\")\n",
    "print(f\"✓ Loaded {len(stats_data)} Stats sheets\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Helper functions defined\n"
     ]
    }
   ],
   "source": [
    "# Function to determine winner with gray zone threshold\n",
    "def determine_winner(row, threshold=GRAY_ZONE_THRESHOLD):\n",
    "    \"\"\"\n",
    "    Determine the winner based on MAE difference with gray zone threshold.\n",
    "    If the percentage difference is less than threshold, it's not significant.\n",
    "    \"\"\"\n",
    "    pct_diff = abs(row['pct_improvement'])\n",
    "    if pct_diff < threshold:\n",
    "        return 'No Significant Difference'\n",
    "    elif row['ml_avg_mae'] < row['stats_avg_mae']:\n",
    "        return 'ML'\n",
    "    else:\n",
    "        return 'Stats'\n",
    "\n",
    "print(\"✓ Helper functions defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merging data by unique_id...\n",
      "✓ Merged 8 datasets\n",
      "✓ Total comparisons: 634\n",
      "✓ Gray zone threshold: 5.0%\n",
      "\n",
      "Sample merged data:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unique_id</th>\n",
       "      <th>ml_best_model</th>\n",
       "      <th>ml_avg_mae</th>\n",
       "      <th>stats_best_model</th>\n",
       "      <th>stats_avg_mae</th>\n",
       "      <th>state</th>\n",
       "      <th>metric</th>\n",
       "      <th>mae_diff</th>\n",
       "      <th>pct_improvement</th>\n",
       "      <th>winner</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MI_A01</td>\n",
       "      <td>RandomForest</td>\n",
       "      <td>1876084.10</td>\n",
       "      <td>WindowAverage</td>\n",
       "      <td>1479399.07</td>\n",
       "      <td>MI</td>\n",
       "      <td>UR</td>\n",
       "      <td>-396685.04</td>\n",
       "      <td>-26.81</td>\n",
       "      <td>Stats</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MI_A02</td>\n",
       "      <td>XGBoost</td>\n",
       "      <td>1301668.45</td>\n",
       "      <td>Naive</td>\n",
       "      <td>1945343.32</td>\n",
       "      <td>MI</td>\n",
       "      <td>UR</td>\n",
       "      <td>643674.87</td>\n",
       "      <td>33.09</td>\n",
       "      <td>ML</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MI_A03</td>\n",
       "      <td>XGBoost</td>\n",
       "      <td>441752.14</td>\n",
       "      <td>SARIMAX</td>\n",
       "      <td>176297.92</td>\n",
       "      <td>MI</td>\n",
       "      <td>UR</td>\n",
       "      <td>-265454.22</td>\n",
       "      <td>-150.57</td>\n",
       "      <td>Stats</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MI_A04</td>\n",
       "      <td>LightGBM</td>\n",
       "      <td>314088.13</td>\n",
       "      <td>HistoricAverage</td>\n",
       "      <td>199760.56</td>\n",
       "      <td>MI</td>\n",
       "      <td>UR</td>\n",
       "      <td>-114327.57</td>\n",
       "      <td>-57.23</td>\n",
       "      <td>Stats</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MI_A05</td>\n",
       "      <td>XGBoost</td>\n",
       "      <td>13822.52</td>\n",
       "      <td>SARIMAX</td>\n",
       "      <td>16040.63</td>\n",
       "      <td>MI</td>\n",
       "      <td>UR</td>\n",
       "      <td>2218.11</td>\n",
       "      <td>13.83</td>\n",
       "      <td>ML</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>MI_A06</td>\n",
       "      <td>RandomForest</td>\n",
       "      <td>6268475.66</td>\n",
       "      <td>WindowAverage</td>\n",
       "      <td>4801812.01</td>\n",
       "      <td>MI</td>\n",
       "      <td>UR</td>\n",
       "      <td>-1466663.66</td>\n",
       "      <td>-30.54</td>\n",
       "      <td>Stats</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>MI_A07</td>\n",
       "      <td>XGBoost</td>\n",
       "      <td>566551.76</td>\n",
       "      <td>ARIMAX</td>\n",
       "      <td>509905.12</td>\n",
       "      <td>MI</td>\n",
       "      <td>UR</td>\n",
       "      <td>-56646.64</td>\n",
       "      <td>-11.11</td>\n",
       "      <td>Stats</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>MI_A09</td>\n",
       "      <td>XGBoost</td>\n",
       "      <td>82450.83</td>\n",
       "      <td>HistoricAverage</td>\n",
       "      <td>64937.39</td>\n",
       "      <td>MI</td>\n",
       "      <td>UR</td>\n",
       "      <td>-17513.44</td>\n",
       "      <td>-26.97</td>\n",
       "      <td>Stats</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>MI_A10</td>\n",
       "      <td>XGBoost</td>\n",
       "      <td>3164579.72</td>\n",
       "      <td>SARIMAX</td>\n",
       "      <td>822034.95</td>\n",
       "      <td>MI</td>\n",
       "      <td>UR</td>\n",
       "      <td>-2342544.77</td>\n",
       "      <td>-284.97</td>\n",
       "      <td>Stats</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>MI_A11</td>\n",
       "      <td>LightGBM</td>\n",
       "      <td>64255.33</td>\n",
       "      <td>WindowAverage</td>\n",
       "      <td>113493.95</td>\n",
       "      <td>MI</td>\n",
       "      <td>UR</td>\n",
       "      <td>49238.62</td>\n",
       "      <td>43.38</td>\n",
       "      <td>ML</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  unique_id ml_best_model  ml_avg_mae stats_best_model  stats_avg_mae state  \\\n",
       "0    MI_A01  RandomForest  1876084.10    WindowAverage     1479399.07    MI   \n",
       "1    MI_A02       XGBoost  1301668.45            Naive     1945343.32    MI   \n",
       "2    MI_A03       XGBoost   441752.14          SARIMAX      176297.92    MI   \n",
       "3    MI_A04      LightGBM   314088.13  HistoricAverage      199760.56    MI   \n",
       "4    MI_A05       XGBoost    13822.52          SARIMAX       16040.63    MI   \n",
       "5    MI_A06  RandomForest  6268475.66    WindowAverage     4801812.01    MI   \n",
       "6    MI_A07       XGBoost   566551.76           ARIMAX      509905.12    MI   \n",
       "7    MI_A09       XGBoost    82450.83  HistoricAverage       64937.39    MI   \n",
       "8    MI_A10       XGBoost  3164579.72          SARIMAX      822034.95    MI   \n",
       "9    MI_A11      LightGBM    64255.33    WindowAverage      113493.95    MI   \n",
       "\n",
       "  metric    mae_diff  pct_improvement winner  \n",
       "0     UR  -396685.04           -26.81  Stats  \n",
       "1     UR   643674.87            33.09     ML  \n",
       "2     UR  -265454.22          -150.57  Stats  \n",
       "3     UR  -114327.57           -57.23  Stats  \n",
       "4     UR     2218.11            13.83     ML  \n",
       "5     UR -1466663.66           -30.54  Stats  \n",
       "6     UR   -56646.64           -11.11  Stats  \n",
       "7     UR   -17513.44           -26.97  Stats  \n",
       "8     UR -2342544.77          -284.97  Stats  \n",
       "9     UR    49238.62            43.38     ML  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Merge ML and Stats data for each state-metric combination\n",
    "print(\"Merging data by unique_id...\")\n",
    "merged_data = {}\n",
    "\n",
    "for state in STATES:\n",
    "    for metric in METRICS:\n",
    "        sheet_name = f\"{state}_ml_{metric}\"\n",
    "        stats_sheet = f\"{state}_stats_{metric}\"\n",
    "        \n",
    "        # Get ML and Stats dataframes\n",
    "        ml_df = ml_data[sheet_name][['unique_id', 'best_model', 'avg_mae']].copy()\n",
    "        stats_df = stats_data[stats_sheet][['unique_id', 'best_model', 'avg_mae']].copy()\n",
    "        \n",
    "        # Rename columns to distinguish between ML and Stats\n",
    "        ml_df.columns = ['unique_id', 'ml_best_model', 'ml_avg_mae']\n",
    "        stats_df.columns = ['unique_id', 'stats_best_model', 'stats_avg_mae']\n",
    "        \n",
    "        # Merge on unique_id\n",
    "        merged = pd.merge(ml_df, stats_df, on='unique_id', how='inner')\n",
    "        \n",
    "        # Add state and metric columns\n",
    "        merged['state'] = state\n",
    "        merged['metric'] = metric\n",
    "        \n",
    "        # Calculate MAE difference (positive = Stats is worse, negative = ML is worse)\n",
    "        merged['mae_diff'] = merged['stats_avg_mae'] - merged['ml_avg_mae']\n",
    "        \n",
    "        # Calculate percentage improvement\n",
    "        merged['pct_improvement'] = ((merged['stats_avg_mae'] - merged['ml_avg_mae']) / \n",
    "                                     merged['stats_avg_mae'] * 100)\n",
    "        \n",
    "        # Determine winner with gray zone threshold\n",
    "        merged['winner'] = merged.apply(determine_winner, axis=1)\n",
    "        \n",
    "        merged_data[sheet_name] = merged\n",
    "\n",
    "# Combine all merged data\n",
    "all_comparisons = pd.concat(merged_data.values(), ignore_index=True)\n",
    "\n",
    "print(f\"✓ Merged {len(merged_data)} datasets\")\n",
    "print(f\"✓ Total comparisons: {len(all_comparisons)}\")\n",
    "print(f\"✓ Gray zone threshold: {GRAY_ZONE_THRESHOLD}%\")\n",
    "print(f\"\\nSample merged data:\")\n",
    "display(all_comparisons.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Best Model Frequency Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "BEST MODEL FREQUENCY ANALYSIS\n",
      "================================================================================\n",
      "\n",
      "Total comparisons: 634\n",
      "Gray zone threshold: 5.0%\n"
     ]
    }
   ],
   "source": [
    "# Overall model frequency\n",
    "print(\"=\"*80)\n",
    "print(\"BEST MODEL FREQUENCY ANALYSIS\")\n",
    "print(\"=\"*80)\n",
    "print(f\"\\nTotal comparisons: {len(all_comparisons)}\")\n",
    "print(f\"Gray zone threshold: {GRAY_ZONE_THRESHOLD}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "ML MODELS - SELECTION FREQUENCY\n",
      "================================================================================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Frequency</th>\n",
       "      <th>Percentage</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ml_best_model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LightGBM</th>\n",
       "      <td>255</td>\n",
       "      <td>40.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBoost</th>\n",
       "      <td>206</td>\n",
       "      <td>32.49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomForest</th>\n",
       "      <td>143</td>\n",
       "      <td>22.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ridge</th>\n",
       "      <td>30</td>\n",
       "      <td>4.73</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Frequency  Percentage\n",
       "ml_best_model                       \n",
       "LightGBM             255       40.22\n",
       "XGBoost              206       32.49\n",
       "RandomForest         143       22.56\n",
       "Ridge                 30        4.73"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total unique ML models: 4\n"
     ]
    }
   ],
   "source": [
    "# ML Models Frequency\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"ML MODELS - SELECTION FREQUENCY\")\n",
    "print(\"=\"*80)\n",
    "ml_model_freq = all_comparisons['ml_best_model'].value_counts()\n",
    "ml_model_pct = (ml_model_freq / len(all_comparisons) * 100).round(2)\n",
    "\n",
    "ml_freq_df = pd.DataFrame({\n",
    "    'Frequency': ml_model_freq,\n",
    "    'Percentage': ml_model_pct\n",
    "})\n",
    "display(ml_freq_df)\n",
    "print(f\"\\nTotal unique ML models: {len(ml_model_freq)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "STATISTICAL MODELS - SELECTION FREQUENCY\n",
      "================================================================================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Frequency</th>\n",
       "      <th>Percentage</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stats_best_model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>HistoricAverage</th>\n",
       "      <td>225</td>\n",
       "      <td>35.49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SARIMAX</th>\n",
       "      <td>157</td>\n",
       "      <td>24.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Naive</th>\n",
       "      <td>117</td>\n",
       "      <td>18.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WindowAverage</th>\n",
       "      <td>89</td>\n",
       "      <td>14.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ARIMAX</th>\n",
       "      <td>24</td>\n",
       "      <td>3.79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SeasonalNaive</th>\n",
       "      <td>22</td>\n",
       "      <td>3.47</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Frequency  Percentage\n",
       "stats_best_model                       \n",
       "HistoricAverage         225       35.49\n",
       "SARIMAX                 157       24.76\n",
       "Naive                   117       18.45\n",
       "WindowAverage            89       14.04\n",
       "ARIMAX                   24        3.79\n",
       "SeasonalNaive            22        3.47"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total unique Stats models: 6\n"
     ]
    }
   ],
   "source": [
    "# Stats Models Frequency\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"STATISTICAL MODELS - SELECTION FREQUENCY\")\n",
    "print(\"=\"*80)\n",
    "stats_model_freq = all_comparisons['stats_best_model'].value_counts()\n",
    "stats_model_pct = (stats_model_freq / len(all_comparisons) * 100).round(2)\n",
    "\n",
    "stats_freq_df = pd.DataFrame({\n",
    "    'Frequency': stats_model_freq,\n",
    "    'Percentage': stats_model_pct\n",
    "})\n",
    "display(stats_freq_df)\n",
    "print(f\"\\nTotal unique Stats models: {len(stats_model_freq)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "BEST MODEL FREQUENCY BY STATE\n",
      "================================================================================\n",
      "\n",
      "MI:\n",
      "  ML Models:\n",
      "    XGBoost: 62 (39.7%)\n",
      "    LightGBM: 52 (33.3%)\n",
      "    RandomForest: 36 (23.1%)\n",
      "  Stats Models:\n",
      "    HistoricAverage: 51 (32.7%)\n",
      "    Naive: 38 (24.4%)\n",
      "    SARIMAX: 32 (20.5%)\n",
      "\n",
      "IN:\n",
      "  ML Models:\n",
      "    LightGBM: 84 (52.5%)\n",
      "    XGBoost: 41 (25.6%)\n",
      "    RandomForest: 28 (17.5%)\n",
      "  Stats Models:\n",
      "    SARIMAX: 63 (39.4%)\n",
      "    HistoricAverage: 45 (28.1%)\n",
      "    Naive: 22 (13.8%)\n",
      "\n",
      "IL:\n",
      "  ML Models:\n",
      "    LightGBM: 53 (34.0%)\n",
      "    XGBoost: 51 (32.7%)\n",
      "    RandomForest: 43 (27.6%)\n",
      "  Stats Models:\n",
      "    HistoricAverage: 61 (39.1%)\n",
      "    SARIMAX: 38 (24.4%)\n",
      "    WindowAverage: 22 (14.1%)\n",
      "\n",
      "OH:\n",
      "  ML Models:\n",
      "    LightGBM: 66 (40.7%)\n",
      "    XGBoost: 52 (32.1%)\n",
      "    RandomForest: 36 (22.2%)\n",
      "  Stats Models:\n",
      "    HistoricAverage: 68 (42.0%)\n",
      "    Naive: 39 (24.1%)\n",
      "    SARIMAX: 24 (14.8%)\n"
     ]
    }
   ],
   "source": [
    "# Model frequency by state and metric\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"BEST MODEL FREQUENCY BY STATE\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "for state in STATES:\n",
    "    print(f\"\\n{state}:\")\n",
    "    state_data = all_comparisons[all_comparisons['state'] == state]\n",
    "    \n",
    "    print(\"  ML Models:\")\n",
    "    ml_state_freq = state_data['ml_best_model'].value_counts()\n",
    "    for model, count in ml_state_freq.head(3).items():\n",
    "        pct = count / len(state_data) * 100\n",
    "        print(f\"    {model}: {count} ({pct:.1f}%)\")\n",
    "    \n",
    "    print(\"  Stats Models:\")\n",
    "    stats_state_freq = state_data['stats_best_model'].value_counts()\n",
    "    for model, count in stats_state_freq.head(3).items():\n",
    "        pct = count / len(state_data) * 100\n",
    "        print(f\"    {model}: {count} ({pct:.1f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "BEST MODEL FREQUENCY BY METRIC\n",
      "================================================================================\n",
      "\n",
      "Units Reimbursed:\n",
      "  ML Models:\n",
      "    LightGBM: 122 (38.5%)\n",
      "    XGBoost: 103 (32.5%)\n",
      "    RandomForest: 75 (23.7%)\n",
      "  Stats Models:\n",
      "    HistoricAverage: 114 (36.0%)\n",
      "    SARIMAX: 80 (25.2%)\n",
      "    Naive: 56 (17.7%)\n",
      "\n",
      "Number of Prescriptions:\n",
      "  ML Models:\n",
      "    LightGBM: 133 (42.0%)\n",
      "    XGBoost: 103 (32.5%)\n",
      "    RandomForest: 68 (21.5%)\n",
      "  Stats Models:\n",
      "    HistoricAverage: 111 (35.0%)\n",
      "    SARIMAX: 77 (24.3%)\n",
      "    Naive: 61 (19.2%)\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"BEST MODEL FREQUENCY BY METRIC\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "for metric in METRICS:\n",
    "    metric_name = 'Units Reimbursed' if metric == 'UR' else 'Number of Prescriptions'\n",
    "    print(f\"\\n{metric_name}:\")\n",
    "    metric_data = all_comparisons[all_comparisons['metric'] == metric]\n",
    "    \n",
    "    print(\"  ML Models:\")\n",
    "    ml_metric_freq = metric_data['ml_best_model'].value_counts()\n",
    "    for model, count in ml_metric_freq.head(3).items():\n",
    "        pct = count / len(metric_data) * 100\n",
    "        print(f\"    {model}: {count} ({pct:.1f}%)\")\n",
    "    \n",
    "    print(\"  Stats Models:\")\n",
    "    stats_metric_freq = metric_data['stats_best_model'].value_counts()\n",
    "    for model, count in stats_metric_freq.head(3).items():\n",
    "        pct = count / len(metric_data) * 100\n",
    "        print(f\"    {model}: {count} ({pct:.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Individual Drug Class Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "INDIVIDUAL DRUG CLASS COMPARISON SUMMARY\n",
      "================================================================================\n",
      "Total drug classes compared: 634\n",
      "Gray zone threshold: 5.0%\n",
      "\n",
      "Winner distribution:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "winner\n",
       "Stats                        415\n",
       "ML                           150\n",
       "No Significant Difference     69\n",
       "Name: count, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Winner percentage:\n",
      "  Stats: 65.46%\n",
      "  ML: 23.66%\n",
      "  No Significant Difference: 10.88%\n"
     ]
    }
   ],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"INDIVIDUAL DRUG CLASS COMPARISON SUMMARY\")\n",
    "print(\"=\"*80)\n",
    "print(f\"Total drug classes compared: {len(all_comparisons)}\")\n",
    "print(f\"Gray zone threshold: {GRAY_ZONE_THRESHOLD}%\")\n",
    "print(f\"\\nWinner distribution:\")\n",
    "winner_counts = all_comparisons['winner'].value_counts()\n",
    "display(winner_counts)\n",
    "\n",
    "print(f\"\\nWinner percentage:\")\n",
    "winner_pct = all_comparisons['winner'].value_counts(normalize=True) * 100\n",
    "for category, pct in winner_pct.items():\n",
    "    print(f\"  {category}: {pct:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "Winner Distribution by State and Metric\n",
      "================================================================================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>winner</th>\n",
       "      <th>ML</th>\n",
       "      <th>No Significant Difference</th>\n",
       "      <th>Stats</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>state</th>\n",
       "      <th>metric</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">IL</th>\n",
       "      <th>NoP</th>\n",
       "      <td>19</td>\n",
       "      <td>11</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>UR</th>\n",
       "      <td>19</td>\n",
       "      <td>5</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">IN</th>\n",
       "      <th>NoP</th>\n",
       "      <td>19</td>\n",
       "      <td>6</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>UR</th>\n",
       "      <td>15</td>\n",
       "      <td>10</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">MI</th>\n",
       "      <th>NoP</th>\n",
       "      <td>18</td>\n",
       "      <td>11</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>UR</th>\n",
       "      <td>26</td>\n",
       "      <td>12</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">OH</th>\n",
       "      <th>NoP</th>\n",
       "      <td>20</td>\n",
       "      <td>5</td>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>UR</th>\n",
       "      <td>14</td>\n",
       "      <td>9</td>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "winner        ML  No Significant Difference  Stats\n",
       "state metric                                      \n",
       "IL    NoP     19                         11     48\n",
       "      UR      19                          5     54\n",
       "IN    NoP     19                          6     55\n",
       "      UR      15                         10     55\n",
       "MI    NoP     18                         11     49\n",
       "      UR      26                         12     40\n",
       "OH    NoP     20                          5     56\n",
       "      UR      14                          9     58"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Percentage Distribution:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>winner</th>\n",
       "      <th>ML_Pct</th>\n",
       "      <th>Stats_Pct</th>\n",
       "      <th>Gray_Pct</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>state</th>\n",
       "      <th>metric</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">IL</th>\n",
       "      <th>NoP</th>\n",
       "      <td>24.36</td>\n",
       "      <td>61.54</td>\n",
       "      <td>14.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>UR</th>\n",
       "      <td>24.36</td>\n",
       "      <td>69.23</td>\n",
       "      <td>6.41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">IN</th>\n",
       "      <th>NoP</th>\n",
       "      <td>23.75</td>\n",
       "      <td>68.75</td>\n",
       "      <td>7.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>UR</th>\n",
       "      <td>18.75</td>\n",
       "      <td>68.75</td>\n",
       "      <td>12.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">MI</th>\n",
       "      <th>NoP</th>\n",
       "      <td>23.08</td>\n",
       "      <td>62.82</td>\n",
       "      <td>14.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>UR</th>\n",
       "      <td>33.33</td>\n",
       "      <td>51.28</td>\n",
       "      <td>15.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">OH</th>\n",
       "      <th>NoP</th>\n",
       "      <td>24.69</td>\n",
       "      <td>69.14</td>\n",
       "      <td>6.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>UR</th>\n",
       "      <td>17.28</td>\n",
       "      <td>71.60</td>\n",
       "      <td>11.11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "winner        ML_Pct  Stats_Pct  Gray_Pct\n",
       "state metric                             \n",
       "IL    NoP      24.36      61.54     14.10\n",
       "      UR       24.36      69.23      6.41\n",
       "IN    NoP      23.75      68.75      7.50\n",
       "      UR       18.75      68.75     12.50\n",
       "MI    NoP      23.08      62.82     14.10\n",
       "      UR       33.33      51.28     15.38\n",
       "OH    NoP      24.69      69.14      6.17\n",
       "      UR       17.28      71.60     11.11"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Winner distribution by state and metric\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"Winner Distribution by State and Metric\")\n",
    "print(\"=\"*80)\n",
    "winner_summary = all_comparisons.groupby(['state', 'metric', 'winner']).size().unstack(fill_value=0)\n",
    "display(winner_summary)\n",
    "\n",
    "# Calculate percentages\n",
    "if 'ML' in winner_summary.columns and 'Stats' in winner_summary.columns:\n",
    "    total_clear = winner_summary['ML'] + winner_summary['Stats']\n",
    "    if 'No Significant Difference' in winner_summary.columns:\n",
    "        total_clear = total_clear + winner_summary['No Significant Difference']\n",
    "    winner_summary['ML_Pct'] = (winner_summary.get('ML', 0) / total_clear * 100).round(2)\n",
    "    winner_summary['Stats_Pct'] = (winner_summary.get('Stats', 0) / total_clear * 100).round(2)\n",
    "    if 'No Significant Difference' in winner_summary.columns:\n",
    "        winner_summary['Gray_Pct'] = (winner_summary['No Significant Difference'] / total_clear * 100).round(2)\n",
    "    \n",
    "    print(\"\\nPercentage Distribution:\")\n",
    "    pct_cols = [col for col in ['ML_Pct', 'Stats_Pct', 'Gray_Pct'] if col in winner_summary.columns]\n",
    "    display(winner_summary[pct_cols])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. State-Level Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "STATE-LEVEL COMPARISON\n",
      "================================================================================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ml_avg_mae</th>\n",
       "      <th>stats_avg_mae</th>\n",
       "      <th>mae_diff</th>\n",
       "      <th>pct_improvement</th>\n",
       "      <th>winner</th>\n",
       "      <th>ML</th>\n",
       "      <th>No Significant Difference</th>\n",
       "      <th>Stats</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>state</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>IL</th>\n",
       "      <td>606701.57</td>\n",
       "      <td>503790.60</td>\n",
       "      <td>-102910.97</td>\n",
       "      <td>-38.41</td>\n",
       "      <td>Stats</td>\n",
       "      <td>38</td>\n",
       "      <td>16</td>\n",
       "      <td>102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>IN</th>\n",
       "      <td>436354.68</td>\n",
       "      <td>309272.39</td>\n",
       "      <td>-127082.29</td>\n",
       "      <td>-608.98</td>\n",
       "      <td>Stats</td>\n",
       "      <td>34</td>\n",
       "      <td>16</td>\n",
       "      <td>110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MI</th>\n",
       "      <td>574509.28</td>\n",
       "      <td>496830.65</td>\n",
       "      <td>-77678.63</td>\n",
       "      <td>-50.11</td>\n",
       "      <td>Stats</td>\n",
       "      <td>44</td>\n",
       "      <td>23</td>\n",
       "      <td>89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OH</th>\n",
       "      <td>801168.65</td>\n",
       "      <td>668411.17</td>\n",
       "      <td>-132757.48</td>\n",
       "      <td>-61.07</td>\n",
       "      <td>Stats</td>\n",
       "      <td>34</td>\n",
       "      <td>14</td>\n",
       "      <td>114</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       ml_avg_mae  stats_avg_mae   mae_diff  pct_improvement winner  ML  \\\n",
       "state                                                                     \n",
       "IL      606701.57      503790.60 -102910.97           -38.41  Stats  38   \n",
       "IN      436354.68      309272.39 -127082.29          -608.98  Stats  34   \n",
       "MI      574509.28      496830.65  -77678.63           -50.11  Stats  44   \n",
       "OH      801168.65      668411.17 -132757.48           -61.07  Stats  34   \n",
       "\n",
       "       No Significant Difference  Stats  \n",
       "state                                    \n",
       "IL                            16    102  \n",
       "IN                            16    110  \n",
       "MI                            23     89  \n",
       "OH                            14    114  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Note: Positive pct_improvement means ML performs better\n",
      "Gray zone threshold: 5.0%\n"
     ]
    }
   ],
   "source": [
    "# State-level aggregation\n",
    "state_comparison = all_comparisons.groupby('state').agg({\n",
    "    'ml_avg_mae': 'mean',\n",
    "    'stats_avg_mae': 'mean',\n",
    "    'mae_diff': 'mean',\n",
    "    'pct_improvement': 'mean'\n",
    "}).round(2)\n",
    "\n",
    "state_comparison['winner'] = state_comparison.apply(\n",
    "    lambda x: 'No Significant Difference' if abs(x['pct_improvement']) < GRAY_ZONE_THRESHOLD\n",
    "    else ('ML' if x['ml_avg_mae'] < x['stats_avg_mae'] else 'Stats'), \n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# Count winners by state\n",
    "state_winner_counts = all_comparisons.groupby(['state', 'winner']).size().unstack(fill_value=0)\n",
    "state_comparison = state_comparison.join(state_winner_counts, rsuffix='_count')\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"STATE-LEVEL COMPARISON\")\n",
    "print(\"=\"*80)\n",
    "display(state_comparison)\n",
    "print(f\"\\nNote: Positive pct_improvement means ML performs better\")\n",
    "print(f\"Gray zone threshold: {GRAY_ZONE_THRESHOLD}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Metric-Level Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "METRIC-LEVEL COMPARISON\n",
      "================================================================================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ml_avg_mae</th>\n",
       "      <th>stats_avg_mae</th>\n",
       "      <th>mae_diff</th>\n",
       "      <th>pct_improvement</th>\n",
       "      <th>winner</th>\n",
       "      <th>ML</th>\n",
       "      <th>No Significant Difference</th>\n",
       "      <th>Stats</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>metric</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>NoP</th>\n",
       "      <td>16954.13</td>\n",
       "      <td>13619.22</td>\n",
       "      <td>-3334.91</td>\n",
       "      <td>-43.60</td>\n",
       "      <td>Stats</td>\n",
       "      <td>76</td>\n",
       "      <td>33</td>\n",
       "      <td>208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>UR</th>\n",
       "      <td>1194007.89</td>\n",
       "      <td>976485.22</td>\n",
       "      <td>-217522.68</td>\n",
       "      <td>-338.54</td>\n",
       "      <td>Stats</td>\n",
       "      <td>74</td>\n",
       "      <td>36</td>\n",
       "      <td>207</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        ml_avg_mae  stats_avg_mae   mae_diff  pct_improvement winner  ML  \\\n",
       "metric                                                                     \n",
       "NoP       16954.13       13619.22   -3334.91           -43.60  Stats  76   \n",
       "UR      1194007.89      976485.22 -217522.68          -338.54  Stats  74   \n",
       "\n",
       "        No Significant Difference  Stats  \n",
       "metric                                    \n",
       "NoP                            33    208  \n",
       "UR                             36    207  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "UR: Units Reimbursed\n",
      "NoP: Number of Prescriptions\n",
      "\n",
      "Note: Positive pct_improvement means ML performs better\n",
      "Gray zone threshold: 5.0%\n"
     ]
    }
   ],
   "source": [
    "# Metric-level aggregation\n",
    "metric_comparison = all_comparisons.groupby('metric').agg({\n",
    "    'ml_avg_mae': 'mean',\n",
    "    'stats_avg_mae': 'mean',\n",
    "    'mae_diff': 'mean',\n",
    "    'pct_improvement': 'mean'\n",
    "}).round(2)\n",
    "\n",
    "metric_comparison['winner'] = metric_comparison.apply(\n",
    "    lambda x: 'No Significant Difference' if abs(x['pct_improvement']) < GRAY_ZONE_THRESHOLD\n",
    "    else ('ML' if x['ml_avg_mae'] < x['stats_avg_mae'] else 'Stats'), \n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# Count winners by metric\n",
    "metric_winner_counts = all_comparisons.groupby(['metric', 'winner']).size().unstack(fill_value=0)\n",
    "metric_comparison = metric_comparison.join(metric_winner_counts, rsuffix='_count')\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"METRIC-LEVEL COMPARISON\")\n",
    "print(\"=\"*80)\n",
    "display(metric_comparison)\n",
    "print(\"\\nUR: Units Reimbursed\")\n",
    "print(\"NoP: Number of Prescriptions\")\n",
    "print(f\"\\nNote: Positive pct_improvement means ML performs better\")\n",
    "print(f\"Gray zone threshold: {GRAY_ZONE_THRESHOLD}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "METRIC-LEVEL COMPARISON BY STATE\n",
      "================================================================================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>ml_avg_mae</th>\n",
       "      <th>stats_avg_mae</th>\n",
       "      <th>pct_improvement</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>metric</th>\n",
       "      <th>state</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">NoP</th>\n",
       "      <th>IL</th>\n",
       "      <td>15940.38</td>\n",
       "      <td>13489.45</td>\n",
       "      <td>-26.43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>IN</th>\n",
       "      <td>12067.70</td>\n",
       "      <td>8219.92</td>\n",
       "      <td>-74.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MI</th>\n",
       "      <td>17594.16</td>\n",
       "      <td>14022.62</td>\n",
       "      <td>-45.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OH</th>\n",
       "      <td>22140.12</td>\n",
       "      <td>18688.38</td>\n",
       "      <td>-27.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">UR</th>\n",
       "      <th>IL</th>\n",
       "      <td>1197462.75</td>\n",
       "      <td>994091.75</td>\n",
       "      <td>-50.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>IN</th>\n",
       "      <td>860641.66</td>\n",
       "      <td>610324.86</td>\n",
       "      <td>-1143.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MI</th>\n",
       "      <td>1131424.40</td>\n",
       "      <td>979638.68</td>\n",
       "      <td>-55.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OH</th>\n",
       "      <td>1580197.18</td>\n",
       "      <td>1318133.96</td>\n",
       "      <td>-94.24</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              ml_avg_mae  stats_avg_mae  pct_improvement\n",
       "metric state                                            \n",
       "NoP    IL       15940.38       13489.45           -26.43\n",
       "       IN       12067.70        8219.92           -74.67\n",
       "       MI       17594.16       14022.62           -45.18\n",
       "       OH       22140.12       18688.38           -27.90\n",
       "UR     IL     1197462.75      994091.75           -50.38\n",
       "       IN      860641.66      610324.86         -1143.28\n",
       "       MI     1131424.40      979638.68           -55.03\n",
       "       OH     1580197.18     1318133.96           -94.24"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Detailed metric-level analysis by state\n",
    "metric_state_comparison = all_comparisons.groupby(['metric', 'state']).agg({\n",
    "    'ml_avg_mae': 'mean',\n",
    "    'stats_avg_mae': 'mean',\n",
    "    'pct_improvement': 'mean'\n",
    "}).round(2)\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"METRIC-LEVEL COMPARISON BY STATE\")\n",
    "print(\"=\"*80)\n",
    "display(metric_state_comparison)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Overall Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "OVERALL COMPARISON SUMMARY\n",
      "================================================================================\n",
      "Gray zone threshold: 5.0%\n",
      "\n",
      "Total Drug Classes................................                  634\n",
      "ML Wins...........................................                  150\n",
      "Stats Wins........................................                  415\n",
      "No Significant Difference.........................                69.00\n",
      "ML Win Rate (%)...................................                23.66%\n",
      "Stats Win Rate (%)................................                65.46%\n",
      "Gray Zone Rate (%)................................                10.88%\n",
      "Avg ML MAE........................................           605,481.01\n",
      "Avg Stats MAE.....................................           495,052.22\n",
      "Avg MAE Difference................................          -110,428.79\n",
      "Avg Pct Improvement...............................              -191.07\n",
      "\n",
      "================================================================================\n",
      "INTERPRETATION\n",
      "================================================================================\n",
      "✓ ML models clearly outperform Stats in 150 cases (23.7%)\n",
      "✓ Stats models clearly outperform ML in 415 cases (65.5%)\n",
      "✓ No significant difference in 69 cases (10.9%)\n",
      "✓ On average, ML reduces MAE by -191.07%\n"
     ]
    }
   ],
   "source": [
    "# Overall comparison across all dimensions\n",
    "overall_stats = {\n",
    "    'Total Drug Classes': len(all_comparisons),\n",
    "    'ML Wins': (all_comparisons['winner'] == 'ML').sum(),\n",
    "    'Stats Wins': (all_comparisons['winner'] == 'Stats').sum(),\n",
    "    'No Significant Difference': (all_comparisons['winner'] == 'No Significant Difference').sum(),\n",
    "    'ML Win Rate (%)': (all_comparisons['winner'] == 'ML').mean() * 100,\n",
    "    'Stats Win Rate (%)': (all_comparisons['winner'] == 'Stats').mean() * 100,\n",
    "    'Gray Zone Rate (%)': (all_comparisons['winner'] == 'No Significant Difference').mean() * 100,\n",
    "    'Avg ML MAE': all_comparisons['ml_avg_mae'].mean(),\n",
    "    'Avg Stats MAE': all_comparisons['stats_avg_mae'].mean(),\n",
    "    'Avg MAE Difference': all_comparisons['mae_diff'].mean(),\n",
    "    'Avg Pct Improvement': all_comparisons['pct_improvement'].mean()\n",
    "}\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"OVERALL COMPARISON SUMMARY\")\n",
    "print(\"=\"*80)\n",
    "print(f\"Gray zone threshold: {GRAY_ZONE_THRESHOLD}%\")\n",
    "print()\n",
    "for key, value in overall_stats.items():\n",
    "    if 'Avg' in key or 'Difference' in key:\n",
    "        print(f\"{key:.<50} {value:>20,.2f}\")\n",
    "    elif 'Rate' in key or 'Improvement' in key:\n",
    "        print(f\"{key:.<50} {value:>20.2f}%\")\n",
    "    else:\n",
    "        print(f\"{key:.<50} {value:>20}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"INTERPRETATION\")\n",
    "print(\"=\"*80)\n",
    "ml_clear_wins = overall_stats['ML Wins']\n",
    "stats_clear_wins = overall_stats['Stats Wins']\n",
    "gray_zone = overall_stats['No Significant Difference']\n",
    "\n",
    "print(f\"✓ ML models clearly outperform Stats in {ml_clear_wins} cases ({overall_stats['ML Win Rate (%)']:.1f}%)\")\n",
    "print(f\"✓ Stats models clearly outperform ML in {stats_clear_wins} cases ({overall_stats['Stats Win Rate (%)']:.1f}%)\")\n",
    "print(f\"✓ No significant difference in {gray_zone} cases ({overall_stats['Gray Zone Rate (%)']:.1f}%)\")\n",
    "print(f\"✓ On average, ML reduces MAE by {overall_stats['Avg Pct Improvement']:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Model Performance Tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "TOP 20 DRUG CLASSES WHERE ML CLEARLY OUTPERFORMS STATS\n",
      "(Improvement > 5.0%)\n",
      "================================================================================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unique_id</th>\n",
       "      <th>state</th>\n",
       "      <th>metric</th>\n",
       "      <th>ml_best_model</th>\n",
       "      <th>stats_best_model</th>\n",
       "      <th>ml_avg_mae</th>\n",
       "      <th>stats_avg_mae</th>\n",
       "      <th>pct_improvement</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>508</th>\n",
       "      <td>OH_G02</td>\n",
       "      <td>OH</td>\n",
       "      <td>UR</td>\n",
       "      <td>LightGBM</td>\n",
       "      <td>HistoricAverage</td>\n",
       "      <td>1216122.11</td>\n",
       "      <td>3692248.76</td>\n",
       "      <td>67.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>589</th>\n",
       "      <td>OH_G02</td>\n",
       "      <td>OH</td>\n",
       "      <td>NoP</td>\n",
       "      <td>XGBoost</td>\n",
       "      <td>WindowAverage</td>\n",
       "      <td>19918.11</td>\n",
       "      <td>59853.67</td>\n",
       "      <td>66.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>610</th>\n",
       "      <td>OH_M05</td>\n",
       "      <td>OH</td>\n",
       "      <td>NoP</td>\n",
       "      <td>XGBoost</td>\n",
       "      <td>Naive</td>\n",
       "      <td>522.20</td>\n",
       "      <td>1234.38</td>\n",
       "      <td>57.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>MI_L01</td>\n",
       "      <td>MI</td>\n",
       "      <td>UR</td>\n",
       "      <td>RandomForest</td>\n",
       "      <td>Naive</td>\n",
       "      <td>59325.40</td>\n",
       "      <td>129655.33</td>\n",
       "      <td>54.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>MI_H04</td>\n",
       "      <td>MI</td>\n",
       "      <td>NoP</td>\n",
       "      <td>RandomForest</td>\n",
       "      <td>WindowAverage</td>\n",
       "      <td>121.05</td>\n",
       "      <td>256.65</td>\n",
       "      <td>52.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>267</th>\n",
       "      <td>IN_D07</td>\n",
       "      <td>IN</td>\n",
       "      <td>NoP</td>\n",
       "      <td>XGBoost</td>\n",
       "      <td>SARIMAX</td>\n",
       "      <td>16128.92</td>\n",
       "      <td>32718.91</td>\n",
       "      <td>50.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>328</th>\n",
       "      <td>IL_B01</td>\n",
       "      <td>IL</td>\n",
       "      <td>UR</td>\n",
       "      <td>XGBoost</td>\n",
       "      <td>WindowAverage</td>\n",
       "      <td>462471.80</td>\n",
       "      <td>929992.00</td>\n",
       "      <td>50.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>252</th>\n",
       "      <td>IN_B06</td>\n",
       "      <td>IN</td>\n",
       "      <td>NoP</td>\n",
       "      <td>XGBoost</td>\n",
       "      <td>WindowAverage</td>\n",
       "      <td>223.03</td>\n",
       "      <td>446.62</td>\n",
       "      <td>50.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>429</th>\n",
       "      <td>IL_G02</td>\n",
       "      <td>IL</td>\n",
       "      <td>NoP</td>\n",
       "      <td>RandomForest</td>\n",
       "      <td>HistoricAverage</td>\n",
       "      <td>17313.70</td>\n",
       "      <td>32392.84</td>\n",
       "      <td>46.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>245</th>\n",
       "      <td>IN_A11</td>\n",
       "      <td>IN</td>\n",
       "      <td>NoP</td>\n",
       "      <td>Ridge</td>\n",
       "      <td>SARIMAX</td>\n",
       "      <td>3287.29</td>\n",
       "      <td>6031.67</td>\n",
       "      <td>45.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>MI_J04</td>\n",
       "      <td>MI</td>\n",
       "      <td>UR</td>\n",
       "      <td>RandomForest</td>\n",
       "      <td>Naive</td>\n",
       "      <td>4109.62</td>\n",
       "      <td>7483.70</td>\n",
       "      <td>45.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>MI_A11</td>\n",
       "      <td>MI</td>\n",
       "      <td>NoP</td>\n",
       "      <td>Ridge</td>\n",
       "      <td>Naive</td>\n",
       "      <td>6340.43</td>\n",
       "      <td>11523.12</td>\n",
       "      <td>44.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>475</th>\n",
       "      <td>OH_A04</td>\n",
       "      <td>OH</td>\n",
       "      <td>UR</td>\n",
       "      <td>RandomForest</td>\n",
       "      <td>Naive</td>\n",
       "      <td>176637.68</td>\n",
       "      <td>317655.57</td>\n",
       "      <td>44.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>MI_D04</td>\n",
       "      <td>MI</td>\n",
       "      <td>UR</td>\n",
       "      <td>XGBoost</td>\n",
       "      <td>Naive</td>\n",
       "      <td>423169.65</td>\n",
       "      <td>760068.62</td>\n",
       "      <td>44.32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>629</th>\n",
       "      <td>OH_S02</td>\n",
       "      <td>OH</td>\n",
       "      <td>NoP</td>\n",
       "      <td>LightGBM</td>\n",
       "      <td>ARIMAX</td>\n",
       "      <td>10364.72</td>\n",
       "      <td>18542.39</td>\n",
       "      <td>44.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>MI_G03</td>\n",
       "      <td>MI</td>\n",
       "      <td>UR</td>\n",
       "      <td>XGBoost</td>\n",
       "      <td>WindowAverage</td>\n",
       "      <td>319823.79</td>\n",
       "      <td>571906.82</td>\n",
       "      <td>44.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>595</th>\n",
       "      <td>OH_H04</td>\n",
       "      <td>OH</td>\n",
       "      <td>NoP</td>\n",
       "      <td>LightGBM</td>\n",
       "      <td>WindowAverage</td>\n",
       "      <td>240.24</td>\n",
       "      <td>428.04</td>\n",
       "      <td>43.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>MI_A11</td>\n",
       "      <td>MI</td>\n",
       "      <td>UR</td>\n",
       "      <td>LightGBM</td>\n",
       "      <td>WindowAverage</td>\n",
       "      <td>64255.33</td>\n",
       "      <td>113493.95</td>\n",
       "      <td>43.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>309</th>\n",
       "      <td>IN_R07</td>\n",
       "      <td>IN</td>\n",
       "      <td>NoP</td>\n",
       "      <td>LightGBM</td>\n",
       "      <td>SARIMAX</td>\n",
       "      <td>46.18</td>\n",
       "      <td>81.38</td>\n",
       "      <td>43.26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>582</th>\n",
       "      <td>OH_D05</td>\n",
       "      <td>OH</td>\n",
       "      <td>NoP</td>\n",
       "      <td>LightGBM</td>\n",
       "      <td>HistoricAverage</td>\n",
       "      <td>874.66</td>\n",
       "      <td>1524.92</td>\n",
       "      <td>42.64</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    unique_id state metric ml_best_model stats_best_model  ml_avg_mae  \\\n",
       "508    OH_G02    OH     UR      LightGBM  HistoricAverage  1216122.11   \n",
       "589    OH_G02    OH    NoP       XGBoost    WindowAverage    19918.11   \n",
       "610    OH_M05    OH    NoP       XGBoost            Naive      522.20   \n",
       "49     MI_L01    MI     UR  RandomForest            Naive    59325.40   \n",
       "120    MI_H04    MI    NoP  RandomForest    WindowAverage      121.05   \n",
       "267    IN_D07    IN    NoP       XGBoost          SARIMAX    16128.92   \n",
       "328    IL_B01    IL     UR       XGBoost    WindowAverage   462471.80   \n",
       "252    IN_B06    IN    NoP       XGBoost    WindowAverage      223.03   \n",
       "429    IL_G02    IL    NoP  RandomForest  HistoricAverage    17313.70   \n",
       "245    IN_A11    IN    NoP         Ridge          SARIMAX     3287.29   \n",
       "46     MI_J04    MI     UR  RandomForest            Naive     4109.62   \n",
       "87     MI_A11    MI    NoP         Ridge            Naive     6340.43   \n",
       "475    OH_A04    OH     UR  RandomForest            Naive   176637.68   \n",
       "28     MI_D04    MI     UR       XGBoost            Naive   423169.65   \n",
       "629    OH_S02    OH    NoP      LightGBM           ARIMAX    10364.72   \n",
       "37     MI_G03    MI     UR       XGBoost    WindowAverage   319823.79   \n",
       "595    OH_H04    OH    NoP      LightGBM    WindowAverage      240.24   \n",
       "9      MI_A11    MI     UR      LightGBM    WindowAverage    64255.33   \n",
       "309    IN_R07    IN    NoP      LightGBM          SARIMAX       46.18   \n",
       "582    OH_D05    OH    NoP      LightGBM  HistoricAverage      874.66   \n",
       "\n",
       "     stats_avg_mae  pct_improvement  \n",
       "508     3692248.76            67.06  \n",
       "589       59853.67            66.72  \n",
       "610        1234.38            57.70  \n",
       "49       129655.33            54.24  \n",
       "120         256.65            52.83  \n",
       "267       32718.91            50.70  \n",
       "328      929992.00            50.27  \n",
       "252         446.62            50.06  \n",
       "429       32392.84            46.55  \n",
       "245        6031.67            45.50  \n",
       "46         7483.70            45.09  \n",
       "87        11523.12            44.98  \n",
       "475      317655.57            44.39  \n",
       "28       760068.62            44.32  \n",
       "629       18542.39            44.10  \n",
       "37       571906.82            44.08  \n",
       "595         428.04            43.87  \n",
       "9        113493.95            43.38  \n",
       "309          81.38            43.26  \n",
       "582        1524.92            42.64  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Top 20 ML improvements (excluding gray zone)\n",
    "ml_clear_wins_df = all_comparisons[all_comparisons['winner'] == 'ML']\n",
    "print(\"=\"*80)\n",
    "print(\"TOP 20 DRUG CLASSES WHERE ML CLEARLY OUTPERFORMS STATS\")\n",
    "print(f\"(Improvement > {GRAY_ZONE_THRESHOLD}%)\")\n",
    "print(\"=\"*80)\n",
    "if len(ml_clear_wins_df) > 0:\n",
    "    top_ml = ml_clear_wins_df.nlargest(20, 'pct_improvement')[[\n",
    "        'unique_id', 'state', 'metric', 'ml_best_model', 'stats_best_model',\n",
    "        'ml_avg_mae', 'stats_avg_mae', 'pct_improvement'\n",
    "    ]]\n",
    "    display(top_ml)\n",
    "else:\n",
    "    print(\"No clear ML wins found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "TOP 20 DRUG CLASSES WHERE STATS CLEARLY OUTPERFORMS ML\n",
      "(Improvement > 5.0%)\n",
      "================================================================================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unique_id</th>\n",
       "      <th>state</th>\n",
       "      <th>metric</th>\n",
       "      <th>ml_best_model</th>\n",
       "      <th>stats_best_model</th>\n",
       "      <th>ml_avg_mae</th>\n",
       "      <th>stats_avg_mae</th>\n",
       "      <th>pct_improvement</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>IN_H04</td>\n",
       "      <td>IN</td>\n",
       "      <td>UR</td>\n",
       "      <td>LightGBM</td>\n",
       "      <td>SARIMAX</td>\n",
       "      <td>99925.75</td>\n",
       "      <td>152.99</td>\n",
       "      <td>-65216.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207</th>\n",
       "      <td>IN_L03</td>\n",
       "      <td>IN</td>\n",
       "      <td>UR</td>\n",
       "      <td>LightGBM</td>\n",
       "      <td>Naive</td>\n",
       "      <td>99284.11</td>\n",
       "      <td>735.41</td>\n",
       "      <td>-13400.54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>IN_C04</td>\n",
       "      <td>IN</td>\n",
       "      <td>UR</td>\n",
       "      <td>XGBoost</td>\n",
       "      <td>Naive</td>\n",
       "      <td>64277.18</td>\n",
       "      <td>2181.96</td>\n",
       "      <td>-2845.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>476</th>\n",
       "      <td>OH_A05</td>\n",
       "      <td>OH</td>\n",
       "      <td>UR</td>\n",
       "      <td>LightGBM</td>\n",
       "      <td>SARIMAX</td>\n",
       "      <td>251642.50</td>\n",
       "      <td>9078.04</td>\n",
       "      <td>-2671.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>IN_H05</td>\n",
       "      <td>IN</td>\n",
       "      <td>UR</td>\n",
       "      <td>LightGBM</td>\n",
       "      <td>Naive</td>\n",
       "      <td>83188.14</td>\n",
       "      <td>3141.55</td>\n",
       "      <td>-2547.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>222</th>\n",
       "      <td>IN_P02</td>\n",
       "      <td>IN</td>\n",
       "      <td>UR</td>\n",
       "      <td>LightGBM</td>\n",
       "      <td>SeasonalNaive</td>\n",
       "      <td>99429.16</td>\n",
       "      <td>4874.73</td>\n",
       "      <td>-1939.69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>MI_M05</td>\n",
       "      <td>MI</td>\n",
       "      <td>NoP</td>\n",
       "      <td>XGBoost</td>\n",
       "      <td>HistoricAverage</td>\n",
       "      <td>4255.35</td>\n",
       "      <td>275.33</td>\n",
       "      <td>-1445.54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>354</th>\n",
       "      <td>IL_H01</td>\n",
       "      <td>IL</td>\n",
       "      <td>UR</td>\n",
       "      <td>XGBoost</td>\n",
       "      <td>HistoricAverage</td>\n",
       "      <td>106539.78</td>\n",
       "      <td>9454.88</td>\n",
       "      <td>-1026.82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>MI_A16</td>\n",
       "      <td>MI</td>\n",
       "      <td>UR</td>\n",
       "      <td>XGBoost</td>\n",
       "      <td>WindowAverage</td>\n",
       "      <td>297728.73</td>\n",
       "      <td>27482.63</td>\n",
       "      <td>-983.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181</th>\n",
       "      <td>IN_C10</td>\n",
       "      <td>IN</td>\n",
       "      <td>UR</td>\n",
       "      <td>RandomForest</td>\n",
       "      <td>SARIMAX</td>\n",
       "      <td>1225046.41</td>\n",
       "      <td>172754.61</td>\n",
       "      <td>-609.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>MI_H01</td>\n",
       "      <td>MI</td>\n",
       "      <td>UR</td>\n",
       "      <td>XGBoost</td>\n",
       "      <td>WindowAverage</td>\n",
       "      <td>45722.30</td>\n",
       "      <td>6651.30</td>\n",
       "      <td>-587.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>MI_C07</td>\n",
       "      <td>MI</td>\n",
       "      <td>UR</td>\n",
       "      <td>XGBoost</td>\n",
       "      <td>SARIMAX</td>\n",
       "      <td>2282507.39</td>\n",
       "      <td>337834.77</td>\n",
       "      <td>-575.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>MI_N04</td>\n",
       "      <td>MI</td>\n",
       "      <td>UR</td>\n",
       "      <td>LightGBM</td>\n",
       "      <td>SARIMAX</td>\n",
       "      <td>473514.49</td>\n",
       "      <td>80800.69</td>\n",
       "      <td>-486.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>213</th>\n",
       "      <td>IN_M05</td>\n",
       "      <td>IN</td>\n",
       "      <td>UR</td>\n",
       "      <td>RandomForest</td>\n",
       "      <td>Naive</td>\n",
       "      <td>23631.59</td>\n",
       "      <td>4055.52</td>\n",
       "      <td>-482.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>IN_H01</td>\n",
       "      <td>IN</td>\n",
       "      <td>UR</td>\n",
       "      <td>LightGBM</td>\n",
       "      <td>SeasonalNaive</td>\n",
       "      <td>25808.84</td>\n",
       "      <td>4676.63</td>\n",
       "      <td>-451.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>229</th>\n",
       "      <td>IN_R07</td>\n",
       "      <td>IN</td>\n",
       "      <td>UR</td>\n",
       "      <td>XGBoost</td>\n",
       "      <td>SARIMAX</td>\n",
       "      <td>26652.38</td>\n",
       "      <td>5315.65</td>\n",
       "      <td>-401.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>291</th>\n",
       "      <td>IN_M03</td>\n",
       "      <td>IN</td>\n",
       "      <td>NoP</td>\n",
       "      <td>XGBoost</td>\n",
       "      <td>SARIMAX</td>\n",
       "      <td>9867.41</td>\n",
       "      <td>2013.05</td>\n",
       "      <td>-390.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211</th>\n",
       "      <td>IN_M03</td>\n",
       "      <td>IN</td>\n",
       "      <td>UR</td>\n",
       "      <td>XGBoost</td>\n",
       "      <td>SARIMAX</td>\n",
       "      <td>885662.66</td>\n",
       "      <td>185039.98</td>\n",
       "      <td>-378.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>288</th>\n",
       "      <td>IN_L04</td>\n",
       "      <td>IN</td>\n",
       "      <td>NoP</td>\n",
       "      <td>LightGBM</td>\n",
       "      <td>SARIMAX</td>\n",
       "      <td>5067.28</td>\n",
       "      <td>1075.59</td>\n",
       "      <td>-371.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>511</th>\n",
       "      <td>OH_H01</td>\n",
       "      <td>OH</td>\n",
       "      <td>UR</td>\n",
       "      <td>XGBoost</td>\n",
       "      <td>Naive</td>\n",
       "      <td>86563.62</td>\n",
       "      <td>18433.26</td>\n",
       "      <td>-369.61</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    unique_id state metric ml_best_model stats_best_model  ml_avg_mae  \\\n",
       "198    IN_H04    IN     UR      LightGBM          SARIMAX    99925.75   \n",
       "207    IN_L03    IN     UR      LightGBM            Naive    99284.11   \n",
       "176    IN_C04    IN     UR       XGBoost            Naive    64277.18   \n",
       "476    OH_A05    OH     UR      LightGBM          SARIMAX   251642.50   \n",
       "199    IN_H05    IN     UR      LightGBM            Naive    83188.14   \n",
       "222    IN_P02    IN     UR      LightGBM    SeasonalNaive    99429.16   \n",
       "135    MI_M05    MI    NoP       XGBoost  HistoricAverage     4255.35   \n",
       "354    IL_H01    IL     UR       XGBoost  HistoricAverage   106539.78   \n",
       "11     MI_A16    MI     UR       XGBoost    WindowAverage   297728.73   \n",
       "181    IN_C10    IN     UR  RandomForest          SARIMAX  1225046.41   \n",
       "39     MI_H01    MI     UR       XGBoost    WindowAverage    45722.30   \n",
       "22     MI_C07    MI     UR       XGBoost          SARIMAX  2282507.39   \n",
       "61     MI_N04    MI     UR      LightGBM          SARIMAX   473514.49   \n",
       "213    IN_M05    IN     UR  RandomForest            Naive    23631.59   \n",
       "195    IN_H01    IN     UR      LightGBM    SeasonalNaive    25808.84   \n",
       "229    IN_R07    IN     UR       XGBoost          SARIMAX    26652.38   \n",
       "291    IN_M03    IN    NoP       XGBoost          SARIMAX     9867.41   \n",
       "211    IN_M03    IN     UR       XGBoost          SARIMAX   885662.66   \n",
       "288    IN_L04    IN    NoP      LightGBM          SARIMAX     5067.28   \n",
       "511    OH_H01    OH     UR       XGBoost            Naive    86563.62   \n",
       "\n",
       "     stats_avg_mae  pct_improvement  \n",
       "198         152.99        -65216.70  \n",
       "207         735.41        -13400.54  \n",
       "176        2181.96         -2845.85  \n",
       "476        9078.04         -2671.99  \n",
       "199        3141.55         -2547.99  \n",
       "222        4874.73         -1939.69  \n",
       "135         275.33         -1445.54  \n",
       "354        9454.88         -1026.82  \n",
       "11        27482.63          -983.33  \n",
       "181      172754.61          -609.13  \n",
       "39         6651.30          -587.42  \n",
       "22       337834.77          -575.63  \n",
       "61        80800.69          -486.03  \n",
       "213        4055.52          -482.70  \n",
       "195        4676.63          -451.87  \n",
       "229        5315.65          -401.39  \n",
       "291        2013.05          -390.17  \n",
       "211      185039.98          -378.63  \n",
       "288        1075.59          -371.12  \n",
       "511       18433.26          -369.61  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Top 20 Stats improvements (excluding gray zone)\n",
    "stats_clear_wins_df = all_comparisons[all_comparisons['winner'] == 'Stats']\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"TOP 20 DRUG CLASSES WHERE STATS CLEARLY OUTPERFORMS ML\")\n",
    "print(f\"(Improvement > {GRAY_ZONE_THRESHOLD}%)\")\n",
    "print(\"=\"*80)\n",
    "if len(stats_clear_wins_df) > 0:\n",
    "    top_stats = stats_clear_wins_df.nsmallest(20, 'pct_improvement')[[\n",
    "        'unique_id', 'state', 'metric', 'ml_best_model', 'stats_best_model',\n",
    "        'ml_avg_mae', 'stats_avg_mae', 'pct_improvement'\n",
    "    ]]\n",
    "    display(top_stats)\n",
    "else:\n",
    "    print(\"No clear Stats wins found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "GRAY ZONE CASES (MAE difference < 5.0%)\n",
      "================================================================================\n",
      "Total: 69\n",
      "\n",
      "Sample cases:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unique_id</th>\n",
       "      <th>state</th>\n",
       "      <th>metric</th>\n",
       "      <th>ml_best_model</th>\n",
       "      <th>stats_best_model</th>\n",
       "      <th>ml_avg_mae</th>\n",
       "      <th>stats_avg_mae</th>\n",
       "      <th>pct_improvement</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>MI_B03</td>\n",
       "      <td>MI</td>\n",
       "      <td>UR</td>\n",
       "      <td>LightGBM</td>\n",
       "      <td>HistoricAverage</td>\n",
       "      <td>504068.96</td>\n",
       "      <td>513680.14</td>\n",
       "      <td>1.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>MI_C08</td>\n",
       "      <td>MI</td>\n",
       "      <td>UR</td>\n",
       "      <td>XGBoost</td>\n",
       "      <td>Naive</td>\n",
       "      <td>330720.04</td>\n",
       "      <td>324453.80</td>\n",
       "      <td>-1.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>MI_C09</td>\n",
       "      <td>MI</td>\n",
       "      <td>UR</td>\n",
       "      <td>XGBoost</td>\n",
       "      <td>Naive</td>\n",
       "      <td>1194435.76</td>\n",
       "      <td>1202443.59</td>\n",
       "      <td>0.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>MI_D02</td>\n",
       "      <td>MI</td>\n",
       "      <td>UR</td>\n",
       "      <td>LightGBM</td>\n",
       "      <td>SARIMAX</td>\n",
       "      <td>290361.48</td>\n",
       "      <td>278081.67</td>\n",
       "      <td>-4.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>MI_D06</td>\n",
       "      <td>MI</td>\n",
       "      <td>UR</td>\n",
       "      <td>XGBoost</td>\n",
       "      <td>HistoricAverage</td>\n",
       "      <td>363870.43</td>\n",
       "      <td>360028.14</td>\n",
       "      <td>-1.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>MI_D07</td>\n",
       "      <td>MI</td>\n",
       "      <td>UR</td>\n",
       "      <td>LightGBM</td>\n",
       "      <td>HistoricAverage</td>\n",
       "      <td>1062457.90</td>\n",
       "      <td>1014864.55</td>\n",
       "      <td>-4.69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>MI_G04</td>\n",
       "      <td>MI</td>\n",
       "      <td>UR</td>\n",
       "      <td>LightGBM</td>\n",
       "      <td>Naive</td>\n",
       "      <td>454447.61</td>\n",
       "      <td>438574.55</td>\n",
       "      <td>-3.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>MI_J06</td>\n",
       "      <td>MI</td>\n",
       "      <td>UR</td>\n",
       "      <td>XGBoost</td>\n",
       "      <td>HistoricAverage</td>\n",
       "      <td>49159.42</td>\n",
       "      <td>51359.12</td>\n",
       "      <td>4.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>MI_M02</td>\n",
       "      <td>MI</td>\n",
       "      <td>UR</td>\n",
       "      <td>XGBoost</td>\n",
       "      <td>HistoricAverage</td>\n",
       "      <td>4844608.84</td>\n",
       "      <td>4788038.23</td>\n",
       "      <td>-1.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>MI_N01</td>\n",
       "      <td>MI</td>\n",
       "      <td>UR</td>\n",
       "      <td>XGBoost</td>\n",
       "      <td>WindowAverage</td>\n",
       "      <td>90621.76</td>\n",
       "      <td>86682.36</td>\n",
       "      <td>-4.54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>MI_N06</td>\n",
       "      <td>MI</td>\n",
       "      <td>UR</td>\n",
       "      <td>LightGBM</td>\n",
       "      <td>SARIMAX</td>\n",
       "      <td>2220987.07</td>\n",
       "      <td>2201458.85</td>\n",
       "      <td>-0.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>MI_P03</td>\n",
       "      <td>MI</td>\n",
       "      <td>UR</td>\n",
       "      <td>XGBoost</td>\n",
       "      <td>SeasonalNaive</td>\n",
       "      <td>28390.04</td>\n",
       "      <td>27884.91</td>\n",
       "      <td>-1.81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>MI_A06</td>\n",
       "      <td>MI</td>\n",
       "      <td>NoP</td>\n",
       "      <td>Ridge</td>\n",
       "      <td>Naive</td>\n",
       "      <td>10521.69</td>\n",
       "      <td>10965.08</td>\n",
       "      <td>4.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>MI_A16</td>\n",
       "      <td>MI</td>\n",
       "      <td>NoP</td>\n",
       "      <td>RandomForest</td>\n",
       "      <td>WindowAverage</td>\n",
       "      <td>89.94</td>\n",
       "      <td>90.21</td>\n",
       "      <td>0.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>MI_B02</td>\n",
       "      <td>MI</td>\n",
       "      <td>NoP</td>\n",
       "      <td>LightGBM</td>\n",
       "      <td>SeasonalNaive</td>\n",
       "      <td>2020.11</td>\n",
       "      <td>2017.79</td>\n",
       "      <td>-0.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>MI_C01</td>\n",
       "      <td>MI</td>\n",
       "      <td>NoP</td>\n",
       "      <td>XGBoost</td>\n",
       "      <td>HistoricAverage</td>\n",
       "      <td>17627.21</td>\n",
       "      <td>17202.26</td>\n",
       "      <td>-2.47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>MI_C10</td>\n",
       "      <td>MI</td>\n",
       "      <td>NoP</td>\n",
       "      <td>XGBoost</td>\n",
       "      <td>Naive</td>\n",
       "      <td>16263.38</td>\n",
       "      <td>16700.67</td>\n",
       "      <td>2.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>MI_D04</td>\n",
       "      <td>MI</td>\n",
       "      <td>NoP</td>\n",
       "      <td>XGBoost</td>\n",
       "      <td>SARIMAX</td>\n",
       "      <td>5143.13</td>\n",
       "      <td>5269.83</td>\n",
       "      <td>2.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>MI_G03</td>\n",
       "      <td>MI</td>\n",
       "      <td>NoP</td>\n",
       "      <td>RandomForest</td>\n",
       "      <td>WindowAverage</td>\n",
       "      <td>11313.17</td>\n",
       "      <td>10893.92</td>\n",
       "      <td>-3.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>MI_H02</td>\n",
       "      <td>MI</td>\n",
       "      <td>NoP</td>\n",
       "      <td>LightGBM</td>\n",
       "      <td>WindowAverage</td>\n",
       "      <td>19807.38</td>\n",
       "      <td>19912.29</td>\n",
       "      <td>0.53</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    unique_id state metric ml_best_model stats_best_model  ml_avg_mae  \\\n",
       "14     MI_B03    MI     UR      LightGBM  HistoricAverage   504068.96   \n",
       "23     MI_C08    MI     UR       XGBoost            Naive   330720.04   \n",
       "24     MI_C09    MI     UR       XGBoost            Naive  1194435.76   \n",
       "27     MI_D02    MI     UR      LightGBM          SARIMAX   290361.48   \n",
       "30     MI_D06    MI     UR       XGBoost  HistoricAverage   363870.43   \n",
       "31     MI_D07    MI     UR      LightGBM  HistoricAverage  1062457.90   \n",
       "38     MI_G04    MI     UR      LightGBM            Naive   454447.61   \n",
       "48     MI_J06    MI     UR       XGBoost  HistoricAverage    49159.42   \n",
       "54     MI_M02    MI     UR       XGBoost  HistoricAverage  4844608.84   \n",
       "58     MI_N01    MI     UR       XGBoost    WindowAverage    90621.76   \n",
       "63     MI_N06    MI     UR      LightGBM          SARIMAX  2220987.07   \n",
       "66     MI_P03    MI     UR       XGBoost    SeasonalNaive    28390.04   \n",
       "83     MI_A06    MI    NoP         Ridge            Naive    10521.69   \n",
       "89     MI_A16    MI    NoP  RandomForest    WindowAverage       89.94   \n",
       "91     MI_B02    MI    NoP      LightGBM    SeasonalNaive     2020.11   \n",
       "95     MI_C01    MI    NoP       XGBoost  HistoricAverage    17627.21   \n",
       "103    MI_C10    MI    NoP       XGBoost            Naive    16263.38   \n",
       "106    MI_D04    MI    NoP       XGBoost          SARIMAX     5143.13   \n",
       "115    MI_G03    MI    NoP  RandomForest    WindowAverage    11313.17   \n",
       "118    MI_H02    MI    NoP      LightGBM    WindowAverage    19807.38   \n",
       "\n",
       "     stats_avg_mae  pct_improvement  \n",
       "14       513680.14             1.87  \n",
       "23       324453.80            -1.93  \n",
       "24      1202443.59             0.67  \n",
       "27       278081.67            -4.42  \n",
       "30       360028.14            -1.07  \n",
       "31      1014864.55            -4.69  \n",
       "38       438574.55            -3.62  \n",
       "48        51359.12             4.28  \n",
       "54      4788038.23            -1.18  \n",
       "58        86682.36            -4.54  \n",
       "63      2201458.85            -0.89  \n",
       "66        27884.91            -1.81  \n",
       "83        10965.08             4.04  \n",
       "89           90.21             0.30  \n",
       "91         2017.79            -0.11  \n",
       "95        17202.26            -2.47  \n",
       "103       16700.67             2.62  \n",
       "106        5269.83             2.40  \n",
       "115       10893.92            -3.85  \n",
       "118       19912.29             0.53  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Gray zone cases\n",
    "gray_zone_cases = all_comparisons[all_comparisons['winner'] == 'No Significant Difference']\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(f\"GRAY ZONE CASES (MAE difference < {GRAY_ZONE_THRESHOLD}%)\")\n",
    "print(\"=\"*80)\n",
    "print(f\"Total: {len(gray_zone_cases)}\")\n",
    "if len(gray_zone_cases) > 0:\n",
    "    print(\"\\nSample cases:\")\n",
    "    display(gray_zone_cases.head(20)[[\n",
    "        'unique_id', 'state', 'metric', 'ml_best_model', 'stats_best_model',\n",
    "        'ml_avg_mae', 'stats_avg_mae', 'pct_improvement'\n",
    "    ]])\n",
    "else:\n",
    "    print(\"No gray zone cases found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "BEST MODEL PERFORMANCE BREAKDOWN\n",
      "================================================================================\n",
      "\n",
      "ML Models Win Rate:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Times Selected</th>\n",
       "      <th>Times Won (Clear)</th>\n",
       "      <th>Win Rate (%)</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ml_best_model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LightGBM</th>\n",
       "      <td>255</td>\n",
       "      <td>67</td>\n",
       "      <td>26.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBoost</th>\n",
       "      <td>206</td>\n",
       "      <td>41</td>\n",
       "      <td>19.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomForest</th>\n",
       "      <td>143</td>\n",
       "      <td>31</td>\n",
       "      <td>21.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ridge</th>\n",
       "      <td>30</td>\n",
       "      <td>11</td>\n",
       "      <td>36.67</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Times Selected  Times Won (Clear)  Win Rate (%)\n",
       "ml_best_model                                                 \n",
       "LightGBM                  255                 67         26.27\n",
       "XGBoost                   206                 41         19.90\n",
       "RandomForest              143                 31         21.68\n",
       "Ridge                      30                 11         36.67"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Stats Models Win Rate:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Times Selected</th>\n",
       "      <th>Times Won (Clear)</th>\n",
       "      <th>Win Rate (%)</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stats_best_model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>HistoricAverage</th>\n",
       "      <td>225</td>\n",
       "      <td>143</td>\n",
       "      <td>63.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SARIMAX</th>\n",
       "      <td>157</td>\n",
       "      <td>118</td>\n",
       "      <td>75.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Naive</th>\n",
       "      <td>117</td>\n",
       "      <td>71</td>\n",
       "      <td>60.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WindowAverage</th>\n",
       "      <td>89</td>\n",
       "      <td>51</td>\n",
       "      <td>57.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SeasonalNaive</th>\n",
       "      <td>22</td>\n",
       "      <td>17</td>\n",
       "      <td>77.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ARIMAX</th>\n",
       "      <td>24</td>\n",
       "      <td>15</td>\n",
       "      <td>62.50</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Times Selected  Times Won (Clear)  Win Rate (%)\n",
       "stats_best_model                                                 \n",
       "HistoricAverage              225                143         63.56\n",
       "SARIMAX                      157                118         75.16\n",
       "Naive                        117                 71         60.68\n",
       "WindowAverage                 89                 51         57.30\n",
       "SeasonalNaive                 22                 17         77.27\n",
       "ARIMAX                        24                 15         62.50"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Model performance breakdown\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"BEST MODEL PERFORMANCE BREAKDOWN\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# ML models\n",
    "print(\"\\nML Models Win Rate:\")\n",
    "ml_model_wins = all_comparisons[all_comparisons['winner'] == 'ML']['ml_best_model'].value_counts()\n",
    "ml_model_total = all_comparisons['ml_best_model'].value_counts()\n",
    "ml_model_perf = pd.DataFrame({\n",
    "    'Times Selected': ml_model_total,\n",
    "    'Times Won (Clear)': ml_model_wins,\n",
    "    'Win Rate (%)': (ml_model_wins / ml_model_total * 100).fillna(0).round(2)\n",
    "}).sort_values('Times Won (Clear)', ascending=False)\n",
    "display(ml_model_perf)\n",
    "\n",
    "# Stats models\n",
    "print(\"\\n\\nStats Models Win Rate:\")\n",
    "stats_model_wins = all_comparisons[all_comparisons['winner'] == 'Stats']['stats_best_model'].value_counts()\n",
    "stats_model_total = all_comparisons['stats_best_model'].value_counts()\n",
    "stats_model_perf = pd.DataFrame({\n",
    "    'Times Selected': stats_model_total,\n",
    "    'Times Won (Clear)': stats_model_wins,\n",
    "    'Win Rate (%)': (stats_model_wins / stats_model_total * 100).fillna(0).round(2)\n",
    "}).sort_values('Times Won (Clear)', ascending=False)\n",
    "display(stats_model_perf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Create Visualizations and Dashboards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Dashboard creation function defined\n"
     ]
    }
   ],
   "source": [
    "# Function to create model-specific dashboard\n",
    "def create_model_dashboard(data, metric_name, approach, output_file):\n",
    "    \"\"\"\n",
    "    Create a dashboard for a specific metric and approach (ML or Stats)\n",
    "    \"\"\"\n",
    "    fig = plt.figure(figsize=(18, 10))\n",
    "    gs = GridSpec(2, 3, figure=fig, hspace=0.3, wspace=0.3)\n",
    "    \n",
    "    # Get appropriate model column\n",
    "    model_col = 'ml_best_model' if approach == 'ML' else 'stats_best_model'\n",
    "    mae_col = 'ml_avg_mae' if approach == 'ML' else 'stats_avg_mae'\n",
    "    \n",
    "    # Filter data by metric\n",
    "    metric_data = data[data['metric'] == metric_name].copy()\n",
    "    \n",
    "    # Color palette for models\n",
    "    models = metric_data[model_col].unique()\n",
    "    n_models = len(models)\n",
    "    if approach == 'ML':\n",
    "        colors = plt.cm.viridis(np.linspace(0.2, 0.9, n_models))\n",
    "    else:\n",
    "        colors = plt.cm.plasma(np.linspace(0.2, 0.9, n_models))\n",
    "    \n",
    "    # ----- Plot 1: Model Selection Frequency (Pie Chart) -----\n",
    "    ax1 = fig.add_subplot(gs[0, 0])\n",
    "    model_freq = metric_data[model_col].value_counts()\n",
    "    wedges, texts, autotexts = ax1.pie(model_freq, labels=model_freq.index, autopct='%1.1f%%',\n",
    "                                        colors=colors, startangle=90, \n",
    "                                        textprops={'fontsize': 10, 'weight': 'bold'})\n",
    "    \n",
    "    # Add total count in center\n",
    "    centre_circle = plt.Circle((0, 0), 0.70, fc='white')\n",
    "    ax1.add_artist(centre_circle)\n",
    "    ax1.text(0, 0, f'{len(metric_data)}', ha='center', va='center', \n",
    "             fontsize=32, weight='bold')\n",
    "    ax1.text(0, -0.15, 'series', ha='center', va='center', fontsize=12)\n",
    "    \n",
    "    ax1.set_title('Model Selection Frequency', fontsize=14, weight='bold', pad=20)\n",
    "    \n",
    "    # ----- Plot 2: Model Frequency by State -----\n",
    "    ax2 = fig.add_subplot(gs[0, 1])\n",
    "    \n",
    "    state_model_freq = {}\n",
    "    for state in STATES:\n",
    "        state_data = metric_data[metric_data['state'] == state]\n",
    "        state_model_freq[state] = state_data[model_col].value_counts()\n",
    "    \n",
    "    state_freq_df = pd.DataFrame(state_model_freq).fillna(0).T\n",
    "    state_freq_df.plot(kind='bar', ax=ax2, color=colors, width=0.8)\n",
    "    \n",
    "    ax2.set_title('Model Frequency by State', fontsize=14, weight='bold', pad=20)\n",
    "    ax2.set_xlabel('State', fontsize=12, weight='bold')\n",
    "    ax2.set_ylabel('Frequency', fontsize=12, weight='bold')\n",
    "    ax2.tick_params(axis='x', rotation=0, labelsize=11)\n",
    "    ax2.tick_params(axis='y', labelsize=10)\n",
    "    ax2.legend(title='Model', fontsize=9, title_fontsize=10, loc='upper right')\n",
    "    ax2.grid(axis='y', alpha=0.3)\n",
    "    \n",
    "    # ----- Plot 3: MAE Distribution by Model -----\n",
    "    ax3 = fig.add_subplot(gs[0, 2])\n",
    "    \n",
    "    model_order = model_freq.index.tolist()\n",
    "    mae_by_model = [metric_data[metric_data[model_col] == model][mae_col].values \n",
    "                    for model in model_order]\n",
    "    \n",
    "    bp = ax3.boxplot(mae_by_model, labels=model_order, patch_artist=True,\n",
    "                     showfliers=True, widths=0.6)\n",
    "    \n",
    "    for patch, color in zip(bp['boxes'], colors):\n",
    "        patch.set_facecolor(color)\n",
    "        patch.set_alpha(0.7)\n",
    "    \n",
    "    for element in ['whiskers', 'fliers', 'means', 'medians', 'caps']:\n",
    "        plt.setp(bp[element], color='black', linewidth=1.5)\n",
    "    \n",
    "    ax3.set_title('MAE Distribution by Model', fontsize=14, weight='bold', pad=20)\n",
    "    ax3.set_xlabel('Model', fontsize=12, weight='bold')\n",
    "    ax3.set_ylabel('MAE', fontsize=12, weight='bold')\n",
    "    ax3.tick_params(axis='x', rotation=45, labelsize=9)\n",
    "    ax3.tick_params(axis='y', labelsize=10)\n",
    "    ax3.grid(axis='y', alpha=0.3)\n",
    "    ax3.set_yscale('log')\n",
    "    \n",
    "    # ----- Plot 4: Mean MAE by Model -----\n",
    "    ax4 = fig.add_subplot(gs[1, :])\n",
    "    \n",
    "    mean_mae = metric_data.groupby(model_col)[mae_col].mean().sort_values(ascending=False)\n",
    "    counts = metric_data[model_col].value_counts()[mean_mae.index]\n",
    "    \n",
    "    bars = ax4.barh(range(len(mean_mae)), mean_mae.values, color=colors)\n",
    "    \n",
    "    ax4.set_yticks(range(len(mean_mae)))\n",
    "    ax4.set_yticklabels(mean_mae.index, fontsize=11, weight='bold')\n",
    "    ax4.set_xlabel('Mean MAE', fontsize=12, weight='bold')\n",
    "    ax4.set_title('Mean MAE by Model', fontsize=14, weight='bold', pad=20)\n",
    "    ax4.grid(axis='x', alpha=0.3)\n",
    "    ax4.invert_yaxis()\n",
    "    \n",
    "    # Add count labels\n",
    "    for i, (mae_val, count) in enumerate(zip(mean_mae.values, counts.values)):\n",
    "        ax4.text(mae_val, i, f'  {mae_val:,.0f} (n={count})', \n",
    "                va='center', ha='left', fontsize=10, weight='bold')\n",
    "    \n",
    "    # Main title\n",
    "    metric_full = 'Units Reimbursed' if metric_name == 'UR' else 'Number of Prescriptions'\n",
    "    approach_full = 'Machine Learning' if approach == 'ML' else 'Statistical'\n",
    "    fig.suptitle(f'{metric_full} - {approach_full} Models Analysis', \n",
    "                 fontsize=18, weight='bold', y=0.98)\n",
    "    \n",
    "    plt.savefig(output_file, dpi=300, bbox_inches='tight', facecolor='white')\n",
    "    print(f\"✓ Saved: {output_file}\")\n",
    "    plt.close()\n",
    "\n",
    "print(\"✓ Dashboard creation function defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating individual model dashboards...\n",
      "✓ Saved: C:\\Users\\Lilian\\OneDrive - purdue.edu\\VS code\\Data\\ATC\\Comparison\\Plots\\\\\n",
      "✓ Saved: C:\\Users\\Lilian\\OneDrive - purdue.edu\\VS code\\Data\\ATC\\Comparison\\Plots\\\\\n",
      "✓ Saved: C:\\Users\\Lilian\\OneDrive - purdue.edu\\VS code\\Data\\ATC\\Comparison\\Plots\\\\\n",
      "✓ Saved: C:\\Users\\Lilian\\OneDrive - purdue.edu\\VS code\\Data\\ATC\\Comparison\\Plots\\\\\n",
      "\n",
      "✓ All individual model dashboards created\n"
     ]
    }
   ],
   "source": [
    "# Create 4 individual model-specific dashboards\n",
    "print(\"Creating individual model dashboards...\")\n",
    "output_file = rf'C:\\Users\\{user}\\OneDrive - purdue.edu\\VS code\\Data\\ATC\\Comparison\\Plots\\\\'\n",
    "# 1. Units Reimbursed - ML Models\n",
    "create_model_dashboard(all_comparisons, 'UR', 'ML', output_file)\n",
    "\n",
    "# 2. Units Reimbursed - Stats Models\n",
    "create_model_dashboard(all_comparisons, 'UR', 'Stats',output_file)\n",
    "\n",
    "# 3. Number of Prescriptions - ML Models\n",
    "create_model_dashboard(all_comparisons, 'NoP', 'ML',output_file)\n",
    "\n",
    "# 4. Number of Prescriptions - Stats Models\n",
    "create_model_dashboard(all_comparisons, 'NoP', 'Stats',output_file)\n",
    "\n",
    "print(\"\\n✓ All individual model dashboards created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating overall comparison dashboard...\n",
      "✓ Saved: Dashboard_Overall_Comparison.png\n",
      "\n",
      "✓ Overall comparison dashboard created\n"
     ]
    }
   ],
   "source": [
    "# Create overall comparison dashboard\n",
    "print(\"Creating overall comparison dashboard...\")\n",
    "\n",
    "fig = plt.figure(figsize=(20, 12))\n",
    "gs = GridSpec(2, 3, figure=fig, hspace=0.3, wspace=0.3)\n",
    "\n",
    "# ----- Row 1: Units Reimbursed -----\n",
    "ur_data = all_comparisons[all_comparisons['metric'] == 'UR']\n",
    "\n",
    "# Overall Distribution\n",
    "ax1 = fig.add_subplot(gs[0, 0])\n",
    "winner_counts = ur_data['winner'].value_counts()\n",
    "colors_winner = [ML_COLOR if w == 'ML' else (GRAY_COLOR if w == 'No Significant Difference' else STATS_COLOR) \n",
    "                 for w in winner_counts.index]\n",
    "\n",
    "wedges, texts, autotexts = ax1.pie(winner_counts, labels=winner_counts.index, \n",
    "                                    autopct='%1.1f%%', colors=colors_winner,\n",
    "                                    startangle=90, textprops={'fontsize': 11, 'weight': 'bold'})\n",
    "\n",
    "centre_circle = plt.Circle((0, 0), 0.70, fc='white')\n",
    "ax1.add_artist(centre_circle)\n",
    "ax1.text(0, 0, f'{len(ur_data)}', ha='center', va='center', fontsize=32, weight='bold')\n",
    "ax1.text(0, -0.15, 'series', ha='center', va='center', fontsize=12)\n",
    "\n",
    "ax1.set_title('Units Reimbursed\\nOverall Distribution', fontsize=14, weight='bold', pad=20)\n",
    "\n",
    "# Win Rate by State\n",
    "ax2 = fig.add_subplot(gs[0, 1])\n",
    "ur_state_winners = ur_data.groupby(['state', 'winner']).size().unstack(fill_value=0)\n",
    "ur_state_pct = ur_state_winners.div(ur_state_winners.sum(axis=1), axis=0) * 100\n",
    "\n",
    "winner_order = ['ML', 'No Significant Difference', 'Stats']\n",
    "ur_state_pct = ur_state_pct.reindex(columns=winner_order, fill_value=0)\n",
    "\n",
    "ur_state_pct.plot(kind='bar', stacked=True, ax=ax2, \n",
    "                  color=[ML_COLOR, GRAY_COLOR, STATS_COLOR], width=0.7)\n",
    "\n",
    "ax2.set_title('Units Reimbursed\\nWin Rate by State', fontsize=14, weight='bold', pad=20)\n",
    "ax2.set_xlabel('State', fontsize=12, weight='bold')\n",
    "ax2.set_ylabel('Percentage (%)', fontsize=12, weight='bold')\n",
    "ax2.tick_params(axis='x', rotation=0, labelsize=11)\n",
    "ax2.legend(title='Winner', fontsize=9, title_fontsize=10)\n",
    "ax2.grid(axis='y', alpha=0.3)\n",
    "\n",
    "for container in ax2.containers:\n",
    "    ax2.bar_label(container, fmt='%.0f%%', label_type='center', fontsize=9, weight='bold')\n",
    "\n",
    "# Model Selection Frequency\n",
    "ax3 = fig.add_subplot(gs[0, 2])\n",
    "\n",
    "ur_ml_freq = ur_data['ml_best_model'].value_counts().head(8)\n",
    "ur_stats_freq = ur_data['stats_best_model'].value_counts().head(8)\n",
    "\n",
    "all_models = sorted(set(ur_ml_freq.index) | set(ur_stats_freq.index))\n",
    "model_freq_df = pd.DataFrame({\n",
    "    'ML Models': ur_ml_freq.reindex(all_models, fill_value=0),\n",
    "    'Stats Models': ur_stats_freq.reindex(all_models, fill_value=0)\n",
    "})\n",
    "\n",
    "model_freq_df.plot(kind='barh', ax=ax3, color=[ML_COLOR, STATS_COLOR], width=0.7)\n",
    "\n",
    "ax3.set_title('Units Reimbursed\\nModel Selection Frequency', fontsize=14, weight='bold', pad=20)\n",
    "ax3.set_xlabel('Times Selected as Best', fontsize=12, weight='bold')\n",
    "ax3.set_ylabel('')\n",
    "ax3.tick_params(axis='y', labelsize=10)\n",
    "ax3.legend(fontsize=10, loc='lower right')\n",
    "ax3.grid(axis='x', alpha=0.3)\n",
    "ax3.invert_yaxis()\n",
    "\n",
    "# ----- Row 2: Number of Prescriptions -----\n",
    "nop_data = all_comparisons[all_comparisons['metric'] == 'NoP']\n",
    "\n",
    "# Overall Distribution\n",
    "ax4 = fig.add_subplot(gs[1, 0])\n",
    "winner_counts_nop = nop_data['winner'].value_counts()\n",
    "colors_winner_nop = [ML_COLOR if w == 'ML' else (GRAY_COLOR if w == 'No Significant Difference' else STATS_COLOR) \n",
    "                     for w in winner_counts_nop.index]\n",
    "\n",
    "wedges, texts, autotexts = ax4.pie(winner_counts_nop, labels=winner_counts_nop.index,\n",
    "                                    autopct='%1.1f%%', colors=colors_winner_nop,\n",
    "                                    startangle=90, textprops={'fontsize': 11, 'weight': 'bold'})\n",
    "\n",
    "centre_circle = plt.Circle((0, 0), 0.70, fc='white')\n",
    "ax4.add_artist(centre_circle)\n",
    "ax4.text(0, 0, f'{len(nop_data)}', ha='center', va='center', fontsize=32, weight='bold')\n",
    "ax4.text(0, -0.15, 'series', ha='center', va='center', fontsize=12)\n",
    "\n",
    "ax4.set_title('Num Prescriptions\\nOverall Distribution', fontsize=14, weight='bold', pad=20)\n",
    "\n",
    "# Win Rate by State\n",
    "ax5 = fig.add_subplot(gs[1, 1])\n",
    "nop_state_winners = nop_data.groupby(['state', 'winner']).size().unstack(fill_value=0)\n",
    "nop_state_pct = nop_state_winners.div(nop_state_winners.sum(axis=1), axis=0) * 100\n",
    "\n",
    "nop_state_pct = nop_state_pct.reindex(columns=winner_order, fill_value=0)\n",
    "\n",
    "nop_state_pct.plot(kind='bar', stacked=True, ax=ax5,\n",
    "                   color=[ML_COLOR, GRAY_COLOR, STATS_COLOR], width=0.7)\n",
    "\n",
    "ax5.set_title('Num Prescriptions\\nWin Rate by State', fontsize=14, weight='bold', pad=20)\n",
    "ax5.set_xlabel('State', fontsize=12, weight='bold')\n",
    "ax5.set_ylabel('Percentage (%)', fontsize=12, weight='bold')\n",
    "ax5.tick_params(axis='x', rotation=0, labelsize=11)\n",
    "ax5.legend(title='Winner', fontsize=9, title_fontsize=10)\n",
    "ax5.grid(axis='y', alpha=0.3)\n",
    "\n",
    "for container in ax5.containers:\n",
    "    ax5.bar_label(container, fmt='%.0f%%', label_type='center', fontsize=9, weight='bold')\n",
    "\n",
    "# Model Selection Frequency\n",
    "ax6 = fig.add_subplot(gs[1, 2])\n",
    "\n",
    "nop_ml_freq = nop_data['ml_best_model'].value_counts().head(8)\n",
    "nop_stats_freq = nop_data['stats_best_model'].value_counts().head(8)\n",
    "\n",
    "all_models_nop = sorted(set(nop_ml_freq.index) | set(nop_stats_freq.index))\n",
    "model_freq_df_nop = pd.DataFrame({\n",
    "    'ML Models': nop_ml_freq.reindex(all_models_nop, fill_value=0),\n",
    "    'Stats Models': nop_stats_freq.reindex(all_models_nop, fill_value=0)\n",
    "})\n",
    "\n",
    "model_freq_df_nop.plot(kind='barh', ax=ax6, color=[ML_COLOR, STATS_COLOR], width=0.7)\n",
    "\n",
    "ax6.set_title('Num Prescriptions\\nModel Selection Frequency', fontsize=14, weight='bold', pad=20)\n",
    "ax6.set_xlabel('Times Selected as Best', fontsize=12, weight='bold')\n",
    "ax6.set_ylabel('')\n",
    "ax6.tick_params(axis='y', labelsize=10)\n",
    "ax6.legend(fontsize=10, loc='lower right')\n",
    "ax6.grid(axis='x', alpha=0.3)\n",
    "ax6.invert_yaxis()\n",
    "\n",
    "# Main title\n",
    "fig.suptitle('Overall Model Comparison Dashboard', fontsize=20, weight='bold', y=0.98)\n",
    "\n",
    "# Add footer note\n",
    "fig.text(0.5, 0.01, f'Gray Zone Threshold: < {GRAY_ZONE_THRESHOLD}% difference in MAE between approaches',\n",
    "         ha='center', fontsize=11, style='italic', color='gray')\n",
    "\n",
    "plt.savefig(output_file + \"Dashboard_Overall_Comparison.png\", \n",
    "            dpi=300, bbox_inches='tight', facecolor='white')\n",
    "print(f\"✓ Saved: Dashboard_Overall_Comparison.png\")\n",
    "plt.close()\n",
    "\n",
    "print(\"\\n✓ Overall comparison dashboard created\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Export Results to Excel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exporting results to Excel...\n",
      "✓ Results exported to: C:\\Users\\Lilian\\OneDrive - purdue.edu\\VS code\\Data\\ATC\\Comparison\\Detailed_Comparison_Results.xlsx\n"
     ]
    }
   ],
   "source": [
    "# Export detailed comparison to Excel\n",
    "print(\"Exporting results to Excel...\")\n",
    "output_file = rf\"C:\\Users\\{user}\\OneDrive - purdue.edu\\VS code\\Data\\ATC\\Comparison\\Detailed_Comparison_Results.xlsx\"\n",
    "\n",
    "with pd.ExcelWriter(output_file, engine='openpyxl') as writer:\n",
    "    # All comparisons\n",
    "    all_comparisons.to_excel(writer, sheet_name='All_Comparisons', index=False)\n",
    "    \n",
    "    # State-level summary\n",
    "    state_comparison.to_excel(writer, sheet_name='State_Summary')\n",
    "    \n",
    "    # Metric-level summary\n",
    "    metric_comparison.to_excel(writer, sheet_name='Metric_Summary')\n",
    "    \n",
    "    # Winner distribution\n",
    "    winner_summary.to_excel(writer, sheet_name='Winner_Distribution')\n",
    "    \n",
    "    # Top ML improvements (clear wins only)\n",
    "    if len(ml_clear_wins_df) > 0:\n",
    "        ml_clear_wins_df.nlargest(50, 'pct_improvement').to_excel(\n",
    "            writer, sheet_name='Top_ML_Wins', index=False\n",
    "        )\n",
    "    \n",
    "    # Top Stats improvements (clear wins only)\n",
    "    if len(stats_clear_wins_df) > 0:\n",
    "        stats_clear_wins_df.nsmallest(50, 'pct_improvement').to_excel(\n",
    "            writer, sheet_name='Top_Stats_Wins', index=False\n",
    "        )\n",
    "    \n",
    "    # Gray zone cases\n",
    "    if len(gray_zone_cases) > 0:\n",
    "        gray_zone_cases.to_excel(writer, sheet_name='Gray_Zone_Cases', index=False)\n",
    "    \n",
    "    # Model performance\n",
    "    ml_model_perf.to_excel(writer, sheet_name='ML_Model_Performance')\n",
    "    stats_model_perf.to_excel(writer, sheet_name='Stats_Model_Performance')\n",
    "    \n",
    "    # Model frequency\n",
    "    ml_freq_df.to_excel(writer, sheet_name='ML_Model_Frequency')\n",
    "    stats_freq_df.to_excel(writer, sheet_name='Stats_Model_Frequency')\n",
    "    \n",
    "    # Overall summary\n",
    "    overall_summary = pd.DataFrame([overall_stats]).T\n",
    "    overall_summary.columns = ['Value']\n",
    "    overall_summary.to_excel(writer, sheet_name='Overall_Summary')\n",
    "\n",
    "print(f\"✓ Results exported to: {output_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Summary and Key Findings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "KEY FINDINGS SUMMARY\n",
      "================================================================================\n",
      "Gray zone threshold: 5.0%\n",
      "\n",
      "1. OVERALL PERFORMANCE:\n",
      "   - ML models clearly won 150 out of 634 comparisons\n",
      "   - Stats models clearly won 415 comparisons\n",
      "   - No significant difference in 69 comparisons\n",
      "   - ML win rate: 23.7%\n",
      "   - Stats win rate: 65.5%\n",
      "   - Gray zone rate: 10.9%\n",
      "   - Average improvement when ML clearly wins: 24.17%\n",
      "   - Average improvement when Stats clearly wins: 300.54%\n",
      "\n",
      "2. BY STATE:\n",
      "   - MI: ML=44 (28.2%), Stats=89 (57.1%), Gray=23 (14.7%)\n",
      "   - IN: ML=34 (21.2%), Stats=110 (68.8%), Gray=16 (10.0%)\n",
      "   - IL: ML=38 (24.4%), Stats=102 (65.4%), Gray=16 (10.3%)\n",
      "   - OH: ML=34 (21.0%), Stats=114 (70.4%), Gray=14 (8.6%)\n",
      "\n",
      "3. BY METRIC:\n",
      "   - Units Reimbursed: ML=74 (23.3%), Stats=207 (65.3%), Gray=36 (11.4%)\n",
      "   - Number of Prescriptions: ML=76 (24.0%), Stats=208 (65.6%), Gray=33 (10.4%)\n",
      "\n",
      "4. MOST FREQUENTLY SELECTED MODELS:\n",
      "   ML Models:\n",
      "      - LightGBM: 255 (40.2%)\n",
      "      - XGBoost: 206 (32.5%)\n",
      "      - RandomForest: 143 (22.6%)\n",
      "   Stats Models:\n",
      "      - HistoricAverage: 225 (35.5%)\n",
      "      - SARIMAX: 157 (24.8%)\n",
      "      - Naive: 117 (18.5%)\n",
      "\n",
      "5. BEST PERFORMING MODELS (Clear Wins):\n",
      "   ML Models:\n",
      "      - LightGBM: 67 clear wins\n",
      "      - XGBoost: 41 clear wins\n",
      "      - RandomForest: 31 clear wins\n",
      "   Stats Models:\n",
      "      - HistoricAverage: 143 clear wins\n",
      "      - SARIMAX: 118 clear wins\n",
      "      - Naive: 71 clear wins\n",
      "\n",
      "6. LARGEST IMPROVEMENTS:\n",
      "   - Best ML improvement: OH_G02 (67.06%)\n",
      "   - Best Stats improvement: IN_H04 (65216.70%)\n",
      "\n",
      "================================================================================\n",
      "ANALYSIS COMPLETE\n",
      "================================================================================\n",
      "\n",
      "Generated files:\n",
      "1. Dashboard_UR_ML.png - Units Reimbursed ML Models\n",
      "2. Dashboard_UR_Stats.png - Units Reimbursed Stats Models\n",
      "3. Dashboard_NoP_ML.png - Number of Prescriptions ML Models\n",
      "4. Dashboard_NoP_Stats.png - Number of Prescriptions Stats Models\n",
      "5. Dashboard_Overall_Comparison.png - Overall Comparison\n",
      "6. Model_Comparison_Results.xlsx - Detailed Excel Report\n",
      "\n",
      "All files saved to: /mnt/user-data/outputs/\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"KEY FINDINGS SUMMARY\")\n",
    "print(\"=\"*80)\n",
    "print(f\"Gray zone threshold: {GRAY_ZONE_THRESHOLD}%\")\n",
    "\n",
    "print(\"\\n1. OVERALL PERFORMANCE:\")\n",
    "print(f\"   - ML models clearly won {overall_stats['ML Wins']} out of {overall_stats['Total Drug Classes']} comparisons\")\n",
    "print(f\"   - Stats models clearly won {overall_stats['Stats Wins']} comparisons\")\n",
    "print(f\"   - No significant difference in {overall_stats['No Significant Difference']} comparisons\")\n",
    "print(f\"   - ML win rate: {overall_stats['ML Win Rate (%)']:.1f}%\")\n",
    "print(f\"   - Stats win rate: {overall_stats['Stats Win Rate (%)']:.1f}%\")\n",
    "print(f\"   - Gray zone rate: {overall_stats['Gray Zone Rate (%)']:.1f}%\")\n",
    "if len(ml_clear_wins_df) > 0:\n",
    "    print(f\"   - Average improvement when ML clearly wins: {ml_clear_wins_df['pct_improvement'].mean():.2f}%\")\n",
    "if len(stats_clear_wins_df) > 0:\n",
    "    print(f\"   - Average improvement when Stats clearly wins: {abs(stats_clear_wins_df['pct_improvement'].mean()):.2f}%\")\n",
    "\n",
    "print(\"\\n2. BY STATE:\")\n",
    "for state in STATES:\n",
    "    state_data = all_comparisons[all_comparisons['state'] == state]\n",
    "    ml_wins = (state_data['winner'] == 'ML').sum()\n",
    "    stats_wins = (state_data['winner'] == 'Stats').sum()\n",
    "    gray = (state_data['winner'] == 'No Significant Difference').sum()\n",
    "    total = len(state_data)\n",
    "    print(f\"   - {state}: ML={ml_wins} ({ml_wins/total*100:.1f}%), Stats={stats_wins} ({stats_wins/total*100:.1f}%), Gray={gray} ({gray/total*100:.1f}%)\")\n",
    "\n",
    "print(\"\\n3. BY METRIC:\")\n",
    "for metric in METRICS:\n",
    "    metric_data = all_comparisons[all_comparisons['metric'] == metric]\n",
    "    ml_wins = (metric_data['winner'] == 'ML').sum()\n",
    "    stats_wins = (metric_data['winner'] == 'Stats').sum()\n",
    "    gray = (metric_data['winner'] == 'No Significant Difference').sum()\n",
    "    total = len(metric_data)\n",
    "    metric_name = 'Units Reimbursed' if metric == 'UR' else 'Number of Prescriptions'\n",
    "    print(f\"   - {metric_name}: ML={ml_wins} ({ml_wins/total*100:.1f}%), Stats={stats_wins} ({stats_wins/total*100:.1f}%), Gray={gray} ({gray/total*100:.1f}%)\")\n",
    "\n",
    "print(\"\\n4. MOST FREQUENTLY SELECTED MODELS:\")\n",
    "print(\"   ML Models:\")\n",
    "for model, count in ml_model_freq.head(3).items():\n",
    "    pct = count / len(all_comparisons) * 100\n",
    "    print(f\"      - {model}: {count} ({pct:.1f}%)\")\n",
    "print(\"   Stats Models:\")\n",
    "for model, count in stats_model_freq.head(3).items():\n",
    "    pct = count / len(all_comparisons) * 100\n",
    "    print(f\"      - {model}: {count} ({pct:.1f}%)\")\n",
    "\n",
    "print(\"\\n5. BEST PERFORMING MODELS (Clear Wins):\")\n",
    "print(\"   ML Models:\")\n",
    "if len(ml_model_wins) > 0:\n",
    "    for model, count in ml_model_wins.head(3).items():\n",
    "        print(f\"      - {model}: {count} clear wins\")\n",
    "print(\"   Stats Models:\")\n",
    "if len(stats_model_wins) > 0:\n",
    "    for model, count in stats_model_wins.head(3).items():\n",
    "        print(f\"      - {model}: {count} clear wins\")\n",
    "\n",
    "print(\"\\n6. LARGEST IMPROVEMENTS:\")\n",
    "if len(ml_clear_wins_df) > 0:\n",
    "    best_ml = ml_clear_wins_df.nlargest(1, 'pct_improvement').iloc[0]\n",
    "    print(f\"   - Best ML improvement: {best_ml['unique_id']} ({best_ml['pct_improvement']:.2f}%)\")\n",
    "if len(stats_clear_wins_df) > 0:\n",
    "    best_stats = stats_clear_wins_df.nsmallest(1, 'pct_improvement').iloc[0]\n",
    "    print(f\"   - Best Stats improvement: {best_stats['unique_id']} ({abs(best_stats['pct_improvement']):.2f}%)\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"ANALYSIS COMPLETE\")\n",
    "print(\"=\"*80)\n",
    "print(\"\\nGenerated files:\")\n",
    "print(\"1. Dashboard_UR_ML.png - Units Reimbursed ML Models\")\n",
    "print(\"2. Dashboard_UR_Stats.png - Units Reimbursed Stats Models\")\n",
    "print(\"3. Dashboard_NoP_ML.png - Number of Prescriptions ML Models\")\n",
    "print(\"4. Dashboard_NoP_Stats.png - Number of Prescriptions Stats Models\")\n",
    "print(\"5. Dashboard_Overall_Comparison.png - Overall Comparison\")\n",
    "print(\"6. Model_Comparison_Results.xlsx - Detailed Excel Report\")\n",
    "print(\"\\nAll files saved to: /mnt/user-data/outputs/\")\n",
    "print(\"=\"*80)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
