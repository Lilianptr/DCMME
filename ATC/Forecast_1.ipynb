{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "14de25d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings \n",
    "from utilsforecast.plotting import plot_series\n",
    "from utilsforecast.evaluation import evaluate\n",
    "from utilsforecast.losses import *\n",
    "from statsforecast import StatsForecast\n",
    "from statsforecast.models import (\n",
    "    Naive,WindowAverage,\n",
    "    AutoARIMA,SeasonalNaive,HoltWinters,\n",
    "    CrostonClassic as Croston, HistoricAverage,DynamicOptimizedTheta as DOT,\n",
    "    SeasonalNaive\n",
    ")\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")  # To ignore warnings from pandas/numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d75a6c67",
   "metadata": {},
   "outputs": [],
   "source": [
    "user=\"lholguin\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93281f08",
   "metadata": {},
   "source": [
    "### Statistical Models - Dataset with pop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e8b5d6df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_prepare_data(filepath, states=None):\n",
    "\n",
    "    df = pd.read_csv(filepath)\n",
    "    \n",
    "    if states is not None:\n",
    "        if isinstance(states, str):\n",
    "            states = [states]\n",
    "        print(f\"Filtering data for states: {states}\")\n",
    "        df=df[df['State'].isin(states)].copy()\n",
    "        print(f\"Filtered to {len(df)} rows across {df['State'].nunique()} state(s).\")\n",
    "\n",
    "        if len(df) == 0:\n",
    "            raise ValueError(\"No data available for the specified states.\")\n",
    "    \n",
    "    df['unique_id'] = df['State'] + '_' + df['ATC2 Class']\n",
    "    df['ds'] = pd.to_datetime(df['Period'])\n",
    "    df = df.sort_values(['unique_id','ds']).reset_index(drop=True)\n",
    "\n",
    "    #Preparing dataframes for statsforecast\n",
    "    df_units=df[['unique_id','ds','Units Reimbursed']].copy()\n",
    "    df_units.columns=['unique_id','ds','y']\n",
    "\n",
    "    df_prescriptions=df[['unique_id','ds','Number of Prescriptions']].copy()\n",
    "    df_prescriptions.columns=['unique_id','ds','y']\n",
    "\n",
    "    return df_units, df_prescriptions, df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d45ba352",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_models():\n",
    "\n",
    "    models = [\n",
    "        Naive(), HistoricAverage(), WindowAverage(window_size=4),\n",
    "        SeasonalNaive(season_length=4), AutoARIMA(seasonal=False,alias=\"ARIMA\"),\n",
    "        AutoARIMA(seasonal=True,season_length=4,alias=\"SARIMA\"),\n",
    "        HoltWinters(season_length=4), DOT(season_length=4),\n",
    "    ]\n",
    "    return models\n",
    "\n",
    "def train_and_forecast(df,target_name, h=4):\n",
    "    \n",
    "    sf=StatsForecast(models=get_models(),freq='QS', n_jobs=-1,fallback_model=SeasonalNaive(season_length=4))\n",
    "    \n",
    "    forecasts_df=sf.forecast(df=df, h=h, level=[95])\n",
    "    return forecasts_df, sf\n",
    "\n",
    "def evaluate_train_test(df,target_name,test_size=4,h=4):\n",
    "\n",
    "    train=df.groupby('unique_id').apply(lambda x: x.iloc[:-test_size]).reset_index(drop=True)\n",
    "    test=df.groupby('unique_id').apply(lambda x: x.iloc[-test_size:]).reset_index(drop=True)\n",
    "\n",
    "    sf=StatsForecast(models=get_models(),freq='QS', n_jobs=-1,fallback_model=SeasonalNaive(season_length=4))\n",
    "    sf.fit(df=train)\n",
    "    preds=sf.predict(h=h)\n",
    "    preds_df=pd.merge(test, preds, on=['unique_id','ds'], how='left')\n",
    "\n",
    "    models=[col for col in preds_df.columns if col not in ['unique_id','ds']]\n",
    "    eval_df=evaluate(preds_df,metrics=[mse, mae, rmse], models=models)\n",
    "    eval_df['best_model']=eval_df[models].idxmin(axis=1)\n",
    "    print(eval_df.groupby('metric')['best_model'].value_counts().unstack(fill_value=0))\n",
    "    return preds_df, eval_df    \n",
    "\n",
    "def evaluate_model_cross(df,target_name,n_windows=5, h=4):\n",
    "    \n",
    "    sf=StatsForecast(models=get_models(),freq='QS', n_jobs=-1,fallback_model=SeasonalNaive(season_length=4))\n",
    "\n",
    "    print(f\"Running cross-validation for {target_name} with {n_windows} windows and horizon {h}...\")\n",
    "    cv_df=sf.cross_validation(df=df, h=h, n_windows=n_windows, step_size=h)\n",
    "    \n",
    "    # Errors metrics calculation\n",
    "    models=[col for col in cv_df.columns if col not in ['unique_id','ds','y','cutoff']]\n",
    "    \n",
    "    eval_df=evaluate(cv_df,metrics=[mse, mae, rmse], models=models)\n",
    "    mae_df=eval_df[eval_df['metric']=='mae'].copy()\n",
    "    mae_df['best_model']=mae_df[models].idxmin(axis=1)\n",
    "    print(\"\\nCross-validation Best Model Summary based on MAE:\")\n",
    "    print(mae_df['best_model'].value_counts())\n",
    "\n",
    "    return eval_df, cv_df, mae_df\n",
    "    \n",
    "\n",
    "    print(f\"\\nBest Models Summary for {target_name}:\")\n",
    "    print(evaluation_df_sumary['best_model'].value_counts())\n",
    "    return eval_df, cv_df, mae_df\n",
    "\n",
    "def get_best_model_forecast(forecasts_df,evaluation_df_sumary):\n",
    "\n",
    "    best_info=evaluation_df_sumary[['unique_id','best_model']]\n",
    "    forecasts_with_best=forecasts_df.reset_index().merge(best_info, on='unique_id', how='left')\n",
    "    result=forecasts_with_best[['unique_id','ds']].copy()\n",
    "    \n",
    "    result['best_forecast']=forecasts_with_best.apply(\n",
    "        lambda row: row[row['best_model']], axis=1)\n",
    "\n",
    "    #confidence intervals\n",
    "    for level in [95]:\n",
    "        lo_col = f'best_forecast-lo-{level}'\n",
    "        hi_col = f'best_forecast-hi-{level}'\n",
    "        \n",
    "        result[lo_col] = forecasts_with_best.apply(\n",
    "            lambda row: row.get(f\"{row['best_model']}-lo-{level}\", np.nan), axis=1\n",
    "        )\n",
    "        result[hi_col] = forecasts_with_best.apply(\n",
    "            lambda row: row.get(f\"{row['best_model']}-hi-{level}\", np.nan), axis=1\n",
    "        )\n",
    "    result=result.merge(best_info, on='unique_id')\n",
    "    return result\n",
    "\n",
    "def save_results(forecasts_df, best_forecasts_df, evaluation_cv_df, evaluation_traintest_df, target_name, save_path=None):\n",
    "    \n",
    "    if save_path is None or save_path == \"\":\n",
    "        save_path = os.getcwd()\n",
    "    \n",
    "    # Create directory if it doesn't exist\n",
    "    os.makedirs(save_path, exist_ok=True)\n",
    "    \n",
    "    prefix = target_name.lower().replace(' ', '_')\n",
    "    \n",
    "    evaluation_traintest_df.to_csv(\n",
    "        os.path.join(save_path, f\"{prefix}_train_test_evaluation.csv\"), index=False\n",
    "    )\n",
    "    \n",
    "    forecasts_df.reset_index().to_csv(\n",
    "        os.path.join(save_path, f\"{prefix}_all_model_forecasts.csv\"), index=False\n",
    "    )\n",
    "    #saving evaluate_train_forecast results\n",
    "    best_forecasts_df.to_csv(\n",
    "        os.path.join(save_path, f\"{prefix}_best_model_forecasts.csv\"), index=False\n",
    "    )\n",
    "    evaluation_df.to_csv(\n",
    "        os.path.join(save_path, f\"{prefix}_model_evaluation.csv\"), index=False\n",
    "    )\n",
    "    \n",
    "    print(f\"âœ“ Results saved to: {save_path}\")\n",
    "    \n",
    "def plot_sample_forecasts(df,forecasts_df,target_name,n_samples=4):\n",
    "\n",
    "    unique_ids = df['unique_id'].unique()\n",
    "    sample_ids = np.random.choice(unique_ids, min(n_samples, len(unique_ids)), replace=False)\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "    axes = axes.flatten()\n",
    "    \n",
    "    for idx, uid in enumerate(sample_ids):\n",
    "        ax = axes[idx]\n",
    "        \n",
    "        # Historical data\n",
    "        hist_data = df[df['unique_id'] == uid]\n",
    "        ax.plot(hist_data['ds'], hist_data['y'], 'o-', label='Historical', linewidth=2)\n",
    "        \n",
    "        # Forecast data (just plot one model for clarity - SeasonalNaive)\n",
    "        forecast_data = forecasts_df.reset_index()\n",
    "        forecast_data = forecast_data[forecast_data['unique_id'] == uid]\n",
    "        \n",
    "        if 'SeasonalNaive' in forecast_data.columns:\n",
    "            ax.plot(forecast_data['ds'], forecast_data['SeasonalNaive'], \n",
    "                   's-', label='SeasonalNaive', linewidth=2)\n",
    "        \n",
    "        if 'AutoARIMA' in forecast_data.columns:\n",
    "            ax.plot(forecast_data['ds'], forecast_data['AutoARIMA'], \n",
    "                   '^-', label='AutoARIMA', linewidth=2)\n",
    "        \n",
    "        ax.set_title(f'{uid}', fontsize=10, fontweight='bold')\n",
    "        ax.set_xlabel('Date')\n",
    "        ax.set_ylabel(target_name)\n",
    "        ax.legend()\n",
    "        ax.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    #\n",
    "    # (f'{target_name.lower().replace(\" \", \"_\")}_sample_forecasts.png', dpi=150, bbox_inches='tight')\n",
    "    print(f\"âœ“ Plot saved: {target_name.lower().replace(' ', '_')}_sample_forecasts.png\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9de0f8a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(filepath, states=None, h=4, run_cv=True, n_windows=5,save_path=None):\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*70); print(\"STATSFORECAST PHARMACEUTICAL FORECASTING PIPELINE\"); print(\"=\"*70)\n",
    "\n",
    "    print(\"\\n1. Loading and preparing data...\")\n",
    "    df_units, df_prescriptions, df_original = load_and_prepare_data(filepath, states=states)\n",
    "    \n",
    "    # Display summary\n",
    "    print(f\"\\nData Summary:\")\n",
    "    print(f\"  â€¢ Total unique series: {df_units['unique_id'].nunique()}\")\n",
    "    min_date = df_units['ds'].min()\n",
    "    max_date = df_units['ds'].max()\n",
    "    print(f\"  â€¢ Date range: {min_date.year}-Q{min_date.quarter} to {max_date.year}-Q{max_date.quarter}\")\n",
    "    if states is not None:\n",
    "        print(f\"  â€¢ Filtered states: {', '.join(states)}\")\n",
    "    \n",
    "\n",
    "    print(\"\\n\" + \"=\"*70); print(\"UNITS REIMBURSED\"); print(\"=\"*70)\n",
    "    \n",
    "    print(\"\\n2. Training models and generating forecasts...\")\n",
    "    forecasts_units, sf_units = train_and_forecast(df_units, \"Units Reimbursed\", h=h)\n",
    "\n",
    "    print(\"\\n3. Evaluating models on training/test split...\")\n",
    "    eval_traintest_units, preds_traintest_units = evaluate_train_test(\n",
    "        df_units, \"Units Reimbursed\", test_size=h, h=h\n",
    "    )\n",
    "    \n",
    "    if run_cv:\n",
    "        print(\"\\n4. Running cross-validation...\")\n",
    "        cv_units, eval_units, eval_summary_units = evaluate_model_cross(\n",
    "            df_units, \"Units Reimbursed\", n_windows=n_windows, h=h\n",
    "        )\n",
    "        \n",
    "        print(\"\\n5. Selecting best forecasts...\")\n",
    "        best_forecasts_units = get_best_model_forecast(forecasts_units, eval_summary_units)\n",
    "        \n",
    "        print(\"\\n6. Saving results...\")\n",
    "        save_results(forecasts_units, best_forecasts_units, eval_units, eval_traintest_units, \"Units Reimbursed\",save_path=save_path)\n",
    "    else:\n",
    "        eval_units = None\n",
    "        best_forecasts_units = forecasts_units.reset_index()\n",
    "        print(\"\\n Skipping cross-validation (run_cv=False)\")\n",
    "    \n",
    "    # Plot sample forecasts\n",
    "    print(\"\\nGenerating forecast plots...\")\n",
    "    plot_sample_forecasts(df_units, forecasts_units, \"Units Reimbursed\", n_samples=4)\n",
    "    \n",
    "\n",
    "    print(\"\\n\" + \"=\"*70); print(\"NUMBER OF PRESCRIPTIONS\"); print(\"=\"*70)\n",
    "    \n",
    "    print(\"\\n2. Training models and generating forecasts...\")\n",
    "    forecasts_prescriptions, sf_prescriptions = train_and_forecast(\n",
    "        df_prescriptions, \"Number of Prescriptions\", h=h\n",
    "    )\n",
    "\n",
    "    print(\"\\n3. Evaluating models on training/test split...\")\n",
    "    eval_traintest_prescriptions, preds_traintest_prescriptions = evaluate_train_test(\n",
    "        df_prescriptions, \"Number of Prescriptions\", test_size=h, h=h\n",
    "    )\n",
    "    \n",
    "    if run_cv:\n",
    "        print(\"\\n4. Running cross-validation...\")\n",
    "        cv_prescriptions, eval_prescriptions, eval_summary_prescriptions = evaluate_model_cross(\n",
    "            df_prescriptions, \"Number of Prescriptions\", n_windows=n_windows, h=h\n",
    "        )\n",
    "        \n",
    "        print(\"\\n5. Selecting best forecasts...\")\n",
    "        best_forecasts_prescriptions = get_best_model_forecast(\n",
    "            forecasts_prescriptions, eval_summary_prescriptions\n",
    "        )\n",
    "        \n",
    "        print(\"\\n6. Saving results...\")\n",
    "        save_results(\n",
    "            forecasts_prescriptions, best_forecasts_prescriptions, \n",
    "            eval_prescriptions, eval_traintest_prescriptions, \"Number of Prescriptions\",save_path=save_path\n",
    "        )\n",
    "    else:\n",
    "        eval_prescriptions = None\n",
    "        best_forecasts_prescriptions = forecasts_prescriptions.reset_index()\n",
    "        print(\"\\n Skipping cross-validation (run_cv=False)\")\n",
    "    \n",
    "    # Plot sample forecasts\n",
    "    print(\"\\n Generating forecast plots...\")\n",
    "    plot_sample_forecasts(\n",
    "        df_prescriptions, \n",
    "        forecasts_prescriptions, \n",
    "        \"Number of Prescriptions\", \n",
    "        n_samples=4\n",
    "    )\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*70); print(\"âœ… PIPELINE COMPLETE!\"); print(\"=\"*70)\n",
    "    \n",
    "    state_info = f\"{', '.join(states)}\" if states else \"ALL\"\n",
    "    print(f\"\\n Forecasts generated for state(s): {state_info}\")\n",
    "    print(f\"Forecast horizon: {h} quarters ahead\")\n",
    "    \n",
    "    if run_cv:\n",
    "        print(f\"\\n All files generated:\")\n",
    "    \n",
    "    print(f\"\\nðŸ“Š Generated Plots:\")\n",
    "    print(f\"   â€¢ units_reimbursed_sample_forecasts.png\")\n",
    "    print(f\"   â€¢ number_of_prescriptions_sample_forecasts.png\")\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    \n",
    "    # Optional: Return results for programmatic access\n",
    "    return {\n",
    "        'units': {\n",
    "            'forecasts': forecasts_units,\n",
    "            'best_forecasts': best_forecasts_units if run_cv else None,\n",
    "            'evaluation': eval_units if run_cv else None,\n",
    "        },\n",
    "        'prescriptions': {\n",
    "            'forecasts': forecasts_prescriptions,\n",
    "            'best_forecasts': best_forecasts_prescriptions if run_cv else None,\n",
    "            'evaluation': eval_prescriptions if run_cv else None,\n",
    "        }\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5dfdb507",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path_save=rf\"C:\\Users\\{user}\\OneDrive - purdue.edu\\VS code\\Data\\ATC\\Forecast\\\\\"\n",
    "os.path.isdir(path_save)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0ca3274c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "STATSFORECAST PHARMACEUTICAL FORECASTING PIPELINE\n",
      "======================================================================\n",
      "\n",
      "1. Loading and preparing data...\n",
      "Filtering data for states: ['IN']\n",
      "Filtered to 2971 rows across 1 state(s).\n",
      "\n",
      "Data Summary:\n",
      "  â€¢ Total unique series: 83\n",
      "  â€¢ Date range: 2016-Q1 to 2024-Q4\n",
      "  â€¢ Filtered states: IN\n",
      "\n",
      "======================================================================\n",
      "UNITS REIMBURSED\n",
      "======================================================================\n",
      "\n",
      "2. Training models and generating forecasts...\n",
      "\n",
      "3. Evaluating models on training/test split...\n",
      "best_model   y\n",
      "metric        \n",
      "mae         83\n",
      "mse         83\n",
      "rmse        83\n",
      "\n",
      "4. Running cross-validation...\n",
      "Running cross-validation for Units Reimbursed with 5 windows and horizon 4...\n",
      "\n",
      "Cross-validation Best Model Summary based on MAE:\n",
      "best_model\n",
      "Naive                    106\n",
      "HoltWinters               69\n",
      "HistoricAverage           67\n",
      "ARIMA                     50\n",
      "WindowAverage             42\n",
      "SeasonalNaive             32\n",
      "DynamicOptimizedTheta     30\n",
      "SARIMA                    19\n",
      "Name: count, dtype: int64\n",
      "\n",
      "5. Selecting best forecasts...\n",
      "\n",
      "6. Saving results...\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'evaluation_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[28]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      3\u001b[39m path_save=\u001b[33mrf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mC:\u001b[39m\u001b[33m\\\u001b[39m\u001b[33mUsers\u001b[39m\u001b[33m\\\u001b[39m\u001b[38;5;132;01m{\u001b[39;00muser\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\\\u001b[39m\u001b[33mOneDrive - purdue.edu\u001b[39m\u001b[33m\\\u001b[39m\u001b[33mVS code\u001b[39m\u001b[33m\\\u001b[39m\u001b[33mData\u001b[39m\u001b[33m\\\u001b[39m\u001b[33mATC\u001b[39m\u001b[33m\\\u001b[39m\u001b[33mForecast\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[34m__name__\u001b[39m == \u001b[33m\"\u001b[39m\u001b[33m__main__\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcsv_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstates\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mIN\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mh\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m4\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_cv\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_windows\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43msave_path\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpath_save\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[26]\u001b[39m\u001b[32m, line 38\u001b[39m, in \u001b[36mmain\u001b[39m\u001b[34m(filepath, states, h, run_cv, n_windows, save_path)\u001b[39m\n\u001b[32m     35\u001b[39m     best_forecasts_units = get_best_model_forecast(forecasts_units, eval_summary_units)\n\u001b[32m     37\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m6. Saving results...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m38\u001b[39m     \u001b[43msave_results\u001b[49m\u001b[43m(\u001b[49m\u001b[43mforecasts_units\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbest_forecasts_units\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meval_units\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meval_traintest_units\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mUnits Reimbursed\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43msave_path\u001b[49m\u001b[43m=\u001b[49m\u001b[43msave_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     39\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     40\u001b[39m     eval_units = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[25]\u001b[39m\u001b[32m, line 101\u001b[39m, in \u001b[36msave_results\u001b[39m\u001b[34m(forecasts_df, best_forecasts_df, evaluation_cv_df, evaluation_traintest_df, target_name, save_path)\u001b[39m\n\u001b[32m     97\u001b[39m \u001b[38;5;66;03m#saving evaluate_train_forecast results\u001b[39;00m\n\u001b[32m     98\u001b[39m best_forecasts_df.to_csv(\n\u001b[32m     99\u001b[39m     os.path.join(save_path, \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mprefix\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m_best_model_forecasts.csv\u001b[39m\u001b[33m\"\u001b[39m), index=\u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m    100\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m101\u001b[39m \u001b[43mevaluation_df\u001b[49m.to_csv(\n\u001b[32m    102\u001b[39m     os.path.join(save_path, \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mprefix\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m_model_evaluation.csv\u001b[39m\u001b[33m\"\u001b[39m), index=\u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m    103\u001b[39m )\n\u001b[32m    105\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mâœ“ Results saved to: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msave_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mNameError\u001b[39m: name 'evaluation_df' is not defined"
     ]
    }
   ],
   "source": [
    "#path to the pre-built dataset\n",
    "csv_path=rf\"C:\\Users\\{user}\\OneDrive - purdue.edu\\VS code\\Data\\ATC\\merged_data\\Prebuilt_panels\\P1_nopop.csv\"\n",
    "path_save=rf\"C:\\Users\\{user}\\OneDrive - purdue.edu\\VS code\\Data\\ATC\\Forecast\"\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main(filepath=csv_path, states=['IN'], h=4, run_cv=True, n_windows=5,save_path=path_save)\n",
    "  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
