{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14de25d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings \n",
    "from utilsforecast.plotting import plot_series\n",
    "from utilsforecast.evaluation import evaluate\n",
    "from utilsforecast.losses import *\n",
    "from statsforecast import StatsForecast\n",
    "from statsforecast.models import Naive, HistoricAverage, WindowAverage, SeasonalNaive, AutoARIMA\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")  # To ignore warnings from pandas/numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19dad7a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "user=\"Lilian\"\n",
    "#Read the panel\n",
    "base_path=rf\"C:\\Users\\{user}\\OneDrive - purdue.edu\\VS code\\Data\\ATC\\merged_data\\prebuilt_panels\"\n",
    "panel_df=pd.read_csv(os.path.join(base_path,\"P1_nopop.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38b89de7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter to Indiana and sort by ATC2 Class and Period\n",
    "df_in = panel_df[panel_df[\"State\"] == \"IN\"].copy()\n",
    "\n",
    "# Filter to period range 2017Q1 to 2024Q4\n",
    "df_in = df_in[(df_in[\"Period\"] >= \"2017Q1\") & (df_in[\"Period\"] <= \"2024Q4\")]\n",
    "df_in = df_in.sort_values([\"ATC2 Class\", \"Period\"]).reset_index(drop=True)\n",
    "\n",
    "print(f\"Indiana data shape: {df_in.shape}\")\n",
    "print(f\"Period range: {df_in['Period'].min()} to {df_in['Period'].max()}\")\n",
    "print(f\"Number of ATC2 classes: {df_in['ATC2 Class'].nunique()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f63643ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "h = 4  # Number of quarters to forecast\n",
    "\n",
    "# Define train-test split: training through 2023Q4, testing from 2024Q1 onward\n",
    "train_end = \"2023Q4\"\n",
    "test_start = \"2024Q1\"\n",
    "\n",
    "# Define target variables\n",
    "target_vars = [\"Number of Prescriptions\", \"Units Reimbursed\"]\n",
    "atc2_classes = df_in[\"ATC2 Class\"].unique()\n",
    "\n",
    "print(f\"Forecast horizon: {h} quarters\")\n",
    "print(f\"Training period: up to {train_end}\"); print(f\"Test period: {test_start} onward\")\n",
    "print(f\"Target variables: {target_vars}\"); print(f\"ATC2 classes to process: {len(atc2_classes)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "208e2f76",
   "metadata": {},
   "outputs": [],
   "source": [
    "def historical_mean_forecast(train_values, h):\n",
    "    #Forecast using the training mean repeated h times\n",
    "    return np.full(h, train_values.mean())\n",
    "\n",
    "def naive_forecast(train_values, h):\n",
    "    #Forecast using the last observed training value repeated h times\n",
    "    return np.full(h, train_values.iloc[-1])\n",
    "\n",
    "def seasonal_naive_forecast(train_values, h, season_length=4):\n",
    "    #Forecast using seasonal naive (repeat last season_length observations)\n",
    "    last_season = train_values.iloc[-season_length:].values\n",
    "    # Tile the last season to cover the forecast horizon\n",
    "    n_full_cycles = h // season_length\n",
    "    remainder = h % season_length\n",
    "    forecast = np.tile(last_season, n_full_cycles)\n",
    "    if remainder > 0:\n",
    "        forecast = np.concatenate([forecast, last_season[:remainder]])\n",
    "    return forecast\n",
    "\n",
    "def autoarima_forecast(train_values, h):\n",
    "    #Forecast using AutoARIMA (non-seasonal)\n",
    "    # Prepare data in StatsForecast format\n",
    "    train_df = pd.DataFrame({\n",
    "        'unique_id': ['series'] * len(train_values),\n",
    "        'ds': range(len(train_values)),\n",
    "        'y': train_values.values\n",
    "    })\n",
    "    model = StatsForecast(models=[AutoARIMA(season_length=False, alias='ARIMA')], freq=1)\n",
    "    model.fit(train_df)\n",
    "    forecast_df = model.predict(h=h)\n",
    "    return forecast_df['ARIMA'].values\n",
    "\n",
    "def sarima_forecast(train_values, h, season_length=4):\n",
    "    #Forecast using Seasonal AutoARIMA (SARIMA)\n",
    "    # Prepare data in StatsForecast format\n",
    "    train_df = pd.DataFrame({\n",
    "        'unique_id': ['series'] * len(train_values),\n",
    "        'ds': range(len(train_values)),\n",
    "        'y': train_values.values\n",
    "    })\n",
    "    model = StatsForecast(models=[AutoARIMA(season_length=season_length, alias='SARIMA')], freq=1)\n",
    "    model.fit(train_df)\n",
    "    forecast_df = model.predict(h=h)\n",
    "    return forecast_df['SARIMA'].values\n",
    "\n",
    "def compute_mae(actual, predicted):\n",
    "    #Compute Mean Absolute Error\n",
    "    return np.mean(np.abs(actual - predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b0525a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "\n",
    "for target in target_vars:\n",
    "    print(f\"\\n{'='*60}\"); print(f\"Processing target: {target}\"); print(f\"{'='*60}\")\n",
    "    \n",
    "    skipped_count = 0\n",
    "    processed_count = 0\n",
    "    \n",
    "    for atc2 in atc2_classes:\n",
    "        # Extract series for this ATC2 class\n",
    "        series_df = df_in[df_in[\"ATC2 Class\"] == atc2][[\"Period\", target]].copy()\n",
    "        series_df = series_df.sort_values(\"Period\").reset_index(drop=True)\n",
    "        \n",
    "        # Split into train and test\n",
    "        train_df = series_df[series_df[\"Period\"] <= train_end]\n",
    "        test_df = series_df[series_df[\"Period\"] >= test_start]\n",
    "        \n",
    "        # Skip if fewer than 24 training observations\n",
    "        if len(train_df) < 24:\n",
    "            skipped_count += 1\n",
    "            continue\n",
    "        \n",
    "        # Skip if no test observations\n",
    "        if len(test_df) == 0:\n",
    "            skipped_count += 1\n",
    "            continue\n",
    "        \n",
    "        train_values = train_df[target]\n",
    "        test_values = test_df[target].values[:h]  # Limit to forecast horizon\n",
    "        test_periods = test_df[\"Period\"].values[:h]  # Limit to forecast horizon\n",
    "        \n",
    "        # Generate forecasts\n",
    "        hist_mean_pred = historical_mean_forecast(train_values, h)\n",
    "        naive_pred = naive_forecast(train_values, h)\n",
    "        snaive_pred = seasonal_naive_forecast(train_values, h, season_length=4)\n",
    "        arima_pred = autoarima_forecast(train_values, h)\n",
    "        sarima_pred = sarima_forecast(train_values, h, season_length=4)\n",
    "        \n",
    "        # Compute MAE for each model\n",
    "        hist_mean_mae = compute_mae(test_values, hist_mean_pred)\n",
    "        naive_mae = compute_mae(test_values, naive_pred)\n",
    "        snaive_mae = compute_mae(test_values, snaive_pred)\n",
    "        arima_mae = compute_mae(test_values, arima_pred)\n",
    "        sarima_mae = compute_mae(test_values, sarima_pred)\n",
    "        \n",
    "        # Store results with forecast and actual values for each period\n",
    "        for i in range(h):\n",
    "            actual = test_values[i]\n",
    "            period = test_periods[i]\n",
    "            \n",
    "            results.append({\n",
    "                \"Target\": target, \"ATC2 Class\": atc2, \"Period\": period,\n",
    "                \"Model\": \"Historical Mean\", \"Actual\": actual, \n",
    "                \"Forecast\": hist_mean_pred[i], \"Error\": abs(actual - hist_mean_pred[i]),\n",
    "                \"MAE\": hist_mean_mae\n",
    "            })\n",
    "            results.append({\n",
    "                \"Target\": target, \"ATC2 Class\": atc2, \"Period\": period,\n",
    "                \"Model\": \"Naive\", \"Actual\": actual,\n",
    "                \"Forecast\": naive_pred[i], \"Error\": abs(actual - naive_pred[i]),\n",
    "                \"MAE\": naive_mae\n",
    "            })\n",
    "            results.append({\n",
    "                \"Target\": target, \"ATC2 Class\": atc2, \"Period\": period,\n",
    "                \"Model\": \"Seasonal Naive\", \"Actual\": actual,\n",
    "                \"Forecast\": snaive_pred[i], \"Error\": abs(actual - snaive_pred[i]),\n",
    "                \"MAE\": snaive_mae\n",
    "            })\n",
    "            results.append({\n",
    "                \"Target\": target, \"ATC2 Class\": atc2, \"Period\": period,\n",
    "                \"Model\": \"AutoARIMA\", \"Actual\": actual,\n",
    "                \"Forecast\": arima_pred[i], \"Error\": abs(actual - arima_pred[i]),\n",
    "                \"MAE\": arima_mae\n",
    "            })\n",
    "            results.append({\n",
    "                \"Target\": target, \"ATC2 Class\": atc2, \"Period\": period,\n",
    "                \"Model\": \"SARIMA\", \"Actual\": actual,\n",
    "                \"Forecast\": sarima_pred[i], \"Error\": abs(actual - sarima_pred[i]),\n",
    "                \"MAE\": sarima_mae\n",
    "            })\n",
    "        \n",
    "        processed_count += 1\n",
    "    \n",
    "    print(f\"Processed: {processed_count} ATC2 classes\")\n",
    "    print(f\"Skipped (insufficient data): {skipped_count} ATC2 classes\")\n",
    "\n",
    "# Create results DataFrame\n",
    "results_df = pd.DataFrame(results)\n",
    "print(f\"\\n{'='*60}\"); print(f\"Total results: {len(results_df)} rows\"); print(f\"{'='*60}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5faac666",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the results table\n",
    "print(\"Baseline Forecasting Results (Long Format)\"); print(\"=\"*60)\n",
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be523509",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get unique MAE per Target, ATC2 Class, and Model (MAE is same for all periods within a group)\n",
    "mae_df = results_df.groupby([\"Target\", \"ATC2 Class\", \"Model\"])[\"MAE\"].first().reset_index()\n",
    "\n",
    "# Summary statistics by Target and Model\n",
    "summary = mae_df.groupby([\"Target\", \"Model\"])[\"MAE\"].agg([\"mean\", \"std\", \"min\", \"max\"]).round(2)\n",
    "summary.columns = [\"Mean MAE\", \"Std MAE\", \"Min MAE\", \"Max MAE\"]\n",
    "print(\"Summary Statistics by Target and Model\"); print(\"=\"*60)\n",
    "summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeae0b95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify best model per Target and ATC2 Class (using mae_df computed above)\n",
    "best_models = mae_df.loc[mae_df.groupby([\"Target\", \"ATC2 Class\"])[\"MAE\"].idxmin()]\n",
    "best_models_display = best_models[[\"Target\", \"ATC2 Class\", \"Model\", \"MAE\"]].sort_values([\"Target\", \"ATC2 Class\"]).reset_index(drop=True)\n",
    "display(best_models_display)\n",
    "\n",
    "# Count how often each model wins\n",
    "print(\"\\n\")\n",
    "model_wins = best_models.groupby([\"Target\", \"Model\"]).size().unstack(fill_value=0)\n",
    "print(\"Model Wins (number of ATC2 classes where each model had lowest MAE):\")\n",
    "model_wins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb8e8a20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export results to CSV files\n",
    "\n",
    "export_path = rf\"C:\\Users\\{user}\\OneDrive - purdue.edu\\VS code\\Data\\ATC\\exported_analysis\"\n",
    "\n",
    "# Export detailed results\n",
    "results_df.to_csv(os.path.join(export_path, \"forecast_traditional_IN_nopop.csv\"), index=False)\n",
    "print(f\"Exported results_df to: {export_path}\\\\forecast_results_IN.csv\")\n",
    "\n",
    "# Export best models summary\n",
    "best_models_display.to_csv(os.path.join(export_path, \"best_models_IN_traditional_nopop.csv\"), index=False)\n",
    "print(f\"Exported best_models_display to: {export_path}\\\\best_models_IN.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7431577",
   "metadata": {},
   "source": [
    "Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ecd43de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define models for cross-validation\n",
    "models = [\n",
    "    HistoricAverage(alias='Historical Mean'),\n",
    "    Naive(alias='Naive'),\n",
    "    SeasonalNaive(season_length=4, alias='Seasonal Naive'),\n",
    "    AutoARIMA(season_length=False, alias='ARIMA')\n",
    "]\n",
    "\n",
    "cv_results = []\n",
    "\n",
    "for target in target_vars:\n",
    "    print(f\"\\n{'='*60}\"); print(f\"Cross-Validation for: {target}\"); print(f\"{'='*60}\")\n",
    "    \n",
    "    skipped_count = 0\n",
    "    processed_count = 0\n",
    "    \n",
    "    for atc2 in atc2_classes:\n",
    "        # Extract series for this ATC2 class\n",
    "        series_df = df_in[df_in[\"ATC2 Class\"] == atc2][[\"Period\", target]].copy()\n",
    "        series_df = series_df.sort_values(\"Period\").reset_index(drop=True)\n",
    "        \n",
    "        # Prepare data in StatsForecast format\n",
    "        cv_df = pd.DataFrame({\n",
    "            'unique_id': [f\"{atc2}\"] * len(series_df),\n",
    "            'ds': range(len(series_df)),\n",
    "            'y': series_df[target].values\n",
    "        })\n",
    "        \n",
    "        # Create StatsForecast object\n",
    "        sf = StatsForecast(models=models, freq=1, n_jobs=1)\n",
    "        \n",
    "        # Perform cross-validation\n",
    "        cv_output = sf.cross_validation(\n",
    "            df=cv_df,\n",
    "            h=h,\n",
    "            n_windows=5,\n",
    "            step_size=h,\n",
    "            refit=True\n",
    "        )\n",
    "        \n",
    "        # Add metadata\n",
    "        cv_output['Target'] = target\n",
    "        cv_output['ATC2 Class'] = atc2\n",
    "        \n",
    "        cv_results.append(cv_output)\n",
    "        processed_count += 1\n",
    "    \n",
    "    print(f\"Processed: {processed_count} ATC2 classes\")\n",
    "    print(f\"Skipped (insufficient data): {skipped_count} ATC2 classes\")\n",
    "\n",
    "# Combine all cross-validation results\n",
    "if len(cv_results) > 0:\n",
    "    cv_results_df = pd.concat(cv_results, ignore_index=True)\n",
    "    print(f\"\\n{'='*60}\"); print(f\"Cross-validation complete! Total rows: {len(cv_results_df)}\"); print(f\"{'='*60}\")\n",
    "else:\n",
    "    cv_results_df = pd.DataFrame()\n",
    "    print(\"\\nNo series had sufficient data for cross-validation.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a7f110f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display cross-validation results\n",
    "print(\"Cross-Validation Results\"); print(\"=\"*60)\n",
    "display(cv_results_df)\n",
    "\n",
    "# Compute MAE for each model across all cross-validation windows\n",
    "model_columns = ['Historical Mean', 'Naive', 'Seasonal Naive', 'ARIMA']\n",
    "\n",
    "# Melt the dataframe to long format for easier analysis\n",
    "cv_long = cv_results_df.melt(\n",
    "    id_vars=['unique_id', 'ds', 'cutoff', 'y', 'Target', 'ATC2 Class'],\n",
    "    value_vars=model_columns,\n",
    "    var_name='Model',\n",
    "    value_name='Forecast'\n",
    ")\n",
    "cv_long['Error'] = np.abs(cv_long['y'] - cv_long['Forecast'])\n",
    "\n",
    "# Compute MAE per Target, ATC2 Class, and Model\n",
    "cv_mae = cv_long.groupby(['Target', 'ATC2 Class', 'Model'])['Error'].mean().reset_index()\n",
    "cv_mae.columns = ['Target', 'ATC2 Class', 'Model', 'CV_MAE']\n",
    "\n",
    "print(\"\\nCross-Validation MAE by Target, ATC2 Class, and Model\"); print(\"=\"*60)\n",
    "display(cv_mae)\n",
    "\n",
    "# Summary statistics by Target and Model\n",
    "cv_summary = cv_mae.groupby(['Target', 'Model'])['CV_MAE'].agg(['mean', 'std', 'min', 'max']).round(2)\n",
    "cv_summary.columns = ['Mean CV_MAE', 'Std CV_MAE', 'Min CV_MAE', 'Max CV_MAE']\n",
    "print(\"\\nCross-Validation Summary Statistics by Target and Model\"); print(\"=\"*60)\n",
    "display(cv_summary)\n",
    "\n",
    "# Best model per Target and ATC2 Class based on CV\n",
    "cv_best_models = cv_mae.loc[cv_mae.groupby(['Target', 'ATC2 Class'])['CV_MAE'].idxmin()]\n",
    "cv_best_display = cv_best_models[['Target', 'ATC2 Class', 'Model', 'CV_MAE']].sort_values(['Target', 'ATC2 Class']).reset_index(drop=True)\n",
    "print(\"\\nBest Model per Target and ATC2 Class (Cross-Validation)\"); print(\"=\"*60)\n",
    "display(cv_best_display)\n",
    "\n",
    "# Model wins based on cross-validation\n",
    "cv_model_wins = cv_best_models.groupby(['Target', 'Model']).size().unstack(fill_value=0)\n",
    "print(\"\\nModel Wins (Cross-Validation):\"); print(\"=\"*60)\n",
    "cv_model_wins"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
