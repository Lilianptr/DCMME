{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14de25d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "import seaborn as sns\n",
    "import warnings \n",
    "from utilsforecast.plotting import plot_series\n",
    "from utilsforecast.evaluation import evaluate\n",
    "from utilsforecast.losses import *\n",
    "from statsforecast import StatsForecast\n",
    "from statsforecast.models import (\n",
    "    Naive,WindowAverage, ARIMA, \n",
    "    AutoARIMA,SeasonalNaive,HoltWinters,\n",
    "    CrostonClassic as Croston, HistoricAverage,DynamicOptimizedTheta as DOT,\n",
    "    SeasonalNaive\n",
    ")\n",
    "from dataclasses import dataclass\n",
    "from typing import Optional, List, Dict, Tuple, Union\n",
    "from itertools import product\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")  # To ignore warnings from pandas/numpy\n",
    "\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "plt.rcParams['font.size'] = 10\n",
    "\n",
    "# Color palette for up to 4 models\n",
    "MODEL_COLORS = {\n",
    "    0: '#E94F37',  # Red\n",
    "    1: '#2E86AB',  # Blue\n",
    "    2: '#28A745',  # Green\n",
    "    3: '#9B59B6',  # Purple\n",
    "}\n",
    "HISTORICAL_COLOR = \"#898992\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d75a6c67",
   "metadata": {},
   "outputs": [],
   "source": [
    "user=\"Lilian\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1baf5dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#New data class created to handle configuration parameters\n",
    "@dataclass\n",
    "class ForecastConfig:\n",
    "    \n",
    "    # Forecast parameters\n",
    "    h: int = 8                          \n",
    "    season_length: int = 4              \n",
    "    \n",
    "    # Cross-validation parameters\n",
    "    n_windows: int = 2                  \n",
    "    step_size: Optional[int] = None     \n",
    "    \n",
    "    # Train-test split parameters\n",
    "    train_size: Optional[int] = None    # Use all available data except test\n",
    "    test_size: Optional[int] = None     # Auto-set to h in __post_init__\n",
    "    \n",
    "    # Plotting parameters\n",
    "    n_samples: int = 4                  # Plot 4 random samples\n",
    "    models_to_plot: Optional[List[str]] = None  # \n",
    "    \n",
    "    # Other settings\n",
    "    confidence_level: int = 95          # 95% confidence intervals\n",
    "    n_jobs: int = -1                    \n",
    "    \n",
    "    def __post_init__(self):\n",
    "        \n",
    "        if self.step_size is None:\n",
    "            self.step_size = self.h\n",
    "        if self.test_size is None:\n",
    "            self.test_size = self.h\n",
    "        if self.models_to_plot is None:\n",
    "            self.models_to_plot = ['Naive', 'ARIMA_manual', 'SARIMA']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa9feee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_models(config):\n",
    "    \n",
    "    models = [Naive(), HistoricAverage(), WindowAverage(window_size=4),\n",
    "        SeasonalNaive(season_length=4), ARIMA(order=(1, 1, 1), alias=\"ARIMA_manual\"),\n",
    "        AutoARIMA(seasonal=True, season_length=4, alias=\"SARIMA\"),\n",
    "    ]\n",
    "    return models\n",
    "\n",
    "def evaluate_train_test(df, target_name, config):\n",
    "\n",
    "    if config.train_size is None:\n",
    "        train = df.groupby('unique_id').apply(\n",
    "            lambda x: x.iloc[:-config.test_size]\n",
    "        ).reset_index(drop=True)\n",
    "    else:\n",
    "        train = df.groupby('unique_id').apply(\n",
    "            lambda x: x.iloc[-(config.train_size + config.test_size):-config.test_size]\n",
    "        ).reset_index(drop=True)\n",
    "    \n",
    "    test = df.groupby('unique_id').apply(\n",
    "        lambda x: x.iloc[-config.test_size:]\n",
    "    ).reset_index(drop=True)\n",
    "    \n",
    "    sf = StatsForecast(\n",
    "        models=get_models(config),\n",
    "        freq='QS',\n",
    "        n_jobs=config.n_jobs,\n",
    "        fallback_model=SeasonalNaive(season_length=config.season_length)\n",
    "    )\n",
    "    sf.fit(df=train)\n",
    "    preds = sf.predict(h=config.h)\n",
    "\n",
    "    preds_df = pd.merge(test, preds.reset_index(), on=['ds', 'unique_id'], how='left')\n",
    "    models = [col for col in preds.columns if col not in ['unique_id', 'ds']]\n",
    "    \n",
    "    eval_df = evaluate(preds_df, metrics=[mae, mse, rmse], models=models)\n",
    "    \n",
    "    mae_df = eval_df[eval_df['metric'] == 'mae'].copy()\n",
    "    mae_df['best_model'] = mae_df[models].idxmin(axis=1)\n",
    "    \n",
    "    print(f\"\\nðŸ“ˆ Best Models (Train-Test Split - based on MAE):\")\n",
    "    print(mae_df['best_model'].value_counts())\n",
    "    \n",
    "    return eval_df, preds_df, train, test \n",
    "\n",
    "def evaluate_model_cross(df, target_name, config):\n",
    "    \n",
    "    sf = StatsForecast(\n",
    "        models=get_models(config),\n",
    "        freq='QS',\n",
    "        n_jobs=config.n_jobs,\n",
    "        fallback_model=SeasonalNaive(season_length=config.season_length)\n",
    "    )\n",
    "\n",
    "    print(f\"   Running cross-validation...\")\n",
    "    cv_df = sf.cross_validation(\n",
    "        df=df,\n",
    "        h=config.h,\n",
    "        n_windows=config.n_windows,\n",
    "        step_size=config.step_size\n",
    "    )\n",
    "    \n",
    "    # Define model columns\n",
    "    exclude_cols = ['unique_id', 'ds', 'y', 'cutoff', 'metric']\n",
    "    model_cols = [col for col in cv_df.columns if col not in exclude_cols]\n",
    "\n",
    "    # Evaluate per cutoff window\n",
    "    all_results = []\n",
    "    \n",
    "    for cutoff in cv_df['cutoff'].unique():\n",
    "        cutoff_data = cv_df[cv_df['cutoff'] == cutoff]\n",
    "        \n",
    "        # Evaluate all metrics for this cutoff\n",
    "        cutoff_eval = evaluate(cutoff_data, metrics=[mae, mse, rmse], models=model_cols)\n",
    "        cutoff_eval['cutoff'] = cutoff\n",
    "        \n",
    "        # Add best_model column (lowest value per row, regardless of metric)\n",
    "        cutoff_eval['best_model'] = cutoff_eval[model_cols].idxmin(axis=1)\n",
    "        cutoff_eval['best_value'] = cutoff_eval[model_cols].min(axis=1)\n",
    "        \n",
    "        all_results.append(cutoff_eval)\n",
    "        \n",
    "        # Print MAE summary for this cutoff\n",
    "        cutoff_mae = cutoff_eval[cutoff_eval['metric'] == 'mae']\n",
    "        print(f\"\\n   Cutoff {cutoff.strftime('%Y-%m-%d')} (MAE best models):\")\n",
    "        print(f\"   {cutoff_mae['best_model'].value_counts().to_dict()}\")\n",
    "\n",
    "    # Combine all cutoff results into single dataframe\n",
    "    eval_df = pd.concat(all_results, ignore_index=True)\n",
    "    \n",
    "    # Print overall summary\n",
    "    mae_overall = eval_df[eval_df['metric'] == 'mae']\n",
    "    print(f\"\\nðŸ“ˆ Overall Best Models (all cutoffs - based on MAE):\")\n",
    "    print(mae_overall['best_model'].value_counts())\n",
    "    \n",
    "    return eval_df, cv_df\n",
    "\n",
    "def sensitivity_analysis_with_production_forecasts(df, target_name, param_grid=None, production_horizons=[4, 8], save_path=None):\n",
    "    \n",
    "    # Default parameter grid if not provided\n",
    "    if param_grid is None:\n",
    "        param_grid = {\n",
    "            'h': [4, 8],\n",
    "            'test_size': [4, 8],\n",
    "            'train_size': [None, 20, 28],\n",
    "            'n_windows': [2, 3, 4],\n",
    "            'step_size': [None, 2, 4],\n",
    "        }\n",
    "   \n",
    "    print(\"\\nPHASE 1: SENSITIVITY ANALYSIS\")\n",
    "    \n",
    "    param_names = list(param_grid.keys())\n",
    "    param_values = list(param_grid.values())\n",
    "    combinations = list(product(*param_values))\n",
    "    \n",
    "    print(f\"Testing {len(combinations)} configurations...\")\n",
    "    \n",
    "    all_results = []\n",
    "    \n",
    "    for i, combo in enumerate(combinations):\n",
    "        params = dict(zip(param_names, combo))\n",
    "        \n",
    "        # Skip invalid combinations\n",
    "        if params.get('test_size') and params.get('h'):\n",
    "            if params['test_size'] < params['h']:\n",
    "                continue\n",
    "        \n",
    "        print(f\"\\nConfiguration {i+1}/{len(combinations)}: {params}\")\n",
    "        \n",
    "        try:\n",
    "            config = ForecastConfig(\n",
    "                h=params.get('h', 8),\n",
    "                train_size=params.get('train_size'),\n",
    "                test_size=params.get('test_size'),\n",
    "                n_windows=params.get('n_windows', 2),\n",
    "                step_size=params.get('step_size'),\n",
    "                season_length=4,\n",
    "                n_samples=4,\n",
    "                confidence_level=95,\n",
    "                n_jobs=-1\n",
    "            )\n",
    "            \n",
    "            # Run train-test evaluation\n",
    "            eval_traintest, preds_traintest, train_df, test_df = evaluate_train_test(\n",
    "                df, target_name, config\n",
    "            )\n",
    "            \n",
    "            # Run cross-validation\n",
    "            eval_cv, cv_df = evaluate_model_cross(df, target_name, config)\n",
    "            \n",
    "            # Extract MAE results\n",
    "            mae_cv = eval_cv[eval_cv['metric'] == 'mae'].copy()\n",
    "            mae_traintest = eval_traintest[eval_traintest['metric'] == 'mae'].copy()\n",
    "            \n",
    "            # Get model columns\n",
    "            exclude_cols = ['unique_id', 'ds', 'y', 'cutoff', 'metric', 'best_model', 'best_value']\n",
    "            model_cols = [col for col in mae_cv.columns if col not in exclude_cols]\n",
    "            \n",
    "            # Add best_model to train-test if not present\n",
    "            if 'best_model' not in mae_traintest.columns:\n",
    "                mae_traintest['best_model'] = mae_traintest[model_cols].idxmin(axis=1)\n",
    "            \n",
    "            # Store results\n",
    "            for uid in df['unique_id'].unique():\n",
    "                uid_cv = mae_cv[mae_cv['unique_id'] == uid]\n",
    "                uid_traintest = mae_traintest[mae_traintest['unique_id'] == uid]\n",
    "                \n",
    "                cv_best_model = uid_cv['best_model'].mode().iloc[0] if len(uid_cv) > 0 else None\n",
    "                cv_best_count = (uid_cv['best_model'] == cv_best_model).sum()\n",
    "                cv_total = len(uid_cv)\n",
    "                cv_consistency = cv_best_count / cv_total if cv_total > 0 else 0\n",
    "                \n",
    "                traintest_best_model = uid_traintest['best_model'].iloc[0] if len(uid_traintest) > 0 else None\n",
    "                \n",
    "                result_row = {\n",
    "                    'unique_id': uid,\n",
    "                    'config_id': i + 1,\n",
    "                    **params,\n",
    "                    'cv_best_model': cv_best_model,\n",
    "                    'cv_consistency': cv_consistency,\n",
    "                    'traintest_best_model': traintest_best_model,\n",
    "                    'cv_traintest_agree': cv_best_model == traintest_best_model,\n",
    "                }\n",
    "                \n",
    "                # Add MAE values for each model\n",
    "                for model in model_cols:\n",
    "                    model_mae = uid_cv[model].mean() if len(uid_cv) > 0 else None\n",
    "                    result_row[f'{model}_mae'] = model_mae\n",
    "                \n",
    "                all_results.append(result_row)\n",
    "            \n",
    "            print(f\"   âœ“ Completed successfully\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"   âœ— Error: {str(e)}\")\n",
    "            continue\n",
    "    \n",
    "    results_df = pd.DataFrame(all_results)\n",
    "    \n",
    "    print(\"\\nPHASE 2: IDENTIFYING BEST MODELS PER HORIZON\")\n",
    "    recommendations_per_horizon = {}\n",
    "    \n",
    "    for horizon in production_horizons:\n",
    "        print(f\"\\nðŸŽ¯ Analyzing h={horizon}...\")\n",
    "        \n",
    "        # Filter results for this horizon\n",
    "        horizon_results = results_df[results_df['h'] == horizon].copy()\n",
    "        \n",
    "        if len(horizon_results) == 0:\n",
    "            print(f\"   âš ï¸ No results found for h={horizon}, skipping\")\n",
    "            continue\n",
    "        \n",
    "        # Get recommendations for each unique_id at this horizon\n",
    "        horizon_recommendations = []\n",
    "        \n",
    "        for uid in horizon_results['unique_id'].unique():\n",
    "            uid_data = horizon_results[horizon_results['unique_id'] == uid]\n",
    "            \n",
    "            # Most frequent CV best model\n",
    "            cv_mode = uid_data['cv_best_model'].mode()\n",
    "            cv_best = cv_mode.iloc[0] if len(cv_mode) > 0 else None\n",
    "            cv_freq = (uid_data['cv_best_model'] == cv_best).sum() / len(uid_data)\n",
    "            \n",
    "            # Most frequent train-test best model\n",
    "            tt_mode = uid_data['traintest_best_model'].mode()\n",
    "            tt_best = tt_mode.iloc[0] if len(tt_mode) > 0 else None\n",
    "            tt_freq = (uid_data['traintest_best_model'] == tt_best).sum() / len(uid_data)\n",
    "            \n",
    "            # Average consistency\n",
    "            avg_consistency = uid_data['cv_consistency'].mean()\n",
    "            \n",
    "            # Determine recommendation\n",
    "            if cv_best == tt_best and cv_freq >= 0.7 and avg_consistency >= 0.7:\n",
    "                confidence = 'High'\n",
    "                recommended_model = cv_best\n",
    "                reason = \"CV and Train-Test agree, high frequency and consistency\"\n",
    "            elif cv_best == tt_best and cv_freq >= 0.5:\n",
    "                confidence = 'Medium-High'\n",
    "                recommended_model = cv_best\n",
    "                reason = \"CV and Train-Test agree with moderate frequency\"\n",
    "            elif cv_freq >= 0.6:\n",
    "                confidence = 'Medium'\n",
    "                recommended_model = cv_best\n",
    "                reason = f\"CV favors {cv_best} ({cv_freq:.0%})\"\n",
    "            elif tt_freq >= 0.6:\n",
    "                confidence = 'Medium'\n",
    "                recommended_model = tt_best\n",
    "                reason = f\"Train-Test favors {tt_best} ({tt_freq:.0%})\"\n",
    "            else:\n",
    "                confidence = 'Low'\n",
    "                mae_cols = [col for col in uid_data.columns if col.endswith('_mae')]\n",
    "                if mae_cols:\n",
    "                    avg_maes = uid_data[mae_cols].mean()\n",
    "                    recommended_model = avg_maes.idxmin().replace('_mae', '')\n",
    "                else:\n",
    "                    recommended_model = cv_best\n",
    "                reason = \"No clear winner - using lowest average MAE\"\n",
    "            \n",
    "            # Get average MAE\n",
    "            rec_mae_col = f'{recommended_model}_mae'\n",
    "            avg_mae = uid_data[rec_mae_col].mean() if rec_mae_col in uid_data.columns else None\n",
    "            \n",
    "            recommendation = {\n",
    "                'unique_id': uid,\n",
    "                'horizon': horizon,\n",
    "                'recommended_model': recommended_model,\n",
    "                'confidence': confidence,\n",
    "                'reason': reason,\n",
    "                'cv_best_model': cv_best,\n",
    "                'cv_frequency': cv_freq,\n",
    "                'cv_consistency': avg_consistency,\n",
    "                'traintest_best_model': tt_best,\n",
    "                'avg_mae': avg_mae\n",
    "            }\n",
    "            \n",
    "            horizon_recommendations.append(recommendation)\n",
    "            mae_display= f\"{avg_mae:,.0f}\" if pd.notna(avg_mae)is not None else \"N/A\"\n",
    "            print(f\"   {uid}: {recommended_model} (confidence: {confidence}, MAE: {mae_display})\")\n",
    "            \n",
    "            print(f\"   {uid}: {recommended_model} (confidence: {confidence}, MAE: {avg_mae:,.0f})\")\n",
    "        \n",
    "        recommendations_per_horizon[horizon] = pd.DataFrame(horizon_recommendations)\n",
    "    \n",
    "\n",
    "    print(\"\\nPHASE 3: GENERATING PRODUCTION FORECASTS\")\n",
    "    \n",
    "    production_forecasts = {}\n",
    "    \n",
    "    for horizon in production_horizons:\n",
    "        if horizon not in recommendations_per_horizon:\n",
    "            continue\n",
    "            \n",
    "        print(f\"\\nðŸ”® Generating forecasts for h={horizon}...\")\n",
    "        \n",
    "        recommendations = recommendations_per_horizon[horizon]\n",
    "        \n",
    "        # Train on FULL dataset\n",
    "        config_prod = ForecastConfig(\n",
    "            h=horizon,\n",
    "            season_length=4,\n",
    "            confidence_level=95,\n",
    "            n_jobs=-1\n",
    "        )\n",
    "        \n",
    "        # Train all models on full data\n",
    "        sf = StatsForecast(\n",
    "            models=get_models(config_prod),\n",
    "            freq='QS',\n",
    "            n_jobs=-1,\n",
    "            fallback_model=SeasonalNaive(season_length=4)\n",
    "        )\n",
    "        \n",
    "        forecasts_df = sf.forecast(df=df, h=horizon, level=[95])\n",
    "        \n",
    "        # Create a \"best model\" forecast by selecting the recommended model for each unique_id\n",
    "        best_forecasts = []\n",
    "        \n",
    "        for uid in df['unique_id'].unique():\n",
    "            uid_forecasts = forecasts_df.reset_index()\n",
    "            uid_forecasts = uid_forecasts[uid_forecasts['unique_id'] == uid]\n",
    "            \n",
    "            uid_rec = recommendations[recommendations['unique_id'] == uid]\n",
    "            if len(uid_rec) == 0:\n",
    "                print(f\"   âš ï¸ No recommendation found for {uid}, skipping\")\n",
    "                continue\n",
    "            \n",
    "            best_model = uid_rec['recommended_model'].iloc[0]\n",
    "            \n",
    "            for _, row in uid_forecasts.iterrows():\n",
    "                best_row = {\n",
    "                    'unique_id': uid,\n",
    "                    'ds': row['ds'],\n",
    "                    'recommended_model': best_model,\n",
    "                    'forecast': row.get(best_model, np.nan),\n",
    "                    'forecast_lo_95': row.get(f'{best_model}-lo-95', np.nan),\n",
    "                    'forecast_hi_95': row.get(f'{best_model}-hi-95', np.nan)\n",
    "                }\n",
    "                best_forecasts.append(best_row)\n",
    "        \n",
    "        best_forecasts_df = pd.DataFrame(best_forecasts)\n",
    "        \n",
    "        production_forecasts[horizon] = {\n",
    "            'all_models': forecasts_df,\n",
    "            'best_model': best_forecasts_df,\n",
    "            'recommendations': recommendations\n",
    "        }\n",
    "        \n",
    "        print(f\"   âœ“ Generated {len(best_forecasts_df)} forecast periods\")\n",
    "        print(f\"   âœ“ Models used: {recommendations['recommended_model'].value_counts().to_dict()}\")\n",
    "    \n",
    "        print(\"\\nPHASE 4: SAVING RESULTS\")\n",
    "        \n",
    "        if save_path:\n",
    "            os.makedirs(save_path, exist_ok=True)\n",
    "            rec_frames=list(recommendations_per_horizon.values())\n",
    "            all_recs = pd.concat(rec_frames, ignore_index=True) if rec_frames else pd.DataFrame()\n",
    "            # Save sensitivity analysis results\n",
    "            sensitivity_file = os.path.join(save_path, f'{target_name.lower().replace(\" \", \"_\")}_sensitivity_analysis.csv')\n",
    "            with pd.ExcelWriter(sensitivity_file, engine='openpyxl') as writer:\n",
    "                results_df.to_excel(writer, sheet_name='All_Configurations', index=False)\n",
    "                all_recs.to_excel(writer, sheet_name='Recommendations', index=False)\n",
    "            \n",
    "            print(f\"âœ“ Sensitivity analysis saved: {sensitivity_file}\")\n",
    "            \n",
    "            # Save production forecasts for each horizon\n",
    "            for horizon, forecasts in production_forecasts.items():\n",
    "                horizon_file = os.path.join(save_path, f'{target_name.lower().replace(\" \", \"_\")}_production_h{horizon}.xlsx')\n",
    "                with pd.ExcelWriter(horizon_file, engine='openpyxl') as writer:\n",
    "                    forecasts['all_models'].reset_index().to_excel(writer, sheet_name='All_Models', index=False)\n",
    "                    forecasts['best_model'].to_excel(writer, sheet_name='Best_Model_Forecast', index=False)\n",
    "                    forecasts['recommendations'].to_excel(writer, sheet_name='Model_Selection', index=False)\n",
    "                print(f\"âœ“ Production forecasts (h={horizon}) saved: {horizon_file}\")\n",
    "        else:\n",
    "            print(\"   âš ï¸ No save_path provided - skipping file export\")\n",
    "                \n",
    "        \n",
    "    return {\n",
    "        'sensitivity_results': results_df,\n",
    "        'production_forecasts': production_forecasts,\n",
    "        'recommendations_per_horizon': recommendations_per_horizon\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78ef96e8",
   "metadata": {},
   "source": [
    "### Population Forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65a1f741",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(filepath, states=None):\n",
    "    \n",
    "    df=pd.read_csv(filepath)\n",
    "    #Filtering for certain years\n",
    "    df = df[(df['Period'] >= '2017Q1') & (df['Period'] <= '2024Q4')].copy()\n",
    "    if states is not None:\n",
    "        if isinstance(states, str):\n",
    "            states = [states]\n",
    "        print(f\"Filtering data for states: {states}\")\n",
    "        df = df[df['State'].isin(states)].copy()\n",
    "        print(f\"Filtered to {len(df)} rows across {df['State'].unique()} state(s)\")\n",
    "        if len(df) == 0:\n",
    "            raise ValueError(\"No data available after filtering by states.\")    \n",
    "    \n",
    "    df['unique_id']=df['State']\n",
    "    df['ds']=pd.to_datetime(df['Period'])\n",
    "    df=df.sort_values(['unique_id','ds']).reset_index(drop=True)\n",
    "    df_pop=df[['unique_id','ds','Population']].copy()\n",
    "    df_pop.columns = ['unique_id', 'ds', 'y']\n",
    "    \n",
    "\n",
    "    return df_pop,df\n",
    "\n",
    "pop_csv_path=rf\"C:\\Users\\{user}\\OneDrive - purdue.edu\\VS code\\Data\\ATC\\merged_data\\Prebuilt_panels\\medi_pop.csv\"\n",
    "pop_save_path=rf\"C:\\Users\\{user}\\OneDrive - purdue.edu\\VS code\\Data\\ATC\\Forecast\\Pop\\\\\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2782a523",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_population_forecast_single_state(\n",
    "    df_historical: pd.DataFrame,\n",
    "    df_forecast: pd.DataFrame,\n",
    "    state: str,\n",
    "    model_cols: List[str] = ['Naive', 'SARIMA'],\n",
    "    show_ci: bool = True,\n",
    "    figsize: Tuple[int, int] = (14, 7),\n",
    "    title: Optional[str] = None,\n",
    "    save_path: Optional[str] = None\n",
    ") -> plt.Figure:\n",
    "\n",
    "    if len(model_cols) > 4:\n",
    "        print(f\"Warning: Only first 4 models plotted.\")\n",
    "        model_cols = model_cols[:4]\n",
    "    \n",
    "    df_hist = df_historical.copy()\n",
    "    df_fore = df_forecast.copy()\n",
    "    if 'ds' not in df_fore.columns and 'ds' in df_fore.index.names:\n",
    "        df_fore = df_fore.reset_index()\n",
    "    df_hist['ds'] = pd.to_datetime(df_hist['ds'])\n",
    "    df_fore['ds'] = pd.to_datetime(df_fore['ds'])\n",
    "    \n",
    "    hist_state = df_hist[df_hist['unique_id'] == state].sort_values('ds')\n",
    "    fore_state = df_fore[df_fore['unique_id'] == state].sort_values('ds')\n",
    "    \n",
    "    if len(hist_state) == 0:\n",
    "        print(f\"No data for state: {state}\")\n",
    "        return None\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=figsize)\n",
    "    \n",
    "    # Historical\n",
    "    ax.plot(hist_state['ds'], hist_state['y'] / 1e6, color=HISTORICAL_COLOR,\n",
    "            linewidth=2.5, marker='o', markersize=5, label='Historical', zorder=10)\n",
    "    \n",
    "    last_hist = hist_state.iloc[-1]\n",
    "    \n",
    "    # Each model\n",
    "    for idx, model_col in enumerate(model_cols):\n",
    "        if model_col not in fore_state.columns:\n",
    "            print(f\"Warning: '{model_col}' not found. Skipping.\")\n",
    "            continue\n",
    "        color = MODEL_COLORS[idx]\n",
    "        # Connect\n",
    "        ax.plot([last_hist['ds'], fore_state['ds'].iloc[0]],\n",
    "                [last_hist['y'] / 1e6, fore_state[model_col].iloc[0] / 1e6],\n",
    "                color=color, linewidth=2, linestyle='--', alpha=0.7)\n",
    "        # Forecast\n",
    "        ax.plot(fore_state['ds'], fore_state[model_col] / 1e6, color=color,\n",
    "                linewidth=2, marker='s', markersize=6, linestyle='--', label=f'{model_col}')\n",
    "        # CI\n",
    "        lo_col, hi_col = f'{model_col}-lo-95', f'{model_col}-hi-95'\n",
    "        if show_ci and lo_col in fore_state.columns and hi_col in fore_state.columns:\n",
    "            ax.fill_between(fore_state['ds'], fore_state[lo_col]/1e6, fore_state[hi_col]/1e6,\n",
    "                           color=color, alpha=0.15, label=f'{model_col} 95% CI')\n",
    "    \n",
    "    ax.axvline(x=last_hist['ds'], color='gray', linestyle=':', alpha=0.7, linewidth=2, label='Forecast Start')\n",
    "    ax.set_xlabel('Year-Quarter', fontsize=12)\n",
    "    ax.set_ylabel('Population (Millions)', fontsize=12)\n",
    "    ax.set_title(title or f'{state} - Medicaid Population Forecast Comparison', fontsize=14, fontweight='bold')\n",
    "    ax.legend(loc='upper left', fontsize=10, ncol=2)\n",
    "    ax.xaxis.set_major_locator(mdates.YearLocator())\n",
    "    ax.xaxis.set_major_formatter(mdates.DateFormatter('%Y'))\n",
    "    ax.tick_params(axis='x', rotation=45)\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    if save_path:\n",
    "        fig.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "        print(f\"âœ” Saved: {save_path}\")\n",
    "    plt.show()\n",
    "    return fig\n",
    "\n",
    "\n",
    "def plot_population_forecast_all_states(\n",
    "    df_historical: pd.DataFrame,\n",
    "    df_forecast: pd.DataFrame,\n",
    "    states: List[str],\n",
    "    model_cols: List[str] = ['Naive', 'SARIMA'],\n",
    "    show_ci: bool = True,\n",
    "    figsize_per_state: Tuple[int, int] = (14, 6),\n",
    "    save_dir: Optional[str] = None\n",
    ") -> Dict[str, plt.Figure]:\n",
    "    \n",
    "    figures = {}\n",
    "    for state in states:\n",
    "        print(f\"\\nðŸ“Š Plotting {state}...\")\n",
    "        save_path = os.path.join(save_dir, f'{state}_population_forecast.png') if save_dir else None\n",
    "        if save_dir:\n",
    "            os.makedirs(save_dir, exist_ok=True)\n",
    "        fig = plot_population_forecast_single_state(\n",
    "            df_historical=df_historical, df_forecast=df_forecast, state=state,\n",
    "            model_cols=model_cols, show_ci=show_ci, figsize=figsize_per_state, save_path=save_path)\n",
    "        if fig:\n",
    "            figures[state] = fig\n",
    "    print(f\"\\nâœ… Generated {len(figures)} state plots\")\n",
    "    return figures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6b66f3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pop, df_original = load_data(filepath=pop_csv_path, states=['IN'])\n",
    "# 'IN','MI','OH','IL'\n",
    "config = ForecastConfig()\n",
    "\n",
    "# This is the manual way using config if you want to run individual evaluations\n",
    "print(\"\\n1. Train-Test Evaluation...\")\n",
    "eval_traintest, preds_traintest, train, test = evaluate_train_test(\n",
    "    df_pop, \"Population\", config\n",
    ")\n",
    "\n",
    "print(\"\\n2. Cross-Validation...\")\n",
    "eval_cv, cv_df = evaluate_model_cross(\n",
    "    df_pop, \"Population\", config\n",
    ")\n",
    "\n",
    "print(\"\\n3. Generate Forecasts...\")\n",
    "sf = StatsForecast(\n",
    "    models=get_models(config),\n",
    "    freq='QS',\n",
    "    n_jobs=config.n_jobs,\n",
    "    fallback_model=SeasonalNaive(season_length=config.season_length)\n",
    ")\n",
    "forecasts = sf.forecast(df=df_pop, h=config.h, level=[config.confidence_level])\n",
    "\n",
    "# Save\n",
    "forecasts.reset_index().to_csv(\n",
    "    os.path.join(pop_save_path, f'population_forecast_h{config.h}.csv'),\n",
    "    index=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "925906ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"PLOTTING POPULATION FORECASTS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Models to compare (max 4)\n",
    "models_to_compare = ['WindowAverage', 'ARIMA_manual']\n",
    "\n",
    "# Plot each state SEPARATELY\n",
    "state_figures = plot_population_forecast_all_states(\n",
    "    df_historical=df_pop,      # Historical data\n",
    "    df_forecast=forecasts,     # Forecast data\n",
    "    states=['IN'],\n",
    "    model_cols=models_to_compare,\n",
    "    show_ci=True,\n",
    "    figsize_per_state=(14, 7),\n",
    "    save_dir=pop_save_path\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8da57bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Sensitivity analysis with production forecasts\n",
    "df_pop, df_original = load_data(filepath=pop_csv_path, states=['IN','MI','OH','IL'])\n",
    "param_grid = {\n",
    "    'h': [4, 8],\n",
    "    'test_size': [4, 8],\n",
    "    'train_size': [None, 26],\n",
    "    'n_windows': [2, 3],\n",
    "    'step_size': [4],\n",
    "}\n",
    "results = sensitivity_analysis_with_production_forecasts(\n",
    "    df=df_pop,\n",
    "    target_name=\"Population\",\n",
    "    param_grid=param_grid,\n",
    "    production_horizons=[4, 8],\n",
    "    save_path=pop_save_path\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd76e1bf",
   "metadata": {},
   "source": [
    "### Ensuring mergind pop forecast with panel for statistical models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "10b01f75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All classes in IN: 84\n",
      "Classes in 2025â€“2026: 84\n",
      "Missing classes: []\n"
     ]
    }
   ],
   "source": [
    "p = pd.read_csv(rf\"C:\\Users\\{user}\\OneDrive - purdue.edu\\VS code\\Data\\ATC\\merged_data\\Prebuilt_panels\\P1_with_pop_forecast.csv\")\n",
    "\n",
    "state = \"MI\"\n",
    "all_classes = set(p.loc[p[\"State\"] == state, \"ATC2 Class\"])\n",
    "\n",
    "forecast = p[(p[\"State\"] == state) & (p[\"Year\"].isin([2025, 2026]))]\n",
    "forecast_classes = set(forecast[\"ATC2 Class\"])\n",
    "\n",
    "print(\"All classes in IN:\", len(all_classes))\n",
    "print(\"Classes in 2025â€“2026:\", len(forecast_classes))\n",
    "\n",
    "missing = sorted(all_classes - forecast_classes)\n",
    "print(\"Missing classes:\", missing)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93281f08",
   "metadata": {},
   "source": [
    "### SDUD with pop - Statistical Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74eb21a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defining functions used above but this time for exogenous feature (pop)\n",
    "def load_data_exog(filepath, states=None):\n",
    "\n",
    "    df = pd.read_csv(filepath)\n",
    "    df['ds'] = pd.to_datetime(df['Period'], errors='coerce')\n",
    "    \n",
    "    df = df[(df['ds'] >= '2017-01-01') & (df['ds'] <= '2024-10-01')].copy()\n",
    "    \n",
    "    if states is not None:\n",
    "        if isinstance(states, str):\n",
    "            states = [states]\n",
    "        print(f\"Filtering data for states: {states}\")\n",
    "        df = df[df['State'].isin(states)].copy()\n",
    "        print(f\"Filtered to {len(df)} rows across {df['State'].unique()} state(s)\")\n",
    "        if len(df) == 0:\n",
    "            raise ValueError(\"No data available after filtering by states.\")\n",
    "    \n",
    "    df['unique_id'] = df['State'] + '_' + df['ATC2 Class']\n",
    "    df = df.sort_values(['unique_id','ds']).reset_index(drop=True)\n",
    "\n",
    "    df_units = df[['unique_id', 'ds', 'Units Reimbursed']].copy()\n",
    "    df_units.columns = ['unique_id', 'ds', 'y']\n",
    "    df_units = df_units.dropna(subset=['y'])  \n",
    "\n",
    "    df_prescriptions = df[['unique_id', 'ds', 'Number of Prescriptions']].copy()\n",
    "    df_prescriptions.columns = ['unique_id', 'ds', 'y']\n",
    "    df_prescriptions = df_prescriptions.dropna(subset=['y'])  # â† Only drop NaN in y\n",
    "\n",
    "    return df_units, df_prescriptions, df\n",
    "\n",
    "def pop_scenarios_exog(filepath,states=None):\n",
    "\n",
    "    df = pd.read_csv(filepath)\n",
    "    df['ds'] = pd.to_datetime(df['Period'], errors='coerce')\n",
    "    \n",
    "    if states is not None:\n",
    "        if isinstance(states, str):\n",
    "            states = [states]\n",
    "        df = df[df['State'].isin(states)].copy()\n",
    "    \n",
    "    df['unique_id'] = df['State'] + '_' + df['ATC2 Class']\n",
    "    df = df.sort_values(['unique_id', 'ds']).reset_index(drop=True)\n",
    "    \n",
    "    df_historical = df[df['ds'] <= '2024-10-01'].copy()\n",
    "    df_future = df[df['ds'] > '2024-10-01'].copy()\n",
    "\n",
    "    pop_historical = df_historical[['unique_id', 'ds', 'population']].copy()\n",
    "    pop_historical.columns = ['unique_id', 'ds', 'population']\n",
    "\n",
    "    scenarios={}\n",
    "    pop_future_point = df_future[['unique_id', 'ds', 'population']].copy()\n",
    "    pop_future_point.columns = ['unique_id', 'ds', 'population']\n",
    "    scenarios['point'] = pd.concat([pop_historical, pop_future_point], ignore_index=True)\n",
    "    \n",
    "    # Scenario 2: Lower bound (uses Forecast_low_95 column)\n",
    "    pop_future_low = df_future[['unique_id', 'ds', 'Forecast_low_95']].copy()\n",
    "    pop_future_low.columns = ['unique_id', 'ds', 'population']\n",
    "    scenarios['low_95'] = pd.concat([pop_historical, pop_future_low], ignore_index=True)\n",
    "    \n",
    "    # Scenario 3: Upper bound (uses Forecast_high_95 column)\n",
    "    pop_future_high = df_future[['unique_id', 'ds', 'Forecast_high_95']].copy()\n",
    "    pop_future_high.columns = ['unique_id', 'ds', 'population']\n",
    "    scenarios['high_95'] = pd.concat([pop_historical, pop_future_high], ignore_index=True)\n",
    "    \n",
    "    # Verify we have future data\n",
    "    for scenario_name, scenario_df in scenarios.items():\n",
    "        future_count = len(scenario_df[scenario_df['ds'] > '2024-10-01'])\n",
    "        print(f\"   {scenario_name}: {future_count} future population records\")\n",
    "    \n",
    "    return scenarios\n",
    "\n",
    "def get_models_exog(config, use_exog=True):\n",
    "    \n",
    "    if use_exog:\n",
    "        models = [\n",
    "            # Baseline models (ignore exog)\n",
    "            Naive(),\n",
    "            SeasonalNaive(season_length=config.season_length),\n",
    "            HistoricAverage(),\n",
    "            WindowAverage(window_size=4),\n",
    "            \n",
    "            # Models with exogenous support\n",
    "            AutoARIMA(\n",
    "                seasonal=True, \n",
    "                season_length=config.season_length, \n",
    "                alias=\"SARIMAX\"\n",
    "            ),\n",
    "            AutoARIMA(\n",
    "                seasonal=False,\n",
    "                season_length=config.season_length,\n",
    "                alias=\"ARIMAX\"\n",
    "            ),\n",
    "            # Note: Can add more exog-aware models here\n",
    "        ]\n",
    "    else:\n",
    "        # Standard models without exog\n",
    "        models = [\n",
    "            Naive(),\n",
    "            HistoricAverage(),\n",
    "            WindowAverage(window_size=4),\n",
    "            SeasonalNaive(season_length=config.season_length),\n",
    "            ARIMA(order=(1, 1, 1), alias=\"ARIMA_manual\"),\n",
    "            AutoARIMA(seasonal=True, season_length=config.season_length, alias=\"SARIMA\"),\n",
    "        ]\n",
    "    \n",
    "    return models\n",
    "\n",
    "def evaluate_train_test_exog(df,target_name,config,population_df=None):\n",
    "    \n",
    "    # Split train/test\n",
    "    if config.train_size is None:\n",
    "        train = df.groupby('unique_id').apply(\n",
    "            lambda x: x.iloc[:-config.test_size]\n",
    "        ).reset_index(drop=True)\n",
    "    else:\n",
    "        train = df.groupby('unique_id').apply(\n",
    "            lambda x: x.iloc[-(config.train_size + config.test_size):-config.test_size]\n",
    "        ).reset_index(drop=True)\n",
    "    \n",
    "    test = df.groupby('unique_id').apply(\n",
    "        lambda x: x.iloc[-config.test_size:]\n",
    "    ).reset_index(drop=True)\n",
    "    \n",
    "    # Get models\n",
    "    use_exog = population_df is not None\n",
    "    models = get_models_exog(config, use_exog=use_exog)\n",
    "    \n",
    "    # Initialize StatsForecast\n",
    "    sf = StatsForecast(\n",
    "        models=models,\n",
    "        freq='QS',\n",
    "        n_jobs=config.n_jobs,\n",
    "        fallback_model=SeasonalNaive(season_length=config.season_length)\n",
    "    )\n",
    "    \n",
    "    # Fit and predict with/without exogenous variables\n",
    "    if use_exog:\n",
    "\n",
    "        if 'population' in train.columns:\n",
    "            train = train.drop(columns=['population'])\n",
    "        if 'population' in test.columns:\n",
    "            test = test.drop(columns=['population'])\n",
    "\n",
    "        # Prepare exogenous data for train and test\n",
    "        pop_train = population_df[population_df['ds'].isin(train['ds'])].copy()\n",
    "        pop_test = population_df[population_df['ds'].isin(test['ds'])].copy()\n",
    "        \n",
    "        # Merge population with train data\n",
    "        train_with_pop = train.merge(pop_train, on=['unique_id', 'ds'], how='left')\n",
    "        \n",
    "        # Fit with exogenous\n",
    "        sf.fit(df=train_with_pop[['unique_id', 'ds', 'y', 'population']])\n",
    "        \n",
    "        # Predict with future exogenous\n",
    "        test_with_pop = test.merge(pop_test, on=['unique_id', 'ds'], how='left')\n",
    "        preds = sf.predict(h=config.h, X_df=test_with_pop[['unique_id', 'ds', 'population']])\n",
    "    else:\n",
    "        sf.fit(df=train)\n",
    "        preds = sf.predict(h=config.h)\n",
    "    \n",
    "    # Merge predictions with actuals\n",
    "    preds_df = pd.merge(test, preds.reset_index(), on=['ds', 'unique_id'], how='left')\n",
    "    \n",
    "    # Evaluate\n",
    "    model_cols = [col for col in preds.columns if col not in ['unique_id', 'ds']]\n",
    "    eval_df = evaluate(preds_df, metrics=[mae, mse, rmse], models=model_cols)\n",
    "    \n",
    "    # Add best model\n",
    "    mae_df = eval_df[eval_df['metric'] == 'mae'].copy()\n",
    "    mae_df['best_model'] = mae_df[model_cols].idxmin(axis=1)\n",
    "    \n",
    "    exog_label = \" (with population)\" if use_exog else \" (no exog)\"\n",
    "    print(f\"\\nðŸ“ˆ Best Models (Train-Test Split - {target_name}{exog_label}):\")\n",
    "    print(mae_df['best_model'].value_counts())\n",
    "    \n",
    "    return eval_df, preds_df, train, test\n",
    "\n",
    "def CV_with_exog(df,target_name,config,population_df=None):\n",
    "    \n",
    "    use_exog = population_df is not None\n",
    "    models = get_models_exog(config, use_exog=use_exog)\n",
    "    \n",
    "    sf = StatsForecast(\n",
    "        models=models,\n",
    "        freq='QS',\n",
    "        n_jobs=config.n_jobs,\n",
    "        fallback_model=SeasonalNaive(season_length=config.season_length)\n",
    "    )\n",
    "    \n",
    "    print(f\"   Running cross-validation...\")\n",
    "    \n",
    "    # Cross-validation with/without exogenous\n",
    "    if use_exog:\n",
    "\n",
    "        df_for_cv = df.copy()\n",
    "        if 'population' in df_for_cv.columns:\n",
    "            df_for_cv = df_for_cv.drop(columns=['population'])\n",
    "            \n",
    "        df_with_pop = df.merge(population_df, on=['unique_id', 'ds'], how='left')\n",
    "        cv_df = sf.cross_validation(\n",
    "            df=df_with_pop[['unique_id', 'ds', 'y', 'population']],\n",
    "            h=config.h,\n",
    "            n_windows=config.n_windows,\n",
    "            step_size=config.step_size\n",
    "        )\n",
    "    else:\n",
    "        cv_df = sf.cross_validation(\n",
    "            df=df,\n",
    "            h=config.h,\n",
    "            n_windows=config.n_windows,\n",
    "            step_size=config.step_size\n",
    "        )\n",
    "    \n",
    "    # Evaluate per cutoff\n",
    "    exclude_cols = ['unique_id', 'ds', 'y', 'cutoff', 'metric', 'population']\n",
    "    model_cols = [col for col in cv_df.columns if col not in exclude_cols]\n",
    "    \n",
    "    all_results = []\n",
    "    \n",
    "    for cutoff in cv_df['cutoff'].unique():\n",
    "        cutoff_data = cv_df[cv_df['cutoff'] == cutoff]\n",
    "        \n",
    "        cutoff_eval = evaluate(cutoff_data, metrics=[mae, mse, rmse], models=model_cols)\n",
    "        cutoff_eval['cutoff'] = cutoff\n",
    "        cutoff_eval['best_model'] = cutoff_eval[model_cols].idxmin(axis=1)\n",
    "        cutoff_eval['best_value'] = cutoff_eval[model_cols].min(axis=1)\n",
    "        \n",
    "        all_results.append(cutoff_eval)\n",
    "        \n",
    "        cutoff_mae = cutoff_eval[cutoff_eval['metric'] == 'mae']\n",
    "        print(f\"\\n   Cutoff {cutoff.strftime('%Y-%m-%d')} (MAE best models):\")\n",
    "        print(f\"   {cutoff_mae['best_model'].value_counts().to_dict()}\")\n",
    "    \n",
    "    eval_df = pd.concat(all_results, ignore_index=True)\n",
    "    \n",
    "    mae_overall = eval_df[eval_df['metric'] == 'mae']\n",
    "    exog_label = \" (with population)\" if use_exog else \"\"\n",
    "    print(f\"\\nðŸ“ˆ Overall Best Models{exog_label}:\")\n",
    "    print(mae_overall['best_model'].value_counts())\n",
    "    \n",
    "    return eval_df, cv_df\n",
    "\n",
    "def generate_future_forecasts(df_historical, target_name, config, population_scenario, horizon=None,save_path=None):\n",
    "    \n",
    "    if horizon is None:\n",
    "        horizon = config.h\n",
    "    use_exog = population_scenario is not None\n",
    "    models = get_models_exog(config, use_exog=use_exog)\n",
    "    \n",
    "    sf = StatsForecast(\n",
    "        models=models,\n",
    "        freq='QS',\n",
    "        n_jobs=config.n_jobs,\n",
    "        fallback_model=SeasonalNaive(season_length=config.season_length)\n",
    "    )\n",
    "    \n",
    "    # Train on full historical data\n",
    "    if use_exog:\n",
    "        # Get historical population\n",
    "        pop_historical = population_scenario[\n",
    "            population_scenario['ds'] <= df_historical['ds'].max()\n",
    "        ].copy()\n",
    "        \n",
    "        df_train = df_historical.merge(pop_historical, on=['unique_id', 'ds'], how='left')\n",
    "        sf.fit(df=df_train[['unique_id', 'ds', 'y', 'population']])\n",
    "        \n",
    "        # Get future population for forecasting\n",
    "        last_date = df_historical['ds'].max()\n",
    "        future_dates = pd.date_range(\n",
    "            start=last_date + pd.DateOffset(months=3),\n",
    "            periods=horizon,\n",
    "            freq='QS'\n",
    "        )\n",
    "        \n",
    "        # Create future exogenous dataframe\n",
    "        future_exog_list = []\n",
    "        for uid in df_historical['unique_id'].unique():\n",
    "            for date in future_dates:\n",
    "                pop_val = population_scenario[\n",
    "                    (population_scenario['unique_id'] == uid) & \n",
    "                    (population_scenario['ds'] == date)\n",
    "                ]['population'].values\n",
    "                \n",
    "                if len(pop_val) > 0:\n",
    "                    future_exog_list.append({\n",
    "                        'unique_id': uid,\n",
    "                        'ds': date,\n",
    "                        'population': pop_val[0]\n",
    "                    })\n",
    "        \n",
    "        future_exog_df = pd.DataFrame(future_exog_list)\n",
    "        forecasts_df = sf.predict(h=horizon, X_df=future_exog_df)\n",
    "    else:\n",
    "        sf.fit(df=df_historical,)\n",
    "        forecasts_df = sf.predict(h=horizon)\n",
    "    \n",
    "    if save_path:\n",
    "        os.makedirs(save_path, exist_ok=True)\n",
    "        filename = os.path.join(\n",
    "            save_path, \n",
    "            f'{target_name.lower().replace(\" \", \"_\")}_future_h{horizon}.csv'\n",
    "        )\n",
    "        forecasts_df.reset_index().to_csv(filename, index=False)\n",
    "        print(f\"âœ… Saved: {filename}\")\n",
    "    \n",
    "    return forecasts_df\n",
    "\n",
    "def forecast_with_population_scenarios(filepath, target_col, states=None, config=None, horizons=None, save_path=None):\n",
    "   \n",
    "    if config is None: config = ForecastConfig()\n",
    "\n",
    "    if horizons is None: horizons = [config.h]\n",
    "\n",
    "    print(f\"\\nFORECASTING: {target_col}, Horizons: {horizons}\")\n",
    "\n",
    "    df_units, df_prescriptions, df_full = load_data_exog(filepath, states)\n",
    "\n",
    "    df = df_units if target_col == 'Units Reimbursed' else df_prescriptions\n",
    "\n",
    "    print(f\"   Unique series: {df['unique_id'].nunique()}, Range: {df['ds'].min()} to {df['ds'].max()}\")\n",
    "    \n",
    "    pop_scenarios = pop_scenarios_exog(filepath, states)\n",
    "    results = {'point': {}, 'low_95': {}, 'high_95': {}}\n",
    "    \n",
    "    for scenario_name, pop_df in pop_scenarios.items():\n",
    "        print(f\"\\n--- SCENARIO: {scenario_name.upper()} ---\")\n",
    "        for h in horizons:\n",
    "            forecasts = generate_future_forecasts(df, target_col, config, pop_df, horizon=h,\n",
    "                                                  save_path=os.path.join(save_path, scenario_name) if save_path else None)\n",
    "            results[scenario_name][f'h{h}'] = {\n",
    "                'forecasts': forecasts,\n",
    "                'df_historical': df.copy()\n",
    "            }\n",
    "    print(\"\\nâœ… COMPLETE!\")\n",
    "    return results\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    return results                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50b544de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sensitivity_analysis_with_exog(filepath, target_col, states=None, param_grid=None, production_horizons=[4, 8],\n",
    "    population_scenario='point',  # 'point', 'low_95', or 'high_95'\n",
    "    save_path=None):\n",
    "\n",
    "    # Default parameter grid\n",
    "    if param_grid is None:\n",
    "        param_grid = {\n",
    "            'h': [4, 8],\n",
    "            'test_size': [4, 8],\n",
    "            'train_size': [None, 20, 28],\n",
    "            'n_windows': [2, 3, 4],\n",
    "            'step_size': [4],\n",
    "        }\n",
    "    \n",
    "    print(\"=\" * 80); print(f\"SENSITIVITY ANALYSIS WITH EXOGENOUS VARIABLES: {target_col}\")\n",
    "    print(f\"Population Scenario: {population_scenario.upper()}\"); print(f\"Testing {len(list(product(*param_grid.values())))} configurations\")\n",
    "    print(\"=\" * 80); print(\"\\nPhase 1: Loading and preparing data...\")\n",
    "    \n",
    "    df_units, df_prescriptions, df_full = load_data_exog(filepath, states)\n",
    "    df = df_units if target_col == 'Units Reimbursed' else df_prescriptions\n",
    "    target_name = target_col\n",
    "    \n",
    "    print(f\"\\nUnique series: {df['unique_id'].nunique()}\")\n",
    "    print(f\"\\nDate range: {df['ds'].min()} to {df['ds'].max()}\")\n",
    "    print(f\"\\nTotal observations: {len(df)}\")\n",
    "    \n",
    "    # Get population scenarios\n",
    "    pop_scenarios = pop_scenarios_exog(filepath, states)\n",
    "    pop_df = pop_scenarios[population_scenario]\n",
    "    \n",
    "    print(f\"\\nPopulation scenario loaded: {population_scenario}\")\n",
    "    print(f\"\\nPopulation records: {len(pop_df)}\")\n",
    "    \n",
    "    print(\"\\nPhase 2: Running sensitivity analysis...\")\n",
    "    param_names = list(param_grid.keys())\n",
    "    param_values = list(param_grid.values())\n",
    "    combinations = list(product(*param_values))\n",
    "    \n",
    "    all_results = []\n",
    "    all_errors = []  # Simplified error tracking - mean per config\n",
    "    \n",
    "    for i, combo in enumerate(combinations):\n",
    "        params = dict(zip(param_names, combo))\n",
    "        \n",
    "        # Skip invalid combinations\n",
    "        if params.get('test_size') and params.get('h'):\n",
    "            if params['test_size'] < params['h']:\n",
    "                continue\n",
    "        \n",
    "        if params['test_size'] != params['h']:\n",
    "            continue\n",
    "\n",
    "        print(f\"\\n{'â”€' * 80}\"); print(f\"Configuration {i+1}/{len(combinations)}: {params}\"); print('â”€' * 80)\n",
    "        \n",
    "        try:\n",
    "            config = ForecastConfig(\n",
    "                h=params.get('h', 8),\n",
    "                train_size=params.get('train_size'),\n",
    "                test_size=params.get('test_size'),\n",
    "                n_windows=params.get('n_windows', 2),\n",
    "                step_size=params.get('step_size'),\n",
    "                season_length=4,\n",
    "                n_jobs=-1\n",
    "            )\n",
    "            \n",
    "            # Train-Test Evaluation\n",
    "            print(\"\\nRunning train-test evaluation...\")\n",
    "            eval_tt, preds_tt, train_df, test_df = evaluate_train_test_exog(\n",
    "                df, target_name, config, pop_df\n",
    "            )\n",
    "            \n",
    "            # Cross-Validation\n",
    "            print(\"\\nRunning Cross-Validation...\")\n",
    "            eval_cv, cv_df = CV_with_exog(\n",
    "                df, target_name, config, pop_df\n",
    "            )\n",
    "            \n",
    "            exclude_cols = ['unique_id', 'ds', 'y', 'cutoff', 'metric', 'best_model', 'best_value', 'population']\n",
    "            model_cols = [col for col in eval_cv.columns if col not in exclude_cols]\n",
    "            \n",
    "            # Extract MAE results\n",
    "            mae_cv = eval_cv[eval_cv['metric'] == 'mae'].copy()\n",
    "            mae_traintest = eval_tt[eval_tt['metric'] == 'mae'].copy()\n",
    "            \n",
    "            # Add best_model if not present\n",
    "            if 'best_model' not in mae_traintest.columns:\n",
    "                mae_traintest['best_model'] = mae_traintest[model_cols].idxmin(axis=1)\n",
    "            \n",
    "            # Collect Results Per Unique_ID \n",
    "            for uid in df['unique_id'].unique():\n",
    "                uid_cv = mae_cv[mae_cv['unique_id'] == uid]\n",
    "                uid_traintest = mae_traintest[mae_traintest['unique_id'] == uid]\n",
    "                \n",
    "                # CV analysis\n",
    "                cv_best_model = uid_cv['best_model'].mode().iloc[0] if len(uid_cv) > 0 else None\n",
    "                cv_best_count = (uid_cv['best_model'] == cv_best_model).sum()\n",
    "                cv_total = len(uid_cv)\n",
    "                cv_consistency = cv_best_count / cv_total if cv_total > 0 else 0\n",
    "                \n",
    "                # Train-test analysis\n",
    "                traintest_best_model = uid_traintest['best_model'].iloc[0] if len(uid_traintest) > 0 else None\n",
    "                \n",
    "                # Build result row\n",
    "                result_row = {\n",
    "                    'unique_id': uid,\n",
    "                    'config_id': i + 1,\n",
    "                    'population_scenario': population_scenario,\n",
    "                    **params,\n",
    "                    'cv_best_model': cv_best_model,\n",
    "                    'cv_consistency': cv_consistency,\n",
    "                    'traintest_best_model': traintest_best_model,\n",
    "                    'cv_traintest_agree': cv_best_model == traintest_best_model,\n",
    "                }\n",
    "                \n",
    "                # Add MAE values for each model\n",
    "                for model in model_cols:\n",
    "                    cv_mae = uid_cv[model].mean() if len(uid_cv) > 0 else None\n",
    "                    tt_mae = uid_traintest[model].iloc[0] if len(uid_traintest) > 0 and model in uid_traintest.columns else None\n",
    "                    \n",
    "                    result_row[f'{model}_cv_mae'] = cv_mae\n",
    "                    result_row[f'{model}_tt_mae'] = tt_mae\n",
    "                \n",
    "                all_results.append(result_row)\n",
    "                \n",
    "                # One row per unique_id per configuration with MEAN CV MAE and Train-Test MAE\n",
    "                error_row = {\n",
    "                    'config_id': i + 1,\n",
    "                    'unique_id': uid,\n",
    "                    'population_scenario': population_scenario,\n",
    "                    **params,\n",
    "                    'n_cv_windows': cv_total,\n",
    "                }\n",
    "                \n",
    "                # Add mean CV MAE and Train-Test MAE for each model\n",
    "                for model in model_cols:\n",
    "                    # Mean MAE across all CV windows\n",
    "                    cv_mean_mae = uid_cv[model].mean() if len(uid_cv) > 0 else None\n",
    "                    error_row[f'{model}_cv_mean_mae'] = cv_mean_mae\n",
    "                    \n",
    "                    # Train-Test MAE\n",
    "                    tt_mae = uid_traintest[model].iloc[0] if len(uid_traintest) > 0 and model in uid_traintest.columns else None\n",
    "                    error_row[f'{model}_tt_mae'] = tt_mae\n",
    "                \n",
    "                all_errors.append(error_row)\n",
    "            \n",
    "            print(f\"   âœ… Configuration {i+1} completed successfully\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"   âŒ Error in configuration {i+1}: {str(e)}\")\n",
    "            import traceback\n",
    "            traceback.print_exc()\n",
    "            continue\n",
    "    \n",
    "    # Convert to DataFrames\n",
    "    results_df = pd.DataFrame(all_results)\n",
    "    errors_df = pd.DataFrame(all_errors)\n",
    "    \n",
    "    print(f\"\\nâœ… Sensitivity analysis complete!\")\n",
    "    print(f\"\\nTotal configurations tested: {results_df['config_id'].nunique()}\")\n",
    "    print(f\"\\nTotal unique_ids analyzed: {results_df['unique_id'].nunique()}\")\n",
    "    \n",
    "    print(\"\\nPhase 3: Identifying best models per horizon...\")\n",
    "    \n",
    "    recommendations_per_horizon = {}\n",
    "    \n",
    "    for horizon in production_horizons:\n",
    "        print(f\"\\nAnalyzing horizon h={horizon}...\")\n",
    "        \n",
    "        horizon_results = results_df[results_df['h'] == horizon].copy()\n",
    "        \n",
    "        if len(horizon_results) == 0:\n",
    "            print(f\"   âš ï¸ No results for h={horizon}\")\n",
    "            continue\n",
    "        \n",
    "        horizon_recommendations = []\n",
    "        \n",
    "        for uid in horizon_results['unique_id'].unique():\n",
    "            uid_data = horizon_results[horizon_results['unique_id'] == uid]\n",
    "            \n",
    "            # Most frequent CV best model\n",
    "            cv_mode = uid_data['cv_best_model'].mode()\n",
    "            cv_best = cv_mode.iloc[0] if len(cv_mode) > 0 else None\n",
    "            cv_freq = (uid_data['cv_best_model'] == cv_best).sum() / len(uid_data)\n",
    "            \n",
    "            # Most frequent train-test best model\n",
    "            tt_mode = uid_data['traintest_best_model'].mode()\n",
    "            tt_best = tt_mode.iloc[0] if len(tt_mode) > 0 else None\n",
    "            tt_freq = (uid_data['traintest_best_model'] == tt_best).sum() / len(uid_data)\n",
    "            \n",
    "            # Average consistency\n",
    "            avg_consistency = uid_data['cv_consistency'].mean()\n",
    "            \n",
    "            # Determine recommendation\n",
    "            if cv_best == tt_best and cv_freq >= 0.7 and avg_consistency >= 0.7:\n",
    "                confidence = 'High'\n",
    "                recommended_model = cv_best\n",
    "                reason = \"CV and Train-Test agree with high frequency and consistency\"\n",
    "            elif cv_best == tt_best and cv_freq >= 0.5:\n",
    "                confidence = 'Medium-High'\n",
    "                recommended_model = cv_best\n",
    "                reason = \"CV and Train-Test agree with moderate frequency\"\n",
    "            elif cv_freq >= 0.6:\n",
    "                confidence = 'Medium'\n",
    "                recommended_model = cv_best\n",
    "                reason = f\"CV favors {cv_best} ({cv_freq:.0%})\"\n",
    "            elif tt_freq >= 0.6:\n",
    "                confidence = 'Medium'\n",
    "                recommended_model = tt_best\n",
    "                reason = f\"Train-Test favors {tt_best} ({tt_freq:.0%})\"\n",
    "            else:\n",
    "                confidence = 'Low'\n",
    "                # Use lowest average CV MAE\n",
    "                mae_cols = [col for col in uid_data.columns if col.endswith('_cv_mae')]\n",
    "                if mae_cols:\n",
    "                    avg_maes = uid_data[mae_cols].mean()\n",
    "                    recommended_model = avg_maes.idxmin().replace('_cv_mae', '')\n",
    "                else:\n",
    "                    recommended_model = cv_best\n",
    "                reason = \"No clear winner - using lowest average CV MAE\"\n",
    "            \n",
    "            # Get average MAE\n",
    "            rec_mae_col = f'{recommended_model}_cv_mae'\n",
    "            avg_mae = uid_data[rec_mae_col].mean() if rec_mae_col in uid_data.columns else None\n",
    "            \n",
    "            recommendation = {\n",
    "                'unique_id': uid,\n",
    "                'horizon': horizon,\n",
    "                'recommended_model': recommended_model,\n",
    "                'confidence': confidence,\n",
    "                'reason': reason,\n",
    "                'cv_best_model': cv_best,\n",
    "                'cv_frequency': cv_freq,\n",
    "                'cv_consistency': avg_consistency,\n",
    "                'traintest_best_model': tt_best,\n",
    "                'avg_cv_mae': avg_mae,\n",
    "                'population_scenario': population_scenario\n",
    "            }\n",
    "            \n",
    "            horizon_recommendations.append(recommendation)\n",
    "            \n",
    "            mae_display = f\"{avg_mae:,.0f}\" if pd.notna(avg_mae) else \"N/A\"\n",
    "            print(f\"   {uid}: {recommended_model} (confidence: {confidence}, MAE: {mae_display})\")\n",
    "        \n",
    "        recommendations_per_horizon[horizon] = pd.DataFrame(horizon_recommendations)\n",
    "    \n",
    "    print(\"\\nPhase 4: Generating production forecasts...\")\n",
    "    \n",
    "    production_forecasts = {}\n",
    "    \n",
    "    for horizon in production_horizons:\n",
    "        if horizon not in recommendations_per_horizon:\n",
    "            continue\n",
    "        \n",
    "        print(f\"\\nGenerating forecasts for h={horizon}...\")\n",
    "        \n",
    "        recommendations = recommendations_per_horizon[horizon]\n",
    "        \n",
    "        # Configuration for production\n",
    "        config_prod = ForecastConfig(\n",
    "            h=horizon,\n",
    "            season_length=4,\n",
    "            confidence_level=95,\n",
    "            n_jobs=-1\n",
    "        )\n",
    "        \n",
    "        # Train all models on full historical data\n",
    "        models = get_models_exog(config_prod, use_exog=True)\n",
    "        \n",
    "        sf = StatsForecast(\n",
    "            models=models,\n",
    "            freq='QS',\n",
    "            n_jobs=-1,\n",
    "            fallback_model=SeasonalNaive(season_length=4)\n",
    "        )\n",
    "        \n",
    "        # Prepare data with population\n",
    "        pop_historical = pop_df[pop_df['ds'] <= df['ds'].max()].copy()\n",
    "        df_train = df.merge(pop_historical, on=['unique_id', 'ds'], how='left')\n",
    "        \n",
    "        # Fit on historical data\n",
    "        sf.fit(df=df_train[['unique_id', 'ds', 'y', 'population']])\n",
    "        \n",
    "        # Prepare future population\n",
    "        last_date = df['ds'].max()\n",
    "        future_dates = pd.date_range(\n",
    "            start=last_date + pd.DateOffset(months=3),\n",
    "            periods=horizon,\n",
    "            freq='QS'\n",
    "        )\n",
    "        \n",
    "        future_exog_list = []\n",
    "        for uid in df['unique_id'].unique():\n",
    "            for date in future_dates:\n",
    "                pop_val = pop_df[\n",
    "                    (pop_df['unique_id'] == uid) & \n",
    "                    (pop_df['ds'] == date)\n",
    "                ]['population'].values\n",
    "                \n",
    "                if len(pop_val) > 0:\n",
    "                    future_exog_list.append({\n",
    "                        'unique_id': uid,\n",
    "                        'ds': date,\n",
    "                        'population': pop_val[0]\n",
    "                    })\n",
    "        \n",
    "        future_exog_df = pd.DataFrame(future_exog_list)\n",
    "        \n",
    "        # Generate forecasts\n",
    "        forecasts_df = sf.predict(h=horizon, X_df=future_exog_df)\n",
    "        \n",
    "        # Create best model forecasts\n",
    "        best_forecasts = []\n",
    "        \n",
    "        for uid in df['unique_id'].unique():\n",
    "            uid_forecasts = forecasts_df.reset_index()\n",
    "            uid_forecasts = uid_forecasts[uid_forecasts['unique_id'] == uid]\n",
    "            \n",
    "            uid_rec = recommendations[recommendations['unique_id'] == uid]\n",
    "            if len(uid_rec) == 0:\n",
    "                print(f\"   âš ï¸ No recommendation for {uid}, skipping\")\n",
    "                continue\n",
    "            \n",
    "            best_model = uid_rec['recommended_model'].iloc[0]\n",
    "            \n",
    "            for _, row in uid_forecasts.iterrows():\n",
    "                best_row = {\n",
    "                    'unique_id': uid,\n",
    "                    'ds': row['ds'],\n",
    "                    'recommended_model': best_model,\n",
    "                    'forecast': row.get(best_model, np.nan),\n",
    "                    'forecast_lo_95': row.get(f'{best_model}-lo-95', np.nan),\n",
    "                    'forecast_hi_95': row.get(f'{best_model}-hi-95', np.nan),\n",
    "                    'population_scenario': population_scenario\n",
    "                }\n",
    "                best_forecasts.append(best_row)\n",
    "        \n",
    "        best_forecasts_df = pd.DataFrame(best_forecasts)\n",
    "        \n",
    "        production_forecasts[horizon] = {\n",
    "            'all_models': forecasts_df,\n",
    "            'best_model': best_forecasts_df,\n",
    "            'recommendations': recommendations\n",
    "        }\n",
    "        \n",
    "        print(f\"   âœ… Generated {len(best_forecasts_df)} forecast periods\")\n",
    "        print(f\"   âœ… Models used: {recommendations['recommended_model'].value_counts().to_dict()}\")\n",
    "    \n",
    "    print(\"\\nPhase 5: Saving results...\")\n",
    "    \n",
    "    if save_path:\n",
    "        os.makedirs(save_path, exist_ok=True)\n",
    "        \n",
    "        # Save comprehensive results\n",
    "        sensitivity_file = os.path.join(\n",
    "            save_path, \n",
    "            f'{target_name.lower().replace(\" \", \"_\")}_sensitivity_{population_scenario}.xlsx'\n",
    "        )\n",
    "        \n",
    "        with pd.ExcelWriter(sensitivity_file, engine='openpyxl') as writer:\n",
    "            # Sheet 1: All configurations summary\n",
    "            results_df.to_excel(writer, sheet_name='All_Configurations', index=False)\n",
    "            \n",
    "            # Sheet 2: Simplified errors - Mean CV MAE and Train-Test MAE per config\n",
    "            errors_df.to_excel(writer, sheet_name='Model_Errors', index=False)\n",
    "            \n",
    "            # Sheet 3: Recommendations\n",
    "            rec_frames = list(recommendations_per_horizon.values())\n",
    "            if rec_frames:\n",
    "                all_recs = pd.concat(rec_frames, ignore_index=True)\n",
    "                all_recs.to_excel(writer, sheet_name='Recommendations', index=False)\n",
    "            \n",
    "            # Sheet 4: Configuration summary statistics\n",
    "            config_summary = results_df.groupby('config_id').agg({\n",
    "                'cv_traintest_agree': 'mean',\n",
    "                'cv_consistency': 'mean'\n",
    "            }).reset_index()\n",
    "            config_summary.columns = ['config_id', 'avg_cv_tt_agreement', 'avg_cv_consistency']\n",
    "            \n",
    "            # Add parameter details\n",
    "            param_details = results_df.groupby('config_id')[param_names].first().reset_index()\n",
    "            config_summary = config_summary.merge(param_details, on='config_id')\n",
    "            config_summary.to_excel(writer, sheet_name='Config_Summary', index=False)\n",
    "        \n",
    "        print(f\"âœ… Sensitivity analysis saved: {sensitivity_file}\")\n",
    "        \n",
    "        # Save production forecasts\n",
    "        for horizon, forecasts in production_forecasts.items():\n",
    "            horizon_file = os.path.join(\n",
    "                save_path,\n",
    "                f'{target_name.lower().replace(\" \", \"_\")}_production_h{horizon}_{population_scenario}.xlsx'\n",
    "            )\n",
    "            \n",
    "            with pd.ExcelWriter(horizon_file, engine='openpyxl') as writer:\n",
    "                forecasts['all_models'].reset_index().to_excel(\n",
    "                    writer, sheet_name='All_Models', index=False\n",
    "                )\n",
    "                forecasts['best_model'].to_excel(\n",
    "                    writer, sheet_name='Best_Model_Forecast', index=False\n",
    "                )\n",
    "                forecasts['recommendations'].to_excel(\n",
    "                    writer, sheet_name='Model_Selection', index=False\n",
    "                )\n",
    "            \n",
    "            print(f\"âœ… Production forecasts (h={horizon}) saved: {horizon_file}\")\n",
    "    else:\n",
    "        print(\"   âš ï¸ No save_path provided - skipping file export\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"âœ… SENSITIVITY ANALYSIS COMPLETE!\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    return {\n",
    "        'sensitivity_results': results_df,\n",
    "        'model_errors': errors_df,\n",
    "        'production_forecasts': production_forecasts,\n",
    "        'recommendations_per_horizon': recommendations_per_horizon\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86c7d7b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_top_atc2_forecasts(\n",
    "    df_historical: pd.DataFrame,\n",
    "    df_forecast: pd.DataFrame,\n",
    "    state: str,\n",
    "    target_col: str = 'Units Reimbursed',\n",
    "    model_cols: List[str] = ['SARIMAX', 'Naive'],\n",
    "    top_n: int = 12,\n",
    "    figsize: Tuple[int, int] = (18, 14),\n",
    "    show_ci: bool = True,\n",
    "    save_path: Optional[str] = None\n",
    ") -> plt.Figure:\n",
    "    \"\"\"Plot top N ATC-2 classes with multiple model comparison (max 4).\"\"\"\n",
    "    if len(model_cols) > 4:\n",
    "        model_cols = model_cols[:4]\n",
    "    \n",
    "    df_hist = df_historical.copy()\n",
    "    df_fore = df_forecast.copy()\n",
    "    if 'ds' not in df_fore.columns and 'ds' in df_fore.index.names:\n",
    "        df_fore = df_fore.reset_index()\n",
    "    df_hist['ds'] = pd.to_datetime(df_hist['ds'])\n",
    "    df_fore['ds'] = pd.to_datetime(df_fore['ds'])\n",
    "    df_hist = df_hist[df_hist['unique_id'].str.startswith(f'{state}_')]\n",
    "    df_fore = df_fore[df_fore['unique_id'].str.startswith(f'{state}_')]\n",
    "    \n",
    "    top_classes = df_hist.groupby('unique_id')['y'].sum().sort_values(ascending=False).head(top_n).index.tolist()\n",
    "    n_cols, n_rows = 4, (top_n + 3) // 4\n",
    "    fig, axes = plt.subplots(n_rows, n_cols, figsize=figsize, squeeze=False)\n",
    "    axes = axes.flatten()\n",
    "    \n",
    "    for idx, uid in enumerate(top_classes):\n",
    "        ax = axes[idx]\n",
    "        atc_class = uid.split('_')[1]\n",
    "        hist_data = df_hist[df_hist['unique_id'] == uid].sort_values('ds')\n",
    "        fore_data = df_fore[df_fore['unique_id'] == uid].sort_values('ds')\n",
    "        scale = 1e6 if hist_data['y'].max() > 1e6 else 1e3 if hist_data['y'].max() > 1e3 else 1\n",
    "        scale_label = 'M' if scale == 1e6 else 'K' if scale == 1e3 else ''\n",
    "        \n",
    "        ax.plot(hist_data['ds'], hist_data['y']/scale, color=HISTORICAL_COLOR, lw=1.5, marker='o', ms=2, label='Historical')\n",
    "        last_hist = hist_data.iloc[-1] if len(hist_data) > 0 else None\n",
    "        \n",
    "        for mi, mc in enumerate(model_cols):\n",
    "            if mc not in fore_data.columns or len(fore_data) == 0: continue\n",
    "            color = MODEL_COLORS[mi]\n",
    "            if last_hist is not None:\n",
    "                ax.plot([last_hist['ds'], fore_data['ds'].iloc[0]], [last_hist['y']/scale, fore_data[mc].iloc[0]/scale],\n",
    "                       color=color, lw=1.5, ls='--', alpha=0.7)\n",
    "            ax.plot(fore_data['ds'], fore_data[mc]/scale, color=color, lw=1.5, marker='s', ms=3, ls='--', label=mc)\n",
    "            if show_ci and mi == 0:\n",
    "                lo, hi = f'{mc}-lo-95', f'{mc}-hi-95'\n",
    "                if lo in fore_data.columns and hi in fore_data.columns:\n",
    "                    ax.fill_between(fore_data['ds'], fore_data[lo]/scale, fore_data[hi]/scale, color=color, alpha=0.1)\n",
    "        \n",
    "        if last_hist is not None:\n",
    "            ax.axvline(x=last_hist['ds'], color='gray', ls=':', alpha=0.5)\n",
    "        ax.set_title(f'{atc_class}', fontsize=10, fontweight='bold')\n",
    "        ax.set_ylabel(scale_label)\n",
    "        ax.tick_params(axis='x', rotation=45, labelsize=7)\n",
    "        ax.grid(True, alpha=0.3)\n",
    "        if idx == 0: ax.legend(loc='upper left', fontsize=7)\n",
    "    \n",
    "    for idx in range(len(top_classes), len(axes)):\n",
    "        axes[idx].set_visible(False)\n",
    "    \n",
    "    fig.suptitle(f'{state} - Top {top_n} ATC-2: {target_col}\\nModels: {\", \".join(model_cols)}', fontsize=14, fontweight='bold', y=1.02)\n",
    "    plt.tight_layout()\n",
    "    if save_path:\n",
    "        fig.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "        print(f\"âœ” Saved: {save_path}\")\n",
    "    plt.show()\n",
    "    return fig\n",
    "\n",
    "\n",
    "def plot_single_atc2_forecast(\n",
    "    df_historical: pd.DataFrame,\n",
    "    df_forecast: pd.DataFrame,\n",
    "    state: str,\n",
    "    atc_class: str,\n",
    "    target_col: str = 'Units Reimbursed',\n",
    "    model_cols: List[str] = ['SARIMAX', 'Naive'],\n",
    "    show_ci: bool = True,\n",
    "    figsize: Tuple[int, int] = (14, 7),\n",
    "    save_path: Optional[str] = None\n",
    ") -> plt.Figure:\n",
    "    \"\"\"Detailed plot for single ATC-2 class with multiple models.\"\"\"\n",
    "    if len(model_cols) > 4:\n",
    "        model_cols = model_cols[:4]\n",
    "    \n",
    "    df_hist = df_historical.copy()\n",
    "    df_fore = df_forecast.copy()\n",
    "    if 'ds' not in df_fore.columns and 'ds' in df_fore.index.names:\n",
    "        df_fore = df_fore.reset_index()\n",
    "    df_hist['ds'] = pd.to_datetime(df_hist['ds'])\n",
    "    df_fore['ds'] = pd.to_datetime(df_fore['ds'])\n",
    "    \n",
    "    uid = f'{state}_{atc_class}'\n",
    "    hist_data = df_hist[df_hist['unique_id'] == uid].sort_values('ds')\n",
    "    fore_data = df_fore[df_fore['unique_id'] == uid].sort_values('ds')\n",
    "    \n",
    "    if len(hist_data) == 0:\n",
    "        print(f\"No data for {uid}\")\n",
    "        return None\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=figsize)\n",
    "    scale = 1e6 if hist_data['y'].max() > 1e6 else 1e3 if hist_data['y'].max() > 1e3 else 1\n",
    "    scale_label = 'Millions' if scale == 1e6 else 'Thousands' if scale == 1e3 else ''\n",
    "    \n",
    "    ax.plot(hist_data['ds'], hist_data['y']/scale, color=HISTORICAL_COLOR, lw=2.5, marker='o', ms=5, label='Historical', zorder=10)\n",
    "    last_hist = hist_data.iloc[-1]\n",
    "    \n",
    "    for mi, mc in enumerate(model_cols):\n",
    "        if mc not in fore_data.columns or len(fore_data) == 0:\n",
    "            print(f\"Warning: '{mc}' not found.\")\n",
    "            continue\n",
    "        color = MODEL_COLORS[mi]\n",
    "        ax.plot([last_hist['ds'], fore_data['ds'].iloc[0]], [last_hist['y']/scale, fore_data[mc].iloc[0]/scale],\n",
    "               color=color, lw=2, ls='--', alpha=0.7)\n",
    "        ax.plot(fore_data['ds'], fore_data[mc]/scale, color=color, lw=2, marker='s', ms=6, ls='--', label=mc)\n",
    "        lo, hi = f'{mc}-lo-95', f'{mc}-hi-95'\n",
    "        if show_ci and lo in fore_data.columns and hi in fore_data.columns:\n",
    "            ax.fill_between(fore_data['ds'], fore_data[lo]/scale, fore_data[hi]/scale, color=color, alpha=0.15, label=f'{mc} 95% CI')\n",
    "    \n",
    "    ax.axvline(x=last_hist['ds'], color='gray', ls=':', alpha=0.7, lw=2, label='Forecast Start')\n",
    "    ax.set_xlabel('Year-Quarter', fontsize=12)\n",
    "    ax.set_ylabel(f'{target_col} ({scale_label})', fontsize=12)\n",
    "    ax.set_title(f'{state} - {atc_class}: {target_col}\\nModels: {\", \".join(model_cols)}', fontsize=14, fontweight='bold')\n",
    "    ax.legend(loc='upper left', fontsize=10, ncol=2)\n",
    "    ax.xaxis.set_major_locator(mdates.YearLocator())\n",
    "    ax.xaxis.set_major_formatter(mdates.DateFormatter('%Y'))\n",
    "    ax.tick_params(axis='x', rotation=45)\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    if save_path:\n",
    "        fig.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "        print(f\"âœ” Saved: {save_path}\")\n",
    "    plt.show()\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21a58b66",
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath_withpop = rf\"C:\\Users\\{user}\\OneDrive - purdue.edu\\VS code\\Data\\ATC\\merged_data\\Prebuilt_panels\\P1_withpop.csv\"\n",
    "save_path = rf\"C:\\Users\\{user}\\OneDrive - purdue.edu\\VS code\\Data\\ATC\\Forecast\\TMF\\\\\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a62a5ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure\n",
    "config = ForecastConfig(\n",
    "    h=8,\n",
    "    season_length=4,\n",
    "    n_windows=3,\n",
    "    train_size=None,\n",
    "    test_size=8,  #Setting it to the same h\n",
    "    n_samples=4,\n",
    "    confidence_level=95,\n",
    "    models_to_plot=['Naive', 'SARIMAX']\n",
    ")\n",
    "\n",
    "# Run forecasting for Units Reimbursed with all three population scenarios\n",
    "results_units = forecast_with_population_scenarios(\n",
    "    filepath=filepath_withpop,\n",
    "    target_col='Units Reimbursed',\n",
    "    states=['MI'],  # Or None for all states\n",
    "    config=config,\n",
    "    horizons=[8],\n",
    "    save_path=save_path\n",
    ")\n",
    "\n",
    "# Run forecasting for Number of Prescriptions\n",
    "results_prescriptions = forecast_with_population_scenarios(\n",
    "    filepath=filepath_withpop,\n",
    "    target_col='Number of Prescriptions',\n",
    "    states=['IL'],\n",
    "    config=config,\n",
    "    horizons=[8],\n",
    "    save_path=save_path\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db51035e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage\n",
    "results = sensitivity_analysis_with_exog(\n",
    "    filepath=filepath_withpop,\n",
    "    target_col='Number of Prescriptions',\n",
    "    states=['MI'],\n",
    "    param_grid={\n",
    "        'h': [4, 8],\n",
    "        'train_size': [None], #Training all the dataset for Cross-Validation, otherwise the n_windows will be too small\n",
    "        'n_windows': [2, 3],\n",
    "        'step_size': [4],\n",
    "        'test_size': [4, 8],  #Setting it to the same as h\n",
    "    },\n",
    "    production_horizons=[4, 8],\n",
    "    population_scenario='point',  # 'point' or 'low_95' or 'high_95'\n",
    "    save_path=save_path\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eafd4325",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"PLOTTING SDUD FORECASTS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "scenario, horizon_key = 'point', 'h8'\n",
    "\n",
    "if scenario in results_units and horizon_key in results_units[scenario]:\n",
    "    # Extract data\n",
    "    df_hist = results_units[scenario][horizon_key]['df_historical']\n",
    "    df_fore = results_units[scenario][horizon_key]['forecasts']\n",
    "    \n",
    "    print(f\"Historical: {df_hist.shape}, {df_hist['ds'].min()} to {df_hist['ds'].max()}\")\n",
    "    print(f\"Forecast cols: {[c for c in df_fore.reset_index().columns if c not in ['unique_id','ds']][:8]}...\")\n",
    "    \n",
    "    # Models to compare (max 4)\n",
    "    models = ['SARIMAX', 'Naive', 'SeasonalNaive', 'HistoricAverage']\n",
    "    \n",
    "    # 1. Top 12 ATC-2 with model comparison\n",
    "    print(\"\\n1. Top 12 ATC-2 classes...\")\n",
    "    plot_top_atc2_forecasts(df_hist, df_fore, 'IN', 'Units Reimbursed', models, top_n=12,\n",
    "                            save_path=os.path.join(save_path, 'IN_top12_multimodel.png'))\n",
    "    \n",
    "    # 2. Single class detail\n",
    "    print(\"\\n2. N06 detailed...\")\n",
    "    plot_single_atc2_forecast(df_hist, df_fore, 'IN', 'N06', 'Units Reimbursed', models,\n",
    "                              save_path=os.path.join(save_path, 'IN_N06_multimodel.png'))\n",
    "    \n",
    "    \n",
    "    print(\"\\nâœ… All plots generated!\")\n",
    "else:\n",
    "    print(\"Run forecast first.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
