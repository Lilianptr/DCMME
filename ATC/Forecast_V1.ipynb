{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14de25d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings \n",
    "from utilsforecast.plotting import plot_series\n",
    "from utilsforecast.evaluation import evaluate\n",
    "from utilsforecast.losses import *\n",
    "from statsforecast import StatsForecast\n",
    "from statsforecast.models import (\n",
    "    Naive,WindowAverage, ARIMA, \n",
    "    AutoARIMA,SeasonalNaive,HoltWinters,\n",
    "    CrostonClassic as Croston, HistoricAverage,DynamicOptimizedTheta as DOT,\n",
    "    SeasonalNaive\n",
    ")\n",
    "from dataclasses import dataclass\n",
    "from typing import Optional, List\n",
    "from itertools import product\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")  # To ignore warnings from pandas/numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d75a6c67",
   "metadata": {},
   "outputs": [],
   "source": [
    "user=\"Lilian\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1baf5dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#New data class created to handle configuration parameters\n",
    "@dataclass\n",
    "class ForecastConfig:\n",
    "    \n",
    "    # Forecast parameters\n",
    "    h: int = 8                          \n",
    "    season_length: int = 4              \n",
    "    \n",
    "    # Cross-validation parameters\n",
    "    n_windows: int = 2                  \n",
    "    step_size: Optional[int] = None     \n",
    "    \n",
    "    # Train-test split parameters\n",
    "    train_size: Optional[int] = None    # Use all available data except test\n",
    "    test_size: Optional[int] = None     # Auto-set to h in __post_init__\n",
    "    \n",
    "    # Plotting parameters\n",
    "    n_samples: int = 4                  # Plot 4 random samples\n",
    "    models_to_plot: Optional[List[str]] = None  # \n",
    "    \n",
    "    # Other settings\n",
    "    confidence_level: int = 95          # 95% confidence intervals\n",
    "    n_jobs: int = -1                    \n",
    "    \n",
    "    def __post_init__(self):\n",
    "        \n",
    "        if self.step_size is None:\n",
    "            self.step_size = self.h\n",
    "        if self.test_size is None:\n",
    "            self.test_size = self.h\n",
    "        if self.models_to_plot is None:\n",
    "            self.models_to_plot = ['Naive', 'ARIMA_manual', 'SARIMA']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa9feee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_models(config):\n",
    "    \n",
    "    models = [Naive(), HistoricAverage(), WindowAverage(window_size=4),\n",
    "        SeasonalNaive(season_length=4), ARIMA(order=(1, 1, 1), alias=\"ARIMA_manual\"),\n",
    "        AutoARIMA(seasonal=True, season_length=4, alias=\"SARIMA\"),\n",
    "    ]\n",
    "    return models\n",
    "\n",
    "def evaluate_train_test(df, target_name, config):\n",
    "\n",
    "    if config.train_size is None:\n",
    "        train = df.groupby('unique_id').apply(\n",
    "            lambda x: x.iloc[:-config.test_size]\n",
    "        ).reset_index(drop=True)\n",
    "    else:\n",
    "        train = df.groupby('unique_id').apply(\n",
    "            lambda x: x.iloc[-(config.train_size + config.test_size):-config.test_size]\n",
    "        ).reset_index(drop=True)\n",
    "    \n",
    "    test = df.groupby('unique_id').apply(\n",
    "        lambda x: x.iloc[-config.test_size:]\n",
    "    ).reset_index(drop=True)\n",
    "    \n",
    "    sf = StatsForecast(\n",
    "        models=get_models(config),\n",
    "        freq='QS',\n",
    "        n_jobs=config.n_jobs,\n",
    "        fallback_model=SeasonalNaive(season_length=config.season_length)\n",
    "    )\n",
    "    sf.fit(df=train)\n",
    "    preds = sf.predict(h=config.h)\n",
    "\n",
    "    preds_df = pd.merge(test, preds.reset_index(), on=['ds', 'unique_id'], how='left')\n",
    "    models = [col for col in preds.columns if col not in ['unique_id', 'ds']]\n",
    "    \n",
    "    eval_df = evaluate(preds_df, metrics=[mae, mse, rmse], models=models)\n",
    "    \n",
    "    mae_df = eval_df[eval_df['metric'] == 'mae'].copy()\n",
    "    mae_df['best_model'] = mae_df[models].idxmin(axis=1)\n",
    "    \n",
    "    print(f\"\\nüìà Best Models (Train-Test Split - based on MAE):\")\n",
    "    print(mae_df['best_model'].value_counts())\n",
    "    \n",
    "    return eval_df, preds_df, train, test \n",
    "\n",
    "def evaluate_model_cross(df, target_name, config):\n",
    "    \n",
    "    sf = StatsForecast(\n",
    "        models=get_models(config),\n",
    "        freq='QS',\n",
    "        n_jobs=config.n_jobs,\n",
    "        fallback_model=SeasonalNaive(season_length=config.season_length)\n",
    "    )\n",
    "\n",
    "    print(f\"   Running cross-validation...\")\n",
    "    cv_df = sf.cross_validation(\n",
    "        df=df,\n",
    "        h=config.h,\n",
    "        n_windows=config.n_windows,\n",
    "        step_size=config.step_size\n",
    "    )\n",
    "    \n",
    "    # Define model columns\n",
    "    exclude_cols = ['unique_id', 'ds', 'y', 'cutoff', 'metric']\n",
    "    model_cols = [col for col in cv_df.columns if col not in exclude_cols]\n",
    "\n",
    "    # Evaluate per cutoff window\n",
    "    all_results = []\n",
    "    \n",
    "    for cutoff in cv_df['cutoff'].unique():\n",
    "        cutoff_data = cv_df[cv_df['cutoff'] == cutoff]\n",
    "        \n",
    "        # Evaluate all metrics for this cutoff\n",
    "        cutoff_eval = evaluate(cutoff_data, metrics=[mae, mse, rmse], models=model_cols)\n",
    "        cutoff_eval['cutoff'] = cutoff\n",
    "        \n",
    "        # Add best_model column (lowest value per row, regardless of metric)\n",
    "        cutoff_eval['best_model'] = cutoff_eval[model_cols].idxmin(axis=1)\n",
    "        cutoff_eval['best_value'] = cutoff_eval[model_cols].min(axis=1)\n",
    "        \n",
    "        all_results.append(cutoff_eval)\n",
    "        \n",
    "        # Print MAE summary for this cutoff\n",
    "        cutoff_mae = cutoff_eval[cutoff_eval['metric'] == 'mae']\n",
    "        print(f\"\\n   Cutoff {cutoff.strftime('%Y-%m-%d')} (MAE best models):\")\n",
    "        print(f\"   {cutoff_mae['best_model'].value_counts().to_dict()}\")\n",
    "\n",
    "    # Combine all cutoff results into single dataframe\n",
    "    eval_df = pd.concat(all_results, ignore_index=True)\n",
    "    \n",
    "    # Print overall summary\n",
    "    mae_overall = eval_df[eval_df['metric'] == 'mae']\n",
    "    print(f\"\\nüìà Overall Best Models (all cutoffs - based on MAE):\")\n",
    "    print(mae_overall['best_model'].value_counts())\n",
    "    \n",
    "    return eval_df, cv_df\n",
    "\n",
    "def sensitivity_analysis_with_production_forecasts(df, target_name, param_grid=None, production_horizons=[4, 8], save_path=None):\n",
    "    \n",
    "    # Default parameter grid if not provided\n",
    "    if param_grid is None:\n",
    "        param_grid = {\n",
    "            'h': [4, 8],\n",
    "            'test_size': [4, 8],\n",
    "            'train_size': [None, 20, 28],\n",
    "            'n_windows': [2, 3, 4],\n",
    "            'step_size': [None, 2, 4],\n",
    "        }\n",
    "   \n",
    "    print(\"\\nPHASE 1: SENSITIVITY ANALYSIS\")\n",
    "    \n",
    "    param_names = list(param_grid.keys())\n",
    "    param_values = list(param_grid.values())\n",
    "    combinations = list(product(*param_values))\n",
    "    \n",
    "    print(f\"Testing {len(combinations)} configurations...\")\n",
    "    \n",
    "    all_results = []\n",
    "    \n",
    "    for i, combo in enumerate(combinations):\n",
    "        params = dict(zip(param_names, combo))\n",
    "        \n",
    "        # Skip invalid combinations\n",
    "        if params.get('test_size') and params.get('h'):\n",
    "            if params['test_size'] < params['h']:\n",
    "                continue\n",
    "        \n",
    "        print(f\"\\nConfiguration {i+1}/{len(combinations)}: {params}\")\n",
    "        \n",
    "        try:\n",
    "            config = ForecastConfig(\n",
    "                h=params.get('h', 8),\n",
    "                train_size=params.get('train_size'),\n",
    "                test_size=params.get('test_size'),\n",
    "                n_windows=params.get('n_windows', 2),\n",
    "                step_size=params.get('step_size'),\n",
    "                season_length=4,\n",
    "                n_samples=4,\n",
    "                confidence_level=95,\n",
    "                n_jobs=-1\n",
    "            )\n",
    "            \n",
    "            # Run train-test evaluation\n",
    "            eval_traintest, preds_traintest, train_df, test_df = evaluate_train_test(\n",
    "                df, target_name, config\n",
    "            )\n",
    "            \n",
    "            # Run cross-validation\n",
    "            eval_cv, cv_df = evaluate_model_cross(df, target_name, config)\n",
    "            \n",
    "            # Extract MAE results\n",
    "            mae_cv = eval_cv[eval_cv['metric'] == 'mae'].copy()\n",
    "            mae_traintest = eval_traintest[eval_traintest['metric'] == 'mae'].copy()\n",
    "            \n",
    "            # Get model columns\n",
    "            exclude_cols = ['unique_id', 'ds', 'y', 'cutoff', 'metric', 'best_model', 'best_value']\n",
    "            model_cols = [col for col in mae_cv.columns if col not in exclude_cols]\n",
    "            \n",
    "            # Add best_model to train-test if not present\n",
    "            if 'best_model' not in mae_traintest.columns:\n",
    "                mae_traintest['best_model'] = mae_traintest[model_cols].idxmin(axis=1)\n",
    "            \n",
    "            # Store results\n",
    "            for uid in df['unique_id'].unique():\n",
    "                uid_cv = mae_cv[mae_cv['unique_id'] == uid]\n",
    "                uid_traintest = mae_traintest[mae_traintest['unique_id'] == uid]\n",
    "                \n",
    "                cv_best_model = uid_cv['best_model'].mode().iloc[0] if len(uid_cv) > 0 else None\n",
    "                cv_best_count = (uid_cv['best_model'] == cv_best_model).sum()\n",
    "                cv_total = len(uid_cv)\n",
    "                cv_consistency = cv_best_count / cv_total if cv_total > 0 else 0\n",
    "                \n",
    "                traintest_best_model = uid_traintest['best_model'].iloc[0] if len(uid_traintest) > 0 else None\n",
    "                \n",
    "                result_row = {\n",
    "                    'unique_id': uid,\n",
    "                    'config_id': i + 1,\n",
    "                    **params,\n",
    "                    'cv_best_model': cv_best_model,\n",
    "                    'cv_consistency': cv_consistency,\n",
    "                    'traintest_best_model': traintest_best_model,\n",
    "                    'cv_traintest_agree': cv_best_model == traintest_best_model,\n",
    "                }\n",
    "                \n",
    "                # Add MAE values for each model\n",
    "                for model in model_cols:\n",
    "                    model_mae = uid_cv[model].mean() if len(uid_cv) > 0 else None\n",
    "                    result_row[f'{model}_mae'] = model_mae\n",
    "                \n",
    "                all_results.append(result_row)\n",
    "            \n",
    "            print(f\"   ‚úì Completed successfully\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"   ‚úó Error: {str(e)}\")\n",
    "            continue\n",
    "    \n",
    "    results_df = pd.DataFrame(all_results)\n",
    "    \n",
    "    print(\"\\nPHASE 2: IDENTIFYING BEST MODELS PER HORIZON\")\n",
    "    recommendations_per_horizon = {}\n",
    "    \n",
    "    for horizon in production_horizons:\n",
    "        print(f\"\\nüéØ Analyzing h={horizon}...\")\n",
    "        \n",
    "        # Filter results for this horizon\n",
    "        horizon_results = results_df[results_df['h'] == horizon].copy()\n",
    "        \n",
    "        if len(horizon_results) == 0:\n",
    "            print(f\"   ‚ö†Ô∏è No results found for h={horizon}, skipping\")\n",
    "            continue\n",
    "        \n",
    "        # Get recommendations for each unique_id at this horizon\n",
    "        horizon_recommendations = []\n",
    "        \n",
    "        for uid in horizon_results['unique_id'].unique():\n",
    "            uid_data = horizon_results[horizon_results['unique_id'] == uid]\n",
    "            \n",
    "            # Most frequent CV best model\n",
    "            cv_mode = uid_data['cv_best_model'].mode()\n",
    "            cv_best = cv_mode.iloc[0] if len(cv_mode) > 0 else None\n",
    "            cv_freq = (uid_data['cv_best_model'] == cv_best).sum() / len(uid_data)\n",
    "            \n",
    "            # Most frequent train-test best model\n",
    "            tt_mode = uid_data['traintest_best_model'].mode()\n",
    "            tt_best = tt_mode.iloc[0] if len(tt_mode) > 0 else None\n",
    "            tt_freq = (uid_data['traintest_best_model'] == tt_best).sum() / len(uid_data)\n",
    "            \n",
    "            # Average consistency\n",
    "            avg_consistency = uid_data['cv_consistency'].mean()\n",
    "            \n",
    "            # Determine recommendation\n",
    "            if cv_best == tt_best and cv_freq >= 0.7 and avg_consistency >= 0.7:\n",
    "                confidence = 'High'\n",
    "                recommended_model = cv_best\n",
    "                reason = \"CV and Train-Test agree, high frequency and consistency\"\n",
    "            elif cv_best == tt_best and cv_freq >= 0.5:\n",
    "                confidence = 'Medium-High'\n",
    "                recommended_model = cv_best\n",
    "                reason = \"CV and Train-Test agree with moderate frequency\"\n",
    "            elif cv_freq >= 0.6:\n",
    "                confidence = 'Medium'\n",
    "                recommended_model = cv_best\n",
    "                reason = f\"CV favors {cv_best} ({cv_freq:.0%})\"\n",
    "            elif tt_freq >= 0.6:\n",
    "                confidence = 'Medium'\n",
    "                recommended_model = tt_best\n",
    "                reason = f\"Train-Test favors {tt_best} ({tt_freq:.0%})\"\n",
    "            else:\n",
    "                confidence = 'Low'\n",
    "                mae_cols = [col for col in uid_data.columns if col.endswith('_mae')]\n",
    "                if mae_cols:\n",
    "                    avg_maes = uid_data[mae_cols].mean()\n",
    "                    recommended_model = avg_maes.idxmin().replace('_mae', '')\n",
    "                else:\n",
    "                    recommended_model = cv_best\n",
    "                reason = \"No clear winner - using lowest average MAE\"\n",
    "            \n",
    "            # Get average MAE\n",
    "            rec_mae_col = f'{recommended_model}_mae'\n",
    "            avg_mae = uid_data[rec_mae_col].mean() if rec_mae_col in uid_data.columns else None\n",
    "            \n",
    "            recommendation = {\n",
    "                'unique_id': uid,\n",
    "                'horizon': horizon,\n",
    "                'recommended_model': recommended_model,\n",
    "                'confidence': confidence,\n",
    "                'reason': reason,\n",
    "                'cv_best_model': cv_best,\n",
    "                'cv_frequency': cv_freq,\n",
    "                'cv_consistency': avg_consistency,\n",
    "                'traintest_best_model': tt_best,\n",
    "                'avg_mae': avg_mae\n",
    "            }\n",
    "            \n",
    "            horizon_recommendations.append(recommendation)\n",
    "            mae_display= f\"{avg_mae:,.0f}\" if pd.notna(avg_mae)is not None else \"N/A\"\n",
    "            print(f\"   {uid}: {recommended_model} (confidence: {confidence}, MAE: {mae_display})\")\n",
    "            \n",
    "            print(f\"   {uid}: {recommended_model} (confidence: {confidence}, MAE: {avg_mae:,.0f})\")\n",
    "        \n",
    "        recommendations_per_horizon[horizon] = pd.DataFrame(horizon_recommendations)\n",
    "    \n",
    "\n",
    "    print(\"\\nPHASE 3: GENERATING PRODUCTION FORECASTS\")\n",
    "    \n",
    "    production_forecasts = {}\n",
    "    \n",
    "    for horizon in production_horizons:\n",
    "        if horizon not in recommendations_per_horizon:\n",
    "            continue\n",
    "            \n",
    "        print(f\"\\nüîÆ Generating forecasts for h={horizon}...\")\n",
    "        \n",
    "        recommendations = recommendations_per_horizon[horizon]\n",
    "        \n",
    "        # Train on FULL dataset\n",
    "        config_prod = ForecastConfig(\n",
    "            h=horizon,\n",
    "            season_length=4,\n",
    "            confidence_level=95,\n",
    "            n_jobs=-1\n",
    "        )\n",
    "        \n",
    "        # Train all models on full data\n",
    "        sf = StatsForecast(\n",
    "            models=get_models(config_prod),\n",
    "            freq='QS',\n",
    "            n_jobs=-1,\n",
    "            fallback_model=SeasonalNaive(season_length=4)\n",
    "        )\n",
    "        \n",
    "        forecasts_df = sf.forecast(df=df, h=horizon, level=[95])\n",
    "        \n",
    "        # Create a \"best model\" forecast by selecting the recommended model for each unique_id\n",
    "        best_forecasts = []\n",
    "        \n",
    "        for uid in df['unique_id'].unique():\n",
    "            uid_forecasts = forecasts_df.reset_index()\n",
    "            uid_forecasts = uid_forecasts[uid_forecasts['unique_id'] == uid]\n",
    "            \n",
    "            uid_rec = recommendations[recommendations['unique_id'] == uid]\n",
    "            if len(uid_rec) == 0:\n",
    "                print(f\"   ‚ö†Ô∏è No recommendation found for {uid}, skipping\")\n",
    "                continue\n",
    "            \n",
    "            best_model = uid_rec['recommended_model'].iloc[0]\n",
    "            \n",
    "            for _, row in uid_forecasts.iterrows():\n",
    "                best_row = {\n",
    "                    'unique_id': uid,\n",
    "                    'ds': row['ds'],\n",
    "                    'recommended_model': best_model,\n",
    "                    'forecast': row.get(best_model, np.nan),\n",
    "                    'forecast_lo_95': row.get(f'{best_model}-lo-95', np.nan),\n",
    "                    'forecast_hi_95': row.get(f'{best_model}-hi-95', np.nan)\n",
    "                }\n",
    "                best_forecasts.append(best_row)\n",
    "        \n",
    "        best_forecasts_df = pd.DataFrame(best_forecasts)\n",
    "        \n",
    "        production_forecasts[horizon] = {\n",
    "            'all_models': forecasts_df,\n",
    "            'best_model': best_forecasts_df,\n",
    "            'recommendations': recommendations\n",
    "        }\n",
    "        \n",
    "        print(f\"   ‚úì Generated {len(best_forecasts_df)} forecast periods\")\n",
    "        print(f\"   ‚úì Models used: {recommendations['recommended_model'].value_counts().to_dict()}\")\n",
    "    \n",
    "        print(\"\\nPHASE 4: SAVING RESULTS\")\n",
    "        \n",
    "        if save_path:\n",
    "            os.makedirs(save_path, exist_ok=True)\n",
    "            rec_frames=list(recommendations_per_horizon.values())\n",
    "            all_recs = pd.concat(rec_frames, ignore_index=True) if rec_frames else pd.DataFrame()\n",
    "            # Save sensitivity analysis results\n",
    "            sensitivity_file = os.path.join(save_path, f'{target_name.lower().replace(\" \", \"_\")}_sensitivity_analysis.csv')\n",
    "            with pd.ExcelWriter(sensitivity_file, engine='openpyxl') as writer:\n",
    "                results_df.to_excel(writer, sheet_name='All_Configurations', index=False)\n",
    "                all_recs.to_excel(writer, sheet_name='Recommendations', index=False)\n",
    "            \n",
    "            print(f\"‚úì Sensitivity analysis saved: {sensitivity_file}\")\n",
    "            \n",
    "            # Save production forecasts for each horizon\n",
    "            for horizon, forecasts in production_forecasts.items():\n",
    "                horizon_file = os.path.join(save_path, f'{target_name.lower().replace(\" \", \"_\")}_production_h{horizon}.xlsx')\n",
    "                with pd.ExcelWriter(horizon_file, engine='openpyxl') as writer:\n",
    "                    forecasts['all_models'].reset_index().to_excel(writer, sheet_name='All_Models', index=False)\n",
    "                    forecasts['best_model'].to_excel(writer, sheet_name='Best_Model_Forecast', index=False)\n",
    "                    forecasts['recommendations'].to_excel(writer, sheet_name='Model_Selection', index=False)\n",
    "                print(f\"‚úì Production forecasts (h={horizon}) saved: {horizon_file}\")\n",
    "        else:\n",
    "            print(\"   ‚ö†Ô∏è No save_path provided - skipping file export\")\n",
    "                \n",
    "        \n",
    "    return {\n",
    "        'sensitivity_results': results_df,\n",
    "        'production_forecasts': production_forecasts,\n",
    "        'recommendations_per_horizon': recommendations_per_horizon\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78ef96e8",
   "metadata": {},
   "source": [
    "### Population Forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65a1f741",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(filepath, states=None):\n",
    "    \n",
    "    df=pd.read_csv(filepath)\n",
    "    #Filtering for certain years\n",
    "    df = df[(df['Period'] >= '2017Q1') & (df['Period'] <= '2024Q4')].copy()\n",
    "    if states is not None:\n",
    "        if isinstance(states, str):\n",
    "            states = [states]\n",
    "        print(f\"Filtering data for states: {states}\")\n",
    "        df = df[df['State'].isin(states)].copy()\n",
    "        print(f\"Filtered to {len(df)} rows across {df['State'].unique()} state(s)\")\n",
    "        if len(df) == 0:\n",
    "            raise ValueError(\"No data available after filtering by states.\")    \n",
    "    \n",
    "    df['unique_id']=df['State']\n",
    "    df['ds']=pd.to_datetime(df['Period'])\n",
    "    df=df.sort_values(['unique_id','ds']).reset_index(drop=True)\n",
    "    df_pop=df[['unique_id','ds','Population']].copy()\n",
    "    df_pop.columns = ['unique_id', 'ds', 'y']\n",
    "    \n",
    "\n",
    "    return df_pop,df\n",
    "\n",
    "pop_csv_path=rf\"C:\\Users\\{user}\\OneDrive - purdue.edu\\VS code\\Data\\ATC\\merged_data\\Prebuilt_panels\\medi_pop.csv\"\n",
    "pop_save_path=rf\"C:\\Users\\{user}\\OneDrive - purdue.edu\\VS code\\Data\\ATC\\Forecast\\Pop\\\\\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6b66f3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pop, df_original = load_data(filepath=pop_csv_path, states=['IN','MI','OH','IL'])\n",
    "config = ForecastConfig()\n",
    "\n",
    "# This is the manual way using config if you want to run individual evaluations\n",
    "print(\"\\n1. Train-Test Evaluation...\")\n",
    "eval_traintest, preds_traintest, train, test = evaluate_train_test(\n",
    "    df_pop, \"Population\", config\n",
    ")\n",
    "\n",
    "print(\"\\n2. Cross-Validation...\")\n",
    "eval_cv, cv_df = evaluate_model_cross(\n",
    "    df_pop, \"Population\", config\n",
    ")\n",
    "\n",
    "print(\"\\n3. Generate Forecasts...\")\n",
    "sf = StatsForecast(\n",
    "    models=get_models(config),\n",
    "    freq='QS',\n",
    "    n_jobs=config.n_jobs,\n",
    "    fallback_model=SeasonalNaive(season_length=config.season_length)\n",
    ")\n",
    "forecasts = sf.forecast(df=df_pop, h=config.h, level=[config.confidence_level])\n",
    "\n",
    "# Save\n",
    "forecasts.reset_index().to_csv(\n",
    "    os.path.join(pop_save_path, f'population_forecast_h{config.h}.csv'),\n",
    "    index=False\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8da57bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Sensitivity analysis with production forecasts\n",
    "df_pop, df_original = load_data(filepath=pop_csv_path, states=['IN','MI','OH','IL'])\n",
    "param_grid = {\n",
    "    'h': [4, 8],\n",
    "    'test_size': [4, 8],\n",
    "    'train_size': [None, 26],\n",
    "    'n_windows': [2, 3],\n",
    "    'step_size': [4],\n",
    "}\n",
    "results = sensitivity_analysis_with_production_forecasts(\n",
    "    df=df_pop,\n",
    "    target_name=\"Population\",\n",
    "    param_grid=param_grid,\n",
    "    production_horizons=[4, 8],\n",
    "    save_path=pop_save_path\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93281f08",
   "metadata": {},
   "source": [
    "### SDUD with pop - Statistical Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31b52ac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "pop_path = rf\"C:\\Users\\{user}\\OneDrive - purdue.edu\\VS code\\Data\\ATC\\merged_data\\Prebuilt_panels\\medi_pop_1.csv\"\n",
    "drug_path = rf\"C:\\Users\\{user}\\OneDrive - purdue.edu\\VS code\\Data\\ATC\\merged_data\\Prebuilt_panels\\P1_nopop.csv\"\n",
    "\n",
    "df_pop = pd.read_csv(pop_path)\n",
    "df_drug = pd.read_csv(drug_path)\n",
    "df_pop = df_pop[df_pop['Period'] >= '2017Q1'].copy()\n",
    "\n",
    "print(\"medi_pop columns:\", df_pop.columns.tolist())\n",
    "print(\"P1_nopop columns:\", df_drug.columns.tolist())\n",
    "\n",
    "df_merged = pd.merge(df_drug, df_pop, on=['State', 'Period'], how='left')\n",
    "\n",
    "existing_periods = df_drug['Period'].unique()\n",
    "all_pop_periods = df_pop['Period'].unique()\n",
    "future_periods = [p for p in all_pop_periods if p not in existing_periods]\n",
    "\n",
    "print(f\"\\nFuture periods to expand: {future_periods}\")\n",
    "state_atc_combos = df_drug[['State', 'ATC2 Class']].drop_duplicates()\n",
    "df_pop_future = df_pop[df_pop['Period'].isin(future_periods)].copy()\n",
    "future_rows = []\n",
    "\n",
    "for _, pop_row in df_pop_future.iterrows():\n",
    "    state = pop_row['State']\n",
    "    # Get all ATC2 classes for this state\n",
    "    atc_classes = state_atc_combos[state_atc_combos['State'] == state]['ATC2 Class'].unique()\n",
    "    \n",
    "    for atc_class in atc_classes:\n",
    "        new_row = {\n",
    "            'State': state,\n",
    "            'ATC2 Class': atc_class,\n",
    "            'Period': pop_row['Period'],\n",
    "            'Population': pop_row.get('Population', np.nan),\n",
    "            'Forecast_low_95': pop_row.get('Forecast_low_95', np.nan),\n",
    "            'Forecast_high_95': pop_row.get('Forecast_high_95', np.nan),\n",
    "            'Units Reimbursed': np.nan,  # No drug data for future periods\n",
    "            'Number of Prescriptions': np.nan\n",
    "        }\n",
    "        if 'Year' in pop_row:\n",
    "            new_row['Year'] = pop_row['Year']\n",
    "        if 'Quarter' in pop_row:\n",
    "            new_row['Quarter'] = pop_row['Quarter']\n",
    "        \n",
    "        future_rows.append(new_row)\n",
    "\n",
    "df_future = pd.DataFrame(future_rows)\n",
    "print(f\"Created {len(df_future)} future period rows\")\n",
    "df_final = pd.concat([df_merged, df_future], ignore_index=True)\n",
    "\n",
    "columns = ['State', 'ATC2 Class', 'Year', 'Quarter', 'Period', \n",
    "           'Units Reimbursed', 'Number of Prescriptions', \n",
    "           'Population', 'Forecast_low_95', 'Forecast_high_95']\n",
    "available_columns = [col for col in columns if col in df_final.columns]\n",
    "\n",
    "df_final = df_final[available_columns].copy()\n",
    "df_final = df_final.sort_values(['State', 'ATC2 Class', 'Period']).reset_index(drop=True)\n",
    "df_final['Period']=pd.to_datetime(df_final['Period'])\n",
    "\n",
    "print(f\"\\nFinal DataFrame shape: {df_final.shape}\")\n",
    "print(f\"Period range: {df_final['Period'].min()} to {df_final['Period'].max()}\")\n",
    "print(f\"Datatypes:\\n{df_final.dtypes}\")\n",
    "\n",
    "output_path = rf\"C:\\Users\\{user}\\OneDrive - purdue.edu\\VS code\\Data\\ATC\\merged_data\\Prebuilt_panels\\P1_withpop.csv\"\n",
    "df_final.to_csv(output_path, index=False)\n",
    "print(f\"\\nMerged DataFrame saved to: {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74eb21a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defining functions used above but this time for exogenous feature (pop)\n",
    "def load_data_exog(filepath, states=None):\n",
    "\n",
    "    df = pd.read_csv(filepath)\n",
    "    df['ds'] = pd.to_datetime(df['Period'], errors='coerce')\n",
    "    \n",
    "    df = df[(df['ds'] >= '2017-01-01') & (df['ds'] <= '2024-10-01')].copy()\n",
    "    \n",
    "    if states is not None:\n",
    "        if isinstance(states, str):\n",
    "            states = [states]\n",
    "        print(f\"Filtering data for states: {states}\")\n",
    "        df = df[df['State'].isin(states)].copy()\n",
    "        print(f\"Filtered to {len(df)} rows across {df['State'].unique()} state(s)\")\n",
    "        if len(df) == 0:\n",
    "            raise ValueError(\"No data available after filtering by states.\")\n",
    "    \n",
    "    df['unique_id'] = df['State'] + '_' + df['ATC2 Class']\n",
    "    df = df.sort_values(['unique_id','ds']).reset_index(drop=True)\n",
    "\n",
    "    # ‚≠ê DON'T include population - we'll get it from scenarios\n",
    "    df_units = df[['unique_id', 'ds', 'Units Reimbursed']].copy()\n",
    "    df_units.columns = ['unique_id', 'ds', 'y']\n",
    "    df_units = df_units.dropna(subset=['y'])  # ‚Üê Only drop NaN in y\n",
    "\n",
    "    df_prescriptions = df[['unique_id', 'ds', 'Number of Prescriptions']].copy()\n",
    "    df_prescriptions.columns = ['unique_id', 'ds', 'y']\n",
    "    df_prescriptions = df_prescriptions.dropna(subset=['y'])  # ‚Üê Only drop NaN in y\n",
    "\n",
    "    return df_units, df_prescriptions, df\n",
    "\n",
    "def pop_scenarios_exog(filepath,states=None):\n",
    "\n",
    "    df = pd.read_csv(filepath)\n",
    "    df['ds'] = pd.to_datetime(df['Period'], errors='coerce')\n",
    "    \n",
    "    if states is not None:\n",
    "        if isinstance(states, str):\n",
    "            states = [states]\n",
    "        df = df[df['State'].isin(states)].copy()\n",
    "    \n",
    "    df['unique_id'] = df['State'] + '_' + df['ATC2 Class']\n",
    "    df = df.sort_values(['unique_id', 'ds']).reset_index(drop=True)\n",
    "    \n",
    "    df_historical = df[df['ds'] <= '2024-10-01'].copy()\n",
    "    df_future = df[df['ds'] > '2024-10-01'].copy()\n",
    "\n",
    "    pop_historical = df_historical[['unique_id', 'ds', 'population']].copy()\n",
    "    pop_historical.columns = ['unique_id', 'ds', 'population']\n",
    "\n",
    "    scenarios={}\n",
    "    pop_future_point = df_future[['unique_id', 'ds', 'population']].copy()\n",
    "    pop_future_point.columns = ['unique_id', 'ds', 'population']\n",
    "    scenarios['point'] = pd.concat([pop_historical, pop_future_point], ignore_index=True)\n",
    "    \n",
    "    # Scenario 2: Lower bound (uses Forecast_low_95 column)\n",
    "    pop_future_low = df_future[['unique_id', 'ds', 'Forecast_low_95']].copy()\n",
    "    pop_future_low.columns = ['unique_id', 'ds', 'population']\n",
    "    scenarios['low_95'] = pd.concat([pop_historical, pop_future_low], ignore_index=True)\n",
    "    \n",
    "    # Scenario 3: Upper bound (uses Forecast_high_95 column)\n",
    "    pop_future_high = df_future[['unique_id', 'ds', 'Forecast_high_95']].copy()\n",
    "    pop_future_high.columns = ['unique_id', 'ds', 'population']\n",
    "    scenarios['high_95'] = pd.concat([pop_historical, pop_future_high], ignore_index=True)\n",
    "    \n",
    "    # Verify we have future data\n",
    "    for scenario_name, scenario_df in scenarios.items():\n",
    "        future_count = len(scenario_df[scenario_df['ds'] > '2024-10-01'])\n",
    "        print(f\"   {scenario_name}: {future_count} future population records\")\n",
    "    \n",
    "    return scenarios\n",
    "\n",
    "def get_models_exog(config, use_exog=True):\n",
    "    \n",
    "    if use_exog:\n",
    "        models = [\n",
    "            # Baseline models (ignore exog)\n",
    "            Naive(),\n",
    "            SeasonalNaive(season_length=config.season_length),\n",
    "            HistoricAverage(),\n",
    "            WindowAverage(window_size=4),\n",
    "            \n",
    "            # Models with exogenous support\n",
    "            AutoARIMA(\n",
    "                seasonal=True, \n",
    "                season_length=config.season_length, \n",
    "                alias=\"SARIMAX\"\n",
    "            ),\n",
    "            AutoARIMA(\n",
    "                seasonal=False,\n",
    "                season_length=config.season_length,\n",
    "                alias=\"ARIMAX\"\n",
    "            ),\n",
    "            # Note: Can add more exog-aware models here\n",
    "        ]\n",
    "    else:\n",
    "        # Standard models without exog\n",
    "        models = [\n",
    "            Naive(),\n",
    "            HistoricAverage(),\n",
    "            WindowAverage(window_size=4),\n",
    "            SeasonalNaive(season_length=config.season_length),\n",
    "            ARIMA(order=(1, 1, 1), alias=\"ARIMA_manual\"),\n",
    "            AutoARIMA(seasonal=True, season_length=config.season_length, alias=\"SARIMA\"),\n",
    "        ]\n",
    "    \n",
    "    return models\n",
    "\n",
    "def evaluate_train_test_exog(df,target_name,config,population_df=None):\n",
    "    \n",
    "    # Split train/test\n",
    "    if config.train_size is None:\n",
    "        train = df.groupby('unique_id').apply(\n",
    "            lambda x: x.iloc[:-config.test_size]\n",
    "        ).reset_index(drop=True)\n",
    "    else:\n",
    "        train = df.groupby('unique_id').apply(\n",
    "            lambda x: x.iloc[-(config.train_size + config.test_size):-config.test_size]\n",
    "        ).reset_index(drop=True)\n",
    "    \n",
    "    test = df.groupby('unique_id').apply(\n",
    "        lambda x: x.iloc[-config.test_size:]\n",
    "    ).reset_index(drop=True)\n",
    "    \n",
    "    # Get models\n",
    "    use_exog = population_df is not None\n",
    "    models = get_models_exog(config, use_exog=use_exog)\n",
    "    \n",
    "    # Initialize StatsForecast\n",
    "    sf = StatsForecast(\n",
    "        models=models,\n",
    "        freq='QS',\n",
    "        n_jobs=config.n_jobs,\n",
    "        fallback_model=SeasonalNaive(season_length=config.season_length)\n",
    "    )\n",
    "    \n",
    "    # Fit and predict with/without exogenous variables\n",
    "    if use_exog:\n",
    "\n",
    "        if 'population' in train.columns:\n",
    "            train = train.drop(columns=['population'])\n",
    "        if 'population' in test.columns:\n",
    "            test = test.drop(columns=['population'])\n",
    "\n",
    "        # Prepare exogenous data for train and test\n",
    "        pop_train = population_df[population_df['ds'].isin(train['ds'])].copy()\n",
    "        pop_test = population_df[population_df['ds'].isin(test['ds'])].copy()\n",
    "        \n",
    "        # Merge population with train data\n",
    "        train_with_pop = train.merge(pop_train, on=['unique_id', 'ds'], how='left')\n",
    "        \n",
    "        # Fit with exogenous\n",
    "        sf.fit(df=train_with_pop[['unique_id', 'ds', 'y', 'population']])\n",
    "        \n",
    "        # Predict with future exogenous\n",
    "        test_with_pop = test.merge(pop_test, on=['unique_id', 'ds'], how='left')\n",
    "        preds = sf.predict(h=config.h, X_df=test_with_pop[['unique_id', 'ds', 'population']])\n",
    "    else:\n",
    "        sf.fit(df=train)\n",
    "        preds = sf.predict(h=config.h)\n",
    "    \n",
    "    # Merge predictions with actuals\n",
    "    preds_df = pd.merge(test, preds.reset_index(), on=['ds', 'unique_id'], how='left')\n",
    "    \n",
    "    # Evaluate\n",
    "    model_cols = [col for col in preds.columns if col not in ['unique_id', 'ds']]\n",
    "    eval_df = evaluate(preds_df, metrics=[mae, mse, rmse], models=model_cols)\n",
    "    \n",
    "    # Add best model\n",
    "    mae_df = eval_df[eval_df['metric'] == 'mae'].copy()\n",
    "    mae_df['best_model'] = mae_df[model_cols].idxmin(axis=1)\n",
    "    \n",
    "    exog_label = \" (with population)\" if use_exog else \" (no exog)\"\n",
    "    print(f\"\\nüìà Best Models (Train-Test Split - {target_name}{exog_label}):\")\n",
    "    print(mae_df['best_model'].value_counts())\n",
    "    \n",
    "    return eval_df, preds_df, train, test\n",
    "\n",
    "def CV_with_exog(df,target_name,config,population_df=None):\n",
    "    \n",
    "    use_exog = population_df is not None\n",
    "    models = get_models_exog(config, use_exog=use_exog)\n",
    "    \n",
    "    sf = StatsForecast(\n",
    "        models=models,\n",
    "        freq='QS',\n",
    "        n_jobs=config.n_jobs,\n",
    "        fallback_model=SeasonalNaive(season_length=config.season_length)\n",
    "    )\n",
    "    \n",
    "    print(f\"   Running cross-validation...\")\n",
    "    \n",
    "    # Cross-validation with/without exogenous\n",
    "    if use_exog:\n",
    "\n",
    "        df_for_cv = df.copy()\n",
    "        if 'population' in df_for_cv.columns:\n",
    "            df_for_cv = df_for_cv.drop(columns=['population'])\n",
    "            \n",
    "        df_with_pop = df.merge(population_df, on=['unique_id', 'ds'], how='left')\n",
    "        cv_df = sf.cross_validation(\n",
    "            df=df_with_pop[['unique_id', 'ds', 'y', 'population']],\n",
    "            h=config.h,\n",
    "            n_windows=config.n_windows,\n",
    "            step_size=config.step_size\n",
    "        )\n",
    "    else:\n",
    "        cv_df = sf.cross_validation(\n",
    "            df=df,\n",
    "            h=config.h,\n",
    "            n_windows=config.n_windows,\n",
    "            step_size=config.step_size\n",
    "        )\n",
    "    \n",
    "    # Evaluate per cutoff\n",
    "    exclude_cols = ['unique_id', 'ds', 'y', 'cutoff', 'metric', 'population']\n",
    "    model_cols = [col for col in cv_df.columns if col not in exclude_cols]\n",
    "    \n",
    "    all_results = []\n",
    "    \n",
    "    for cutoff in cv_df['cutoff'].unique():\n",
    "        cutoff_data = cv_df[cv_df['cutoff'] == cutoff]\n",
    "        \n",
    "        cutoff_eval = evaluate(cutoff_data, metrics=[mae, mse, rmse], models=model_cols)\n",
    "        cutoff_eval['cutoff'] = cutoff\n",
    "        cutoff_eval['best_model'] = cutoff_eval[model_cols].idxmin(axis=1)\n",
    "        cutoff_eval['best_value'] = cutoff_eval[model_cols].min(axis=1)\n",
    "        \n",
    "        all_results.append(cutoff_eval)\n",
    "        \n",
    "        cutoff_mae = cutoff_eval[cutoff_eval['metric'] == 'mae']\n",
    "        print(f\"\\n   Cutoff {cutoff.strftime('%Y-%m-%d')} (MAE best models):\")\n",
    "        print(f\"   {cutoff_mae['best_model'].value_counts().to_dict()}\")\n",
    "    \n",
    "    eval_df = pd.concat(all_results, ignore_index=True)\n",
    "    \n",
    "    mae_overall = eval_df[eval_df['metric'] == 'mae']\n",
    "    exog_label = \" (with population)\" if use_exog else \"\"\n",
    "    print(f\"\\nüìà Overall Best Models{exog_label}:\")\n",
    "    print(mae_overall['best_model'].value_counts())\n",
    "    \n",
    "    return eval_df, cv_df\n",
    "\n",
    "def generate_future_forecasts(df_historical, target_name, config, population_scenario, horizon=None,save_path=None):\n",
    "    \n",
    "    if horizon is None:\n",
    "        horizon = config.h\n",
    "    use_exog = population_scenario is not None\n",
    "    models = get_models_exog(config, use_exog=use_exog)\n",
    "    \n",
    "    sf = StatsForecast(\n",
    "        models=models,\n",
    "        freq='QS',\n",
    "        n_jobs=config.n_jobs,\n",
    "        fallback_model=SeasonalNaive(season_length=config.season_length)\n",
    "    )\n",
    "    \n",
    "    # Train on full historical data\n",
    "    if use_exog:\n",
    "        # Get historical population\n",
    "        pop_historical = population_scenario[\n",
    "            population_scenario['ds'] <= df_historical['ds'].max()\n",
    "        ].copy()\n",
    "        \n",
    "        df_train = df_historical.merge(pop_historical, on=['unique_id', 'ds'], how='left')\n",
    "        sf.fit(df=df_train[['unique_id', 'ds', 'y', 'population']])\n",
    "        \n",
    "        # Get future population for forecasting\n",
    "        last_date = df_historical['ds'].max()\n",
    "        future_dates = pd.date_range(\n",
    "            start=last_date + pd.DateOffset(months=3),\n",
    "            periods=horizon,\n",
    "            freq='QS'\n",
    "        )\n",
    "        \n",
    "        # Create future exogenous dataframe\n",
    "        future_exog_list = []\n",
    "        for uid in df_historical['unique_id'].unique():\n",
    "            for date in future_dates:\n",
    "                pop_val = population_scenario[\n",
    "                    (population_scenario['unique_id'] == uid) & \n",
    "                    (population_scenario['ds'] == date)\n",
    "                ]['population'].values\n",
    "                \n",
    "                if len(pop_val) > 0:\n",
    "                    future_exog_list.append({\n",
    "                        'unique_id': uid,\n",
    "                        'ds': date,\n",
    "                        'population': pop_val[0]\n",
    "                    })\n",
    "        \n",
    "        future_exog_df = pd.DataFrame(future_exog_list)\n",
    "        forecasts_df = sf.predict(h=horizon, X_df=future_exog_df)\n",
    "    else:\n",
    "        sf.fit(df=df_historical,)\n",
    "        forecasts_df = sf.predict(h=horizon)\n",
    "    \n",
    "    if save_path:\n",
    "        os.makedirs(save_path, exist_ok=True)\n",
    "        filename = os.path.join(\n",
    "            save_path, \n",
    "            f'{target_name.lower().replace(\" \", \"_\")}_future_h{horizon}.csv'\n",
    "        )\n",
    "        forecasts_df.reset_index().to_csv(filename, index=False)\n",
    "        print(f\"‚úÖ Saved: {filename}\")\n",
    "    \n",
    "    return forecasts_df\n",
    "\n",
    "def forecast_with_population_scenarios(filepath, target_col, states=None, config=None, horizons=None, save_path=None):\n",
    "    \n",
    "    if config is None:\n",
    "        config = ForecastConfig()\n",
    "    \n",
    "    # ‚≠ê If horizons not specified, use config.h\n",
    "    if horizons is None:\n",
    "        horizons = [config.h]\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(f\"FORECASTING: {target_col}\")\n",
    "    print(f\"Horizons: {horizons} quarters\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    # Load data\n",
    "    print(\"\\n1. Loading data...\")\n",
    "    df_units, df_prescriptions, df_full = load_data_exog(filepath, states)\n",
    "    \n",
    "    df = df_units if target_col == 'Units Reimbursed' else df_prescriptions\n",
    "    target_name = target_col\n",
    "    \n",
    "    print(f\"   ‚Ä¢ Unique series: {df['unique_id'].nunique()}\")\n",
    "    print(f\"   ‚Ä¢ Date range: {df['ds'].min()} to {df['ds'].max()}\")\n",
    "    \n",
    "    # Create population scenarios\n",
    "    print(\"\\n2. Creating population scenarios...\")\n",
    "    pop_scenarios = pop_scenarios_exog(filepath, states)\n",
    "    \n",
    "    results = {\n",
    "        'point': {},\n",
    "        'low_95': {},\n",
    "        'high_95': {}\n",
    "    }\n",
    "    \n",
    "    # Run for each scenario\n",
    "    for scenario_name, pop_df in pop_scenarios.items():\n",
    "        print(f\"\\n{'='*70}\")\n",
    "        print(f\"SCENARIO: {scenario_name.upper()}\")\n",
    "        print(\"=\"*70)\n",
    "        \n",
    "        # Evaluation (uses config.h for train-test and CV)\n",
    "        print(\"\\n3. Train-Test Evaluation...\")\n",
    "        eval_tt, preds_tt, train, test = evaluate_train_test_exog(\n",
    "            df, target_name, config, pop_df\n",
    "        )\n",
    "        \n",
    "        print(\"\\n4. Cross-Validation...\")\n",
    "        eval_cv, cv_df = CV_with_exog(\n",
    "            df, target_name, config, pop_df\n",
    "        )\n",
    "        \n",
    "        # Production forecasts for each horizon\n",
    "        for h in horizons:\n",
    "            print(f\"\\n5. Generating future forecasts (h={h})...\")\n",
    "            \n",
    "            forecasts = generate_future_forecasts(\n",
    "                df, target_name, config, pop_df, \n",
    "                horizon=h,  # ‚≠ê Override config.h with specific horizon\n",
    "                save_path=os.path.join(save_path, scenario_name) if save_path else None\n",
    "            )\n",
    "            \n",
    "            results[scenario_name][f'h{h}'] = {\n",
    "                'forecasts': forecasts,\n",
    "                'eval_train_test': eval_tt,\n",
    "                'eval_cross_val': eval_cv,\n",
    "                'predictions': preds_tt\n",
    "            }\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"‚úÖ COMPLETE!\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    return results                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50b544de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sensitivity_analysis_with_exog(filepath, target_col, states=None, param_grid=None, production_horizons=[4, 8],\n",
    "    population_scenario='point',  # 'point', 'low_95', or 'high_95'\n",
    "    save_path=None):\n",
    "\n",
    "    # Default parameter grid\n",
    "    if param_grid is None:\n",
    "        param_grid = {\n",
    "            'h': [4, 8],\n",
    "            'test_size': [4, 8],\n",
    "            'train_size': [None, 20, 28],\n",
    "            'n_windows': [2, 3, 4],\n",
    "            'step_size': [4],\n",
    "        }\n",
    "    \n",
    "    print(\"=\" * 80); print(f\"SENSITIVITY ANALYSIS WITH EXOGENOUS VARIABLES: {target_col}\")\n",
    "    print(f\"Population Scenario: {population_scenario.upper()}\"); print(f\"Testing {len(list(product(*param_grid.values())))} configurations\")\n",
    "    print(\"=\" * 80); print(\"\\nPhase 1: Loading and preparing data...\")\n",
    "    \n",
    "    df_units, df_prescriptions, df_full = load_data_exog(filepath, states)\n",
    "    df = df_units if target_col == 'Units Reimbursed' else df_prescriptions\n",
    "    target_name = target_col\n",
    "    \n",
    "    print(f\"\\nUnique series: {df['unique_id'].nunique()}\")\n",
    "    print(f\"\\nDate range: {df['ds'].min()} to {df['ds'].max()}\")\n",
    "    print(f\"\\nTotal observations: {len(df)}\")\n",
    "    \n",
    "    # Get population scenarios\n",
    "    pop_scenarios = pop_scenarios_exog(filepath, states)\n",
    "    pop_df = pop_scenarios[population_scenario]\n",
    "    \n",
    "    print(f\"\\nPopulation scenario loaded: {population_scenario}\")\n",
    "    print(f\"\\nPopulation records: {len(pop_df)}\")\n",
    "    \n",
    "    print(\"\\nPhase 2: Running sensitivity analysis...\")\n",
    "    param_names = list(param_grid.keys())\n",
    "    param_values = list(param_grid.values())\n",
    "    combinations = list(product(*param_values))\n",
    "    \n",
    "    all_results = []\n",
    "    all_errors = []  # Simplified error tracking - mean per config\n",
    "    \n",
    "    for i, combo in enumerate(combinations):\n",
    "        params = dict(zip(param_names, combo))\n",
    "        \n",
    "        # Skip invalid combinations\n",
    "        if params.get('test_size') and params.get('h'):\n",
    "            if params['test_size'] < params['h']:\n",
    "                continue\n",
    "        \n",
    "        if params['test_size'] != params['h']:\n",
    "            continue\n",
    "\n",
    "        print(f\"\\n{'‚îÄ' * 80}\"); print(f\"Configuration {i+1}/{len(combinations)}: {params}\"); print('‚îÄ' * 80)\n",
    "        \n",
    "        try:\n",
    "            config = ForecastConfig(\n",
    "                h=params.get('h', 8),\n",
    "                train_size=params.get('train_size'),\n",
    "                test_size=params.get('test_size'),\n",
    "                n_windows=params.get('n_windows', 2),\n",
    "                step_size=params.get('step_size'),\n",
    "                season_length=4,\n",
    "                n_jobs=-1\n",
    "            )\n",
    "            \n",
    "            # Train-Test Evaluation\n",
    "            print(\"\\nRunning train-test evaluation...\")\n",
    "            eval_tt, preds_tt, train_df, test_df = evaluate_train_test_exog(\n",
    "                df, target_name, config, pop_df\n",
    "            )\n",
    "            \n",
    "            # Cross-Validation\n",
    "            print(\"\\nRunning Cross-Validation...\")\n",
    "            eval_cv, cv_df = CV_with_exog(\n",
    "                df, target_name, config, pop_df\n",
    "            )\n",
    "            \n",
    "            exclude_cols = ['unique_id', 'ds', 'y', 'cutoff', 'metric', 'best_model', 'best_value', 'population']\n",
    "            model_cols = [col for col in eval_cv.columns if col not in exclude_cols]\n",
    "            \n",
    "            # Extract MAE results\n",
    "            mae_cv = eval_cv[eval_cv['metric'] == 'mae'].copy()\n",
    "            mae_traintest = eval_tt[eval_tt['metric'] == 'mae'].copy()\n",
    "            \n",
    "            # Add best_model if not present\n",
    "            if 'best_model' not in mae_traintest.columns:\n",
    "                mae_traintest['best_model'] = mae_traintest[model_cols].idxmin(axis=1)\n",
    "            \n",
    "            # Collect Results Per Unique_ID \n",
    "            for uid in df['unique_id'].unique():\n",
    "                uid_cv = mae_cv[mae_cv['unique_id'] == uid]\n",
    "                uid_traintest = mae_traintest[mae_traintest['unique_id'] == uid]\n",
    "                \n",
    "                # CV analysis\n",
    "                cv_best_model = uid_cv['best_model'].mode().iloc[0] if len(uid_cv) > 0 else None\n",
    "                cv_best_count = (uid_cv['best_model'] == cv_best_model).sum()\n",
    "                cv_total = len(uid_cv)\n",
    "                cv_consistency = cv_best_count / cv_total if cv_total > 0 else 0\n",
    "                \n",
    "                # Train-test analysis\n",
    "                traintest_best_model = uid_traintest['best_model'].iloc[0] if len(uid_traintest) > 0 else None\n",
    "                \n",
    "                # Build result row\n",
    "                result_row = {\n",
    "                    'unique_id': uid,\n",
    "                    'config_id': i + 1,\n",
    "                    'population_scenario': population_scenario,\n",
    "                    **params,\n",
    "                    'cv_best_model': cv_best_model,\n",
    "                    'cv_consistency': cv_consistency,\n",
    "                    'traintest_best_model': traintest_best_model,\n",
    "                    'cv_traintest_agree': cv_best_model == traintest_best_model,\n",
    "                }\n",
    "                \n",
    "                # Add MAE values for each model\n",
    "                for model in model_cols:\n",
    "                    cv_mae = uid_cv[model].mean() if len(uid_cv) > 0 else None\n",
    "                    tt_mae = uid_traintest[model].iloc[0] if len(uid_traintest) > 0 and model in uid_traintest.columns else None\n",
    "                    \n",
    "                    result_row[f'{model}_cv_mae'] = cv_mae\n",
    "                    result_row[f'{model}_tt_mae'] = tt_mae\n",
    "                \n",
    "                all_results.append(result_row)\n",
    "                \n",
    "                # One row per unique_id per configuration with MEAN CV MAE and Train-Test MAE\n",
    "                error_row = {\n",
    "                    'config_id': i + 1,\n",
    "                    'unique_id': uid,\n",
    "                    'population_scenario': population_scenario,\n",
    "                    **params,\n",
    "                    'n_cv_windows': cv_total,\n",
    "                }\n",
    "                \n",
    "                # Add mean CV MAE and Train-Test MAE for each model\n",
    "                for model in model_cols:\n",
    "                    # Mean MAE across all CV windows\n",
    "                    cv_mean_mae = uid_cv[model].mean() if len(uid_cv) > 0 else None\n",
    "                    error_row[f'{model}_cv_mean_mae'] = cv_mean_mae\n",
    "                    \n",
    "                    # Train-Test MAE\n",
    "                    tt_mae = uid_traintest[model].iloc[0] if len(uid_traintest) > 0 and model in uid_traintest.columns else None\n",
    "                    error_row[f'{model}_tt_mae'] = tt_mae\n",
    "                \n",
    "                all_errors.append(error_row)\n",
    "            \n",
    "            print(f\"   ‚úÖ Configuration {i+1} completed successfully\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"   ‚ùå Error in configuration {i+1}: {str(e)}\")\n",
    "            import traceback\n",
    "            traceback.print_exc()\n",
    "            continue\n",
    "    \n",
    "    # Convert to DataFrames\n",
    "    results_df = pd.DataFrame(all_results)\n",
    "    errors_df = pd.DataFrame(all_errors)\n",
    "    \n",
    "    print(f\"\\n‚úÖ Sensitivity analysis complete!\")\n",
    "    print(f\"\\nTotal configurations tested: {results_df['config_id'].nunique()}\")\n",
    "    print(f\"\\nTotal unique_ids analyzed: {results_df['unique_id'].nunique()}\")\n",
    "    \n",
    "    print(\"\\nPhase 3: Identifying best models per horizon...\")\n",
    "    \n",
    "    recommendations_per_horizon = {}\n",
    "    \n",
    "    for horizon in production_horizons:\n",
    "        print(f\"\\nAnalyzing horizon h={horizon}...\")\n",
    "        \n",
    "        horizon_results = results_df[results_df['h'] == horizon].copy()\n",
    "        \n",
    "        if len(horizon_results) == 0:\n",
    "            print(f\"   ‚ö†Ô∏è No results for h={horizon}\")\n",
    "            continue\n",
    "        \n",
    "        horizon_recommendations = []\n",
    "        \n",
    "        for uid in horizon_results['unique_id'].unique():\n",
    "            uid_data = horizon_results[horizon_results['unique_id'] == uid]\n",
    "            \n",
    "            # Most frequent CV best model\n",
    "            cv_mode = uid_data['cv_best_model'].mode()\n",
    "            cv_best = cv_mode.iloc[0] if len(cv_mode) > 0 else None\n",
    "            cv_freq = (uid_data['cv_best_model'] == cv_best).sum() / len(uid_data)\n",
    "            \n",
    "            # Most frequent train-test best model\n",
    "            tt_mode = uid_data['traintest_best_model'].mode()\n",
    "            tt_best = tt_mode.iloc[0] if len(tt_mode) > 0 else None\n",
    "            tt_freq = (uid_data['traintest_best_model'] == tt_best).sum() / len(uid_data)\n",
    "            \n",
    "            # Average consistency\n",
    "            avg_consistency = uid_data['cv_consistency'].mean()\n",
    "            \n",
    "            # Determine recommendation\n",
    "            if cv_best == tt_best and cv_freq >= 0.7 and avg_consistency >= 0.7:\n",
    "                confidence = 'High'\n",
    "                recommended_model = cv_best\n",
    "                reason = \"CV and Train-Test agree with high frequency and consistency\"\n",
    "            elif cv_best == tt_best and cv_freq >= 0.5:\n",
    "                confidence = 'Medium-High'\n",
    "                recommended_model = cv_best\n",
    "                reason = \"CV and Train-Test agree with moderate frequency\"\n",
    "            elif cv_freq >= 0.6:\n",
    "                confidence = 'Medium'\n",
    "                recommended_model = cv_best\n",
    "                reason = f\"CV favors {cv_best} ({cv_freq:.0%})\"\n",
    "            elif tt_freq >= 0.6:\n",
    "                confidence = 'Medium'\n",
    "                recommended_model = tt_best\n",
    "                reason = f\"Train-Test favors {tt_best} ({tt_freq:.0%})\"\n",
    "            else:\n",
    "                confidence = 'Low'\n",
    "                # Use lowest average CV MAE\n",
    "                mae_cols = [col for col in uid_data.columns if col.endswith('_cv_mae')]\n",
    "                if mae_cols:\n",
    "                    avg_maes = uid_data[mae_cols].mean()\n",
    "                    recommended_model = avg_maes.idxmin().replace('_cv_mae', '')\n",
    "                else:\n",
    "                    recommended_model = cv_best\n",
    "                reason = \"No clear winner - using lowest average CV MAE\"\n",
    "            \n",
    "            # Get average MAE\n",
    "            rec_mae_col = f'{recommended_model}_cv_mae'\n",
    "            avg_mae = uid_data[rec_mae_col].mean() if rec_mae_col in uid_data.columns else None\n",
    "            \n",
    "            recommendation = {\n",
    "                'unique_id': uid,\n",
    "                'horizon': horizon,\n",
    "                'recommended_model': recommended_model,\n",
    "                'confidence': confidence,\n",
    "                'reason': reason,\n",
    "                'cv_best_model': cv_best,\n",
    "                'cv_frequency': cv_freq,\n",
    "                'cv_consistency': avg_consistency,\n",
    "                'traintest_best_model': tt_best,\n",
    "                'avg_cv_mae': avg_mae,\n",
    "                'population_scenario': population_scenario\n",
    "            }\n",
    "            \n",
    "            horizon_recommendations.append(recommendation)\n",
    "            \n",
    "            mae_display = f\"{avg_mae:,.0f}\" if pd.notna(avg_mae) else \"N/A\"\n",
    "            print(f\"   {uid}: {recommended_model} (confidence: {confidence}, MAE: {mae_display})\")\n",
    "        \n",
    "        recommendations_per_horizon[horizon] = pd.DataFrame(horizon_recommendations)\n",
    "    \n",
    "    print(\"\\nPhase 4: Generating production forecasts...\")\n",
    "    \n",
    "    production_forecasts = {}\n",
    "    \n",
    "    for horizon in production_horizons:\n",
    "        if horizon not in recommendations_per_horizon:\n",
    "            continue\n",
    "        \n",
    "        print(f\"\\nGenerating forecasts for h={horizon}...\")\n",
    "        \n",
    "        recommendations = recommendations_per_horizon[horizon]\n",
    "        \n",
    "        # Configuration for production\n",
    "        config_prod = ForecastConfig(\n",
    "            h=horizon,\n",
    "            season_length=4,\n",
    "            confidence_level=95,\n",
    "            n_jobs=-1\n",
    "        )\n",
    "        \n",
    "        # Train all models on full historical data\n",
    "        models = get_models_exog(config_prod, use_exog=True)\n",
    "        \n",
    "        sf = StatsForecast(\n",
    "            models=models,\n",
    "            freq='QS',\n",
    "            n_jobs=-1,\n",
    "            fallback_model=SeasonalNaive(season_length=4)\n",
    "        )\n",
    "        \n",
    "        # Prepare data with population\n",
    "        pop_historical = pop_df[pop_df['ds'] <= df['ds'].max()].copy()\n",
    "        df_train = df.merge(pop_historical, on=['unique_id', 'ds'], how='left')\n",
    "        \n",
    "        # Fit on historical data\n",
    "        sf.fit(df=df_train[['unique_id', 'ds', 'y', 'population']])\n",
    "        \n",
    "        # Prepare future population\n",
    "        last_date = df['ds'].max()\n",
    "        future_dates = pd.date_range(\n",
    "            start=last_date + pd.DateOffset(months=3),\n",
    "            periods=horizon,\n",
    "            freq='QS'\n",
    "        )\n",
    "        \n",
    "        future_exog_list = []\n",
    "        for uid in df['unique_id'].unique():\n",
    "            for date in future_dates:\n",
    "                pop_val = pop_df[\n",
    "                    (pop_df['unique_id'] == uid) & \n",
    "                    (pop_df['ds'] == date)\n",
    "                ]['population'].values\n",
    "                \n",
    "                if len(pop_val) > 0:\n",
    "                    future_exog_list.append({\n",
    "                        'unique_id': uid,\n",
    "                        'ds': date,\n",
    "                        'population': pop_val[0]\n",
    "                    })\n",
    "        \n",
    "        future_exog_df = pd.DataFrame(future_exog_list)\n",
    "        \n",
    "        # Generate forecasts\n",
    "        forecasts_df = sf.predict(h=horizon, X_df=future_exog_df)\n",
    "        \n",
    "        # Create best model forecasts\n",
    "        best_forecasts = []\n",
    "        \n",
    "        for uid in df['unique_id'].unique():\n",
    "            uid_forecasts = forecasts_df.reset_index()\n",
    "            uid_forecasts = uid_forecasts[uid_forecasts['unique_id'] == uid]\n",
    "            \n",
    "            uid_rec = recommendations[recommendations['unique_id'] == uid]\n",
    "            if len(uid_rec) == 0:\n",
    "                print(f\"   ‚ö†Ô∏è No recommendation for {uid}, skipping\")\n",
    "                continue\n",
    "            \n",
    "            best_model = uid_rec['recommended_model'].iloc[0]\n",
    "            \n",
    "            for _, row in uid_forecasts.iterrows():\n",
    "                best_row = {\n",
    "                    'unique_id': uid,\n",
    "                    'ds': row['ds'],\n",
    "                    'recommended_model': best_model,\n",
    "                    'forecast': row.get(best_model, np.nan),\n",
    "                    'forecast_lo_95': row.get(f'{best_model}-lo-95', np.nan),\n",
    "                    'forecast_hi_95': row.get(f'{best_model}-hi-95', np.nan),\n",
    "                    'population_scenario': population_scenario\n",
    "                }\n",
    "                best_forecasts.append(best_row)\n",
    "        \n",
    "        best_forecasts_df = pd.DataFrame(best_forecasts)\n",
    "        \n",
    "        production_forecasts[horizon] = {\n",
    "            'all_models': forecasts_df,\n",
    "            'best_model': best_forecasts_df,\n",
    "            'recommendations': recommendations\n",
    "        }\n",
    "        \n",
    "        print(f\"   ‚úÖ Generated {len(best_forecasts_df)} forecast periods\")\n",
    "        print(f\"   ‚úÖ Models used: {recommendations['recommended_model'].value_counts().to_dict()}\")\n",
    "    \n",
    "    print(\"\\nPhase 5: Saving results...\")\n",
    "    \n",
    "    if save_path:\n",
    "        os.makedirs(save_path, exist_ok=True)\n",
    "        \n",
    "        # Save comprehensive results\n",
    "        sensitivity_file = os.path.join(\n",
    "            save_path, \n",
    "            f'{target_name.lower().replace(\" \", \"_\")}_sensitivity_{population_scenario}.xlsx'\n",
    "        )\n",
    "        \n",
    "        with pd.ExcelWriter(sensitivity_file, engine='openpyxl') as writer:\n",
    "            # Sheet 1: All configurations summary\n",
    "            results_df.to_excel(writer, sheet_name='All_Configurations', index=False)\n",
    "            \n",
    "            # Sheet 2: Simplified errors - Mean CV MAE and Train-Test MAE per config\n",
    "            errors_df.to_excel(writer, sheet_name='Model_Errors', index=False)\n",
    "            \n",
    "            # Sheet 3: Recommendations\n",
    "            rec_frames = list(recommendations_per_horizon.values())\n",
    "            if rec_frames:\n",
    "                all_recs = pd.concat(rec_frames, ignore_index=True)\n",
    "                all_recs.to_excel(writer, sheet_name='Recommendations', index=False)\n",
    "            \n",
    "            # Sheet 4: Configuration summary statistics\n",
    "            config_summary = results_df.groupby('config_id').agg({\n",
    "                'cv_traintest_agree': 'mean',\n",
    "                'cv_consistency': 'mean'\n",
    "            }).reset_index()\n",
    "            config_summary.columns = ['config_id', 'avg_cv_tt_agreement', 'avg_cv_consistency']\n",
    "            \n",
    "            # Add parameter details\n",
    "            param_details = results_df.groupby('config_id')[param_names].first().reset_index()\n",
    "            config_summary = config_summary.merge(param_details, on='config_id')\n",
    "            config_summary.to_excel(writer, sheet_name='Config_Summary', index=False)\n",
    "        \n",
    "        print(f\"‚úÖ Sensitivity analysis saved: {sensitivity_file}\")\n",
    "        \n",
    "        # Save production forecasts\n",
    "        for horizon, forecasts in production_forecasts.items():\n",
    "            horizon_file = os.path.join(\n",
    "                save_path,\n",
    "                f'{target_name.lower().replace(\" \", \"_\")}_production_h{horizon}_{population_scenario}.xlsx'\n",
    "            )\n",
    "            \n",
    "            with pd.ExcelWriter(horizon_file, engine='openpyxl') as writer:\n",
    "                forecasts['all_models'].reset_index().to_excel(\n",
    "                    writer, sheet_name='All_Models', index=False\n",
    "                )\n",
    "                forecasts['best_model'].to_excel(\n",
    "                    writer, sheet_name='Best_Model_Forecast', index=False\n",
    "                )\n",
    "                forecasts['recommendations'].to_excel(\n",
    "                    writer, sheet_name='Model_Selection', index=False\n",
    "                )\n",
    "            \n",
    "            print(f\"‚úÖ Production forecasts (h={horizon}) saved: {horizon_file}\")\n",
    "    else:\n",
    "        print(\"   ‚ö†Ô∏è No save_path provided - skipping file export\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"‚úÖ SENSITIVITY ANALYSIS COMPLETE!\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    return {\n",
    "        'sensitivity_results': results_df,\n",
    "        'model_errors': errors_df,\n",
    "        'production_forecasts': production_forecasts,\n",
    "        'recommendations_per_horizon': recommendations_per_horizon\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21a58b66",
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath_withpop = rf\"C:\\Users\\{user}\\OneDrive - purdue.edu\\VS code\\Data\\ATC\\merged_data\\Prebuilt_panels\\P1_withpop.csv\"\n",
    "save_path = rf\"C:\\Users\\{user}\\OneDrive - purdue.edu\\VS code\\Data\\ATC\\Forecast\\TMF\\\\\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a62a5ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure\n",
    "config = ForecastConfig(\n",
    "    h=8,\n",
    "    season_length=4,\n",
    "    n_windows=3,\n",
    "    train_size=None,\n",
    "    test_size=8,  #Setting it to the same h\n",
    "    n_samples=4,\n",
    "    confidence_level=95,\n",
    "    models_to_plot=['Naive', 'SARIMAX']\n",
    ")\n",
    "\n",
    "# Run forecasting for Units Reimbursed with all three population scenarios\n",
    "results_units = forecast_with_population_scenarios(\n",
    "    filepath=filepath_withpop,\n",
    "    target_col='Units Reimbursed',\n",
    "    states=['IN'],  # Or None for all states\n",
    "    config=config,\n",
    "    horizons=[8],\n",
    "    save_path=save_path\n",
    ")\n",
    "\n",
    "# Run forecasting for Number of Prescriptions\n",
    "results_prescriptions = forecast_with_population_scenarios(\n",
    "    filepath=filepath_withpop,\n",
    "    target_col='Number of Prescriptions',\n",
    "    states=['IN'],\n",
    "    config=config,\n",
    "    horizons=[8],\n",
    "    save_path=save_path\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db51035e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage\n",
    "results = sensitivity_analysis_with_exog(\n",
    "    filepath=filepath_withpop,\n",
    "    target_col='Number of Prescriptions',\n",
    "    states=['IN'],\n",
    "    param_grid={\n",
    "        'h': [4, 8],\n",
    "        'train_size': [None], #Training all the dataset for Cross-Validation, otherwise the n_windows will be too small\n",
    "        'n_windows': [2, 3],\n",
    "        'step_size': [4],\n",
    "    },\n",
    "    production_horizons=[4, 8],\n",
    "    population_scenario='high_95',  # 'point' or 'low_95' or 'high_95'\n",
    "    save_path=save_path\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
