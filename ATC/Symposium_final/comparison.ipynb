{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d18a1b2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "import os\n",
    "from pathlib import Path\n",
    "from pathlib import Path\n",
    "from openpyxl import Workbook\n",
    "from openpyxl.styles import Font, PatternFill, Alignment, Border, Side"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6d070275",
   "metadata": {},
   "outputs": [],
   "source": [
    "user='Lilian'\n",
    "\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "plt.rcParams.update({\n",
    "    'font.family': 'sans-serif',\n",
    "    'font.sans-serif': ['Arial', 'DejaVu Sans'],\n",
    "    'font.size': 11,\n",
    "    'axes.titlesize': 13,\n",
    "    'axes.titleweight': 'bold',\n",
    "    'axes.labelsize': 11,\n",
    "    'xtick.labelsize': 10,\n",
    "    'ytick.labelsize': 10,\n",
    "    'legend.fontsize': 10,\n",
    "    'figure.titlesize': 16,\n",
    "    'figure.titleweight': 'bold',\n",
    "    'axes.spines.top': False,\n",
    "    'axes.spines.right': False,\n",
    "})\n",
    "\n",
    "# Color palette\n",
    "COLORS = {\n",
    "    'ml': '#2E86AB',        # Professional blue\n",
    "    'stats': '#F18F01',     # Warm orange\n",
    "    'gray': '#8D99AE',      # Elegant gray\n",
    "    'ml_light': '#A8D5E5',  \n",
    "    'stats_light': '#FCCF7D',\n",
    "    'background': '#F8F9FA',\n",
    "    'text': '#2B2D42',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7319c714",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ForecastComparisonPipeline:\n",
    "    \n",
    "    def __init__(self, file_path: str, gray_zone_pct: float = 5.0):\n",
    "        \"\"\"\n",
    "        Initialize pipeline.\n",
    "        \n",
    "        Args:\n",
    "            file_path: Path to Excel file\n",
    "            gray_zone_pct: If |MAE_stats - MAE_ml| < X% of avg(MAE_stats, MAE_ml), \n",
    "                          classify as \"Gray Zone\" (practical equivalence)\n",
    "        \"\"\"\n",
    "        self.file_path = file_path\n",
    "        self.file_name = Path(file_path).stem\n",
    "        self.states = ['IN', 'IL', 'OH', 'MI']\n",
    "        self.gray_zone_pct = gray_zone_pct\n",
    "        self.results = {}\n",
    "        \n",
    "    def _get_ml_best_mae(self, row: pd.Series) -> float:\n",
    "        \"\"\"Extract MAE for the recommended model from ML sheet.\"\"\"\n",
    "        model = row['recommended_model']\n",
    "        mae_col = f\"{model}_mae\"\n",
    "        if mae_col in row.index:\n",
    "            return row[mae_col]\n",
    "        return row['cv_mae']\n",
    "    \n",
    "    def _determine_best_approach(self, row: pd.Series) -> str:\n",
    "        \"\"\"Determine best approach with percentage-based gray zone.\"\"\"\n",
    "        avg_mae = (row['ml_mae'] + row['stats_mae']) / 2\n",
    "        threshold = avg_mae * (self.gray_zone_pct / 100)\n",
    "        mae_diff = abs(row['ml_mae'] - row['stats_mae'])\n",
    "        \n",
    "        if mae_diff < threshold:\n",
    "            return 'Gray Zone'\n",
    "        elif row['ml_mae'] < row['stats_mae']:\n",
    "            return 'ML'\n",
    "        else:\n",
    "            return 'Stats'\n",
    "    \n",
    "    def _determine_best_model(self, row: pd.Series) -> str:\n",
    "        \"\"\"Determine best model with gray zone consideration.\"\"\"\n",
    "        if row['best_approach'] == 'Gray Zone':\n",
    "            return f\"{row['ml_model']} â‰ˆ {row['stats_model']}\"\n",
    "        elif row['best_approach'] == 'ML':\n",
    "            return row['ml_model']\n",
    "        else:\n",
    "            return row['stats_model']\n",
    "    \n",
    "    def _determine_best_mae(self, row: pd.Series) -> float:\n",
    "        \"\"\"Determine best MAE (use average for gray zone).\"\"\"\n",
    "        if row['best_approach'] == 'Gray Zone':\n",
    "            return (row['ml_mae'] + row['stats_mae']) / 2\n",
    "        else:\n",
    "            return min(row['ml_mae'], row['stats_mae'])\n",
    "    \n",
    "    def process_state(self, state: str) -> pd.DataFrame:\n",
    "        \"\"\"Process and compare ML vs Stats for a given state.\"\"\"\n",
    "        ml_df = pd.read_excel(self.file_path, sheet_name=f'{state}_ML')\n",
    "        stats_df = pd.read_excel(self.file_path, sheet_name=f'{state}_Stats')\n",
    "        \n",
    "        ml_df['ml_best_mae'] = ml_df.apply(self._get_ml_best_mae, axis=1)\n",
    "        ml_processed = ml_df[['unique_id', 'recommended_model', 'ml_best_mae', 'confidence']].copy()\n",
    "        ml_processed.columns = ['unique_id', 'ml_model', 'ml_mae', 'ml_confidence']\n",
    "        \n",
    "        stats_processed = stats_df[['unique_id', 'recommended_model', 'avg_cv_mae', 'confidence']].copy()\n",
    "        stats_processed.columns = ['unique_id', 'stats_model', 'stats_mae', 'stats_confidence']\n",
    "        \n",
    "        comparison = pd.merge(ml_processed, stats_processed, on='unique_id', how='inner')\n",
    "        \n",
    "        # Calculate metrics\n",
    "        comparison['mae_difference'] = comparison['stats_mae'] - comparison['ml_mae']\n",
    "        comparison['abs_mae_difference'] = comparison['mae_difference'].abs()\n",
    "        comparison['avg_mae'] = (comparison['ml_mae'] + comparison['stats_mae']) / 2\n",
    "        comparison['pct_difference'] = (comparison['abs_mae_difference'] / comparison['avg_mae']) * 100\n",
    "        \n",
    "        # Apply gray zone logic\n",
    "        comparison['best_approach'] = comparison.apply(self._determine_best_approach, axis=1)\n",
    "        comparison['best_model'] = comparison.apply(self._determine_best_model, axis=1)\n",
    "        comparison['best_mae'] = comparison.apply(self._determine_best_mae, axis=1)\n",
    "        comparison['state'] = state\n",
    "        \n",
    "        return comparison\n",
    "    \n",
    "    def run_comparison(self) -> pd.DataFrame:\n",
    "        \"\"\"Run comparison for all states.\"\"\"\n",
    "        all_comparisons = []\n",
    "        for state in self.states:\n",
    "            try:\n",
    "                state_comparison = self.process_state(state)\n",
    "                all_comparisons.append(state_comparison)\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing {state}: {e}\")\n",
    "        \n",
    "        self.results_df = pd.concat(all_comparisons, ignore_index=True)\n",
    "        return self.results_df\n",
    "    \n",
    "    def get_summary_statistics(self) -> dict:\n",
    "        \"\"\"Generate comprehensive summary statistics with gray zone.\"\"\"\n",
    "        df = self.results_df\n",
    "        \n",
    "        n_total = len(df)\n",
    "        n_ml = (df['best_approach'] == 'ML').sum()\n",
    "        n_stats = (df['best_approach'] == 'Stats').sum()\n",
    "        n_gray = (df['best_approach'] == 'Gray Zone').sum()\n",
    "        \n",
    "        summary = {\n",
    "            'overall': {\n",
    "                'total_series': n_total,\n",
    "                'ml_wins': int(n_ml),\n",
    "                'stats_wins': int(n_stats),\n",
    "                'gray_zone': int(n_gray),\n",
    "                'ml_win_rate': n_ml / n_total * 100,\n",
    "                'stats_win_rate': n_stats / n_total * 100,\n",
    "                'gray_zone_rate': n_gray / n_total * 100,\n",
    "                'gray_zone_pct_threshold': self.gray_zone_pct,\n",
    "                'avg_ml_mae': df['ml_mae'].mean(),\n",
    "                'avg_stats_mae': df['stats_mae'].mean(),\n",
    "                'avg_best_mae': df['best_mae'].mean(),\n",
    "                'median_pct_difference': df['pct_difference'].median(),\n",
    "                'avg_pct_difference': df['pct_difference'].mean(),\n",
    "            },\n",
    "            'by_state': {},\n",
    "            'by_ml_model': df[df['best_approach'] == 'ML']['ml_model'].value_counts().to_dict(),\n",
    "            'by_stats_model': df[df['best_approach'] == 'Stats']['stats_model'].value_counts().to_dict(),\n",
    "        }\n",
    "        \n",
    "        for state in df['state'].unique():\n",
    "            state_df = df[df['state'] == state]\n",
    "            n_state = len(state_df)\n",
    "            summary['by_state'][state] = {\n",
    "                'total_series': n_state,\n",
    "                'ml_wins': int((state_df['best_approach'] == 'ML').sum()),\n",
    "                'stats_wins': int((state_df['best_approach'] == 'Stats').sum()),\n",
    "                'gray_zone': int((state_df['best_approach'] == 'Gray Zone').sum()),\n",
    "                'ml_win_rate': (state_df['best_approach'] == 'ML').mean() * 100,\n",
    "                'stats_win_rate': (state_df['best_approach'] == 'Stats').mean() * 100,\n",
    "                'gray_zone_rate': (state_df['best_approach'] == 'Gray Zone').mean() * 100,\n",
    "                'avg_pct_difference': state_df['pct_difference'].mean(),\n",
    "            }\n",
    "        \n",
    "        return summary\n",
    "    \n",
    "    def get_model_frequency_analysis(self) -> pd.DataFrame:\n",
    "        \"\"\"Analyze which models are most frequently selected (excluding gray zone).\"\"\"\n",
    "        df = self.results_df\n",
    "        clear_winners = df[df['best_approach'] != 'Gray Zone'].copy()\n",
    "        \n",
    "        if len(clear_winners) == 0:\n",
    "            return pd.DataFrame()\n",
    "        \n",
    "        clear_winners['single_best_model'] = np.where(\n",
    "            clear_winners['best_approach'] == 'ML',\n",
    "            clear_winners['ml_model'],\n",
    "            clear_winners['stats_model']\n",
    "        )\n",
    "        \n",
    "        best_model_counts = clear_winners['single_best_model'].value_counts().reset_index()\n",
    "        best_model_counts.columns = ['Model', 'Times_Selected']\n",
    "        \n",
    "        avg_mae_by_model = clear_winners.groupby('single_best_model')['best_mae'].agg(['mean', 'median']).reset_index()\n",
    "        avg_mae_by_model.columns = ['Model', 'Avg_MAE', 'Median_MAE']\n",
    "        \n",
    "        model_analysis = pd.merge(best_model_counts, avg_mae_by_model, on='Model')\n",
    "        model_analysis['Selection_Rate_%'] = (model_analysis['Times_Selected'] / len(clear_winners) * 100).round(1)\n",
    "        \n",
    "        ml_models = ['RandomForest', 'LightGBM', 'Ridge', 'XGBoost']\n",
    "        model_analysis['Approach'] = model_analysis['Model'].apply(\n",
    "            lambda x: 'ML' if x in ml_models else 'Stats'\n",
    "        )\n",
    "        \n",
    "        return model_analysis.sort_values('Times_Selected', ascending=False)\n",
    "    \n",
    "    def get_all_model_frequency(self) -> pd.DataFrame:\n",
    "        \"\"\"Get model frequency for ALL selections (ML models when ML wins, Stats when Stats wins).\"\"\"\n",
    "        df = self.results_df\n",
    "        \n",
    "        # ML models (count when ML approach wins)\n",
    "        ml_wins = df[df['best_approach'] == 'ML']\n",
    "        ml_counts = ml_wins['ml_model'].value_counts().reset_index()\n",
    "        ml_counts.columns = ['Model', 'Count']\n",
    "        ml_counts['Approach'] = 'ML'\n",
    "        \n",
    "        # Stats models (count when Stats approach wins)\n",
    "        stats_wins = df[df['best_approach'] == 'Stats']\n",
    "        stats_counts = stats_wins['stats_model'].value_counts().reset_index()\n",
    "        stats_counts.columns = ['Model', 'Count']\n",
    "        stats_counts['Approach'] = 'Stats'\n",
    "        \n",
    "        all_counts = pd.concat([ml_counts, stats_counts], ignore_index=True)\n",
    "        return all_counts.sort_values('Count', ascending=False)\n",
    "\n",
    "def create_output_excel(pipeline, summary, model_analysis, output_path):\n",
    "    \"\"\"Create formatted Excel output with gray zone.\"\"\"\n",
    "    wb = Workbook()\n",
    "    \n",
    "    header_font = Font(bold=True, color='FFFFFF')\n",
    "    header_fill = PatternFill('solid', fgColor='2F5496')\n",
    "    thin_border = Border(\n",
    "        left=Side(style='thin'), right=Side(style='thin'),\n",
    "        top=Side(style='thin'), bottom=Side(style='thin')\n",
    "    )\n",
    "    ml_fill = PatternFill('solid', fgColor='C6EFCE')\n",
    "    stats_fill = PatternFill('solid', fgColor='FFEB9C')\n",
    "    gray_fill = PatternFill('solid', fgColor='D9D9D9')\n",
    "    \n",
    "    # Sheet 1: Summary\n",
    "    ws_summary = wb.active\n",
    "    ws_summary.title = 'Summary'\n",
    "    \n",
    "    ws_summary['A1'] = 'COMPARISON SUMMARY WITH PERCENTAGE-BASED GRAY ZONE'\n",
    "    ws_summary['A1'].font = Font(bold=True, size=14)\n",
    "    ws_summary['A2'] = f'Gray Zone: |MAE difference| < {summary[\"overall\"][\"gray_zone_pct_threshold\"]}% of average MAE'\n",
    "    ws_summary['A2'].font = Font(italic=True, color='666666')\n",
    "    \n",
    "    summary_data = [\n",
    "        ['Metric', 'Value'],\n",
    "        ['Total Series Compared', summary['overall']['total_series']],\n",
    "        ['ML Wins (Clear)', summary['overall']['ml_wins']],\n",
    "        ['Stats Wins (Clear)', summary['overall']['stats_wins']],\n",
    "        ['Gray Zone (Equivalent)', summary['overall']['gray_zone']],\n",
    "        ['ML Win Rate (%)', round(summary['overall']['ml_win_rate'], 1)],\n",
    "        ['Stats Win Rate (%)', round(summary['overall']['stats_win_rate'], 1)],\n",
    "        ['Gray Zone Rate (%)', round(summary['overall']['gray_zone_rate'], 1)],\n",
    "        ['', ''],\n",
    "        ['Average ML MAE', f\"{summary['overall']['avg_ml_mae']:,.2f}\"],\n",
    "        ['Average Stats MAE', f\"{summary['overall']['avg_stats_mae']:,.2f}\"],\n",
    "        ['Average Best MAE', f\"{summary['overall']['avg_best_mae']:,.2f}\"],\n",
    "        ['', ''],\n",
    "        ['Avg % Difference', f\"{summary['overall']['avg_pct_difference']:.1f}%\"],\n",
    "        ['Median % Difference', f\"{summary['overall']['median_pct_difference']:.1f}%\"],\n",
    "    ]\n",
    "    \n",
    "    for row_idx, row_data in enumerate(summary_data, start=4):\n",
    "        for col_idx, value in enumerate(row_data, start=1):\n",
    "            cell = ws_summary.cell(row=row_idx, column=col_idx, value=value)\n",
    "            cell.border = thin_border\n",
    "            if row_idx == 4:\n",
    "                cell.font = header_font\n",
    "                cell.fill = header_fill\n",
    "    \n",
    "    # State-level summary\n",
    "    ws_summary['A22'] = 'BY STATE COMPARISON'\n",
    "    ws_summary['A22'].font = Font(bold=True, size=14)\n",
    "    \n",
    "    state_headers = ['State', 'Total', 'ML Wins', 'Stats Wins', 'Gray Zone', \n",
    "                     'ML %', 'Stats %', 'Gray %', 'Avg % Diff']\n",
    "    for col_idx, header in enumerate(state_headers, start=1):\n",
    "        cell = ws_summary.cell(row=24, column=col_idx, value=header)\n",
    "        cell.font = header_font\n",
    "        cell.fill = header_fill\n",
    "        cell.border = thin_border\n",
    "    \n",
    "    row_idx = 25\n",
    "    for state, stats in summary['by_state'].items():\n",
    "        values = [state, stats['total_series'], stats['ml_wins'], stats['stats_wins'],\n",
    "                  stats['gray_zone'], round(stats['ml_win_rate'], 1), \n",
    "                  round(stats['stats_win_rate'], 1), round(stats['gray_zone_rate'], 1),\n",
    "                  f\"{stats['avg_pct_difference']:.1f}%\"]\n",
    "        for col_idx, value in enumerate(values, start=1):\n",
    "            cell = ws_summary.cell(row=row_idx, column=col_idx, value=value)\n",
    "            cell.border = thin_border\n",
    "        row_idx += 1\n",
    "    \n",
    "    ws_summary.column_dimensions['A'].width = 30\n",
    "    ws_summary.column_dimensions['B'].width = 15\n",
    "    for col in ['C', 'D', 'E', 'F', 'G', 'H', 'I']:\n",
    "        ws_summary.column_dimensions[col].width = 12\n",
    "    \n",
    "    # Sheet 2: Model Analysis\n",
    "    ws_models = wb.create_sheet('Model_Analysis')\n",
    "    ws_models['A1'] = 'MODEL PERFORMANCE (Clear Winners Only)'\n",
    "    ws_models['A1'].font = Font(bold=True, size=14)\n",
    "    \n",
    "    if len(model_analysis) > 0:\n",
    "        model_cols = ['Model', 'Approach', 'Times_Selected', 'Selection_Rate_%', 'Avg_MAE', 'Median_MAE']\n",
    "        for col_idx, col in enumerate(model_cols, start=1):\n",
    "            cell = ws_models.cell(row=3, column=col_idx, value=col)\n",
    "            cell.font = header_font\n",
    "            cell.fill = header_fill\n",
    "            cell.border = thin_border\n",
    "        \n",
    "        for row_idx, (_, row) in enumerate(model_analysis.iterrows(), start=4):\n",
    "            for col_idx, col in enumerate(model_cols, start=1):\n",
    "                value = row[col] if col in row else ''\n",
    "                if isinstance(value, float):\n",
    "                    value = round(value, 2)\n",
    "                cell = ws_models.cell(row=row_idx, column=col_idx, value=value)\n",
    "                cell.border = thin_border\n",
    "                if col == 'Approach':\n",
    "                    cell.fill = ml_fill if value == 'ML' else stats_fill\n",
    "    \n",
    "    for col in ['A', 'B', 'C', 'D', 'E', 'F']:\n",
    "        ws_models.column_dimensions[col].width = 16\n",
    "    \n",
    "    # Sheet 3: Detailed Results\n",
    "    ws_detail = wb.create_sheet('Detailed_Results')\n",
    "    \n",
    "    detail_df = pipeline.results_df[[\n",
    "        'state', 'unique_id', 'ml_model', 'ml_mae', 'stats_model', 'stats_mae',\n",
    "        'pct_difference', 'best_approach', 'best_model', 'best_mae'\n",
    "    ]].copy()\n",
    "    detail_df = detail_df.sort_values(['state', 'unique_id'])\n",
    "    \n",
    "    headers = list(detail_df.columns)\n",
    "    for col_idx, header in enumerate(headers, start=1):\n",
    "        cell = ws_detail.cell(row=1, column=col_idx, value=header)\n",
    "        cell.font = header_font\n",
    "        cell.fill = header_fill\n",
    "        cell.border = thin_border\n",
    "    \n",
    "    for row_idx, (_, row) in enumerate(detail_df.iterrows(), start=2):\n",
    "        for col_idx, col in enumerate(headers, start=1):\n",
    "            value = row[col]\n",
    "            if isinstance(value, float):\n",
    "                value = round(value, 2)\n",
    "            cell = ws_detail.cell(row=row_idx, column=col_idx, value=value)\n",
    "            cell.border = thin_border\n",
    "            if col == 'best_approach':\n",
    "                if value == 'ML':\n",
    "                    cell.fill = ml_fill\n",
    "                elif value == 'Stats':\n",
    "                    cell.fill = stats_fill\n",
    "                else:\n",
    "                    cell.fill = gray_fill\n",
    "    \n",
    "    for col in ws_detail.column_dimensions:\n",
    "        ws_detail.column_dimensions[col].width = 14\n",
    "    ws_detail.column_dimensions['I'].width = 28\n",
    "    \n",
    "    wb.save(output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "19553027",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_visualizations(results_dict, output_path):\n",
    "    \"\"\"Create beautiful visualizations with model frequency.\"\"\"\n",
    "    \n",
    "    fig = plt.figure(figsize=(20, 12), facecolor=COLORS['background'])\n",
    "    \n",
    "    # Create grid layout\n",
    "    gs = fig.add_gridspec(2, 3, hspace=0.35, wspace=0.3, \n",
    "                          left=0.06, right=0.98, top=0.90, bottom=0.08)\n",
    "    \n",
    "    #fig.suptitle('ML vs Statistical Models: Forecasting Performance Comparison', fontsize=18, fontweight='bold', color=COLORS['text'], y=0.96)\n",
    "    \n",
    "    for idx, (file_name, data) in enumerate(results_dict.items()):\n",
    "        summary = data['summary']\n",
    "        model_freq = data['model_freq']\n",
    "        threshold = summary['overall']['gray_zone_pct_threshold']\n",
    "        \n",
    "        # Clean file name for display\n",
    "        display_name = file_name.replace('PANEL_COMPARISON_', '').replace('_', ' ')\n",
    "        if 'UR' in display_name:\n",
    "            display_name = 'Units Reimbursed'\n",
    "        elif 'NoP' in display_name:\n",
    "            display_name = 'Number of Prescriptions'\n",
    "        \n",
    "        # ===== Plot 1: Donut Chart for Overall Win Rates =====\n",
    "        ax1 = fig.add_subplot(gs[idx, 0])\n",
    "        \n",
    "        sizes = [summary['overall']['ml_win_rate'], \n",
    "                 summary['overall']['stats_win_rate'],\n",
    "                 summary['overall']['gray_zone_rate']]\n",
    "        colors = [COLORS['ml'], COLORS['stats'], COLORS['gray']]\n",
    "        labels = ['ML', 'Stats', 'Gray Zone']\n",
    "        \n",
    "        # Create donut\n",
    "        wedges, texts, autotexts = ax1.pie(\n",
    "            sizes, colors=colors, autopct='%1.1f%%',\n",
    "            startangle=90, pctdistance=0.75,\n",
    "            wedgeprops=dict(width=0.5, edgecolor='white', linewidth=2),\n",
    "            textprops={'fontsize': 11, 'fontweight': 'bold', 'color': 'white'}\n",
    "        )\n",
    "        \n",
    "        # Add center text\n",
    "        centre_circle = plt.Circle((0, 0), 0.35, fc=COLORS['background'])\n",
    "        ax1.add_patch(centre_circle)\n",
    "        ax1.text(0, 0.05, f'{summary[\"overall\"][\"total_series\"]}', ha='center', va='center', \n",
    "                fontsize=20, fontweight='bold', color=COLORS['text'])\n",
    "        ax1.text(0, -0.15, 'series', ha='center', va='center', \n",
    "                fontsize=10, color=COLORS['text'])\n",
    "        \n",
    "        ax1.set_title(f'{display_name}\\nOverall Distribution', pad=15, fontsize=13, fontweight='bold')\n",
    "        \n",
    "        # Legend\n",
    "        legend_labels = [f'{l} ({s:.1f}%)' for l, s in zip(labels, sizes)]\n",
    "        ax1.legend(wedges, legend_labels, loc='lower center', bbox_to_anchor=(0.5, -0.12),\n",
    "                  ncol=3, fontsize=9, frameon=False)\n",
    "        \n",
    "        # ===== Plot 2: Stacked Bar for State Comparison =====\n",
    "        ax2 = fig.add_subplot(gs[idx, 1])\n",
    "        \n",
    "        states = list(summary['by_state'].keys())\n",
    "        ml_rates = [summary['by_state'][s]['ml_win_rate'] for s in states]\n",
    "        stats_rates = [summary['by_state'][s]['stats_win_rate'] for s in states]\n",
    "        gray_rates = [summary['by_state'][s]['gray_zone_rate'] for s in states]\n",
    "        \n",
    "        x = np.arange(len(states))\n",
    "        width = 0.6\n",
    "        \n",
    "        bars1 = ax2.bar(x, ml_rates, width, label='ML', color=COLORS['ml'], edgecolor='white', linewidth=1)\n",
    "        bars2 = ax2.bar(x, stats_rates, width, bottom=ml_rates, label='Stats', \n",
    "                       color=COLORS['stats'], edgecolor='white', linewidth=1)\n",
    "        bars3 = ax2.bar(x, gray_rates, width, bottom=np.array(ml_rates)+np.array(stats_rates), \n",
    "                       label='Gray Zone', color=COLORS['gray'], edgecolor='white', linewidth=1)\n",
    "        \n",
    "        ax2.set_ylabel('Percentage (%)', fontsize=11)\n",
    "        ax2.set_title(f'{display_name}\\nWin Rate by State', pad=15, fontsize=13, fontweight='bold')\n",
    "        ax2.set_xticks(x)\n",
    "        ax2.set_xticklabels(states, fontsize=11, fontweight='bold')\n",
    "        ax2.set_ylim(0, 105)\n",
    "        \n",
    "        # Add percentage labels on bars\n",
    "        for i, (m, s, g) in enumerate(zip(ml_rates, stats_rates, gray_rates)):\n",
    "            if m > 10:\n",
    "                ax2.text(i, m/2, f'{m:.0f}%', ha='center', va='center', \n",
    "                        fontsize=9, color='white', fontweight='bold')\n",
    "            if s > 10:\n",
    "                ax2.text(i, m + s/2, f'{s:.0f}%', ha='center', va='center', \n",
    "                        fontsize=9, color='white', fontweight='bold')\n",
    "            if g > 8:\n",
    "                ax2.text(i, m + s + g/2, f'{g:.0f}%', ha='center', va='center', \n",
    "                        fontsize=9, color='white', fontweight='bold')\n",
    "        \n",
    "        ax2.set_facecolor(COLORS['background'])\n",
    "        \n",
    "        # ===== Plot 3: Horizontal Bar for Model Frequency =====\n",
    "        ax3 = fig.add_subplot(gs[idx, 2])\n",
    "        \n",
    "        # Get top 8 models\n",
    "        top_models = model_freq.head(8).copy()\n",
    "        top_models = top_models.iloc[::-1]  # Reverse for horizontal bar\n",
    "        \n",
    "        colors_bars = [COLORS['ml'] if app == 'ML' else COLORS['stats'] \n",
    "                      for app in top_models['Approach']]\n",
    "        \n",
    "        bars = ax3.barh(top_models['Model'], top_models['Count'], \n",
    "                       color=colors_bars, edgecolor='white', linewidth=1, height=0.7)\n",
    "        \n",
    "        ax3.set_xlabel('Times Selected as Best', fontsize=11)\n",
    "        ax3.set_title(f'{display_name}\\nModel Selection Frequency', pad=15, fontsize=13, fontweight='bold')\n",
    "        \n",
    "        # Add count labels\n",
    "        for bar, count in zip(bars, top_models['Count']):\n",
    "            width = bar.get_width()\n",
    "            ax3.text(width + 2, bar.get_y() + bar.get_height()/2, \n",
    "                    f'{count}', ha='left', va='center', fontsize=10, fontweight='bold')\n",
    "        \n",
    "        ax3.set_xlim(0, top_models['Count'].max() * 1.15)\n",
    "        ax3.set_facecolor(COLORS['background'])\n",
    "        \n",
    "        # Custom legend for model types\n",
    "        ml_patch = mpatches.Patch(color=COLORS['ml'], label='ML Models')\n",
    "        stats_patch = mpatches.Patch(color=COLORS['stats'], label='Stats Models')\n",
    "        ax3.legend(handles=[ml_patch, stats_patch], loc='lower right', fontsize=9, framealpha=0.9)\n",
    "    \n",
    "    # Add footnote\n",
    "    fig.text(0.5, 0.02, f'Gray Zone Threshold: < {threshold}% difference in MAE between approaches', \n",
    "             ha='center', fontsize=10, style='italic', color=COLORS['text'], alpha=0.7)\n",
    "    \n",
    "    plt.savefig(output_path, dpi=200, facecolor=COLORS['background'], \n",
    "                bbox_inches='tight', pad_inches=0.3)\n",
    "    plt.close()\n",
    "    print(f\"Visualization saved to: {output_path}\")\n",
    "\n",
    "def create_detailed_model_chart(results_dict, output_path):\n",
    "    \"\"\"Create a detailed model comparison chart.\"\"\"\n",
    "    \n",
    "    fig, axes = plt.subplots(1, 2, figsize=(16, 7), facecolor=COLORS['background'])\n",
    "    fig.suptitle('Best Model Selection Breakdown by Approach', \n",
    "                 fontsize=16, fontweight='bold', color=COLORS['text'], y=1.02)\n",
    "    \n",
    "    for idx, (file_name, data) in enumerate(results_dict.items()):\n",
    "        ax = axes[idx]\n",
    "        summary = data['summary']\n",
    "        \n",
    "        display_name = 'Units Reimbursed' if 'UR' in file_name else 'Number of Prescriptions'\n",
    "        \n",
    "        # Prepare data\n",
    "        ml_models = summary['by_ml_model']\n",
    "        stats_models = summary['by_stats_model']\n",
    "        \n",
    "        # Create combined data\n",
    "        all_models = []\n",
    "        all_counts = []\n",
    "        all_approaches = []\n",
    "        \n",
    "        for model, count in sorted(ml_models.items(), key=lambda x: -x[1]):\n",
    "            all_models.append(model)\n",
    "            all_counts.append(count)\n",
    "            all_approaches.append('ML')\n",
    "        \n",
    "        for model, count in sorted(stats_models.items(), key=lambda x: -x[1]):\n",
    "            all_models.append(model)\n",
    "            all_counts.append(count)\n",
    "            all_approaches.append('Stats')\n",
    "        \n",
    "        # Create DataFrame and sort\n",
    "        df_plot = pd.DataFrame({\n",
    "            'Model': all_models,\n",
    "            'Count': all_counts,\n",
    "            'Approach': all_approaches\n",
    "        }).sort_values('Count', ascending=True).tail(10)\n",
    "        \n",
    "        colors_bars = [COLORS['ml'] if app == 'ML' else COLORS['stats'] \n",
    "                      for app in df_plot['Approach']]\n",
    "        \n",
    "        bars = ax.barh(df_plot['Model'], df_plot['Count'], color=colors_bars, \n",
    "                      edgecolor='white', linewidth=1.5, height=0.7)\n",
    "        \n",
    "        # Add labels\n",
    "        for bar, count in zip(bars, df_plot['Count']):\n",
    "            ax.text(bar.get_width() + 1, bar.get_y() + bar.get_height()/2, \n",
    "                   f'{count}', ha='left', va='center', fontsize=10, fontweight='bold')\n",
    "        \n",
    "        ax.set_xlabel('Times Selected as Best Model', fontsize=11)\n",
    "        ax.set_title(f'{display_name}', fontsize=14, fontweight='bold', pad=10)\n",
    "        ax.set_xlim(0, df_plot['Count'].max() * 1.15)\n",
    "        ax.set_facecolor(COLORS['background'])\n",
    "        \n",
    "        # Legend\n",
    "        ml_patch = mpatches.Patch(color=COLORS['ml'], label='ML Models')\n",
    "        stats_patch = mpatches.Patch(color=COLORS['stats'], label='Stats Models')\n",
    "        ax.legend(handles=[ml_patch, stats_patch], loc='lower right', fontsize=10)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(output_path, dpi=200, facecolor=COLORS['background'], \n",
    "                bbox_inches='tight', pad_inches=0.2)\n",
    "    plt.close()\n",
    "    print(f\"Detailed chart saved to: {output_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e7f3a01b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Processing: Units_Reimbursed\n",
      "============================================================\n",
      "Excel saved to: C:\\Users\\Lilian\\OneDrive - purdue.edu\\VS code\\Data\\ATC\\COMPARISON\\Results_last\\Results_Units_Reimbursed.xlsx\n",
      "\n",
      "============================================================\n",
      "Processing: Num_Prescriptions\n",
      "============================================================\n",
      "Excel saved to: C:\\Users\\Lilian\\OneDrive - purdue.edu\\VS code\\Data\\ATC\\COMPARISON\\Results_last\\Results_Num_Prescriptions.xlsx\n",
      "\n",
      "Generating visualizations...\n",
      "Visualization saved to: C:\\Users\\Lilian\\OneDrive - purdue.edu\\VS code\\Data\\ATC\\COMPARISON\\Results_last\\Comparison_Dashboard.png\n",
      "Detailed chart saved to: C:\\Users\\Lilian\\OneDrive - purdue.edu\\VS code\\Data\\ATC\\COMPARISON\\Results_last\\Comparison_Detailed_Models.png\n",
      "Visualizations saved to folder: C:\\Users\\Lilian\\OneDrive - purdue.edu\\VS code\\Data\\ATC\\COMPARISON\\Results_last\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "def main():\n",
    "    # 1. Define your paths\n",
    "    # Note: I'm assuming 'user' is already defined as 'Lilian' based on your previous code\n",
    "    base_folder = rf'C:\\Users\\{user}\\OneDrive - purdue.edu\\VS code\\Data\\ATC\\COMPARISON'\n",
    "    \n",
    "    # Define the output subfolder\n",
    "    results_folder = os.path.join(base_folder, 'Results_last')\n",
    "    \n",
    "    # Create the folder if it doesn't exist\n",
    "    if not os.path.exists(results_folder):\n",
    "        os.makedirs(results_folder)\n",
    "        print(f\"Created output folder: {results_folder}\")\n",
    "    \n",
    "    # Input files (These stay in the base folder)\n",
    "    UR_path = os.path.join(base_folder, 'PANEL_COMPARISON_UR.xlsx')\n",
    "    NoP_path = os.path.join(base_folder, 'PANEL_COMPARISON_NoP.xlsx')\n",
    "\n",
    "    files_config = [\n",
    "        {'path': UR_path,  'name': 'Units_Reimbursed'},\n",
    "        {'path': NoP_path, 'name': 'Num_Prescriptions'}\n",
    "    ]\n",
    "    \n",
    "    GRAY_ZONE_PCT = 5.0\n",
    "    all_results = {}\n",
    "    \n",
    "    # --- PROCESSING LOOP ---\n",
    "    for config in files_config:\n",
    "        file_path = config['path']\n",
    "        file_name = config['name'] \n",
    "        \n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(f\"Processing: {file_name}\")\n",
    "        print('='*60)\n",
    "        \n",
    "        # Run your pipeline\n",
    "        pipeline = ForecastComparisonPipeline(file_path, gray_zone_pct=GRAY_ZONE_PCT)\n",
    "        pipeline.run_comparison()\n",
    "        \n",
    "        # Gather results\n",
    "        summary = pipeline.get_summary_statistics()\n",
    "        model_analysis = pipeline.get_model_frequency_analysis()\n",
    "        model_freq = pipeline.get_all_model_frequency()\n",
    "        \n",
    "        all_results[file_name] = {\n",
    "            'pipeline': pipeline,\n",
    "            'summary': summary,\n",
    "            'model_analysis': model_analysis,\n",
    "            'model_freq': model_freq\n",
    "        }\n",
    "        \n",
    "        # --- SAVE EXCEL ---\n",
    "        # Save to results_folder instead of base_folder\n",
    "        excel_filename = f\"Results_{file_name}.xlsx\"\n",
    "        excel_save_path = os.path.join(results_folder, excel_filename)\n",
    "        \n",
    "        create_output_excel(pipeline, summary, model_analysis, excel_save_path)\n",
    "        print(f\"Excel saved to: {excel_save_path}\")\n",
    "\n",
    "    # --- SAVE VISUALIZATIONS ---\n",
    "    print(f\"\\nGenerating visualizations...\")\n",
    "    \n",
    "    # Save images to results_folder\n",
    "    viz_path = os.path.join(results_folder, \"Comparison_Dashboard.png\")\n",
    "    detailed_viz_path = os.path.join(results_folder, \"Comparison_Detailed_Models.png\")\n",
    "    \n",
    "    create_visualizations(all_results, viz_path)\n",
    "    create_detailed_model_chart(all_results, detailed_viz_path)\n",
    "    \n",
    "    print(f\"Visualizations saved to folder: {results_folder}\")\n",
    "    return all_results\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    results = main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
