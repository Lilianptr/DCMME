{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4996a3a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import requests\n",
    "import shelve\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "import scipy.stats as stats\n",
    "from scipy.stats import pearsonr, spearmanr\n",
    "import statsmodels \n",
    "from scipy.stats import mannwhitneyu\n",
    "from statsmodels.sandbox.stats.runs import runstest_1samp\n",
    "import glob\n",
    "\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "16cf3afa",
   "metadata": {},
   "outputs": [],
   "source": [
    "user=\"lholguin\"\n",
    "years_list = [2017, 2018, 2019, 2020, 2021, 2022, 2023, 2024]\n",
    "#user in personal pc1 <- \"asus\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f557914",
   "metadata": {},
   "source": [
    "#### Generating some stats and Runs Test for the panels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d39f104f",
   "metadata": {},
   "source": [
    "Doing the statistical analysis. Be careful with the units scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71234f73",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NDCATC_stats:  #Creating a new class to analyze correlations\n",
    "    \n",
    "    @staticmethod \n",
    "    def correlation_look(years_list, base_path=None, min_records=8, state_filter=None):\n",
    "        \n",
    "        if base_path is None:\n",
    "            base_path = rf\"c:\\Users\\{user}\\OneDrive - purdue.edu\\VS code\\Data\"\n",
    "        \n",
    "        print(\"CORRELATION ANALYSIS: Units Reimbursed vs Number of Prescriptions\")\n",
    "        print(\"THREE-PANEL ANALYSIS\")\n",
    "        print(\"=\"*70)\n",
    "        \n",
    "        results = {\n",
    "            'panel1_state_atc2': [],\n",
    "            'panel2_national_atc2': [], \n",
    "            'panel3_atc2_quarter': []\n",
    "        }\n",
    "        \n",
    "        # Load all data first\n",
    "        all_data = {}\n",
    "        for year in years_list:\n",
    "            print(f\"Loading {year} data...\", end=\" \")\n",
    "            try:\n",
    "                csv_path = os.path.join(base_path, f\"ATC\\\\merged_data\\\\merged_NEWdata_{year}.csv\")\n",
    "                df_merged = pd.read_csv(csv_path)\n",
    "                records = df_merged[df_merged['ATC4 Class'].notna()].copy()\n",
    "                records['ATC2 Class'] = records['ATC4 Class'].str[:3]\n",
    "                all_data[year] = records\n",
    "                print(f\"✓ ({len(records):,} records)\")\n",
    "            except Exception as e:\n",
    "                print(f\"✗ Error: {e}\")\n",
    "        \n",
    "        # ==================== PANEL 1: STATE x ATC2 ANALYSIS ====================\n",
    "        print(f\"\\n{'='*70}\")\n",
    "        if state_filter:\n",
    "            print(f\"PANEL 1: {state_filter} STATE x ATC2 CORRELATION ANALYSIS\")\n",
    "        else:\n",
    "            print(\"PANEL 1: STATE x ATC2 CORRELATION ANALYSIS\")\n",
    "        print(f\"{'='*70}\")\n",
    "        \n",
    "        # Combine all years first\n",
    "        all_combined = []\n",
    "        for year, records in all_data.items():\n",
    "            records_copy = records.copy()\n",
    "            records_copy['Year'] = year\n",
    "            all_combined.append(records_copy)\n",
    "        \n",
    "        combined_df = pd.concat(all_combined, ignore_index=True)\n",
    "        \n",
    "        # Apply state filter for Panel 1\n",
    "        if state_filter:\n",
    "            panel1_states = [state_filter]\n",
    "        else:\n",
    "            panel1_states = combined_df['State'].unique()\n",
    "        \n",
    "        # Now analyze across all years\n",
    "        for state in panel1_states:\n",
    "            state_data = combined_df[combined_df['State'] == state]\n",
    "            \n",
    "            for atc2 in state_data['ATC2 Class'].unique():\n",
    "                subset = state_data[state_data['ATC2 Class'] == atc2]\n",
    "                \n",
    "                # AGGREGATE TO QUARTERLY TIME SERIES\n",
    "                subset_ts = subset.groupby(['Year', 'Quarter']).agg({\n",
    "                    'Units Reimbursed': 'sum', \n",
    "                    'Number of Prescriptions': 'sum'\n",
    "                }).reset_index().sort_values(['Year','Quarter'])\n",
    "                \n",
    "                # DEBUG LINE\n",
    "                #if state == 'IN' and len(subset_ts) > 0:\n",
    "                #    print(f\"DEBUG: {state}-{atc2}: {len(subset_ts)} quarterly records\")\n",
    "                \n",
    "                if len(subset_ts) >= min_records:\n",
    "                    try:\n",
    "                        atc2_name = subset['ATC2_Name'].iloc[0] if 'ATC2_Name' in subset.columns else ''\n",
    "                        \n",
    "                        # Calculate correlations\n",
    "                        pearson_r, pearson_p = pearsonr(subset_ts['Units Reimbursed'], subset_ts['Number of Prescriptions'])\n",
    "                        spearman_r, spearman_p = spearmanr(subset_ts['Units Reimbursed'], subset_ts['Number of Prescriptions'])\n",
    "                        \n",
    "                        results['panel1_state_atc2'].append({\n",
    "                            'State': state,\n",
    "                            'ATC2_Class': atc2,\n",
    "                            'ATC2_Name': atc2_name,\n",
    "                            'N_Records': len(subset_ts),\n",
    "                            'Pearson_r': pearson_r,\n",
    "                            'Pearson_p': pearson_p,\n",
    "                            'Spearman_r': spearman_r,\n",
    "                            'Spearman_p': spearman_p,\n",
    "                            'Mean_Units': subset_ts['Units Reimbursed'].mean(),\n",
    "                            'Mean_Prescriptions': subset_ts['Number of Prescriptions'].mean()\n",
    "                        })\n",
    "                        \n",
    "                    except Exception as e:\n",
    "                        print(f\"Error processing {state}-{atc2}: {e}\")\n",
    "        \n",
    "        # Display Panel 1 results\n",
    "        panel1_df = pd.DataFrame(results['panel1_state_atc2'])\n",
    "        if not panel1_df.empty:\n",
    "            print(f\"\\nPanel 1 Results: {len(panel1_df)} state x ATC2 combinations analyzed\")\n",
    "            \n",
    "            # Summary statistics\n",
    "            print(f\"Average Pearson correlation: {panel1_df['Pearson_r'].mean():.4f}\")\n",
    "            print(f\"Range: {panel1_df['Pearson_r'].min():.4f} to {panel1_df['Pearson_r'].max():.4f}\")\n",
    "            print(f\"Significant correlations (p<0.05): {(panel1_df['Pearson_p'] < 0.05).sum()}/{len(panel1_df)} ({100*(panel1_df['Pearson_p'] < 0.05).sum()/len(panel1_df):.1f}%)\")\n",
    "            \n",
    "            # Top correlations\n",
    "            print(f\"\\nTop 10 Highest Pearson Correlations (State x ATC2):\")\n",
    "            top_corr = panel1_df.nlargest(10, 'Pearson_r')[['State', 'ATC2_Class', 'ATC2_Name', 'Pearson_r', 'Pearson_p', 'N_Records']].copy()\n",
    "            top_corr['Pearson_p'] = top_corr['Pearson_p'].apply(lambda x: f\"{x:.6f}\" if pd.notna(x) else 'NaN')\n",
    "            print(top_corr.to_string(index=False))\n",
    "            \n",
    "            # Lowest correlations\n",
    "            print(f\"\\nTop 10 Lowest Pearson Correlations (State x ATC2):\")\n",
    "            low_corr = panel1_df.nsmallest(10, 'Pearson_r')[['State', 'ATC2_Class', 'ATC2_Name', 'Pearson_r', 'Pearson_p', 'N_Records']].copy()\n",
    "            low_corr['Pearson_p'] = low_corr['Pearson_p'].apply(lambda x: f\"{x:.6f}\" if pd.notna(x) else 'NaN')\n",
    "            print(low_corr.to_string(index=False))\n",
    "        \n",
    "        # ==================== PANEL 2: NATIONAL x ATC2 ANALYSIS ====================\n",
    "        print(f\"\\n{'='*70}\")\n",
    "        print(\"PANEL 2: NATIONAL x ATC2 CORRELATION ANALYSIS\")\n",
    "        print(f\"{'='*70}\")\n",
    "        \n",
    "        # Use the combined_df from Panel 1\n",
    "        for atc2 in combined_df['ATC2 Class'].unique():\n",
    "            subset = combined_df[combined_df['ATC2 Class'] == atc2]\n",
    "            \n",
    "            # AGGREGATE TO QUARTERLY TIME SERIES\n",
    "            subset_ts = subset.groupby(['Year', 'Quarter']).agg({\n",
    "                'Units Reimbursed': 'sum', \n",
    "                'Number of Prescriptions': 'sum'\n",
    "            }).reset_index().sort_values(['Year','Quarter'])\n",
    "            \n",
    "            # DEBUG LINE\n",
    "            if len(subset_ts) > 0:\n",
    "                print(f\"DEBUG: National-{atc2}: {len(subset_ts)} quarterly records\")\n",
    "            \n",
    "            if len(subset_ts) >= min_records:\n",
    "                try:\n",
    "                    atc2_name = subset['ATC2_Name'].iloc[0] if 'ATC2_Name' in subset.columns else ''\n",
    "                    \n",
    "                    # Calculate correlations\n",
    "                    pearson_r, pearson_p = pearsonr(subset_ts['Units Reimbursed'], subset_ts['Number of Prescriptions'])\n",
    "                    spearman_r, spearman_p = spearmanr(subset_ts['Units Reimbursed'], subset_ts['Number of Prescriptions'])\n",
    "                    \n",
    "                    results['panel2_national_atc2'].append({\n",
    "                        'ATC2_Class': atc2,\n",
    "                        'ATC2_Name': atc2_name,\n",
    "                        'N_Records': len(subset_ts),\n",
    "                        'N_States': subset['State'].nunique(),\n",
    "                        'Pearson_r': pearson_r,\n",
    "                        'Pearson_p': pearson_p,\n",
    "                        'Spearman_r': spearman_r,\n",
    "                        'Spearman_p': spearman_p,\n",
    "                        'Mean_Units': subset_ts['Units Reimbursed'].mean(),\n",
    "                        'Mean_Prescriptions': subset_ts['Number of Prescriptions'].mean()\n",
    "                    })\n",
    "                    \n",
    "                except Exception as e:\n",
    "                    print(f\"Error processing National-{atc2}: {e}\")\n",
    "        \n",
    "        # Display Panel 2 results\n",
    "        panel2_df = pd.DataFrame(results['panel2_national_atc2'])\n",
    "        if not panel2_df.empty:\n",
    "            print(f\"\\nPanel 2 Results: {len(panel2_df)} national x ATC2 combinations analyzed\")\n",
    "            \n",
    "            print(f\"Average Pearson correlation: {panel2_df['Pearson_r'].mean():.4f}\")\n",
    "            print(f\"Range: {panel2_df['Pearson_r'].min():.4f} to {panel2_df['Pearson_r'].max():.4f}\")\n",
    "            print(f\"Significant correlations (p<0.05): {(panel2_df['Pearson_p'] < 0.05).sum()}/{len(panel2_df)} ({100*(panel2_df['Pearson_p'] < 0.05).sum()/len(panel2_df):.1f}%)\")\n",
    "            \n",
    "            print(f\"\\nTop 10 Highest Pearson Correlations (National x ATC2):\")\n",
    "            top_corr_nat = panel2_df.nlargest(10, 'Pearson_r')[['ATC2_Class', 'ATC2_Name', 'Pearson_r', 'Pearson_p', 'N_Records']].copy()\n",
    "            top_corr_nat['Pearson_p'] = top_corr_nat['Pearson_p'].apply(lambda x: f\"{x:.6f}\" if pd.notna(x) else 'NaN')\n",
    "            print(top_corr_nat.to_string(index=False))\n",
    "            \n",
    "            print(f\"\\nTop 10 Lowest Pearson Correlations (National x ATC2):\")\n",
    "            low_corr_nat = panel2_df.nsmallest(10, 'Pearson_r')[['ATC2_Class', 'ATC2_Name', 'Pearson_r', 'Pearson_p', 'N_Records']].copy()\n",
    "            low_corr_nat['Pearson_p'] = low_corr_nat['Pearson_p'].apply(lambda x: f\"{x:.6f}\" if pd.notna(x) else 'NaN')\n",
    "            print(low_corr_nat.to_string(index=False))\n",
    "        \n",
    "        # ==================== PANEL 3: ATC2 x QUARTER ANALYSIS ====================\n",
    "        print(f\"\\n{'='*70}\")\n",
    "        print(\"PANEL 3: ATC2 x QUARTER CORRELATION ANALYSIS\")\n",
    "        print(f\"{'='*70}\")\n",
    "        \n",
    "        # combined_df already exists from Panel 1\n",
    "        for atc2 in combined_df['ATC2 Class'].unique():\n",
    "            atc2_data = combined_df[combined_df['ATC2 Class'] == atc2]\n",
    "            \n",
    "            for quarter in sorted(atc2_data['Quarter'].unique()):\n",
    "                subset = atc2_data[atc2_data['Quarter'] == quarter]\n",
    "                \n",
    "                # AGGREGATE TO YEARLY TIME SERIES (for this specific quarter across years)\n",
    "                subset_ts = subset.groupby(['Year', 'Quarter']).agg({\n",
    "                    'Units Reimbursed': 'sum', \n",
    "                    'Number of Prescriptions': 'sum'\n",
    "                }).reset_index().sort_values(['Year','Quarter'])\n",
    "                \n",
    "                # DEBUG LINE\n",
    "                #if len(subset_ts) > 0:\n",
    "                    #print(f\"DEBUG: {atc2}-Q{quarter}: {len(subset_ts)} quarterly records\")\n",
    "                \n",
    "                if len(subset_ts) >= min_records:\n",
    "                    try:\n",
    "                        atc2_name = subset['ATC2_Name'].iloc[0] if 'ATC2_Name' in subset.columns else ''\n",
    "                        \n",
    "                        # Calculate correlations\n",
    "                        pearson_r, pearson_p = pearsonr(subset_ts['Units Reimbursed'], subset_ts['Number of Prescriptions'])\n",
    "                        spearman_r, spearman_p = spearmanr(subset_ts['Units Reimbursed'], subset_ts['Number of Prescriptions'])\n",
    "                        \n",
    "                        results['panel3_atc2_quarter'].append({\n",
    "                            'ATC2_Class': atc2,\n",
    "                            'ATC2_Name': atc2_name,\n",
    "                            'Quarter': quarter,\n",
    "                            'N_Records': len(subset_ts),\n",
    "                            'N_Years': subset_ts['Year'].nunique(),\n",
    "                            'N_States': subset['State'].nunique(),\n",
    "                            'Pearson_r': pearson_r,\n",
    "                            'Pearson_p': pearson_p,\n",
    "                            'Spearman_r': spearman_r,\n",
    "                            'Spearman_p': spearman_p,\n",
    "                            'Mean_Units': subset_ts['Units Reimbursed'].mean(),\n",
    "                            'Mean_Prescriptions': subset_ts['Number of Prescriptions'].mean()\n",
    "                        })\n",
    "                        \n",
    "                    except Exception as e:\n",
    "                        print(f\"Error processing {atc2}-Q{quarter}: {e}\")\n",
    "        \n",
    "        # Display Panel 3 results\n",
    "        panel3_df = pd.DataFrame(results['panel3_atc2_quarter'])\n",
    "        if not panel3_df.empty:\n",
    "            print(f\"\\nPanel 3 Results: {len(panel3_df)} ATC2 x quarter combinations analyzed\")\n",
    "            \n",
    "            print(f\"Average Pearson correlation: {panel3_df['Pearson_r'].mean():.4f}\")\n",
    "            print(f\"Range: {panel3_df['Pearson_r'].min():.4f} to {panel3_df['Pearson_r'].max():.4f}\")\n",
    "            print(f\"Significant correlations (p<0.05): {(panel3_df['Pearson_p'] < 0.05).sum()}/{len(panel3_df)} ({100*(panel3_df['Pearson_p'] < 0.05).sum()/len(panel3_df):.1f}%)\")\n",
    "            \n",
    "            # Summary by Quarter\n",
    "            quarter_summary = panel3_df.groupby('Quarter').agg({\n",
    "                'Pearson_r': ['mean', 'std', 'min', 'max'], 'N_Records': 'sum'\n",
    "            }).round(4)\n",
    "            quarter_summary.columns = ['Avg_Pearson', 'Std_Pearson', 'Min_Pearson', 'Max_Pearson', 'Total_Records']\n",
    "            \n",
    "            print(f\"\\nCorrelation Summary by Quarter:\")\n",
    "            print(f\"{'Quarter':<8} {'Avg':<8} {'Std':<8} {'Min':<8} {'Max':<8} {'Records':<10}\")\n",
    "            print(\"-\" * 60)\n",
    "            for quarter, row in quarter_summary.iterrows():\n",
    "                print(f\"Q{quarter:<7} {row['Avg_Pearson']:<8.4f} {row['Std_Pearson']:<8.4f} {row['Min_Pearson']:<8.4f} {row['Max_Pearson']:<8.4f} {row['Total_Records']:<10.0f}\")\n",
    "            \n",
    "            print(f\"\\nTop 10 Highest Pearson Correlations (ATC2 x Quarter):\")\n",
    "            top_corr_quarter = panel3_df.nlargest(10, 'Pearson_r')[['ATC2_Class', 'ATC2_Name', 'Quarter', 'Pearson_r', 'Pearson_p', 'N_Records']].copy()\n",
    "            top_corr_quarter['Pearson_p'] = top_corr_quarter['Pearson_p'].apply(lambda x: f\"{x:.6f}\" if pd.notna(x) else 'NaN')\n",
    "            print(top_corr_quarter.to_string(index=False))\n",
    "            \n",
    "            print(f\"\\nTop 10 Lowest Pearson Correlations (ATC2 x Quarter):\")\n",
    "            low_corr_quarter = panel3_df.nsmallest(10, 'Pearson_r')[['ATC2_Class', 'ATC2_Name', 'Quarter', 'Pearson_r', 'Pearson_p', 'N_Records']].copy()\n",
    "            low_corr_quarter['Pearson_p'] = low_corr_quarter['Pearson_p'].apply(lambda x: f\"{x:.6f}\" if pd.notna(x) else 'NaN')\n",
    "            print(low_corr_quarter.to_string(index=False))\n",
    "        \n",
    "        # ==================== COMPARATIVE SUMMARY ACROSS PANELS ====================\n",
    "        print(f\"\\n{'='*80}\")\n",
    "        print(\"COMPARATIVE SUMMARY ACROSS ALL THREE PANELS\")\n",
    "        print(f\"{'='*80}\")\n",
    "        \n",
    "        summary_data = []\n",
    "        \n",
    "        if not panel1_df.empty:\n",
    "            panel1_avg = panel1_df['Pearson_r'].mean()\n",
    "            panel1_std = panel1_df['Pearson_r'].std()\n",
    "            panel1_sig = (panel1_df['Pearson_p'] < 0.05).sum()\n",
    "            panel1_total = len(panel1_df)\n",
    "            summary_data.append(['State x ATC2', panel1_total, panel1_avg, panel1_std, panel1_sig])\n",
    "        \n",
    "        if not panel2_df.empty:\n",
    "            panel2_avg = panel2_df['Pearson_r'].mean()\n",
    "            panel2_std = panel2_df['Pearson_r'].std()\n",
    "            panel2_sig = (panel2_df['Pearson_p'] < 0.05).sum()\n",
    "            panel2_total = len(panel2_df)\n",
    "            summary_data.append(['National x ATC2', panel2_total, panel2_avg, panel2_std, panel2_sig])\n",
    "        \n",
    "        if not panel3_df.empty:\n",
    "            panel3_avg = panel3_df['Pearson_r'].mean()\n",
    "            panel3_std = panel3_df['Pearson_r'].std()\n",
    "            panel3_sig = (panel3_df['Pearson_p'] < 0.05).sum()\n",
    "            panel3_total = len(panel3_df)\n",
    "            summary_data.append(['ATC2 x Quarter', panel3_total, panel3_avg, panel3_std, panel3_sig])\n",
    "        \n",
    "        if summary_data:\n",
    "            summary_df = pd.DataFrame(summary_data, columns=['Panel', 'Total_Tests', 'Avg_Pearson', 'Std_Pearson', 'Sig_Correlations'])\n",
    "            summary_df['Sig_Percentage'] = (summary_df['Sig_Correlations'] / summary_df['Total_Tests'] * 100).round(1)\n",
    "            summary_df['Avg_Pearson'] = summary_df['Avg_Pearson'].round(4)\n",
    "            summary_df['Std_Pearson'] = summary_df['Std_Pearson'].round(4)\n",
    "            \n",
    "            print(summary_df.to_string(index=False))\n",
    "            \n",
    "            # Additional insights\n",
    "            print(f\"\\nKey Insights:\")\n",
    "            if len(summary_data) > 1:\n",
    "                highest_avg_panel = summary_df.loc[summary_df['Avg_Pearson'].idxmax(), 'Panel']\n",
    "                lowest_avg_panel = summary_df.loc[summary_df['Avg_Pearson'].idxmin(), 'Panel']\n",
    "                print(f\"  - Highest average correlation: {highest_avg_panel}\")\n",
    "                print(f\"  - Lowest average correlation: {lowest_avg_panel}\")\n",
    "                \n",
    "                highest_sig_panel = summary_df.loc[summary_df['Sig_Percentage'].idxmax(), 'Panel']\n",
    "                print(f\"  - Most significant correlations: {highest_sig_panel}\")\n",
    "        \n",
    "        print(f\"\\nNote: Correlations measure linear (Pearson) and monotonic (Spearman) relationships.\")\n",
    "        print(f\"Significant p-values (< 0.05) indicate correlations likely not due to chance.\")\n",
    "        \n",
    "        # Convert results to DataFrames for return\n",
    "        results_dfs = {\n",
    "            'panel1_state_atc2': panel1_df,\n",
    "            'panel2_national_atc2': panel2_df,\n",
    "            'panel3_atc2_quarter': panel3_df\n",
    "        }\n",
    "        \n",
    "        return results_dfs\n",
    "\n",
    "    @staticmethod #This is for Indiana data\n",
    "    def plot_units_vs_prescriptions_by_atc(years_list, base_path=None, min_records=8, include_negative=True):\n",
    "\n",
    "        if base_path is None:\n",
    "            base_path = rf\"c:\\Users\\{user}\\OneDrive - purdue.edu\\VS code\\Data\"\n",
    "        \n",
    "        print(\"Creating plots for Indiana ATC classes...\")\n",
    "        \n",
    "        # Combine all years of data\n",
    "        all_data = []\n",
    "        for year in years_list:\n",
    "            try:\n",
    "                csv_path = os.path.join(base_path, f\"ATC\\\\merged_data\\\\merged_NEWdata_{year}.csv\")\n",
    "                df_merged = pd.read_csv(csv_path)\n",
    "                records = df_merged[(df_merged['ATC4 Class'].notna()) & (df_merged['State'] == 'IN')].copy()\n",
    "                records['Year'] = year\n",
    "                all_data.append(records)\n",
    "            except Exception as e:\n",
    "                print(f\"Error loading {year}: {e}\")\n",
    "        \n",
    "        if not all_data:\n",
    "            print(\"No data loaded!\")\n",
    "            return\n",
    "        \n",
    "        combined_df = pd.concat(all_data, ignore_index=True)\n",
    "        \n",
    "        # Get ATC classes with sufficient data and calculate correlations\n",
    "        atc_counts = combined_df['ATC2 Class'].value_counts()\n",
    "        sufficient_data_classes = atc_counts[atc_counts >= min_records].index\n",
    "        \n",
    "        # Calculate correlations for all classes with sufficient data\n",
    "        class_correlations = {}\n",
    "        for atc_class in sufficient_data_classes:\n",
    "            subset = combined_df[combined_df['ATC2 Class'] == atc_class]\n",
    "            if len(subset) > 1:\n",
    "                corr = subset['Number of Prescriptions'].corr(subset['Units Reimbursed'])\n",
    "                class_correlations[atc_class] = corr\n",
    "        \n",
    "        # Select classes to plot\n",
    "        if include_negative:\n",
    "            # Get top positive correlations and all negative correlations\n",
    "            positive_corrs = {k: v for k, v in class_correlations.items() if v >= 0}\n",
    "            negative_corrs = {k: v for k, v in class_correlations.items() if v < 0}\n",
    "            \n",
    "            # Sort positive by correlation (descending) and negative by correlation (ascending, most negative first)\n",
    "            positive_sorted = sorted(positive_corrs.items(), key=lambda x: x[1], reverse=True)\n",
    "            negative_sorted = sorted(negative_corrs.items(), key=lambda x: x[1])\n",
    "            \n",
    "            # Take top 8 positive and all negative (up to 4 more)\n",
    "            selected_positive = [x[0] for x in positive_sorted[:8]]\n",
    "            selected_negative = [x[0] for x in negative_sorted[:4]]\n",
    "            \n",
    "            valid_atc_classes = selected_positive + selected_negative\n",
    "            \n",
    "            print(f\"\\nSelected classes: {len(selected_positive)} positive correlations + {len(selected_negative)} negative correlations\")\n",
    "            if selected_negative:\n",
    "                print(f\"Negative correlation classes: {selected_negative}\")\n",
    "        else:\n",
    "            # Original behavior - top classes by count\n",
    "            valid_atc_classes = sufficient_data_classes[:12]\n",
    "        \n",
    "        # Determine grid size based on number of classes\n",
    "        n_classes = len(valid_atc_classes)\n",
    "        if n_classes <= 6:\n",
    "            rows, cols = 2, 3\n",
    "        elif n_classes <= 9:\n",
    "            rows, cols = 3, 3\n",
    "        elif n_classes <= 12:\n",
    "            rows, cols = 3, 4\n",
    "        else:\n",
    "            rows, cols = 4, 4\n",
    "            valid_atc_classes = valid_atc_classes[:16]  # Limit to 16 for display\n",
    "        \n",
    "        # Set up the plot grid\n",
    "        fig, axes = plt.subplots(rows, cols, figsize=(cols*5, rows*4))\n",
    "        if rows == 1 or cols == 1:\n",
    "            axes = axes.flatten() if hasattr(axes, 'flatten') else [axes]\n",
    "        else:\n",
    "            axes = axes.flatten()\n",
    "        \n",
    "        colors = plt.cm.Set3(np.linspace(0, 1, len(valid_atc_classes)))\n",
    "        \n",
    "        for i, atc_class in enumerate(valid_atc_classes):\n",
    "            subset = combined_df[combined_df['ATC2 Class'] == atc_class]\n",
    "            atc_name = subset['ATC2_Name'].iloc[0] if 'ATC2_Name' in subset.columns and not subset['ATC2_Name'].isna().all() else atc_class\n",
    "            \n",
    "            # Create scatter plot\n",
    "            axes[i].scatter(subset['Number of Prescriptions'], \n",
    "                           subset['Units Reimbursed'], \n",
    "                           alpha=0.6, color=colors[i], s=20)\n",
    "            \n",
    "            # Add trend line\n",
    "            if len(subset) > 1:\n",
    "                z = np.polyfit(subset['Number of Prescriptions'], subset['Units Reimbursed'], 1)\n",
    "                p = np.poly1d(z)\n",
    "                axes[i].plot(subset['Number of Prescriptions'], p(subset['Number of Prescriptions']), \n",
    "                            \"r--\", alpha=0.8, linewidth=1)\n",
    "            \n",
    "            # Format axes\n",
    "            axes[i].set_xlabel('Number of Prescriptions')\n",
    "            axes[i].set_ylabel('Units Reimbursed')\n",
    "            axes[i].set_title(f'{atc_class}\\n{atc_name[:30]}', fontsize=10)\n",
    "            axes[i].grid(True, alpha=0.3)\n",
    "            \n",
    "            # Add correlation coefficient with color coding\n",
    "            if len(subset) > 1:\n",
    "                corr = subset['Number of Prescriptions'].corr(subset['Units Reimbursed'])\n",
    "                color = 'red' if corr < 0 else 'blue'\n",
    "                axes[i].text(0.05, 0.95, f'r = {corr:.3f}', \n",
    "                            transform=axes[i].transAxes, \n",
    "                            bbox=dict(boxstyle=\"round,pad=0.3\", facecolor=\"white\", alpha=0.8, edgecolor=color),\n",
    "                            fontsize=9, color=color)\n",
    "        \n",
    "        # Hide unused subplots\n",
    "        for j in range(len(valid_atc_classes), len(axes)):\n",
    "            axes[j].set_visible(False)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        title_suffix = \" (Including Negative Correlations)\" if include_negative else \"\"\n",
    "        plt.suptitle(f'Indiana: Units Reimbursed vs Number of Prescriptions by ATC2 Class{title_suffix}\\n(All Years Combined)', \n",
    "                     fontsize=16, y=1.02)\n",
    "        plt.show()\n",
    "        \n",
    "        # Summary table\n",
    "        print(f\"\\n{'='*80}\")\n",
    "        print(\"PLOT SUMMARY - INDIANA ATC CLASSES\")\n",
    "        print(f\"{'='*80}\")\n",
    "        print(f\"{'ATC2':<5} {'Name':<30} {'Records':<8} {'Correlation':<12} {'Type':<8}\")\n",
    "        print(\"-\" * 90)\n",
    "        \n",
    "        for atc_class in valid_atc_classes:\n",
    "            subset = combined_df[combined_df['ATC2 Class'] == atc_class]\n",
    "            atc_name = subset['ATC2_Name'].iloc[0] if 'ATC2_Name' in subset.columns and not subset['ATC2_Name'].isna().all() else atc_class\n",
    "            corr = subset['Number of Prescriptions'].corr(subset['Units Reimbursed'])\n",
    "            corr_type = \"Negative\" if corr < 0 else \"Positive\"\n",
    "            \n",
    "            print(f\"{atc_class:<5} {atc_name[:28]:<30} {len(subset):<8} {corr:<12.4f} {corr_type:<8}\")\n",
    "        \n",
    "        return combined_df[combined_df['ATC2 Class'].isin(valid_atc_classes)]\n",
    "    \n",
    "    @staticmethod\n",
    "    def runs_test_analysis(years_list, base_path=None, min_records=8, generate_heatmaps=False, export_results=False):\n",
    "        \n",
    "        if base_path is None:\n",
    "            base_path = rf\"c:\\Users\\{user}\\OneDrive - purdue.edu\\VS code\\Data\"\n",
    "        \n",
    "        print(\"RUNS TEST ANALYSIS: Testing for Randomness in Units Reimbursed and Number of Prescriptions\")\n",
    "        print(\"=\"*80)\n",
    "        \n",
    "        all_results = {\n",
    "            'state_atc2': [],\n",
    "            'national_atc2': [], \n",
    "            'atc2_quarter': []\n",
    "        }\n",
    "        \n",
    "        # Load all data first\n",
    "        all_data = {}\n",
    "        for year in years_list:\n",
    "            print(f\"Loading {year} data...\", end=\" \")\n",
    "            try:\n",
    "                csv_path = os.path.join(base_path, f\"ATC\\\\merged_data\\\\merged_NEWdata_{year}.csv\")\n",
    "                df_merged = pd.read_csv(csv_path)\n",
    "                records = df_merged[df_merged['ATC4 Class'].notna()].copy()\n",
    "                records['ATC2 Class'] = records['ATC4 Class'].str[:3]\n",
    "                all_data[year] = records\n",
    "                print(f\"✓ ({len(records):,} records)\")\n",
    "            except Exception as e:\n",
    "                print(f\"✗ Error: {e}\")\n",
    "        \n",
    "        # ==================== PANEL 1: STATE x ATC2 CLASSES RUNS TEST ====================\n",
    "        print(f\"\\n{'='*80}\")\n",
    "        print(\"PANEL 1: STATE x ATC2 CLASSES RUNS TEST\")\n",
    "        print(f\"{'='*80}\")\n",
    "        \n",
    "        # Combine all years first\n",
    "        all_combined = []\n",
    "        for year, records in all_data.items():\n",
    "            records_copy = records.copy()\n",
    "            records_copy['Year'] = year\n",
    "            all_combined.append(records_copy)\n",
    "        \n",
    "        combined_df = pd.concat(all_combined, ignore_index=True)\n",
    "        \n",
    "        # Now analyze across all years\n",
    "        for state in combined_df['State'].unique():\n",
    "            state_data = combined_df[combined_df['State'] == state]\n",
    "            \n",
    "            for atc2 in state_data['ATC2 Class'].unique():\n",
    "                subset = state_data[state_data['ATC2 Class'] == atc2]\n",
    "                \n",
    "                # AGGREGATE TO QUARTERLY TIME SERIES\n",
    "                subset_ts = subset.groupby(['Year', 'Quarter']).agg({\n",
    "                    'Units Reimbursed': 'sum', \n",
    "                    'Number of Prescriptions': 'sum'\n",
    "                }).reset_index().sort_values(['Year','Quarter'])\n",
    "                \n",
    "                # DEBUG LINE\n",
    "                #if state == 'IN' and len(subset_ts) > 0:\n",
    "                #    print(f\"DEBUG: {state}-{atc2}: {len(subset_ts)} quarterly records\")\n",
    "                \n",
    "                if len(subset_ts) >= min_records:\n",
    "                    try:\n",
    "                        atc2_name = subset['ATC2_Name'].iloc[0] if 'ATC2_Name' in subset.columns else ''\n",
    "                        \n",
    "                        # Test Units Reimbursed\n",
    "                        units_values = subset_ts['Units Reimbursed'].values\n",
    "                        units_median = np.median(units_values)\n",
    "                        units_binary = (units_values > units_median).astype(int)\n",
    "                        \n",
    "                        if len(np.unique(units_binary)) > 1:\n",
    "                            runs_stat_units, p_val_units = runstest_1samp(units_binary)\n",
    "                        else:\n",
    "                            runs_stat_units, p_val_units = np.nan, np.nan\n",
    "                        \n",
    "                        # Test Number of Prescriptions\n",
    "                        presc_values = subset_ts['Number of Prescriptions'].values\n",
    "                        presc_median = np.median(presc_values)\n",
    "                        presc_binary = (presc_values > presc_median).astype(int)\n",
    "                        \n",
    "                        if len(np.unique(presc_binary)) > 1:\n",
    "                            runs_stat_presc, p_val_presc = runstest_1samp(presc_binary)\n",
    "                        else:\n",
    "                            runs_stat_presc, p_val_presc = np.nan, np.nan\n",
    "                        \n",
    "                        all_results['state_atc2'].append({\n",
    "                            'State': state,\n",
    "                            'ATC2_Class': atc2,\n",
    "                            'ATC2_Name': atc2_name,\n",
    "                            'N_Records': len(subset_ts),\n",
    "                            'Units_Runs_Stat': runs_stat_units,\n",
    "                            'Units_P_Value': p_val_units,\n",
    "                            'Presc_Runs_Stat': runs_stat_presc,\n",
    "                            'Presc_P_Value': p_val_presc\n",
    "                        })\n",
    "                        \n",
    "                    except Exception as e:\n",
    "                        print(f\"Error processing {state}-{atc2}: {e}\")\n",
    "        \n",
    "        # Convert to DataFrame and display results\n",
    "        state_atc2_df = pd.DataFrame(all_results['state_atc2'])\n",
    "        if not state_atc2_df.empty:\n",
    "            print(f\"\\nState x ATC2 Results: {len(state_atc2_df)} combinations analyzed\")\n",
    "            \n",
    "            # Summary statistics\n",
    "            units_significant = (state_atc2_df['Units_P_Value'] < 0.05).sum()\n",
    "            presc_significant = (state_atc2_df['Presc_P_Value'] < 0.05).sum() \n",
    "            total_valid = state_atc2_df['Units_P_Value'].notna().sum()\n",
    "            \n",
    "            print(f\"Units Reimbursed - Significant non-randomness: {units_significant}/{total_valid} ({100*units_significant/total_valid if total_valid > 0 else 0:.1f}%)\")\n",
    "            print(f\"Number of Prescriptions - Significant non-randomness: {presc_significant}/{total_valid} ({100*presc_significant/total_valid if total_valid > 0 else 0:.1f}%)\")\n",
    "            \n",
    "            # Top significant results\n",
    "            print(f\"\\nTop 10 Most Significant Units Reimbursed Results (State x ATC2):\")\n",
    "            top_units = state_atc2_df.nsmallest(10, 'Units_P_Value')[['State', 'ATC2_Class', 'ATC2_Name', 'Units_Runs_Stat', 'Units_P_Value', 'N_Records']].copy()\n",
    "            top_units['Units_P_Value'] = top_units['Units_P_Value'].apply(lambda x: f\"{x:.6f}\" if pd.notna(x) else 'NaN')\n",
    "            print(top_units.to_string(index=False))\n",
    "            \n",
    "            print(f\"\\nTop 10 Most Significant Number of Prescriptions Results (State x ATC2):\")\n",
    "            top_presc = state_atc2_df.nsmallest(10, 'Presc_P_Value')[['State', 'ATC2_Class', 'ATC2_Name', 'Presc_Runs_Stat', 'Presc_P_Value', 'N_Records']].copy()\n",
    "            top_presc['Presc_P_Value'] = top_presc['Presc_P_Value'].apply(lambda x: f\"{x:.6f}\" if pd.notna(x) else 'NaN')\n",
    "            print(top_presc.to_string(index=False))\n",
    "        \n",
    "        # ==================== PANEL 2: NATIONAL x ATC2 CLASSES RUNS TEST ====================\n",
    "        print(f\"\\n{'='*80}\")\n",
    "        print(\"PANEL 2: NATIONAL x ATC2 CLASSES RUNS TEST\") \n",
    "        print(f\"{'='*80}\")\n",
    "        \n",
    "        # Use the combined_df from Panel 1\n",
    "        for atc2 in combined_df['ATC2 Class'].unique():\n",
    "            subset = combined_df[combined_df['ATC2 Class'] == atc2]\n",
    "            \n",
    "            # AGGREGATE TO QUARTERLY TIME SERIES\n",
    "            subset_ts = subset.groupby(['Year', 'Quarter']).agg({\n",
    "                'Units Reimbursed': 'sum', \n",
    "                'Number of Prescriptions': 'sum'\n",
    "            }).reset_index().sort_values(['Year','Quarter'])\n",
    "            \n",
    "            # DEBUG LINE\n",
    "            #if len(subset_ts) > 0:\n",
    "            #    print(f\"DEBUG: National-{atc2}: {len(subset_ts)} quarterly records\")\n",
    "            \n",
    "            if len(subset_ts) >= min_records:\n",
    "                try:\n",
    "                    atc2_name = subset['ATC2_Name'].iloc[0] if 'ATC2_Name' in subset.columns else ''\n",
    "                    \n",
    "                    # Test Units Reimbursed\n",
    "                    units_values = subset_ts['Units Reimbursed'].values\n",
    "                    units_median = np.median(units_values)\n",
    "                    units_binary = (units_values > units_median).astype(int)\n",
    "                    \n",
    "                    if len(np.unique(units_binary)) > 1:\n",
    "                        runs_stat_units, p_val_units = runstest_1samp(units_binary)\n",
    "                    else:\n",
    "                        runs_stat_units, p_val_units = np.nan, np.nan\n",
    "                    \n",
    "                    # Test Number of Prescriptions\n",
    "                    presc_values = subset_ts['Number of Prescriptions'].values\n",
    "                    presc_median = np.median(presc_values)\n",
    "                    presc_binary = (presc_values > presc_median).astype(int)\n",
    "                    \n",
    "                    if len(np.unique(presc_binary)) > 1:\n",
    "                        runs_stat_presc, p_val_presc = runstest_1samp(presc_binary)\n",
    "                    else:\n",
    "                        runs_stat_presc, p_val_presc = np.nan, np.nan\n",
    "                    \n",
    "                    all_results['national_atc2'].append({\n",
    "                        'ATC2_Class': atc2,\n",
    "                        'ATC2_Name': atc2_name,\n",
    "                        'N_Records': len(subset_ts),\n",
    "                        'N_States': subset['State'].nunique(),\n",
    "                        'Units_Runs_Stat': runs_stat_units,\n",
    "                        'Units_P_Value': p_val_units,\n",
    "                        'Presc_Runs_Stat': runs_stat_presc,\n",
    "                        'Presc_P_Value': p_val_presc\n",
    "                    })\n",
    "                    \n",
    "                except Exception as e:\n",
    "                    print(f\"Error processing National-{atc2}: {e}\")\n",
    "        \n",
    "        # Display National x ATC2 results\n",
    "        national_atc2_df = pd.DataFrame(all_results['national_atc2'])\n",
    "        if not national_atc2_df.empty:\n",
    "            print(f\"\\nPanel 2 Results: {len(national_atc2_df)} national x ATC2 combinations analyzed\")\n",
    "            \n",
    "            units_significant = (national_atc2_df['Units_P_Value'] < 0.05).sum()\n",
    "            presc_significant = (national_atc2_df['Presc_P_Value'] < 0.05).sum()\n",
    "            total_valid = national_atc2_df['Units_P_Value'].notna().sum()\n",
    "            \n",
    "            print(f\"Units Reimbursed - Significant non-randomness: {units_significant}/{total_valid} ({100*units_significant/total_valid if total_valid > 0 else 0:.1f}%)\")\n",
    "            print(f\"Number of Prescriptions - Significant non-randomness: {presc_significant}/{total_valid} ({100*presc_significant/total_valid if total_valid > 0 else 0:.1f}%)\")\n",
    "            \n",
    "            print(f\"\\nTop 10 Most Significant Units Reimbursed Results (National x ATC2):\")\n",
    "            top_units_nat = national_atc2_df.nsmallest(10, 'Units_P_Value')[['ATC2_Class', 'ATC2_Name', 'Units_Runs_Stat', 'Units_P_Value', 'N_Records']].copy()\n",
    "            top_units_nat['Units_P_Value'] = top_units_nat['Units_P_Value'].apply(lambda x: f\"{x:.6f}\" if pd.notna(x) else 'NaN')\n",
    "            print(top_units_nat.to_string(index=False))\n",
    "            \n",
    "            print(f\"\\nTop 10 Most Significant Number of Prescriptions Results (National x ATC2):\")\n",
    "            top_presc_nat = national_atc2_df.nsmallest(10, 'Presc_P_Value')[['ATC2_Class', 'ATC2_Name', 'Presc_Runs_Stat', 'Presc_P_Value', 'N_Records']].copy()\n",
    "            top_presc_nat['Presc_P_Value'] = top_presc_nat['Presc_P_Value'].apply(lambda x: f\"{x:.6f}\" if pd.notna(x) else 'NaN')\n",
    "            print(top_presc_nat.to_string(index=False))\n",
    "        \n",
    "        # ==================== PANEL 3: ATC2 CLASSES x QUARTER RUNS TEST ====================\n",
    "        print(f\"\\n{'='*80}\")\n",
    "        print(\"PANEL 3: ATC2 CLASSES x QUARTER RUNS TEST\")\n",
    "        print(f\"{'='*80}\")\n",
    "        \n",
    "        # combined_df already exists from Panel 1\n",
    "        for atc2 in combined_df['ATC2 Class'].unique():\n",
    "            atc2_data = combined_df[combined_df['ATC2 Class'] == atc2]\n",
    "            \n",
    "            for quarter in sorted(atc2_data['Quarter'].unique()):\n",
    "                subset = atc2_data[atc2_data['Quarter'] == quarter]\n",
    "                \n",
    "                # AGGREGATE TO YEARLY TIME SERIES (for this specific quarter across years)\n",
    "                subset_ts = subset.groupby(['Year', 'Quarter']).agg({\n",
    "                    'Units Reimbursed': 'sum', \n",
    "                    'Number of Prescriptions': 'sum'\n",
    "                }).reset_index().sort_values(['Year','Quarter'])\n",
    "                \n",
    "                # DEBUG LINE\n",
    "                #if len(subset_ts) > 0:\n",
    "                #    print(f\"DEBUG: {atc2}-Q{quarter}: {len(subset_ts)} quarterly records\")\n",
    "                \n",
    "                if len(subset_ts) >= min_records:\n",
    "                    try:\n",
    "                        atc2_name = subset['ATC2_Name'].iloc[0] if 'ATC2_Name' in subset.columns else ''\n",
    "                        \n",
    "                        # Test Units Reimbursed\n",
    "                        units_values = subset_ts['Units Reimbursed'].values\n",
    "                        units_median = np.median(units_values)\n",
    "                        units_binary = (units_values > units_median).astype(int)\n",
    "                        \n",
    "                        if len(np.unique(units_binary)) > 1:\n",
    "                            runs_stat_units, p_val_units = runstest_1samp(units_binary)\n",
    "                        else:\n",
    "                            runs_stat_units, p_val_units = np.nan, np.nan\n",
    "                        \n",
    "                        # Test Number of Prescriptions\n",
    "                        presc_values = subset_ts['Number of Prescriptions'].values\n",
    "                        presc_median = np.median(presc_values)\n",
    "                        presc_binary = (presc_values > presc_median).astype(int)\n",
    "                        \n",
    "                        if len(np.unique(presc_binary)) > 1:\n",
    "                            runs_stat_presc, p_val_presc = runstest_1samp(presc_binary)\n",
    "                        else:\n",
    "                            runs_stat_presc, p_val_presc = np.nan, np.nan\n",
    "                        \n",
    "                        all_results['atc2_quarter'].append({\n",
    "                            'ATC2_Class': atc2,\n",
    "                            'ATC2_Name': atc2_name,\n",
    "                            'Quarter': quarter,\n",
    "                            'N_Records': len(subset_ts),\n",
    "                            'N_Years': subset_ts['Year'].nunique(),\n",
    "                            'N_States': subset['State'].nunique(),\n",
    "                            'Units_Runs_Stat': runs_stat_units,\n",
    "                            'Units_P_Value': p_val_units,\n",
    "                            'Presc_Runs_Stat': runs_stat_presc,\n",
    "                            'Presc_P_Value': p_val_presc\n",
    "                        })\n",
    "                        \n",
    "                    except Exception as e:\n",
    "                        print(f\"Error processing {atc2}-Q{quarter}: {e}\")\n",
    "        \n",
    "        # Display ATC2 x Quarter results\n",
    "        atc2_quarter_df = pd.DataFrame(all_results['atc2_quarter'])\n",
    "        if not atc2_quarter_df.empty:\n",
    "            print(f\"\\nATC2 x Quarter Results: {len(atc2_quarter_df)} combinations analyzed\")\n",
    "            \n",
    "            units_significant = (atc2_quarter_df['Units_P_Value'] < 0.05).sum()\n",
    "            presc_significant = (atc2_quarter_df['Presc_P_Value'] < 0.05).sum()\n",
    "            total_valid = atc2_quarter_df['Units_P_Value'].notna().sum()\n",
    "            \n",
    "            print(f\"Units Reimbursed - Significant non-randomness: {units_significant}/{total_valid} ({100*units_significant/total_valid if total_valid > 0 else 0:.1f}%)\")\n",
    "            print(f\"Number of Prescriptions - Significant non-randomness: {presc_significant}/{total_valid} ({100*presc_significant/total_valid if total_valid > 0 else 0:.1f}%)\")\n",
    "            \n",
    "            print(f\"\\nTop 10 Most Significant Units Reimbursed Results (ATC2 x Quarter):\")\n",
    "            top_units_quarter = atc2_quarter_df.nsmallest(10, 'Units_P_Value')[['ATC2_Class', 'ATC2_Name', 'Quarter', 'Units_Runs_Stat', 'Units_P_Value', 'N_Records']].copy()\n",
    "            top_units_quarter['Units_P_Value'] = top_units_quarter['Units_P_Value'].apply(lambda x: f\"{x:.6f}\" if pd.notna(x) else 'NaN')\n",
    "            print(top_units_quarter.to_string(index=False))\n",
    "            \n",
    "            print(f\"\\nTop 10 Most Significant Number of Prescriptions Results (ATC2 x Quarter):\")\n",
    "            top_presc_quarter = atc2_quarter_df.nsmallest(10, 'Presc_P_Value')[['ATC2_Class', 'ATC2_Name', 'Quarter', 'Presc_Runs_Stat', 'Presc_P_Value', 'N_Records']].copy()\n",
    "            top_presc_quarter['Presc_P_Value'] = top_presc_quarter['Presc_P_Value'].apply(lambda x: f\"{x:.6f}\" if pd.notna(x) else 'NaN')\n",
    "            print(top_presc_quarter.to_string(index=False))\n",
    "        \n",
    "        # ==================== SUMMARY SECTION ====================\n",
    "        print(f\"\\n{'='*80}\")\n",
    "        print(\"RUNS TEST SUMMARY\")\n",
    "        print(f\"{'='*80}\")\n",
    "        \n",
    "        summary_data = []\n",
    "        \n",
    "        if not state_atc2_df.empty:\n",
    "            state_units_sig = (state_atc2_df['Units_P_Value'] < 0.05).sum()\n",
    "            state_presc_sig = (state_atc2_df['Presc_P_Value'] < 0.05).sum()\n",
    "            state_total = state_atc2_df['Units_P_Value'].notna().sum()\n",
    "            summary_data.append(['State x ATC2', state_total, state_units_sig, state_presc_sig])\n",
    "        \n",
    "        if not national_atc2_df.empty:\n",
    "            nat_units_sig = (national_atc2_df['Units_P_Value'] < 0.05).sum()\n",
    "            nat_presc_sig = (national_atc2_df['Presc_P_Value'] < 0.05).sum()\n",
    "            nat_total = national_atc2_df['Units_P_Value'].notna().sum()\n",
    "            summary_data.append(['National x ATC2', nat_total, nat_units_sig, nat_presc_sig])\n",
    "        \n",
    "        if not atc2_quarter_df.empty:\n",
    "            quarter_units_sig = (atc2_quarter_df['Units_P_Value'] < 0.05).sum()\n",
    "            quarter_presc_sig = (atc2_quarter_df['Presc_P_Value'] < 0.05).sum()\n",
    "            quarter_total = atc2_quarter_df['Units_P_Value'].notna().sum()\n",
    "            summary_data.append(['ATC2 x Quarter', quarter_total, quarter_units_sig, quarter_presc_sig])\n",
    "        \n",
    "        if summary_data:\n",
    "            summary_df = pd.DataFrame(summary_data, columns=['Panel', 'Total Tests', 'Units Sig (p<0.05)', 'Prescriptions Sig (p<0.05)'])\n",
    "            summary_df['Units % Sig'] = (summary_df['Units Sig (p<0.05)'] / summary_df['Total Tests'] * 100).round(1)\n",
    "            summary_df['Prescriptions % Sig'] = (summary_df['Prescriptions Sig (p<0.05)'] / summary_df['Total Tests'] * 100).round(1)\n",
    "            print(summary_df.to_string(index=False))\n",
    "        \n",
    "        print(f\"\\nNote: Runs test examines whether data points occur in a random sequence.\")\n",
    "        print(f\"Significant p-values (< 0.05) indicate non-random patterns in the data.\")\n",
    "        print(f\"Lower runs statistics suggest more clustering; higher values suggest more alternation.\")\n",
    "        \n",
    "        # ==================== EXPORT PANEL DATAFRAMES ====================\n",
    "        if export_results:\n",
    "            export_dir = os.path.join(base_path, \"ATC\\\\exported_analysis\")\n",
    "            os.makedirs(export_dir, exist_ok=True)\n",
    "            if not state_atc2_df.empty:\n",
    "                state_atc2_df.to_csv(os.path.join(export_dir, \"runs_test_panel1_state_atc2.csv\"), index=False)\n",
    "            if not national_atc2_df.empty:\n",
    "                national_atc2_df.to_csv(os.path.join(export_dir, \"runs_test_panel2_national_atc2.csv\"), index=False)\n",
    "            if not atc2_quarter_df.empty:\n",
    "                atc2_quarter_df.to_csv(os.path.join(export_dir, \"runs_test_panel3_atc2_quarter.csv\"), index=False)\n",
    "            print(f\"Exported panel DataFrames to {export_dir}\")\n",
    "        \n",
    "        # ==================== HEATMAPS ====================\n",
    "        if generate_heatmaps:\n",
    "            from matplotlib.colors import LinearSegmentedColormap\n",
    "            \n",
    "            # Top classes by Units and Prescriptions (union of both top-30 lists)\n",
    "            if not combined_df.empty:\n",
    "                top_units = (combined_df.groupby('ATC2 Class')['Units Reimbursed'].sum()\n",
    "                            .sort_values(ascending=False).head(30).index.tolist())\n",
    "                top_presc = (combined_df.groupby('ATC2 Class')['Number of Prescriptions'].sum()\n",
    "                            .sort_values(ascending=False).head(30).index.tolist())\n",
    "                top_classes = list(dict.fromkeys(top_units + top_presc))\n",
    "            else:\n",
    "                top_classes = []\n",
    "            \n",
    "            def _prepare_pivot(df, value_col):\n",
    "                if 'ATC2_Class' not in df.columns:\n",
    "                    return pd.DataFrame()\n",
    "                filtered = df[df['ATC2_Class'].isin(top_classes)]\n",
    "                if filtered.empty:\n",
    "                    return pd.DataFrame()\n",
    "                agg = (filtered.groupby(['ATC2_Class', 'State'])[value_col]\n",
    "                            .mean().reset_index())\n",
    "                pivot = agg.pivot(index='ATC2_Class', columns='State', values=value_col)\n",
    "                return pivot.reindex(top_classes)\n",
    "            \n",
    "            def _prepare_pivot_state(df, value_col, state_code='IN'):\n",
    "                if 'ATC2_Class' not in df.columns:\n",
    "                    return pd.DataFrame()\n",
    "                filtered = df[(df['ATC2_Class'].isin(top_classes)) & (df['State'] == state_code)]\n",
    "                if filtered.empty:\n",
    "                    return pd.DataFrame()\n",
    "                agg = (filtered.groupby(['ATC2_Class', 'State'])[value_col]\n",
    "                            .mean().reset_index())\n",
    "                pivot = agg.pivot(index='ATC2_Class', columns='State', values=value_col)\n",
    "                return pivot.reindex(top_classes)\n",
    "            \n",
    "            def _prepare_pivot_quarter(df, value_col):\n",
    "                if 'ATC2_Class' not in df.columns:\n",
    "                    return pd.DataFrame()\n",
    "                filtered = df[df['ATC2_Class'].isin(top_classes)]\n",
    "                if filtered.empty or 'Quarter' not in filtered.columns:\n",
    "                    return pd.DataFrame()\n",
    "                agg = (filtered.groupby(['ATC2_Class', 'Quarter'])[value_col]\n",
    "                            .mean().reset_index())\n",
    "                pivot = agg.pivot(index='ATC2_Class', columns='Quarter', values=value_col)\n",
    "                return pivot.reindex(top_classes)\n",
    "            \n",
    "            def _plot_heatmap(pivot_df, title):\n",
    "                if pivot_df.empty:\n",
    "                    print(f\"No data for {title}\")\n",
    "                    return\n",
    "                cmap = LinearSegmentedColormap.from_list('pval_map', ['green', 'yellow', 'red'])\n",
    "                plt.figure(figsize=(14, max(6, len(pivot_df)*0.35)))\n",
    "                sns.heatmap(pivot_df, cmap=cmap, vmin=0.01, vmax=0.1, annot=False, cbar_kws={'label': 'Avg p-value'}, linewidths=0.5)\n",
    "                plt.title(title, fontsize=12, fontweight='bold')\n",
    "                plt.xlabel(pivot_df.columns.name if pivot_df.columns.name else '')\n",
    "                plt.ylabel('ATC2 Class')\n",
    "                plt.tight_layout()\n",
    "                plt.show()\n",
    "            \n",
    "            # Panel 1 (State x ATC2)\n",
    "            units_pivot = _prepare_pivot(state_atc2_df, 'Units_P_Value')\n",
    "            presc_pivot = _prepare_pivot(state_atc2_df, 'Presc_P_Value')\n",
    "            _plot_heatmap(units_pivot, 'Runs Test p-values by State (Units Reimbursed)')\n",
    "            _plot_heatmap(presc_pivot, 'Runs Test p-values by State (Number of Prescriptions)')\n",
    "            \n",
    "            # Indiana-only heatmap\n",
    "            in_units_pivot = _prepare_pivot_state(state_atc2_df, 'Units_P_Value', state_code='IN')\n",
    "            in_presc_pivot = _prepare_pivot_state(state_atc2_df, 'Presc_P_Value', state_code='IN')\n",
    "            _plot_heatmap(in_units_pivot, 'Runs Test p-values for Indiana (Units Reimbursed)')\n",
    "            _plot_heatmap(in_presc_pivot, 'Runs Test p-values for Indiana (Number of Prescriptions)')\n",
    "            \n",
    "            # Panel 3 (ATC2 x Quarter)\n",
    "            units_quarter_pivot = _prepare_pivot_quarter(atc2_quarter_df, 'Units_P_Value')\n",
    "            presc_quarter_pivot = _prepare_pivot_quarter(atc2_quarter_df, 'Presc_P_Value')\n",
    "            _plot_heatmap(units_quarter_pivot, 'Runs Test p-values by Quarter (Units)')\n",
    "            _plot_heatmap(presc_quarter_pivot, 'Runs Test p-values by Quarter (Prescriptions)')\n",
    "        \n",
    "        return {\n",
    "            'state_atc2': state_atc2_df,\n",
    "            'national_atc2': national_atc2_df, \n",
    "            'atc2_quarter': atc2_quarter_df\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04705709",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#covarience_results = NDCATC_ind.covariance_look(years_list)\n",
    "\n",
    "# Example 1: Indiana only\n",
    "correlation_results_IN = NDCATC_stats.correlation_look(years_list, state_filter='IN')\n",
    "\n",
    "# Example 2: All states (original behavior)\n",
    "# correlation_results_all = NDCATC_stats.correlation_look(years_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c71bc133",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Run the three-panel correlation analysis\n",
    "correlation_results = NDCATC_stats.correlation_look(years_list, min_records=8)\n",
    "\n",
    "# Uncomment the line below to run the analysis\n",
    "# runs_results = NDCATC_ind.runs_test_analysis(years_list, min_records=25, generate_heatmaps=True, export_results=True)\n",
    "runs_results = NDCATC_stats.runs_test_analysis(years_list, min_records=8, generate_heatmaps=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5c4e7f4",
   "metadata": {},
   "source": [
    "#### Working with Medicaid Enrollment Data collected through MBES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99308c32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "State                                             object\n",
      "Total Medicaid Enrollees                           int64\n",
      "Total VIII Group Enrollees                       float64\n",
      "Total VIII Group Newly Eligible Enrollees        float64\n",
      "Total VIII Group Not Newly Eligible Enrollees    float64\n",
      "Updated Year                                       int64\n",
      "Updated Month                                      int64\n",
      "Enrollment Year                                    int64\n",
      "Enrollment Month                                   int64\n",
      "Notes                                             object\n",
      "dtype: object\n",
      "State                                            object\n",
      "Total Medicaid Enrollees                         object\n",
      "Total VIII Group Enrollees                       object\n",
      "Total VIII Group Newly Eligible Enrollees        object\n",
      "Total VIII Group Not Newly Eligible Enrollees    object\n",
      "Updated Year                                      int64\n",
      "Updated Month                                     int64\n",
      "Enrollment Year                                   int64\n",
      "Enrollment Month                                  int64\n",
      "Notes                                            object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Looking the datatypes in the column\n",
    "enroll_csv_path=rf\"c:\\Users\\{user}\\OneDrive - purdue.edu\\VS code\\Data\\ATC\\Medicaid_ENR\\2017_Q1.csv\"\n",
    "df_enroll = pd.read_csv(enroll_csv_path)\n",
    "print(df_enroll.dtypes)\n",
    "\n",
    "enroll_csv_path=rf\"c:\\Users\\{user}\\OneDrive - purdue.edu\\VS code\\Data\\ATC\\Medicaid_ENR\\2022_Q1.csv\"\n",
    "df_enroll1 = pd.read_csv(enroll_csv_path)\n",
    "print(df_enroll1.dtypes)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "39b39af7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MedicaidProcessor:\n",
    "   \n",
    "    def __init__(self):\n",
    "      \n",
    "        self.data_directory = r'c:\\Users\\lholguin\\OneDrive - purdue.edu\\VS code\\Data\\ATC\\Medicaid_ENR'\n",
    "        self.output_filename = 'quarterly_medicaid_panel.csv'\n",
    "\n",
    "    def build_quarterly_panel(self):\n",
    "       \n",
    "        file_pattern = os.path.join(self.data_directory, \"*.csv\")\n",
    "        csv_files = glob.glob(file_pattern)\n",
    "        \n",
    "        if not csv_files:\n",
    "            print(f\"No CSV files found in directory: {self.data_directory}\")\n",
    "            return None\n",
    "        \n",
    "        print(f\"Found {len(csv_files)} files. Loading and concatenating...\")\n",
    "        \n",
    "        df_list = []\n",
    "        for file in csv_files:\n",
    "            try:\n",
    "                # specific encoding might be needed depending on source (e.g., 'latin1')\n",
    "                df = pd.read_csv(file)\n",
    "                df_list.append(df)\n",
    "            except Exception as e:\n",
    "                print(f\"Error reading {file}: {e}\")\n",
    "                continue\n",
    "                \n",
    "        if not df_list:\n",
    "            return None\n",
    "\n",
    "        full_df = pd.concat(df_list, ignore_index=True)\n",
    "        \n",
    "        full_df['Enrollment Month'] = pd.to_numeric(full_df['Enrollment Month'], errors='coerce')\n",
    "        \n",
    "        # Clean 'Total Medicaid Enrollees' to handle commas (e.g., \"1,000\") and non-numeric data\n",
    "        full_df['Total Medicaid Enrollees'] = (\n",
    "            full_df['Total Medicaid Enrollees']\n",
    "            .astype(str)\n",
    "            .str.replace(',', '', regex=False)\n",
    "        )\n",
    "        full_df['Total Medicaid Enrollees'] = pd.to_numeric(full_df['Total Medicaid Enrollees'], errors='coerce')\n",
    "     \n",
    "        # 2. Create a Quarter variable based on Enrollment Month\n",
    "        full_df['Quarter'] = (full_df['Enrollment Month'] - 1) // 3 + 1\n",
    "        \n",
    "        # 3. Group by State, Enrollment Year, and Quarter\n",
    "        # 4. Compute quarterly averages\n",
    "        group_cols = ['State', 'Enrollment Year', 'Quarter']\n",
    "        \n",
    "        quarterly_panel = full_df.groupby(group_cols, as_index=False)['Total Medicaid Enrollees'].mean()\n",
    "        \n",
    "        # Rename column for clarity\n",
    "        quarterly_panel.rename(columns={'Total Medicaid Enrollees': 'Avg_Total_Medicaid_Enrollees'}, inplace=True)\n",
    "        \n",
    "        # 5. Export to CSV\n",
    "        output_path = os.path.join(self.data_directory, self.output_filename)\n",
    "        quarterly_panel.to_csv(output_path, index=False)\n",
    "        print(f\"Successfully saved quarterly panel to: {output_path}\")\n",
    "        \n",
    "        return quarterly_panel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "16b89dc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 46 files. Loading and concatenating...\n",
      "Successfully saved quarterly panel to: c:\\Users\\lholguin\\OneDrive - purdue.edu\\VS code\\Data\\ATC\\Medicaid_ENR\\quarterly_medicaid_panel.csv\n"
     ]
    }
   ],
   "source": [
    "#Calling the method\n",
    "medicaid_processor = MedicaidProcessor()\n",
    "quarterly_medicaid_panel = medicaid_processor.build_quarterly_panel()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
