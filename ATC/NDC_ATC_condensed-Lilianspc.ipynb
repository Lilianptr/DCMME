{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c2b3e3b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "import shelve\n",
    "import os\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, clear_output\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "56f7f271",
   "metadata": {},
   "outputs": [],
   "source": [
    "user=\"lholguin\"\n",
    "#user in personal pc <- \"asus\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "73aebaf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#New changes to the class\n",
    "class NDCATCAnalyzer:\n",
    "\n",
    "    def __init__(self, year, base_path=None):\n",
    "\n",
    "        self.year = year\n",
    "        if base_path is None:\n",
    "            #Lookup the user's base path\n",
    "            self.base_path = rf\"c:\\Users\\{user}\\OneDrive - purdue.edu\\VS code\\Data\"\n",
    "        else:\n",
    "            self.base_path = base_path\n",
    "            \n",
    "        self.df_cleaned = None\n",
    "        self.df_merged = None\n",
    "        self.atc_mapping = None\n",
    "        self.df_faf = None\n",
    "        \n",
    "    def clean_sdud_data(self):\n",
    "        csv_file = os.path.join(self.base_path, f\"SDUD\\\\SDUD{self.year}.csv\")\n",
    "        print(f\"Reading CSV file: {csv_file}\")\n",
    "        \n",
    "        # Read with NDC as string to preserve leading zeros\n",
    "        df = pd.read_csv(csv_file, dtype={'NDC': 'object'})\n",
    "        \n",
    "        print(f\"Total rows in {self.year} before filtering: {len(df)}\")\n",
    "        \n",
    "        # Remove NA values\n",
    "        df_filtered = df.dropna(subset=['Units Reimbursed', 'Number of Prescriptions'])\n",
    "        print(f\"Rows after removing NA: {len(df_filtered)}\")\n",
    "        \n",
    "        # Filter out State='XX'\n",
    "        df_filtered = df_filtered[df_filtered['State'] != 'XX']\n",
    "        print(f\"Rows after filtering State='XX': {len(df_filtered)}\")\n",
    "        print(f\"Unique NDCs: {df_filtered['NDC'].nunique()}\")\n",
    "        \n",
    "        self.df_cleaned = df_filtered\n",
    "        return self.df_cleaned\n",
    "    \n",
    "    #NEW\n",
    "    def adding_key(self):\n",
    "        \"\"\"Add record_id column to cleaned dataframe.\"\"\"\n",
    "        if self.df_cleaned is None:\n",
    "            raise ValueError(\"Must run clean_sdud_data() first\")\n",
    "        \n",
    "        print(\"Adding record_id column...\")\n",
    "        \n",
    "        # Create record_id column\n",
    "        self.df_cleaned['record_id'] = (\n",
    "            self.df_cleaned['State'].astype(str) + \"_\" +\n",
    "            self.df_cleaned['Year'].astype(str) + \"_\" +\n",
    "            self.df_cleaned['Quarter'].astype(str) + \"_\" +\n",
    "            self.df_cleaned['Utilization Type'].astype(str) + \"_\" +\n",
    "            self.df_cleaned['NDC'].astype(str)\n",
    "        )\n",
    "        \n",
    "        print(f\"Created {len(self.df_cleaned)} record IDs\")\n",
    "        print(f\"Sample record_id: {self.df_cleaned['record_id'].iloc[0]}\")\n",
    "        \n",
    "        return self.df_cleaned\n",
    "    \n",
    "    def generate_ndc_txt(self, output_filename=None):\n",
    "        \"\"\"Step 2: Generate text file with unique NDC values and their record_id keys.\"\"\"\n",
    "        if self.df_cleaned is None:\n",
    "            raise ValueError(\"Must run clean_sdud_data() first\")\n",
    "        \n",
    "        if 'record_id' not in self.df_cleaned.columns:\n",
    "            raise ValueError(\"Must run adding_key() first to create record_id column\")\n",
    "            \n",
    "        if output_filename is None:\n",
    "            output_filename = f\"NDCNEW_{self.year}.txt\"\n",
    "        \n",
    "        output_path = os.path.join(self.base_path, f\"ATC\\\\text_files\\\\{output_filename}\")\n",
    "        \n",
    "        # Get unique combinations of NDC and record_id\n",
    "        unique_pairs = self.df_cleaned[['NDC', 'record_id']].drop_duplicates()\n",
    "        \n",
    "        with open(output_path, 'w') as f:\n",
    "            # Write header\n",
    "            f.write(\"NDC\\trecord_id\\n\")\n",
    "            # Write each unique pair\n",
    "            for _, row in unique_pairs.iterrows():\n",
    "                f.write(f\"{row['NDC']}\\t{row['record_id']}\\n\")\n",
    "        \n",
    "        print(f\"Exported to: {output_path}\")\n",
    "        print(f\"Unique record_id values: {unique_pairs['record_id'].nunique()}\")\n",
    "        return output_path\n",
    "    \n",
    "    def analyze_atc4_mapping(self):\n",
    "        \"\"\"Step 3: Analyze ATC4 mapping results and identify missing NDCs.\"\"\"\n",
    "        atc4_path = os.path.join(self.base_path, f\"ATC\\\\ATC4_classes\\\\NDCNEW_{self.year}_ATC4_classes.csv\")\n",
    "        \n",
    "        # Read ATC4 mapping\n",
    "        df_atc4 = pd.read_csv(atc4_path, dtype={'NDC': 'object', 'record_id': 'string'})\n",
    "        df_atc4['NDC'] = df_atc4['NDC'].str.zfill(11)\n",
    "        \n",
    "        # Ensure consistent data types before merge\n",
    "        self.df_cleaned['record_id'] = self.df_cleaned['record_id'].astype('string')\n",
    "        self.df_cleaned['NDC'] = self.df_cleaned['NDC'].astype('object')  \n",
    "        df_atc4['record_id'] = df_atc4['record_id'].astype('string')\n",
    "        df_atc4['NDC'] = df_atc4['NDC'].astype('object')  \n",
    "\n",
    "        # Merge ATC4 mapping with cleaned data using record_id\n",
    "        if self.df_cleaned is None:\n",
    "            raise ValueError(\"Must run clean_sdud_data() and adding_key() first\")\n",
    "        \n",
    "        if 'record_id' not in self.df_cleaned.columns:\n",
    "            raise ValueError(\"Must run adding_key() first to create record_id column\")\n",
    "        \n",
    "        print(f\"Merging ATC4 mapping with cleaned data using record_id and NDC...\")\n",
    "        \n",
    "        # Merge on BOTH record_id AND NDC\n",
    "        self.atc_mapping = pd.merge(\n",
    "            self.df_cleaned,\n",
    "            df_atc4[['record_id', 'NDC', 'ATC4 Class']],  # Include NDC in the selection\n",
    "            on=['record_id', 'NDC'],  # Merge on both columns\n",
    "            how='left'\n",
    "        )\n",
    "        \n",
    "        # Print rows of the merged dataframe\n",
    "        print(f\"Merged dataframe rows: {len(self.atc_mapping)}\")\n",
    "        print(self.atc_mapping.head())\n",
    "        total_records = len(self.atc_mapping)\n",
    "        mapped_records = self.atc_mapping['ATC4 Class'].notna().sum()\n",
    "        print(f\"Records with ATC4 mapping: {mapped_records} ({mapped_records/total_records*100:.1f}%)\")\n",
    "        \n",
    "        # Identify missing mappings\n",
    "        missing_records = self.atc_mapping[self.atc_mapping['ATC4 Class'].isna()]\n",
    "        if len(missing_records) > 0:\n",
    "            print(f\"\\nRecords without ATC4 mapping: {len(missing_records)}\")\n",
    "            print(f\"Unique NDCs without mapping: {missing_records['NDC'].nunique()}\")\n",
    "        \n",
    "        return self.atc_mapping\n",
    "        \n",
    "    def analyze_atc4_distribution(self):\n",
    "\n",
    "        \"\"\"Analyze distribution of ATC4 classes per record_id.\"\"\"\n",
    "        if self.atc_mapping is None:\n",
    "            raise ValueError(\"Must run analyze_atc4_mapping() first\")\n",
    "        \n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(\"ATC4 CLASSES PER RECORD_ID DISTRIBUTION\")\n",
    "        print(f\"{'='*60}\")\n",
    "        \n",
    "        # Count ATC4 classes per record_id (only valid mappings)\n",
    "        records_with_mapping = self.atc_mapping[self.atc_mapping['ATC4 Class'].notna()].copy()\n",
    "        \n",
    "        if len(records_with_mapping) == 0:\n",
    "            print(\"No records with valid ATC4 mappings found.\")\n",
    "            return None\n",
    "        \n",
    "        # Group by record_id and count unique ATC4 classes\n",
    "        atc4_per_record = records_with_mapping.groupby('record_id').agg({\n",
    "            'ATC4 Class': 'nunique',\n",
    "            'NDC': 'first',  # Get the NDC for reference\n",
    "            'State': 'first',  # Get the state for reference\n",
    "            'Year': 'first'    # Get the year for reference\n",
    "        }).reset_index()\n",
    "        \n",
    "        atc4_per_record.columns = ['record_id', 'num_atc4_classes', 'NDC', 'State', 'Year']\n",
    "        \n",
    "        # Distribution analysis\n",
    "        distribution = atc4_per_record['num_atc4_classes'].value_counts().sort_index()\n",
    "        \n",
    "        print(\"Distribution of ATC4 classes per record_id:\")\n",
    "        for classes, count in distribution.items():\n",
    "            pct = (count / len(atc4_per_record)) * 100\n",
    "            print(f\"  {classes} class(es): {count:,} record_ids ({pct:.1f}%)\")\n",
    "        \n",
    "        # Show examples of multi-class records\n",
    "        multi_class = atc4_per_record[atc4_per_record['num_atc4_classes'] > 1].sort_values('num_atc4_classes', ascending=False)\n",
    "        \n",
    "        if len(multi_class) > 0:\n",
    "            print(f\"\\nTop 10 record_ids with most ATC4 classes:\")\n",
    "            for _, row in multi_class.head(10).iterrows():\n",
    "                record_classes = records_with_mapping[records_with_mapping['record_id'] == row['record_id']]['ATC4 Class'].unique()\n",
    "                print(f\"  {row['record_id']}: {row['num_atc4_classes']} classes\")\n",
    "                print(f\"    NDC: {row['NDC']}, State: {row['State']}, Year: {row['Year']}\")\n",
    "                print(f\"    Classes: {list(record_classes)}\")\n",
    "                print()\n",
    "        \n",
    "        return atc4_per_record\n",
    "\n",
    "    def fetch_atc_names(self, cache_path=None):\n",
    "        \"\"\"Fetch ATC class names (ATC4, ATC3, ATC2) from RxNav API.\"\"\"\n",
    "        if self.atc_mapping is None:\n",
    "            raise ValueError(\"Must run analyze_atc4_mapping() first\")\n",
    "        \n",
    "        if cache_path is None:\n",
    "            cache_path = os.path.join(self.base_path, \"ATC\\\\cache_files\\\\atc_names_cache\")\n",
    "        \n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(\"FETCHING ATC CLASS NAMES\")\n",
    "        print(f\"{'='*60}\")\n",
    "        print(f\"Using cache: {cache_path}\")\n",
    "        \n",
    "        # Get only records with valid ATC4 mappings\n",
    "        df_with_atc = self.atc_mapping[self.atc_mapping['ATC4 Class'].notna()].copy()\n",
    "        \n",
    "        # Create ATC3 and ATC2 columns from ATC4\n",
    "        print(\"\\nCreating ATC3 and ATC2 columns from ATC4...\")\n",
    "        df_with_atc['ATC3 Class'] = df_with_atc['ATC4 Class'].str[:4]\n",
    "        df_with_atc['ATC2 Class'] = df_with_atc['ATC4 Class'].str[:3]\n",
    "        \n",
    "        # Get unique codes for each level\n",
    "        unique_atc4 = df_with_atc['ATC4 Class'].dropna().unique()\n",
    "        unique_atc3 = df_with_atc['ATC3 Class'].dropna().unique()\n",
    "        unique_atc2 = df_with_atc['ATC2 Class'].dropna().unique()\n",
    "        \n",
    "        # Filter out invalid codes\n",
    "        unique_atc4 = [c for c in unique_atc4 if c not in ['No ATC Mapping Found', 'No RxCUI Found', '']]\n",
    "        unique_atc3 = [c for c in unique_atc3 if c not in ['No ATC Mapping Found', 'No RxCUI Found', '', 'No ', 'No']]\n",
    "        unique_atc2 = [c for c in unique_atc2 if c not in ['No ATC Mapping Found', 'No RxCUI Found', '', 'No ', 'No']]\n",
    "        \n",
    "        print(f\"\\nUnique codes to fetch:\")\n",
    "        print(f\"  ATC4: {len(unique_atc4)}\")\n",
    "        print(f\"  ATC3: {len(unique_atc3)}\")\n",
    "        print(f\"  ATC2: {len(unique_atc2)}\")\n",
    "        \n",
    "        # Build mappings\n",
    "        atc4_names = {}\n",
    "        atc3_names = {}\n",
    "        atc2_names = {}\n",
    "        \n",
    "        with shelve.open(cache_path) as cache:\n",
    "            start_time = datetime.now()\n",
    "            \n",
    "            print(\"\\nFetching ATC4 names...\")\n",
    "            for code in unique_atc4:\n",
    "                atc4_names[code] = self._get_atc_name(code, cache)\n",
    "            \n",
    "            print(\"Fetching ATC3 names...\")\n",
    "            for code in unique_atc3:\n",
    "                atc3_names[code] = self._get_atc_name(code, cache)\n",
    "            \n",
    "            print(\"Fetching ATC2 names...\")\n",
    "            for code in unique_atc2:\n",
    "                atc2_names[code] = self._get_atc_name(code, cache)\n",
    "            \n",
    "            print(f\"\\nTotal processing time: {(datetime.now() - start_time).total_seconds()/60:.1f} minutes\")\n",
    "        \n",
    "        # Apply names to all records in atc_mapping\n",
    "        print(\"\\nApplying names to dataframe...\")\n",
    "        self.atc_mapping['ATC3 Class'] = self.atc_mapping['ATC4 Class'].str[:4]\n",
    "        self.atc_mapping['ATC2 Class'] = self.atc_mapping['ATC4 Class'].str[:3]\n",
    "        \n",
    "        self.atc_mapping['ATC4_Name'] = self.atc_mapping['ATC4 Class'].map(atc4_names).fillna('')\n",
    "        self.atc_mapping['ATC3_Name'] = self.atc_mapping['ATC3 Class'].map(atc3_names).fillna('')\n",
    "        self.atc_mapping['ATC2_Name'] = self.atc_mapping['ATC2 Class'].map(atc2_names).fillna('')\n",
    "        \n",
    "        print(f\"\\nATC names added successfully!\")\n",
    "        print(\"\\nSample output:\")\n",
    "        sample = self.atc_mapping[self.atc_mapping['ATC4 Class'].notna()][['NDC', 'record_id', 'ATC4 Class', 'ATC4_Name', 'ATC3 Class', 'ATC3_Name', 'ATC2 Class', 'ATC2_Name']].head(5)\n",
    "        print(sample.to_string())\n",
    "        \n",
    "        return self.atc_mapping\n",
    "    \n",
    "    def prepare_final_dataframe(self):\n",
    "        \"\"\"Prepare final dataframe with scaled metrics for export.\"\"\"\n",
    "        if self.atc_mapping is None:\n",
    "            raise ValueError(\"Must run fetch_atc_names() first\")\n",
    "        \n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(\"PREPARING FINAL DATAFRAME\")\n",
    "        print(f\"{'='*60}\")\n",
    "        \n",
    "        # Create a copy for final output\n",
    "        self.df_merged = self.atc_mapping.copy()\n",
    "        \n",
    "        # Scale units\n",
    "        print(\"\\nScaling units...\")\n",
    "        self.df_merged['Units Reimbursed'] = self.df_merged['Units Reimbursed'] / 1e9\n",
    "        self.df_merged['Number of Prescriptions'] = self.df_merged['Number of Prescriptions'] / 1e6\n",
    "        \n",
    "        # Report final statistics\n",
    "        total_records = len(self.df_merged)\n",
    "        mapped_records = self.df_merged['ATC4 Class'].notna().sum()\n",
    "        \n",
    "        print(f\"\\nFinal statistics:\")\n",
    "        print(f\"Total records: {total_records:,}\")\n",
    "        print(f\"Records with ATC4 mapping: {mapped_records:,} ({mapped_records/total_records*100:.1f}%)\")\n",
    "        print(f\"Total Units Reimbursed: {self.df_merged['Units Reimbursed'].sum():.2f} Billion\")\n",
    "        print(f\"Total Prescriptions: {self.df_merged['Number of Prescriptions'].sum():.2f} Million\")\n",
    "        \n",
    "        return self.df_merged\n",
    "    \n",
    "    def _get_atc_name(self, atc_code, cache):\n",
    "        \"\"\"Get ATC class name from code, using cache.\"\"\"\n",
    "        cache_key = f\"atc_name:{atc_code}\"\n",
    "        if cache_key in cache:\n",
    "            return cache[cache_key]\n",
    "        \n",
    "        try:\n",
    "            url = f\"https://rxnav.nlm.nih.gov/REST/rxclass/class/byId.json?classId={atc_code}\"\n",
    "            response = requests.get(url)\n",
    "            response.raise_for_status()\n",
    "            data = response.json()\n",
    "            \n",
    "            # Get class name\n",
    "            if 'rxclassMinConceptList' in data and 'rxclassMinConcept' in data['rxclassMinConceptList']:\n",
    "                concepts = data['rxclassMinConceptList']['rxclassMinConcept']\n",
    "                if concepts:\n",
    "                    name = concepts[0].get('className', '')\n",
    "                    cache[cache_key] = name\n",
    "                    return name\n",
    "            \n",
    "            cache[cache_key] = ''\n",
    "            return ''\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error retrieving name for {atc_code}: {e}\")\n",
    "            cache[cache_key] = ''\n",
    "            return ''\n",
    "    \n",
    "    def analyze_atc3_distribution(self):\n",
    "        \"\"\"Analyze distribution of ATC3 classes per record_id.\"\"\"\n",
    "        if self.atc_mapping is None:\n",
    "            raise ValueError(\"Must run analyze_atc4_mapping() first\")\n",
    "        \n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(\"ATC3 CLASSES PER RECORD_ID DISTRIBUTION\")\n",
    "        print(f\"{'='*60}\")\n",
    "        \n",
    "        # Create ATC3 classes from ATC4\n",
    "        records_with_mapping = self.atc_mapping[self.atc_mapping['ATC4 Class'].notna()].copy()\n",
    "        \n",
    "        if len(records_with_mapping) == 0:\n",
    "            print(\"No records with valid ATC4 mappings found.\")\n",
    "            return None\n",
    "        \n",
    "        # Create ATC3 class from ATC4 class (first 4 characters)\n",
    "        records_with_mapping['ATC3 Class'] = records_with_mapping['ATC4 Class'].str[:4]\n",
    "        \n",
    "        # Group by record_id and count unique ATC3 classes\n",
    "        atc3_per_record = records_with_mapping.groupby('record_id').agg({\n",
    "            'ATC3 Class': 'nunique',\n",
    "            'NDC': 'first',\n",
    "            'State': 'first',\n",
    "            'Year': 'first'\n",
    "        }).reset_index()\n",
    "        \n",
    "        atc3_per_record.columns = ['record_id', 'num_atc3_classes', 'NDC', 'State', 'Year']\n",
    "        \n",
    "        # Distribution analysis\n",
    "        distribution = atc3_per_record['num_atc3_classes'].value_counts().sort_index()\n",
    "        \n",
    "        print(\"Distribution of ATC3 classes per record_id:\")\n",
    "        for classes, count in distribution.items():\n",
    "            pct = (count / len(atc3_per_record)) * 100\n",
    "            print(f\"  {classes} class(es): {count:,} record_ids ({pct:.1f}%)\")\n",
    "        \n",
    "        # Show examples of multi-class records\n",
    "        multi_class = atc3_per_record[atc3_per_record['num_atc3_classes'] > 1].sort_values('num_atc3_classes', ascending=False)\n",
    "        \n",
    "        if len(multi_class) > 0:\n",
    "            print(f\"\\nTop 10 record_ids with most ATC3 classes:\")\n",
    "            for _, row in multi_class.head(10).iterrows():\n",
    "                record_classes = records_with_mapping[records_with_mapping['record_id'] == row['record_id']]['ATC3 Class'].unique()\n",
    "                print(f\"  {row['record_id']}: {row['num_atc3_classes']} classes\")\n",
    "                print(f\"    NDC: {row['NDC']}, State: {row['State']}, Year: {row['Year']}\")\n",
    "                print(f\"    Classes: {list(record_classes)}\")\n",
    "                print()\n",
    "        \n",
    "        # Summary statistics\n",
    "        print(f\"\\nATC3 Summary:\")\n",
    "        print(f\"  Total record_ids with ATC3 mapping: {len(atc3_per_record):,}\")\n",
    "        print(f\"  Average ATC3 classes per record_id: {atc3_per_record['num_atc3_classes'].mean():.2f}\")\n",
    "        print(f\"  Max ATC3 classes for single record_id: {atc3_per_record['num_atc3_classes'].max()}\")\n",
    "        \n",
    "        return atc3_per_record\n",
    "\n",
    "    def analyze_atc2_distribution(self):\n",
    "        \"\"\"Analyze distribution of ATC2 classes per record_id.\"\"\"\n",
    "        if self.atc_mapping is None:\n",
    "            raise ValueError(\"Must run analyze_atc4_mapping() first\")\n",
    "        \n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(\"ATC2 CLASSES PER RECORD_ID DISTRIBUTION\")\n",
    "        print(f\"{'='*60}\")\n",
    "        \n",
    "        # Create ATC2 classes from ATC4\n",
    "        records_with_mapping = self.atc_mapping[self.atc_mapping['ATC4 Class'].notna()].copy()\n",
    "        \n",
    "        if len(records_with_mapping) == 0:\n",
    "            print(\"No records with valid ATC4 mappings found.\")\n",
    "            return None\n",
    "        \n",
    "        # Create ATC2 class from ATC4 class (first 3 characters)\n",
    "        records_with_mapping['ATC2 Class'] = records_with_mapping['ATC4 Class'].str[:3]\n",
    "        \n",
    "        # Group by record_id and count unique ATC2 classes\n",
    "        atc2_per_record = records_with_mapping.groupby('record_id').agg({\n",
    "            'ATC2 Class': 'nunique',\n",
    "            'NDC': 'first',\n",
    "            'State': 'first',\n",
    "            'Year': 'first'\n",
    "        }).reset_index()\n",
    "        \n",
    "        atc2_per_record.columns = ['record_id', 'num_atc2_classes', 'NDC', 'State', 'Year']\n",
    "        \n",
    "        # Distribution analysis\n",
    "        distribution = atc2_per_record['num_atc2_classes'].value_counts().sort_index()\n",
    "        \n",
    "        print(\"Distribution of ATC2 classes per record_id:\")\n",
    "        for classes, count in distribution.items():\n",
    "            pct = (count / len(atc2_per_record)) * 100\n",
    "            print(f\"  {classes} class(es): {count:,} record_ids ({pct:.1f}%)\")\n",
    "        \n",
    "        # Show examples of multi-class records\n",
    "        multi_class = atc2_per_record[atc2_per_record['num_atc2_classes'] > 1].sort_values('num_atc2_classes', ascending=False)\n",
    "        \n",
    "        if len(multi_class) > 0:\n",
    "            print(f\"\\nTop 10 record_ids with most ATC2 classes:\")\n",
    "            for _, row in multi_class.head(10).iterrows():\n",
    "                record_classes = records_with_mapping[records_with_mapping['record_id'] == row['record_id']]['ATC2 Class'].unique()\n",
    "                print(f\"  {row['record_id']}: {row['num_atc2_classes']} classes\")\n",
    "                print(f\"    NDC: {row['NDC']}, State: {row['State']}, Year: {row['Year']}\")\n",
    "                print(f\"    Classes: {list(record_classes)}\")\n",
    "                print()\n",
    "        \n",
    "        # Summary statistics\n",
    "        print(f\"\\nATC2 Summary:\")\n",
    "        print(f\"  Total record_ids with ATC2 mapping: {len(atc2_per_record):,}\")\n",
    "        print(f\"  Average ATC2 classes per record_id: {atc2_per_record['num_atc2_classes'].mean():.2f}\")\n",
    "        print(f\"  Max ATC2 classes for single record_id: {atc2_per_record['num_atc2_classes'].max()}\")\n",
    "        \n",
    "        return atc2_per_record\n",
    "\n",
    "    def export_merged_data(self, output_filename=None):\n",
    "        \"\"\"Export the final merged dataframe to CSV after removing duplicate record_ids.\"\"\"\n",
    "        if self.df_merged is None:\n",
    "            raise ValueError(\"Must run prepare_final_dataframe() first to create merged dataframe\")\n",
    "            \n",
    "        if output_filename is None:\n",
    "            output_filename = f\"merged_NEWdata_{self.year}.csv\"\n",
    "\n",
    "        output_path = os.path.join(self.base_path, f\"ATC\\\\merged_data\\\\{output_filename}\")\n",
    "\n",
    "        # Create directory if it doesn't exist\n",
    "        os.makedirs(os.path.dirname(output_path), exist_ok=True)\n",
    "\n",
    "        # Check for duplicate record_ids before removal\n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(\"CHECKING FOR DUPLICATE RECORD_IDs\")\n",
    "        print(f\"{'='*60}\")\n",
    "        print(f\"Total rows before deduplication: {len(self.df_merged):,}\")\n",
    "        \n",
    "        duplicate_count = self.df_merged['record_id'].duplicated().sum()\n",
    "        print(f\"Duplicate record_ids found: {duplicate_count:,}\")\n",
    "        \n",
    "        if duplicate_count > 0:\n",
    "            print(f\"Unique record_ids: {self.df_merged['record_id'].nunique():,}\")\n",
    "            \n",
    "            # Show sample duplicates BEFORE deduplication\n",
    "            duplicated_records = self.df_merged[self.df_merged['record_id'].duplicated(keep=False)].sort_values('record_id')\n",
    "            print(f\"\\nSample duplicate record_ids BEFORE deduplication (first 10 rows):\")\n",
    "            print(duplicated_records[['record_id', 'NDC', 'State', 'ATC4 Class']].head(10))\n",
    "            \n",
    "            # Print two specific record_id values before deduplication\n",
    "            print(f\"\\n{'='*60}\")\n",
    "            print(\"DETAILED VIEW: Two record_ids BEFORE deduplication\")\n",
    "            print(f\"{'='*60}\")\n",
    "            sample_record_ids = duplicated_records['record_id'].unique()[:2]\n",
    "            for rid in sample_record_ids:\n",
    "                print(f\"\\nrecord_id: {rid}\")\n",
    "                sample_rows = self.df_merged[self.df_merged['record_id'] == rid]\n",
    "                print(sample_rows[['record_id', 'NDC', 'State', 'Year', 'Quarter', 'ATC4 Class', 'ATC3 Class','ATC2 Class', 'Units Reimbursed', 'Number of Prescriptions']].to_string(index=False))\n",
    "        \n",
    "        # Remove duplicates, keeping first occurrence\n",
    "        df_deduplicated = self.df_merged.drop_duplicates(subset='record_id', keep='first')\n",
    "        \n",
    "        print(f\"\\nTotal rows after deduplication: {len(df_deduplicated):,}\")\n",
    "        print(f\"Rows removed: {len(self.df_merged) - len(df_deduplicated):,}\")\n",
    "        \n",
    "        # Show sample of data AFTER deduplication\n",
    "        print(f\"\\nSample of deduplicated data (first 10 rows):\")\n",
    "        print(df_deduplicated[['record_id', 'NDC', 'State', 'ATC4 Class']].head(10))\n",
    "        \n",
    "        # Print the same two record_id values after deduplication\n",
    "        if duplicate_count > 0:\n",
    "            print(f\"\\n{'='*60}\")\n",
    "            print(\"DETAILED VIEW: Same two record_ids AFTER deduplication\")\n",
    "            print(f\"{'='*60}\")\n",
    "            for rid in sample_record_ids:\n",
    "                print(f\"\\nrecord_id: {rid}\")\n",
    "                sample_rows = df_deduplicated[df_deduplicated['record_id'] == rid]\n",
    "                print(sample_rows[['record_id', 'NDC', 'State', 'Year', 'Quarter', 'ATC4 Class', 'ATC3 Class','ATC2 Class','Units Reimbursed', 'Number of Prescriptions']].to_string(index=False))\n",
    "\n",
    "        # Export deduplicated dataframe\n",
    "        df_deduplicated.to_csv(output_path, index=False)\n",
    "        \n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(\"DATA EXPORT COMPLETE\")\n",
    "        print(f\"{'='*60}\")\n",
    "        print(f\"Exported to: {output_path}\")\n",
    "        print(f\"Total rows exported: {len(df_deduplicated):,}\")\n",
    "        print(f\"Columns: {', '.join(df_deduplicated.columns.tolist())}\")\n",
    "        \n",
    "        # Compare with analyze_atc4_mapping output\n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(\"COMPARISON WITH analyze_atc4_mapping()\")\n",
    "        print(f\"{'='*60}\")\n",
    "        if self.atc_mapping is not None:\n",
    "            print(f\"Rows in atc_mapping (from analyze_atc4_mapping): {len(self.atc_mapping):,}\")\n",
    "            print(f\"Rows in df_merged (before deduplication): {len(self.df_merged):,}\")\n",
    "            print(f\"Rows in exported file (after deduplication): {len(df_deduplicated):,}\")\n",
    "            print(f\"Difference from atc_mapping: {len(df_deduplicated) - len(self.atc_mapping):,}\")\n",
    "        else:\n",
    "            print(\"atc_mapping not available for comparison\")\n",
    "        \n",
    "        return output_path\n",
    "\n",
    "    def analyze_different_atc2_records(self):\n",
    "        \"\"\"Find and display records that have different ATC2 classes with names.\"\"\"\n",
    "        if self.atc_mapping is None:\n",
    "            raise ValueError(\"Must run analyze_atc4_mapping() first\")\n",
    "        \n",
    "        print(\"RECORDS WITH DIFFERENT ATC2 CLASSES\")\n",
    "        print(\"=\"*40)\n",
    "        \n",
    "        # Get records and create ATC2\n",
    "        records = self.atc_mapping[self.atc_mapping['ATC4 Class'].notna()].copy()\n",
    "        records['ATC2 Class'] = records['ATC4 Class'].str[:3]\n",
    "        \n",
    "        # Find records with multiple ATC2 classes\n",
    "        multi_atc2 = records.groupby('record_id')['ATC2 Class'].nunique()\n",
    "        different_records = multi_atc2[multi_atc2 > 1].index.tolist()\n",
    "        \n",
    "        if len(different_records) == 0:\n",
    "            print(\"No records found with different ATC2 classes.\")\n",
    "            return None\n",
    "        \n",
    "        print(f\"Found {len(different_records)} records with different ATC2 classes\\n\")\n",
    "        \n",
    "        # Show first 3 examples\n",
    "        has_names = 'ATC2_Name' in records.columns\n",
    "        for i, record_id in enumerate(different_records[:3]):\n",
    "            record_data = records[records['record_id'] == record_id]\n",
    "            atc_info = record_data[['ATC2 Class', 'ATC2_Name']].drop_duplicates() if has_names else record_data[['ATC2 Class']].drop_duplicates()\n",
    "            \n",
    "            print(f\"{i+1}. {record_id} | NDC: {record_data['NDC'].iloc[0]}\")\n",
    "            for _, row in atc_info.iterrows():\n",
    "                if has_names:\n",
    "                    print(f\"   ATC2: {row['ATC2 Class']} - {row['ATC2_Name'][:40]}...\")\n",
    "                else:\n",
    "                    print(f\"   ATC2: {row['ATC2 Class']}\")\n",
    "            print()\n",
    "        \n",
    "        # Quick summary\n",
    "        print(f\"Summary: {multi_atc2[multi_atc2 > 1].value_counts().to_dict()}\")\n",
    "        \n",
    "        return records[records['record_id'].isin(different_records)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "workflow_execution",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading CSV file: c:\\Users\\lholguin\\OneDrive - purdue.edu\\VS code\\Data\\SDUD\\SDUD2022.csv\n",
      "Total rows in 2022 before filtering: 5164804\n",
      "Rows after removing NA: 2621949\n",
      "Rows after filtering State='XX': 2389418\n",
      "Unique NDCs: 33005\n",
      "Adding record_id column...\n",
      "Created 2389418 record IDs\n",
      "Sample record_id: AK_2022_4_FFSU_00002143380\n",
      "Exported to: c:\\Users\\lholguin\\OneDrive - purdue.edu\\VS code\\Data\\ATC\\text_files\\NDCNEW_2022.txt\n",
      "Unique record_id values: 2389418\n",
      "Merging ATC4 mapping with cleaned data using record_id and NDC...\n",
      "Merged dataframe rows: 4421713\n",
      "  Utilization Type State          NDC  Labeler Code  Product Code  \\\n",
      "0             FFSU    AK  00002143380             2          1433   \n",
      "1             FFSU    AK  00002143480             2          1434   \n",
      "2             FFSU    AK  00002143611             2          1436   \n",
      "3             FFSU    AK  00002144511             2          1445   \n",
      "4             FFSU    AK  00002147180             2          1471   \n",
      "\n",
      "   Package Size  Year  Quarter  Suppression Used Product Name  \\\n",
      "0            80  2022        4             False   TRULICITY    \n",
      "1            80  2022        4             False   TRULICITY    \n",
      "2            11  2022        4             False   EMGALITY P   \n",
      "3            11  2022        4             False   TALTZ AUTO   \n",
      "4            80  2022        4             False   MOUNJARO     \n",
      "\n",
      "   Units Reimbursed  Number of Prescriptions  Total Amount Reimbursed  \\\n",
      "0             473.0                    198.0                201743.95   \n",
      "1             646.0                    231.0                275657.31   \n",
      "2              26.0                     25.0                 16642.78   \n",
      "3              26.0                     23.0                164678.63   \n",
      "4              26.0                     12.0                 12214.55   \n",
      "\n",
      "   Medicaid Amount Reimbursed  Non Medicaid Amount Reimbursed  \\\n",
      "0                   195095.41                         6648.54   \n",
      "1                   267347.63                         8309.68   \n",
      "2                    16642.78                            0.00   \n",
      "3                   164678.63                            0.00   \n",
      "4                    10397.54                         1817.01   \n",
      "\n",
      "                    record_id ATC4 Class  \n",
      "0  AK_2022_4_FFSU_00002143380      A10BJ  \n",
      "1  AK_2022_4_FFSU_00002143480      A10BJ  \n",
      "2  AK_2022_4_FFSU_00002143611      N02CD  \n",
      "3  AK_2022_4_FFSU_00002144511      L04AC  \n",
      "4  AK_2022_4_FFSU_00002147180      A10BX  \n",
      "Records with ATC4 mapping: 4385476 (99.2%)\n",
      "\n",
      "Records without ATC4 mapping: 36237\n",
      "Unique NDCs without mapping: 2159\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Utilization Type</th>\n",
       "      <th>State</th>\n",
       "      <th>NDC</th>\n",
       "      <th>Labeler Code</th>\n",
       "      <th>Product Code</th>\n",
       "      <th>Package Size</th>\n",
       "      <th>Year</th>\n",
       "      <th>Quarter</th>\n",
       "      <th>Suppression Used</th>\n",
       "      <th>Product Name</th>\n",
       "      <th>Units Reimbursed</th>\n",
       "      <th>Number of Prescriptions</th>\n",
       "      <th>Total Amount Reimbursed</th>\n",
       "      <th>Medicaid Amount Reimbursed</th>\n",
       "      <th>Non Medicaid Amount Reimbursed</th>\n",
       "      <th>record_id</th>\n",
       "      <th>ATC4 Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>FFSU</td>\n",
       "      <td>AK</td>\n",
       "      <td>00002143380</td>\n",
       "      <td>2</td>\n",
       "      <td>1433</td>\n",
       "      <td>80</td>\n",
       "      <td>2022</td>\n",
       "      <td>4</td>\n",
       "      <td>False</td>\n",
       "      <td>TRULICITY</td>\n",
       "      <td>473.0</td>\n",
       "      <td>198.0</td>\n",
       "      <td>201743.95</td>\n",
       "      <td>195095.41</td>\n",
       "      <td>6648.54</td>\n",
       "      <td>AK_2022_4_FFSU_00002143380</td>\n",
       "      <td>A10BJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>FFSU</td>\n",
       "      <td>AK</td>\n",
       "      <td>00002143480</td>\n",
       "      <td>2</td>\n",
       "      <td>1434</td>\n",
       "      <td>80</td>\n",
       "      <td>2022</td>\n",
       "      <td>4</td>\n",
       "      <td>False</td>\n",
       "      <td>TRULICITY</td>\n",
       "      <td>646.0</td>\n",
       "      <td>231.0</td>\n",
       "      <td>275657.31</td>\n",
       "      <td>267347.63</td>\n",
       "      <td>8309.68</td>\n",
       "      <td>AK_2022_4_FFSU_00002143480</td>\n",
       "      <td>A10BJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>FFSU</td>\n",
       "      <td>AK</td>\n",
       "      <td>00002143611</td>\n",
       "      <td>2</td>\n",
       "      <td>1436</td>\n",
       "      <td>11</td>\n",
       "      <td>2022</td>\n",
       "      <td>4</td>\n",
       "      <td>False</td>\n",
       "      <td>EMGALITY P</td>\n",
       "      <td>26.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>16642.78</td>\n",
       "      <td>16642.78</td>\n",
       "      <td>0.00</td>\n",
       "      <td>AK_2022_4_FFSU_00002143611</td>\n",
       "      <td>N02CD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>FFSU</td>\n",
       "      <td>AK</td>\n",
       "      <td>00002144511</td>\n",
       "      <td>2</td>\n",
       "      <td>1445</td>\n",
       "      <td>11</td>\n",
       "      <td>2022</td>\n",
       "      <td>4</td>\n",
       "      <td>False</td>\n",
       "      <td>TALTZ AUTO</td>\n",
       "      <td>26.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>164678.63</td>\n",
       "      <td>164678.63</td>\n",
       "      <td>0.00</td>\n",
       "      <td>AK_2022_4_FFSU_00002144511</td>\n",
       "      <td>L04AC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>FFSU</td>\n",
       "      <td>AK</td>\n",
       "      <td>00002147180</td>\n",
       "      <td>2</td>\n",
       "      <td>1471</td>\n",
       "      <td>80</td>\n",
       "      <td>2022</td>\n",
       "      <td>4</td>\n",
       "      <td>False</td>\n",
       "      <td>MOUNJARO</td>\n",
       "      <td>26.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>12214.55</td>\n",
       "      <td>10397.54</td>\n",
       "      <td>1817.01</td>\n",
       "      <td>AK_2022_4_FFSU_00002147180</td>\n",
       "      <td>A10BX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4421708</th>\n",
       "      <td>FFSU</td>\n",
       "      <td>WY</td>\n",
       "      <td>78206012701</td>\n",
       "      <td>78206</td>\n",
       "      <td>127</td>\n",
       "      <td>1</td>\n",
       "      <td>2022</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>DULERA 100</td>\n",
       "      <td>546.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>13077.27</td>\n",
       "      <td>13077.27</td>\n",
       "      <td>0.00</td>\n",
       "      <td>WY_2022_1_FFSU_78206012701</td>\n",
       "      <td>R03CC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4421709</th>\n",
       "      <td>FFSU</td>\n",
       "      <td>WY</td>\n",
       "      <td>78206012701</td>\n",
       "      <td>78206</td>\n",
       "      <td>127</td>\n",
       "      <td>1</td>\n",
       "      <td>2022</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>DULERA 100</td>\n",
       "      <td>546.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>13077.27</td>\n",
       "      <td>13077.27</td>\n",
       "      <td>0.00</td>\n",
       "      <td>WY_2022_1_FFSU_78206012701</td>\n",
       "      <td>R03AK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4421710</th>\n",
       "      <td>FFSU</td>\n",
       "      <td>WY</td>\n",
       "      <td>78206012701</td>\n",
       "      <td>78206</td>\n",
       "      <td>127</td>\n",
       "      <td>1</td>\n",
       "      <td>2022</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>DULERA 100</td>\n",
       "      <td>546.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>13077.27</td>\n",
       "      <td>13077.27</td>\n",
       "      <td>0.00</td>\n",
       "      <td>WY_2022_1_FFSU_78206012701</td>\n",
       "      <td>R01AD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4421711</th>\n",
       "      <td>FFSU</td>\n",
       "      <td>WY</td>\n",
       "      <td>78206012701</td>\n",
       "      <td>78206</td>\n",
       "      <td>127</td>\n",
       "      <td>1</td>\n",
       "      <td>2022</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>DULERA 100</td>\n",
       "      <td>546.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>13077.27</td>\n",
       "      <td>13077.27</td>\n",
       "      <td>0.00</td>\n",
       "      <td>WY_2022_1_FFSU_78206012701</td>\n",
       "      <td>D07AC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4421712</th>\n",
       "      <td>FFSU</td>\n",
       "      <td>WY</td>\n",
       "      <td>78206012701</td>\n",
       "      <td>78206</td>\n",
       "      <td>127</td>\n",
       "      <td>1</td>\n",
       "      <td>2022</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>DULERA 100</td>\n",
       "      <td>546.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>13077.27</td>\n",
       "      <td>13077.27</td>\n",
       "      <td>0.00</td>\n",
       "      <td>WY_2022_1_FFSU_78206012701</td>\n",
       "      <td>R03AC</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4421713 rows × 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Utilization Type State          NDC  Labeler Code  Product Code  \\\n",
       "0                   FFSU    AK  00002143380             2          1433   \n",
       "1                   FFSU    AK  00002143480             2          1434   \n",
       "2                   FFSU    AK  00002143611             2          1436   \n",
       "3                   FFSU    AK  00002144511             2          1445   \n",
       "4                   FFSU    AK  00002147180             2          1471   \n",
       "...                  ...   ...          ...           ...           ...   \n",
       "4421708             FFSU    WY  78206012701         78206           127   \n",
       "4421709             FFSU    WY  78206012701         78206           127   \n",
       "4421710             FFSU    WY  78206012701         78206           127   \n",
       "4421711             FFSU    WY  78206012701         78206           127   \n",
       "4421712             FFSU    WY  78206012701         78206           127   \n",
       "\n",
       "         Package Size  Year  Quarter  Suppression Used Product Name  \\\n",
       "0                  80  2022        4             False   TRULICITY    \n",
       "1                  80  2022        4             False   TRULICITY    \n",
       "2                  11  2022        4             False   EMGALITY P   \n",
       "3                  11  2022        4             False   TALTZ AUTO   \n",
       "4                  80  2022        4             False   MOUNJARO     \n",
       "...               ...   ...      ...               ...          ...   \n",
       "4421708             1  2022        1             False   DULERA 100   \n",
       "4421709             1  2022        1             False   DULERA 100   \n",
       "4421710             1  2022        1             False   DULERA 100   \n",
       "4421711             1  2022        1             False   DULERA 100   \n",
       "4421712             1  2022        1             False   DULERA 100   \n",
       "\n",
       "         Units Reimbursed  Number of Prescriptions  Total Amount Reimbursed  \\\n",
       "0                   473.0                    198.0                201743.95   \n",
       "1                   646.0                    231.0                275657.31   \n",
       "2                    26.0                     25.0                 16642.78   \n",
       "3                    26.0                     23.0                164678.63   \n",
       "4                    26.0                     12.0                 12214.55   \n",
       "...                   ...                      ...                      ...   \n",
       "4421708             546.0                     38.0                 13077.27   \n",
       "4421709             546.0                     38.0                 13077.27   \n",
       "4421710             546.0                     38.0                 13077.27   \n",
       "4421711             546.0                     38.0                 13077.27   \n",
       "4421712             546.0                     38.0                 13077.27   \n",
       "\n",
       "         Medicaid Amount Reimbursed  Non Medicaid Amount Reimbursed  \\\n",
       "0                         195095.41                         6648.54   \n",
       "1                         267347.63                         8309.68   \n",
       "2                          16642.78                            0.00   \n",
       "3                         164678.63                            0.00   \n",
       "4                          10397.54                         1817.01   \n",
       "...                             ...                             ...   \n",
       "4421708                    13077.27                            0.00   \n",
       "4421709                    13077.27                            0.00   \n",
       "4421710                    13077.27                            0.00   \n",
       "4421711                    13077.27                            0.00   \n",
       "4421712                    13077.27                            0.00   \n",
       "\n",
       "                          record_id ATC4 Class  \n",
       "0        AK_2022_4_FFSU_00002143380      A10BJ  \n",
       "1        AK_2022_4_FFSU_00002143480      A10BJ  \n",
       "2        AK_2022_4_FFSU_00002143611      N02CD  \n",
       "3        AK_2022_4_FFSU_00002144511      L04AC  \n",
       "4        AK_2022_4_FFSU_00002147180      A10BX  \n",
       "...                             ...        ...  \n",
       "4421708  WY_2022_1_FFSU_78206012701      R03CC  \n",
       "4421709  WY_2022_1_FFSU_78206012701      R03AK  \n",
       "4421710  WY_2022_1_FFSU_78206012701      R01AD  \n",
       "4421711  WY_2022_1_FFSU_78206012701      D07AC  \n",
       "4421712  WY_2022_1_FFSU_78206012701      R03AC  \n",
       "\n",
       "[4421713 rows x 17 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analyzer = NDCATCAnalyzer(year=2022)\n",
    "analyzer.clean_sdud_data()           # Clean SDUD data\n",
    "analyzer.adding_key()                # Add record_id key\n",
    "analyzer.generate_ndc_txt()          # Generate NDC text file\n",
    "analyzer.analyze_atc4_mapping()      # Merge ATC4 by record_id & NDC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "644c005a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "ATC4 CLASSES PER RECORD_ID DISTRIBUTION\n",
      "============================================================\n",
      "Distribution of ATC4 classes per record_id:\n",
      "  1 class(es): 1,614,669 record_ids (68.6%)\n",
      "  2 class(es): 285,692 record_ids (12.1%)\n",
      "  3 class(es): 226,981 record_ids (9.6%)\n",
      "  4 class(es): 62,089 record_ids (2.6%)\n",
      "  5 class(es): 50,428 record_ids (2.1%)\n",
      "  6 class(es): 14,941 record_ids (0.6%)\n",
      "  7 class(es): 25,751 record_ids (1.1%)\n",
      "  8 class(es): 23,149 record_ids (1.0%)\n",
      "  9 class(es): 14,940 record_ids (0.6%)\n",
      "  10 class(es): 719 record_ids (0.0%)\n",
      "  11 class(es): 22,722 record_ids (1.0%)\n",
      "  12 class(es): 2,300 record_ids (0.1%)\n",
      "  13 class(es): 680 record_ids (0.0%)\n",
      "  14 class(es): 3,738 record_ids (0.2%)\n",
      "  15 class(es): 519 record_ids (0.0%)\n",
      "  16 class(es): 884 record_ids (0.0%)\n",
      "  17 class(es): 388 record_ids (0.0%)\n",
      "  20 class(es): 1,475 record_ids (0.1%)\n",
      "  21 class(es): 52 record_ids (0.0%)\n",
      "  22 class(es): 1,064 record_ids (0.0%)\n",
      "\n",
      "Top 10 record_ids with most ATC4 classes:\n",
      "  IA_2022_3_MCOU_24208083060: 22 classes\n",
      "    NDC: 24208083060, State: IA, Year: 2022\n",
      "    Classes: ['S01AA', 'R02AB', 'R01AD', 'D06AX', 'D07AB', 'S02AA', 'A01AB', 'S01BA', 'C05AA', 'S03BA', 'S01CB', 'B05CA', 'J01XB', 'A07AA', 'S02BA', 'S01CA', 'H02AB', 'D10AA', 'D07XB', 'A01AC', 'J01GB', 'S03AA']\n",
      "\n",
      "  MT_2022_2_FFSU_61314063006: 22 classes\n",
      "    NDC: 61314063006, State: MT, Year: 2022\n",
      "    Classes: ['D10AA', 'D07XB', 'A01AC', 'S03AA', 'S01AA', 'R02AB', 'R01AD', 'J01GB', 'D07AB', 'S02AA', 'A01AB', 'D06AX', 'S01BA', 'S03BA', 'S01CB', 'B05CA', 'C05AA', 'J01XB', 'A07AA', 'S02BA', 'S01CA', 'H02AB']\n",
      "\n",
      "  MT_2022_2_FFSU_61314063136: 22 classes\n",
      "    NDC: 61314063136, State: MT, Year: 2022\n",
      "    Classes: ['C05AA', 'B05CA', 'J01XB', 'A07AA', 'S02BA', 'S01CA', 'H02AB', 'A01AC', 'D10AA', 'D07XB', 'J01GB', 'S03AA', 'S01AA', 'R02AB', 'R01AD', 'D06AX', 'D07AB', 'S02AA', 'A01AB', 'S03BA', 'S01CB', 'S01BA']\n",
      "\n",
      "  VA_2022_2_MCOU_24208083060: 22 classes\n",
      "    NDC: 24208083060, State: VA, Year: 2022\n",
      "    Classes: ['H02AB', 'A01AC', 'D10AA', 'S03AA', 'D07XB', 'J01GB', 'S01AA', 'A01AB', 'R02AB', 'R01AD', 'D06AX', 'D07AB', 'S02AA', 'S03BA', 'S01CB', 'S01BA', 'B05CA', 'C05AA', 'A07AA', 'S01CA', 'J01XB', 'S02BA']\n",
      "\n",
      "  IL_2022_4_MCOU_61314063006: 22 classes\n",
      "    NDC: 61314063006, State: IL, Year: 2022\n",
      "    Classes: ['S03BA', 'S01CB', 'S01BA', 'C05AA', 'B05CA', 'J01XB', 'A07AA', 'S02BA', 'S01CA', 'H02AB', 'A01AC', 'D10AA', 'D07XB', 'J01GB', 'S03AA', 'S01AA', 'A01AB', 'R02AB', 'R01AD', 'D06AX', 'D07AB', 'S02AA']\n",
      "\n",
      "  IL_2022_4_MCOU_61314063136: 22 classes\n",
      "    NDC: 61314063136, State: IL, Year: 2022\n",
      "    Classes: ['S03BA', 'S01CB', 'S01BA', 'B05CA', 'C05AA', 'A07AA', 'S01CA', 'H02AB', 'J01XB', 'S02BA', 'A01AC', 'D10AA', 'S03AA', 'D07XB', 'R02AB', 'R01AD', 'J01GB', 'S01AA', 'S02AA', 'A01AB', 'D06AX', 'D07AB']\n",
      "\n",
      "  MD_2022_3_MCOU_24208079535: 22 classes\n",
      "    NDC: 24208079535, State: MD, Year: 2022\n",
      "    Classes: ['D06AX', 'D07AB', 'S02AA', 'A01AB', 'S01BA', 'C05AA', 'S03BA', 'S01CB', 'B05CA', 'J01XB', 'A07AA', 'S02BA', 'S01CA', 'H02AB', 'A01AC', 'D10AA', 'D07XB', 'J01GB', 'S03AA', 'S01AA', 'R02AB', 'R01AD']\n",
      "\n",
      "  MD_2022_3_MCOU_24208083060: 22 classes\n",
      "    NDC: 24208083060, State: MD, Year: 2022\n",
      "    Classes: ['S01AA', 'R02AB', 'R01AD', 'J01GB', 'D07AB', 'S02AA', 'A01AB', 'D06AX', 'S01BA', 'S03BA', 'S01CB', 'B05CA', 'C05AA', 'J01XB', 'A07AA', 'S02BA', 'S01CA', 'H02AB', 'D10AA', 'D07XB', 'A01AC', 'S03AA']\n",
      "\n",
      "  NV_2022_4_MCOU_61314063136: 22 classes\n",
      "    NDC: 61314063136, State: NV, Year: 2022\n",
      "    Classes: ['S01BA', 'C05AA', 'S03BA', 'S01CB', 'B05CA', 'J01XB', 'A07AA', 'S02BA', 'S01CA', 'H02AB', 'A01AC', 'D10AA', 'D07XB', 'J01GB', 'S03AA', 'S01AA', 'R02AB', 'R01AD', 'D06AX', 'D07AB', 'S02AA', 'A01AB']\n",
      "\n",
      "  MT_2022_4_FFSU_61314063006: 22 classes\n",
      "    NDC: 61314063006, State: MT, Year: 2022\n",
      "    Classes: ['S01AA', 'S02AA', 'A01AB', 'D06AX', 'D07AB', 'S03BA', 'S01CB', 'S01BA', 'B05CA', 'C05AA', 'A07AA', 'S01CA', 'H02AB', 'J01XB', 'S02BA', 'A01AC', 'D10AA', 'S03AA', 'D07XB', 'R02AB', 'R01AD', 'J01GB']\n",
      "\n",
      "\n",
      "============================================================\n",
      "ATC3 CLASSES PER RECORD_ID DISTRIBUTION\n",
      "============================================================\n",
      "Distribution of ATC3 classes per record_id:\n",
      "  1 class(es): 1,662,582 record_ids (70.7%)\n",
      "  2 class(es): 273,904 record_ids (11.6%)\n",
      "  3 class(es): 213,198 record_ids (9.1%)\n",
      "  4 class(es): 67,237 record_ids (2.9%)\n",
      "  5 class(es): 44,206 record_ids (1.9%)\n",
      "  6 class(es): 10,395 record_ids (0.4%)\n",
      "  7 class(es): 15,992 record_ids (0.7%)\n",
      "  8 class(es): 16,688 record_ids (0.7%)\n",
      "  9 class(es): 15,089 record_ids (0.6%)\n",
      "  10 class(es): 1,198 record_ids (0.1%)\n",
      "  11 class(es): 21,783 record_ids (0.9%)\n",
      "  12 class(es): 2,174 record_ids (0.1%)\n",
      "  13 class(es): 2,278 record_ids (0.1%)\n",
      "  14 class(es): 2,594 record_ids (0.1%)\n",
      "  15 class(es): 498 record_ids (0.0%)\n",
      "  16 class(es): 774 record_ids (0.0%)\n",
      "  18 class(es): 184 record_ids (0.0%)\n",
      "  19 class(es): 1,343 record_ids (0.1%)\n",
      "  20 class(es): 1,064 record_ids (0.0%)\n",
      "\n",
      "Top 10 record_ids with most ATC3 classes:\n",
      "  ND_2022_1_FFSU_61314063136: 20 classes\n",
      "    NDC: 61314063136, State: ND, Year: 2022\n",
      "    Classes: ['S01A', 'A01A', 'R02A', 'R01A', 'D06A', 'D07A', 'S02A', 'S03B', 'S01C', 'S01B', 'B05C', 'C05A', 'A07A', 'J01X', 'S02B', 'H02A', 'D10A', 'S03A', 'D07X', 'J01G']\n",
      "\n",
      "  CT_2022_2_FFSU_24208083060: 20 classes\n",
      "    NDC: 24208083060, State: CT, Year: 2022\n",
      "    Classes: ['R02A', 'R01A', 'J01G', 'S01A', 'D07A', 'S02A', 'A01A', 'D06A', 'S03B', 'S01C', 'S01B', 'B05C', 'C05A', 'A07A', 'H02A', 'J01X', 'S02B', 'D07X', 'D10A', 'S03A']\n",
      "\n",
      "  CT_2022_2_FFSU_24208079535: 20 classes\n",
      "    NDC: 24208079535, State: CT, Year: 2022\n",
      "    Classes: ['A07A', 'S02B', 'S01C', 'H02A', 'D10A', 'D07X', 'A01A', 'J01G', 'S03A', 'S01A', 'R02A', 'R01A', 'D06A', 'D07A', 'S02A', 'S01B', 'C05A', 'S03B', 'B05C', 'J01X']\n",
      "\n",
      "  NJ_2022_4_MCOU_61314063136: 20 classes\n",
      "    NDC: 61314063136, State: NJ, Year: 2022\n",
      "    Classes: ['S01C', 'H02A', 'J01X', 'D10A', 'S02B', 'D07X', 'A01A', 'S03A', 'S01A', 'R02A', 'R01A', 'J01G', 'D07A', 'S02A', 'D06A', 'S03B', 'S01B', 'B05C', 'C05A', 'A07A']\n",
      "\n",
      "  NJ_2022_4_MCOU_61314063006: 20 classes\n",
      "    NDC: 61314063006, State: NJ, Year: 2022\n",
      "    Classes: ['J01G', 'S01A', 'A01A', 'R02A', 'R01A', 'D06A', 'D07A', 'S02A', 'S03B', 'S01C', 'S01B', 'B05C', 'C05A', 'A07A', 'J01X', 'S02B', 'H02A', 'D10A', 'S03A', 'D07X']\n",
      "\n",
      "  OR_2022_2_MCOU_61314063006: 20 classes\n",
      "    NDC: 61314063006, State: OR, Year: 2022\n",
      "    Classes: ['S03B', 'S01C', 'S01B', 'B05C', 'C05A', 'A07A', 'H02A', 'J01X', 'S02B', 'A01A', 'D10A', 'S03A', 'D07X', 'R01A', 'J01G', 'S01A', 'S02A', 'R02A', 'D06A', 'D07A']\n",
      "\n",
      "  LA_2022_2_MCOU_61314063136: 20 classes\n",
      "    NDC: 61314063136, State: LA, Year: 2022\n",
      "    Classes: ['H02A', 'A01A', 'D10A', 'S03A', 'D07X', 'J01G', 'S01A', 'R02A', 'R01A', 'D06A', 'D07A', 'S02A', 'S03B', 'S01C', 'S01B', 'B05C', 'C05A', 'A07A', 'J01X', 'S02B']\n",
      "\n",
      "  LA_2022_2_MCOU_61314063006: 20 classes\n",
      "    NDC: 61314063006, State: LA, Year: 2022\n",
      "    Classes: ['D10A', 'D07X', 'J01G', 'S03A', 'S01A', 'R02A', 'R01A', 'D06A', 'D07A', 'S02A', 'A01A', 'S01B', 'C05A', 'S03B', 'S01C', 'B05C', 'J01X', 'A07A', 'S02B', 'H02A']\n",
      "\n",
      "  CA_2022_4_FFSU_61314063006: 20 classes\n",
      "    NDC: 61314063006, State: CA, Year: 2022\n",
      "    Classes: ['C05A', 'A07A', 'S01C', 'J01X', 'S02B', 'H02A', 'A01A', 'D10A', 'S03A', 'D07X', 'J01G', 'S01A', 'R02A', 'R01A', 'D06A', 'D07A', 'S02A', 'S03B', 'S01B', 'B05C']\n",
      "\n",
      "  LA_2022_3_FFSU_24208083060: 20 classes\n",
      "    NDC: 24208083060, State: LA, Year: 2022\n",
      "    Classes: ['S02B', 'A01A', 'D10A', 'S03A', 'D07X', 'R02A', 'R01A', 'J01G', 'S01A', 'D07A', 'S02A', 'D06A', 'S03B', 'S01C', 'S01B', 'B05C', 'C05A', 'A07A', 'H02A', 'J01X']\n",
      "\n",
      "\n",
      "ATC3 Summary:\n",
      "  Total record_ids with ATC3 mapping: 2,353,181\n",
      "  Average ATC3 classes per record_id: 1.78\n",
      "  Max ATC3 classes for single record_id: 20\n",
      "\n",
      "============================================================\n",
      "ATC2 CLASSES PER RECORD_ID DISTRIBUTION\n",
      "============================================================\n",
      "Distribution of ATC2 classes per record_id:\n",
      "  1 class(es): 1,705,000 record_ids (72.5%)\n",
      "  2 class(es): 336,470 record_ids (14.3%)\n",
      "  3 class(es): 151,546 record_ids (6.4%)\n",
      "  4 class(es): 43,052 record_ids (1.8%)\n",
      "  5 class(es): 33,269 record_ids (1.4%)\n",
      "  6 class(es): 6,403 record_ids (0.3%)\n",
      "  7 class(es): 37,804 record_ids (1.6%)\n",
      "  8 class(es): 6,112 record_ids (0.3%)\n",
      "  9 class(es): 23,196 record_ids (1.0%)\n",
      "  10 class(es): 4,504 record_ids (0.2%)\n",
      "  11 class(es): 981 record_ids (0.0%)\n",
      "  12 class(es): 3,730 record_ids (0.2%)\n",
      "  14 class(es): 1,114 record_ids (0.0%)\n",
      "\n",
      "Top 10 record_ids with most ATC2 classes:\n",
      "  IN_2022_2_FFSU_24208083060: 14 classes\n",
      "    NDC: 24208083060, State: IN, Year: 2022\n",
      "    Classes: ['D06', 'D07', 'S02', 'S03', 'S01', 'B05', 'C05', 'A07', 'J01', 'H02', 'A01', 'D10', 'R02', 'R01']\n",
      "\n",
      "  MN_2022_4_FFSU_24208079535: 14 classes\n",
      "    NDC: 24208079535, State: MN, Year: 2022\n",
      "    Classes: ['R02', 'R01', 'J01', 'S01', 'S02', 'A01', 'D06', 'D07', 'S03', 'B05', 'C05', 'A07', 'H02', 'D10']\n",
      "\n",
      "  MN_2022_4_FFSU_24208083060: 14 classes\n",
      "    NDC: 24208083060, State: MN, Year: 2022\n",
      "    Classes: ['S01', 'C05', 'S03', 'B05', 'J01', 'A07', 'S02', 'H02', 'D10', 'D07', 'A01', 'R02', 'R01', 'D06']\n",
      "\n",
      "  KY_2022_3_FFSU_61314063136: 14 classes\n",
      "    NDC: 61314063136, State: KY, Year: 2022\n",
      "    Classes: ['J01', 'S01', 'A01', 'R02', 'R01', 'D06', 'D07', 'S02', 'S03', 'B05', 'C05', 'A07', 'H02', 'D10']\n",
      "\n",
      "  NV_2022_1_FFSU_24208079535: 14 classes\n",
      "    NDC: 24208079535, State: NV, Year: 2022\n",
      "    Classes: ['S01', 'R02', 'R01', 'J01', 'D07', 'S02', 'A01', 'D06', 'S03', 'B05', 'C05', 'A07', 'H02', 'D10']\n",
      "\n",
      "  NE_2022_2_MCOU_24208079535: 14 classes\n",
      "    NDC: 24208079535, State: NE, Year: 2022\n",
      "    Classes: ['D06', 'D07', 'S03', 'S01', 'B05', 'C05', 'A07', 'J01', 'S02', 'H02', 'A01', 'D10', 'R02', 'R01']\n",
      "\n",
      "  NE_2022_2_MCOU_24208083060: 14 classes\n",
      "    NDC: 24208083060, State: NE, Year: 2022\n",
      "    Classes: ['R02', 'R01', 'J01', 'D07', 'S02', 'A01', 'D06', 'S03', 'S01', 'B05', 'C05', 'A07', 'H02', 'D10']\n",
      "\n",
      "  OR_2022_3_MCOU_61314063006: 14 classes\n",
      "    NDC: 61314063006, State: OR, Year: 2022\n",
      "    Classes: ['B05', 'C05', 'A07', 'S01', 'H02', 'J01', 'S02', 'D07', 'A01', 'D10', 'S03', 'R02', 'R01', 'D06']\n",
      "\n",
      "  OR_2022_3_MCOU_61314063136: 14 classes\n",
      "    NDC: 61314063136, State: OR, Year: 2022\n",
      "    Classes: ['S03', 'S01', 'B05', 'C05', 'A07', 'H02', 'J01', 'S02', 'A01', 'D10', 'D07', 'R01', 'R02', 'D06']\n",
      "\n",
      "  MI_2022_4_FFSU_61314063006: 14 classes\n",
      "    NDC: 61314063006, State: MI, Year: 2022\n",
      "    Classes: ['S01', 'R02', 'R01', 'J01', 'D07', 'S02', 'A01', 'D06', 'S03', 'B05', 'C05', 'A07', 'H02', 'D10']\n",
      "\n",
      "\n",
      "ATC2 Summary:\n",
      "  Total record_ids with ATC2 mapping: 2,353,181\n",
      "  Average ATC2 classes per record_id: 1.64\n",
      "  Max ATC2 classes for single record_id: 14\n",
      "RECORDS WITH DIFFERENT ATC2 CLASSES\n",
      "========================================\n",
      "Found 648181 records with different ATC2 classes\n",
      "\n",
      "1. AK_2022_1_FFSU_00003029305 | NDC: 00003029305\n",
      "   ATC2: R01\n",
      "   ATC2: D07\n",
      "   ATC2: S01\n",
      "   ATC2: C05\n",
      "   ATC2: R03\n",
      "   ATC2: H02\n",
      "   ATC2: A01\n",
      "\n",
      "2. AK_2022_1_FFSU_00003029328 | NDC: 00003029328\n",
      "   ATC2: C05\n",
      "   ATC2: R03\n",
      "   ATC2: H02\n",
      "   ATC2: D07\n",
      "   ATC2: A01\n",
      "   ATC2: R01\n",
      "   ATC2: S01\n",
      "\n",
      "3. AK_2022_1_FFSU_00003049420 | NDC: 00003049420\n",
      "   ATC2: R01\n",
      "   ATC2: D07\n",
      "   ATC2: S01\n",
      "   ATC2: C05\n",
      "   ATC2: R03\n",
      "   ATC2: H02\n",
      "   ATC2: A01\n",
      "\n",
      "Summary: {2: 336470, 3: 151546, 4: 43052, 7: 37804, 5: 33269, 9: 23196, 6: 6403, 8: 6112, 10: 4504, 12: 3730, 14: 1114, 11: 981}\n"
     ]
    }
   ],
   "source": [
    "# Distribution analyses\n",
    "atc4_dist = analyzer.analyze_atc4_distribution()\n",
    "atc3_dist = analyzer.analyze_atc3_distribution() \n",
    "atc2_dist = analyzer.analyze_atc2_distribution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "524d0ef0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "FETCHING ATC CLASS NAMES\n",
      "============================================================\n",
      "Using cache: c:\\Users\\lholguin\\OneDrive - purdue.edu\\VS code\\Data\\ATC\\cache_files\\atc_names_cache\n",
      "\n",
      "Creating ATC3 and ATC2 columns from ATC4...\n",
      "\n",
      "Unique codes to fetch:\n",
      "  ATC4: 606\n",
      "  ATC3: 209\n",
      "  ATC2: 89\n",
      "\n",
      "Fetching ATC4 names...\n",
      "Fetching ATC3 names...\n",
      "Fetching ATC2 names...\n",
      "\n",
      "Total processing time: 0.0 minutes\n",
      "\n",
      "Applying names to dataframe...\n",
      "\n",
      "ATC names added successfully!\n",
      "\n",
      "Sample output:\n",
      "           NDC                   record_id ATC4 Class                                           ATC4_Name ATC3 Class                                     ATC3_Name ATC2 Class               ATC2_Name\n",
      "0  00002143380  AK_2022_4_FFSU_00002143380      A10BJ           Glucagon-like peptide-1 (GLP-1) analogues       A10B  BLOOD GLUCOSE LOWERING DRUGS, EXCL. INSULINS        A10  DRUGS USED IN DIABETES\n",
      "1  00002143480  AK_2022_4_FFSU_00002143480      A10BJ           Glucagon-like peptide-1 (GLP-1) analogues       A10B  BLOOD GLUCOSE LOWERING DRUGS, EXCL. INSULINS        A10  DRUGS USED IN DIABETES\n",
      "2  00002143611  AK_2022_4_FFSU_00002143611      N02CD  Calcitonin gene-related peptide (CGRP) antagonists       N02C                     ANTIMIGRAINE PREPARATIONS        N02              ANALGESICS\n",
      "3  00002144511  AK_2022_4_FFSU_00002144511      L04AC                              Interleukin inhibitors       L04A                            IMMUNOSUPPRESSANTS        L04      IMMUNOSUPPRESSANTS\n",
      "4  00002147180  AK_2022_4_FFSU_00002147180      A10BX  Other blood glucose lowering drugs, excl. insulins       A10B  BLOOD GLUCOSE LOWERING DRUGS, EXCL. INSULINS        A10  DRUGS USED IN DIABETES\n",
      "\n",
      "============================================================\n",
      "PREPARING FINAL DATAFRAME\n",
      "============================================================\n",
      "\n",
      "Scaling units...\n",
      "\n",
      "Final statistics:\n",
      "Total records: 4,421,713\n",
      "Records with ATC4 mapping: 4,385,476 (99.2%)\n",
      "Total Units Reimbursed: 104.36 Billion\n",
      "Total Prescriptions: 1483.73 Million\n",
      "RECORDS WITH DIFFERENT ATC2 CLASSES\n",
      "========================================\n",
      "Found 648181 records with different ATC2 classes\n",
      "\n",
      "1. AK_2022_1_FFSU_00003029305 | NDC: 00003029305\n",
      "   ATC2: R01 - NASAL PREPARATIONS...\n",
      "   ATC2: D07 - CORTICOSTEROIDS, DERMATOLOGICAL PREPARAT...\n",
      "   ATC2: S01 - OPHTHALMOLOGICALS...\n",
      "   ATC2: C05 - VASOPROTECTIVES...\n",
      "   ATC2: R03 - DRUGS FOR OBSTRUCTIVE AIRWAY DISEASES...\n",
      "   ATC2: H02 - CORTICOSTEROIDS FOR SYSTEMIC USE...\n",
      "   ATC2: A01 - STOMATOLOGICAL PREPARATIONS...\n",
      "\n",
      "2. AK_2022_1_FFSU_00003029328 | NDC: 00003029328\n",
      "   ATC2: C05 - VASOPROTECTIVES...\n",
      "   ATC2: R03 - DRUGS FOR OBSTRUCTIVE AIRWAY DISEASES...\n",
      "   ATC2: H02 - CORTICOSTEROIDS FOR SYSTEMIC USE...\n",
      "   ATC2: D07 - CORTICOSTEROIDS, DERMATOLOGICAL PREPARAT...\n",
      "   ATC2: A01 - STOMATOLOGICAL PREPARATIONS...\n",
      "   ATC2: R01 - NASAL PREPARATIONS...\n",
      "   ATC2: S01 - OPHTHALMOLOGICALS...\n",
      "\n",
      "3. AK_2022_1_FFSU_00003049420 | NDC: 00003049420\n",
      "   ATC2: R01 - NASAL PREPARATIONS...\n",
      "   ATC2: D07 - CORTICOSTEROIDS, DERMATOLOGICAL PREPARAT...\n",
      "   ATC2: S01 - OPHTHALMOLOGICALS...\n",
      "   ATC2: C05 - VASOPROTECTIVES...\n",
      "   ATC2: R03 - DRUGS FOR OBSTRUCTIVE AIRWAY DISEASES...\n",
      "   ATC2: H02 - CORTICOSTEROIDS FOR SYSTEMIC USE...\n",
      "   ATC2: A01 - STOMATOLOGICAL PREPARATIONS...\n",
      "\n",
      "Summary: {2: 336470, 3: 151546, 4: 43052, 7: 37804, 5: 33269, 9: 23196, 6: 6403, 8: 6112, 10: 4504, 12: 3730, 14: 1114, 11: 981}\n",
      "\n",
      "============================================================\n",
      "CHECKING FOR DUPLICATE RECORD_IDs\n",
      "============================================================\n",
      "Total rows before deduplication: 4,421,713\n",
      "Duplicate record_ids found: 2,032,295\n",
      "Unique record_ids: 2,389,418\n",
      "\n",
      "Sample duplicate record_ids BEFORE deduplication (first 10 rows):\n",
      "                        record_id          NDC State ATC4 Class\n",
      "25412  AK_2022_1_FFSU_00002751001  00002751001    AK      A10AC\n",
      "25413  AK_2022_1_FFSU_00002751001  00002751001    AK      A10AB\n",
      "25414  AK_2022_1_FFSU_00002751001  00002751001    AK      A10AD\n",
      "25415  AK_2022_1_FFSU_00002751659  00002751659    AK      A10AD\n",
      "25416  AK_2022_1_FFSU_00002751659  00002751659    AK      A10AC\n",
      "25417  AK_2022_1_FFSU_00002751659  00002751659    AK      A10AB\n",
      "25420  AK_2022_1_FFSU_00002771227  00002771227    AK      A10AD\n",
      "25421  AK_2022_1_FFSU_00002771227  00002771227    AK      A10AC\n",
      "25422  AK_2022_1_FFSU_00002771227  00002771227    AK      A10AB\n",
      "25423  AK_2022_1_FFSU_00002771459  00002771459    AK      A10AC\n",
      "\n",
      "============================================================\n",
      "DETAILED VIEW: Two record_ids BEFORE deduplication\n",
      "============================================================\n",
      "\n",
      "record_id: AK_2022_1_FFSU_00002751001\n",
      "                 record_id         NDC State  Year  Quarter ATC4 Class ATC3 Class ATC2 Class  Units Reimbursed  Number of Prescriptions\n",
      "AK_2022_1_FFSU_00002751001 00002751001    AK  2022        1      A10AC       A10A        A10          0.000001                 0.000041\n",
      "AK_2022_1_FFSU_00002751001 00002751001    AK  2022        1      A10AB       A10A        A10          0.000001                 0.000041\n",
      "AK_2022_1_FFSU_00002751001 00002751001    AK  2022        1      A10AD       A10A        A10          0.000001                 0.000041\n",
      "\n",
      "record_id: AK_2022_1_FFSU_00002751659\n",
      "                 record_id         NDC State  Year  Quarter ATC4 Class ATC3 Class ATC2 Class  Units Reimbursed  Number of Prescriptions\n",
      "AK_2022_1_FFSU_00002751659 00002751659    AK  2022        1      A10AD       A10A        A10      5.910000e-07                 0.000029\n",
      "AK_2022_1_FFSU_00002751659 00002751659    AK  2022        1      A10AC       A10A        A10      5.910000e-07                 0.000029\n",
      "AK_2022_1_FFSU_00002751659 00002751659    AK  2022        1      A10AB       A10A        A10      5.910000e-07                 0.000029\n",
      "\n",
      "Total rows after deduplication: 2,389,418\n",
      "Rows removed: 2,032,295\n",
      "\n",
      "Sample of deduplicated data (first 10 rows):\n",
      "                    record_id          NDC State ATC4 Class\n",
      "0  AK_2022_4_FFSU_00002143380  00002143380    AK      A10BJ\n",
      "1  AK_2022_4_FFSU_00002143480  00002143480    AK      A10BJ\n",
      "2  AK_2022_4_FFSU_00002143611  00002143611    AK      N02CD\n",
      "3  AK_2022_4_FFSU_00002144511  00002144511    AK      L04AC\n",
      "4  AK_2022_4_FFSU_00002147180  00002147180    AK      A10BX\n",
      "5  AK_2022_4_FFSU_00002149580  00002149580    AK      A10BX\n",
      "6  AK_2022_4_FFSU_00002150680  00002150680    AK      A10BX\n",
      "7  AK_2022_4_FFSU_00002223680  00002223680    AK      A10BJ\n",
      "8  AK_2022_4_FFSU_00002318280  00002318280    AK      A10BJ\n",
      "9  AK_2022_4_FFSU_00002533754  00002533754    AK      L01EF\n",
      "\n",
      "============================================================\n",
      "DETAILED VIEW: Same two record_ids AFTER deduplication\n",
      "============================================================\n",
      "\n",
      "record_id: AK_2022_1_FFSU_00002751001\n",
      "                 record_id         NDC State  Year  Quarter ATC4 Class ATC3 Class ATC2 Class  Units Reimbursed  Number of Prescriptions\n",
      "AK_2022_1_FFSU_00002751001 00002751001    AK  2022        1      A10AC       A10A        A10          0.000001                 0.000041\n",
      "\n",
      "record_id: AK_2022_1_FFSU_00002751659\n",
      "                 record_id         NDC State  Year  Quarter ATC4 Class ATC3 Class ATC2 Class  Units Reimbursed  Number of Prescriptions\n",
      "AK_2022_1_FFSU_00002751659 00002751659    AK  2022        1      A10AD       A10A        A10      5.910000e-07                 0.000029\n",
      "\n",
      "============================================================\n",
      "DATA EXPORT COMPLETE\n",
      "============================================================\n",
      "Exported to: c:\\Users\\lholguin\\OneDrive - purdue.edu\\VS code\\Data\\ATC\\merged_data\\merged_NEWdata_2022.csv\n",
      "Total rows exported: 2,389,418\n",
      "Columns: Utilization Type, State, NDC, Labeler Code, Product Code, Package Size, Year, Quarter, Suppression Used, Product Name, Units Reimbursed, Number of Prescriptions, Total Amount Reimbursed, Medicaid Amount Reimbursed, Non Medicaid Amount Reimbursed, record_id, ATC4 Class, ATC3 Class, ATC2 Class, ATC4_Name, ATC3_Name, ATC2_Name\n",
      "\n",
      "============================================================\n",
      "COMPARISON WITH analyze_atc4_mapping()\n",
      "============================================================\n",
      "Rows in atc_mapping (from analyze_atc4_mapping): 4,421,713\n",
      "Rows in df_merged (before deduplication): 4,421,713\n",
      "Rows in exported file (after deduplication): 2,389,418\n",
      "Difference from atc_mapping: -2,032,295\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\lholguin\\\\OneDrive - purdue.edu\\\\VS code\\\\Data\\\\ATC\\\\merged_data\\\\merged_NEWdata_2022.csv'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analyzer.fetch_atc_names()           # Fetch ATC4, ATC3, ATC2 names\n",
    "analyzer.prepare_final_dataframe()   # Scale units and finalize\n",
    "#Just to see something\n",
    "different_atc2_records = analyzer.analyze_different_atc2_records()\n",
    "analyzer.export_merged_data()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8a9cdb6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           NDC                   record_id ATC4 Class\n",
      "0  63323010601  WV_2023_1_MCOU_63323010601      A06AD\n",
      "1  65862016901  NC_2023_2_MCOU_65862016901      C07AB\n",
      "2  51672206902  MN_2023_1_MCOU_51672206902      S02BA\n",
      "3  65162083594  CT_2023_3_FFSU_65162083594      J05AB\n",
      "4  16714098502  IA_2023_4_MCOU_16714098502      D07AB\n",
      "5    409653311  VA_2023_1_MCOU_00409653311      A07AA\n",
      "6  65162008203  NV_2023_3_MCOU_65162008203      N05AE\n",
      "7  59651003212  MA_2023_3_FFSU_59651003212      M02AA\n",
      "8  67877025130  NY_2023_3_FFSU_67877025130      D07AB\n",
      "9  42858011830  SD_2023_3_FFSU_42858011830      C01BB\n",
      "Index(['NDC', 'record_id', 'ATC4 Class'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "#Looking at the new key identifier\n",
    "path=r\"C:\\Users\\lholguin\\OneDrive - purdue.edu\\VS code\\Data\\ATC\\ATC4_classes\\NDCNEW_2023_ATC4_classes.csv\"\n",
    "df_atcnew=pd.read_csv(path)\n",
    "print(df_atcnew.head(10))\n",
    "print(df_atcnew.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "check_totals",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_atc_distributions_across_years(self, years_list):\n",
    "    \"\"\"Compare ATC distribution metrics across multiple years.\"\"\"\n",
    "    \n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(\"ATC DISTRIBUTION COMPARISON ACROSS YEARS\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    results_summary = {}\n",
    "    \n",
    "    for year in years_list:\n",
    "        print(f\"\\nProcessing year {year}...\")\n",
    "        \n",
    "        try:\n",
    "            # Create analyzer for this year\n",
    "            year_analyzer = NDCATCAnalyzer(year=year)\n",
    "            year_analyzer.clean_sdud_data()\n",
    "            year_analyzer.adding_key()\n",
    "            year_analyzer.analyze_atc4_mapping()\n",
    "            \n",
    "            # Get distribution data\n",
    "            atc4_dist = year_analyzer.analyze_atc4_distribution()\n",
    "            atc3_dist = year_analyzer.analyze_atc3_distribution() \n",
    "            atc2_dist = year_analyzer.analyze_atc2_distribution()\n",
    "            \n",
    "            # Extract key metrics\n",
    "            results_summary[year] = {\n",
    "                'total_records': len(year_analyzer.atc_mapping[year_analyzer.atc_mapping['ATC4 Class'].notna()]),\n",
    "                'unique_record_ids': len(atc4_dist) if atc4_dist is not None else 0,\n",
    "                'atc4_avg': atc4_dist['num_atc4_classes'].mean() if atc4_dist is not None else 0,\n",
    "                'atc4_max': atc4_dist['num_atc4_classes'].max() if atc4_dist is not None else 0,\n",
    "                'atc3_avg': atc3_dist['num_atc3_classes'].mean() if atc3_dist is not None else 0,\n",
    "                'atc3_max': atc3_dist['num_atc3_classes'].max() if atc3_dist is not None else 0,\n",
    "                'atc2_avg': atc2_dist['num_atc2_classes'].mean() if atc2_dist is not None else 0,\n",
    "                'atc2_max': atc2_dist['num_atc2_classes'].max() if atc2_dist is not None else 0,\n",
    "            }\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing year {year}: {e}\")\n",
    "            results_summary[year] = None\n",
    "    \n",
    "    # Display comparison table\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(\"SUMMARY COMPARISON TABLE\")\n",
    "    print(f\"{'='*80}\")\n",
    "    \n",
    "    import pandas as pd\n",
    "    comparison_df = pd.DataFrame(results_summary).T\n",
    "    comparison_df = comparison_df.dropna()\n",
    "    \n",
    "    print(\"\\nKey Metrics Across Years:\")\n",
    "    print(comparison_df.round(2))\n",
    "    \n",
    "    # Show trends\n",
    "    if len(comparison_df) > 1:\n",
    "        print(f\"\\nTrends:\")\n",
    "        print(f\"Total Records: {comparison_df['total_records'].iloc[0]:,.0f} → {comparison_df['total_records'].iloc[-1]:,.0f}\")\n",
    "        print(f\"Avg ATC4/record: {comparison_df['atc4_avg'].iloc[0]:.2f} → {comparison_df['atc4_avg'].iloc[-1]:.2f}\")\n",
    "        print(f\"Avg ATC3/record: {comparison_df['atc3_avg'].iloc[0]:.2f} → {comparison_df['atc3_avg'].iloc[-1]:.2f}\")\n",
    "        print(f\"Avg ATC2/record: {comparison_df['atc2_avg'].iloc[0]:.2f} → {comparison_df['atc2_avg'].iloc[-1]:.2f}\")\n",
    "    \n",
    "    return comparison_df\n",
    "\n",
    "def quick_atc_metrics_only(self, years_list):\n",
    "    \"\"\"Get only the ATC distribution metrics for multiple years (faster version).\"\"\"\n",
    "    \n",
    "    print(\"ATC DISTRIBUTION METRICS ACROSS YEARS\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    metrics = {}\n",
    "    \n",
    "    for year in years_list:\n",
    "        print(f\"Year {year}:\", end=\" \")\n",
    "        \n",
    "        try:\n",
    "            # Quick setup\n",
    "            analyzer = NDCATCAnalyzer(year=year)\n",
    "            analyzer.clean_sdud_data()\n",
    "            analyzer.adding_key()\n",
    "            analyzer.analyze_atc4_mapping()\n",
    "            \n",
    "            # Get only the metrics we need\n",
    "            records = analyzer.atc_mapping[analyzer.atc_mapping['ATC4 Class'].notna()].copy()\n",
    "            records['ATC2 Class'] = records['ATC4 Class'].str[:3]\n",
    "            records['ATC3 Class'] = records['ATC4 Class'].str[:4]\n",
    "            \n",
    "            # Quick calculations\n",
    "            atc4_per_record = records.groupby('record_id')['ATC4 Class'].nunique()\n",
    "            atc3_per_record = records.groupby('record_id')['ATC3 Class'].nunique()\n",
    "            atc2_per_record = records.groupby('record_id')['ATC2 Class'].nunique()\n",
    "            \n",
    "            metrics[year] = {\n",
    "                'Records': len(records),\n",
    "                'Unique_IDs': len(atc4_per_record),\n",
    "                'ATC4_Avg': atc4_per_record.mean(),\n",
    "                'ATC4_Max': atc4_per_record.max(),\n",
    "                'ATC3_Avg': atc3_per_record.mean(),\n",
    "                'ATC3_Max': atc3_per_record.max(),\n",
    "                'ATC2_Avg': atc2_per_record.mean(),\n",
    "                'ATC2_Max': atc2_per_record.max(),\n",
    "            }\n",
    "            \n",
    "            print(\"✓\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"✗ ({e})\")\n",
    "            metrics[year] = None\n",
    "    \n",
    "    # Display results\n",
    "    print(f\"\\nRESULTS:\")\n",
    "    import pandas as pd\n",
    "    results_df = pd.DataFrame(metrics).T.dropna()\n",
    "    print(results_df.round(2))\n",
    "    \n",
    "    return results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20d701d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Option 1: Full analysis for each year (slower but complete)\n",
    "years_to_analyze = [2021, 2020, 2021, 2022]\n",
    "comparison_results = analyzer.compare_atc_distributions_across_years(years_to_analyze)\n",
    "\n",
    "# Option 2: Quick metrics only (faster)\n",
    "quick_results = analyzer.quick_atc_metrics_only([2019, 2020, 2021, 2022])\n",
    "\n",
    "# Option 3: Just call one year at a time and collect metrics manually\n",
    "years_metrics = {}\n",
    "for year in [2019, 2020, 2021]:\n",
    "    analyzer = NDCATCAnalyzer(year=year)\n",
    "    analyzer.clean_sdud_data()\n",
    "    analyzer.adding_key()\n",
    "    analyzer.analyze_atc4_mapping()\n",
    "    \n",
    "    # Get just the distribution summaries\n",
    "    atc4_dist = analyzer.analyze_atc4_distribution()\n",
    "    atc3_dist = analyzer.analyze_atc3_distribution() \n",
    "    atc2_dist = analyzer.analyze_atc2_distribution()\n",
    "    \n",
    "    years_metrics[year] = {\n",
    "        'atc4_avg': atc4_dist['num_atc4_classes'].mean(),\n",
    "        'atc3_avg': atc3_dist['num_atc3_classes'].mean(),\n",
    "        'atc2_avg': atc2_dist['num_atc2_classes'].mean()\n",
    "    }\n",
    "\n",
    "print(years_metrics)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
