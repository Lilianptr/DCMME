{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "header-cell",
   "metadata": {},
   "source": [
    "# StatsForecast Pipeline - Enhanced with Best Model Selection & Plotting\n",
    "\n",
    "This notebook includes two new functions:\n",
    "1. **`select_best_model_per_series()`** - Selects the best model per unique_id based on horizon=8 cross-validation, with consistency metrics and exports low/point/high forecasts to CSV\n",
    "2. **`plot_forecast_with_intervals()`** - Plots historical data + point forecast + confidence intervals for any unique_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14de25d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "import seaborn as sns\n",
    "import warnings \n",
    "from utilsforecast.plotting import plot_series\n",
    "from utilsforecast.evaluation import evaluate\n",
    "from utilsforecast.losses import *\n",
    "from statsforecast import StatsForecast\n",
    "from statsforecast.models import (Naive,WindowAverage, ARIMA, AutoARIMA,SeasonalNaive,HoltWinters, CrostonClassic as Croston, HistoricAverage,DynamicOptimizedTheta as DOT,SeasonalNaive)\n",
    "from dataclasses import dataclass\n",
    "from typing import Optional, List, Dict, Tuple, Union\n",
    "from itertools import product\n",
    "\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")  # To ignore warnings from pandas/numpy\n",
    "\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "plt.rcParams['font.size'] = 10\n",
    "\n",
    "# Color palette for up to 4 models\n",
    "MODEL_COLORS = {\n",
    "    0: '#E94F37',  # Red\n",
    "    1: '#2E86AB',  # Blue\n",
    "    2: '#28A745',  # Green\n",
    "    3: '#9B59B6',  # Purple\n",
    "}\n",
    "HISTORICAL_COLOR = \"#898992\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d75a6c67",
   "metadata": {},
   "outputs": [],
   "source": [
    "user=\"lholguin\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1baf5dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class ForecastConfig:\n",
    "    \n",
    "    # Forecast parameters\n",
    "    h: int = 8                          \n",
    "    season_length: int = 4              \n",
    "    \n",
    "    # Cross-validation parameters\n",
    "    n_windows: int = 2                  \n",
    "    step_size: Optional[int] = None     \n",
    "    \n",
    "    # Train-test split parameters\n",
    "    train_size: Optional[int] = None    # Use all available data except test\n",
    "    test_size: Optional[int] = None     # Auto-set to h in __post_init__\n",
    "    \n",
    "    # Plotting parameters\n",
    "    n_samples: int = 4                  # Plot 4 random samples\n",
    "    models_to_plot: Optional[List[str]] = None  # \n",
    "    \n",
    "    # Other settings\n",
    "    confidence_level: int = 95          # 95% confidence intervals\n",
    "    n_jobs: int = -1                    \n",
    "    \n",
    "    def __post_init__(self):\n",
    "        \n",
    "        if self.step_size is None:\n",
    "            self.step_size = self.h\n",
    "        if self.test_size is None:\n",
    "            self.test_size = self.h\n",
    "        if self.models_to_plot is None:\n",
    "            self.models_to_plot = ['Naive', 'ARIMA_manual', 'SARIMA']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93281f08",
   "metadata": {},
   "source": [
    "### Data Loading Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74eb21a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data_exog(filepath, states=None):\n",
    "\n",
    "    df = pd.read_csv(filepath)\n",
    "    df['ds'] = pd.to_datetime(df['Period'], errors='coerce')\n",
    "    \n",
    "    df = df[(df['ds'] >= '2017-01-01') & (df['ds'] <= '2024-10-01')].copy()\n",
    "    \n",
    "    if states is not None:\n",
    "        if isinstance(states, str):\n",
    "            states = [states]\n",
    "        print(f\"Filtering data for states: {states}\")\n",
    "        df = df[df['State'].isin(states)].copy()\n",
    "        print(f\"Filtered to {len(df)} rows across {df['State'].unique()} state(s)\")\n",
    "        if len(df) == 0:\n",
    "            raise ValueError(\"No data available after filtering by states.\")\n",
    "    \n",
    "    df['unique_id'] = df['State'] + '_' + df['ATC2 Class']\n",
    "    df = df.sort_values(['unique_id','ds']).reset_index(drop=True)\n",
    "\n",
    "    df_units = df[['unique_id', 'ds', 'Units Reimbursed']].copy()\n",
    "    df_units.columns = ['unique_id', 'ds', 'y']\n",
    "    df_units = df_units.dropna(subset=['y'])  \n",
    "\n",
    "    df_prescriptions = df[['unique_id', 'ds', 'Number of Prescriptions']].copy()\n",
    "    df_prescriptions.columns = ['unique_id', 'ds', 'y']\n",
    "    df_prescriptions = df_prescriptions.dropna(subset=['y'])\n",
    "\n",
    "    return df_units, df_prescriptions, df\n",
    "\n",
    "def pop_scenarios_exog(filepath,states=None):\n",
    "\n",
    "    df = pd.read_csv(filepath)\n",
    "    df['ds'] = pd.to_datetime(df['Period'], errors='coerce')\n",
    "    \n",
    "    if states is not None:\n",
    "        if isinstance(states, str):\n",
    "            states = [states]\n",
    "        df = df[df['State'].isin(states)].copy()\n",
    "    \n",
    "    df['unique_id'] = df['State'] + '_' + df['ATC2 Class']\n",
    "    df = df.sort_values(['unique_id', 'ds']).reset_index(drop=True)\n",
    "    \n",
    "    df_historical = df[df['ds'] <= '2024-10-01'].copy()\n",
    "    df_future = df[df['ds'] > '2024-10-01'].copy()\n",
    "\n",
    "    pop_historical = df_historical[['unique_id', 'ds', 'population']].copy()\n",
    "    pop_historical.columns = ['unique_id', 'ds', 'population']\n",
    "\n",
    "    scenarios={}\n",
    "    pop_future_point = df_future[['unique_id', 'ds', 'population']].copy()\n",
    "    pop_future_point.columns = ['unique_id', 'ds', 'population']\n",
    "    scenarios['point'] = pd.concat([pop_historical, pop_future_point], ignore_index=True)\n",
    "    \n",
    "    pop_future_low = df_future[['unique_id', 'ds', 'Forecast_low_95']].copy()\n",
    "    pop_future_low.columns = ['unique_id', 'ds', 'population']\n",
    "    scenarios['low_95'] = pd.concat([pop_historical, pop_future_low], ignore_index=True)\n",
    "    \n",
    "    pop_future_high = df_future[['unique_id', 'ds', 'Forecast_high_95']].copy()\n",
    "    pop_future_high.columns = ['unique_id', 'ds', 'population']\n",
    "    scenarios['high_95'] = pd.concat([pop_historical, pop_future_high], ignore_index=True)\n",
    "    \n",
    "    for scenario_name, scenario_df in scenarios.items():\n",
    "        future_count = len(scenario_df[scenario_df['ds'] > '2024-10-01'])\n",
    "        print(f\"   {scenario_name}: {future_count} future population records\")\n",
    "    \n",
    "    return scenarios\n",
    "\n",
    "def get_models_exog(config, use_exog=True):\n",
    "    \n",
    "    if use_exog:\n",
    "        models = [\n",
    "            Naive(),\n",
    "            SeasonalNaive(season_length=config.season_length),\n",
    "            HistoricAverage(),\n",
    "            WindowAverage(window_size=4),\n",
    "            AutoARIMA(\n",
    "                seasonal=True, \n",
    "                season_length=config.season_length, \n",
    "                alias=\"SARIMAX\"\n",
    "            ),\n",
    "            AutoARIMA(\n",
    "                seasonal=False,\n",
    "                season_length=config.season_length,\n",
    "                alias=\"ARIMAX\"\n",
    "            ),\n",
    "        ]\n",
    "    else:\n",
    "        models = [\n",
    "            Naive(),\n",
    "            HistoricAverage(),\n",
    "            WindowAverage(window_size=4),\n",
    "            SeasonalNaive(season_length=config.season_length),\n",
    "            ARIMA(order=(1, 1, 1), alias=\"ARIMA_manual\"),\n",
    "            AutoARIMA(seasonal=True, season_length=config.season_length, alias=\"SARIMA\"),\n",
    "        ]\n",
    "    \n",
    "    return models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "new-functions-header",
   "metadata": {},
   "source": [
    "---\n",
    "## NEW FUNCTION 1: Select Best Model Per Series (Horizon=8)\n",
    "\n",
    "This function:\n",
    "1. Runs cross-validation with horizon=8\n",
    "2. Evaluates model consistency across CV windows\n",
    "3. Selects the best model per unique_id based on consistency and performance\n",
    "4. Generates forecasts for all three population scenarios (low, point, high)\n",
    "5. Exports a single CSV with best model forecasts for each scenario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "best-model-function",
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_best_model_per_series(\n",
    "    filepath: str,\n",
    "    target_col: str,\n",
    "    states: Optional[List[str]] = None,\n",
    "    config: Optional[ForecastConfig] = None,\n",
    "    horizon: int = 8,\n",
    "    n_windows: int = 3,\n",
    "    consistency_threshold: float = 0.5,\n",
    "    metric: str = 'mae',\n",
    "    save_path: Optional[str] = None\n",
    ") -> Dict:\n",
    "    \"\"\"\n",
    "    Select the best model per unique_id based on cross-validation performance at horizon=8.\n",
    "    \n",
    "    The function evaluates model consistency across CV windows and selects models that:\n",
    "    - Perform consistently well across multiple CV windows\n",
    "    - Have high confidence based on agreement between CV folds\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    filepath : str\n",
    "        Path to the data file with population scenarios\n",
    "    target_col : str\n",
    "        Target column ('Units Reimbursed' or 'Number of Prescriptions')\n",
    "    states : Optional[List[str]]\n",
    "        List of states to filter (None for all states)\n",
    "    config : Optional[ForecastConfig]\n",
    "        Configuration object (will be created with horizon=8 if None)\n",
    "    horizon : int\n",
    "        Forecast horizon (default=8 quarters)\n",
    "    n_windows : int\n",
    "        Number of cross-validation windows (default=3)\n",
    "    consistency_threshold : float\n",
    "        Minimum consistency ratio to consider a model \"highly confident\" (default=0.5)\n",
    "    metric : str\n",
    "        Evaluation metric ('mae', 'mse', 'smape', 'rmse')\n",
    "    save_path : Optional[str]\n",
    "        Path to save the output CSV\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    Dict containing:\n",
    "        - 'best_model_df': DataFrame with best model selection per unique_id\n",
    "        - 'combined_forecasts': DataFrame with forecasts for all scenarios\n",
    "        - 'cv_details': Detailed cross-validation results\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"=\" * 80)\n",
    "    print(f\"BEST MODEL SELECTION PER SERIES (Horizon={horizon})\")\n",
    "    print(f\"Target: {target_col}\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    # Create config if not provided\n",
    "    if config is None:\n",
    "        config = ForecastConfig(\n",
    "            h=horizon,\n",
    "            season_length=4,\n",
    "            n_windows=n_windows,\n",
    "            step_size=4,\n",
    "            confidence_level=95,\n",
    "            n_jobs=-1\n",
    "        )\n",
    "    \n",
    "    # Load data\n",
    "    print(\"\\nðŸ“Š Phase 1: Loading data...\")\n",
    "    df_units, df_prescriptions, df_full = load_data_exog(filepath, states)\n",
    "    df = df_units if target_col == 'Units Reimbursed' else df_prescriptions\n",
    "    \n",
    "    print(f\"   Unique series: {df['unique_id'].nunique()}\")\n",
    "    print(f\"   Date range: {df['ds'].min()} to {df['ds'].max()}\")\n",
    "    \n",
    "    # Get population scenarios\n",
    "    pop_scenarios = pop_scenarios_exog(filepath, states)\n",
    "    \n",
    "    # Get models\n",
    "    models = get_models_exog(config, use_exog=True)\n",
    "    model_names = [m.__class__.__name__ if not hasattr(m, 'alias') else m.alias for m in models]\n",
    "    \n",
    "    # Initialize StatsForecast\n",
    "    sf = StatsForecast(\n",
    "        models=models,\n",
    "        freq='QS',\n",
    "        n_jobs=config.n_jobs,\n",
    "        fallback_model=SeasonalNaive(season_length=config.season_length)\n",
    "    )\n",
    "    \n",
    "    # Phase 2: Cross-Validation\n",
    "    print(f\"\\nðŸ”„ Phase 2: Running Cross-Validation (n_windows={n_windows}, h={horizon})...\")\n",
    "    \n",
    "    # Use point population scenario for CV\n",
    "    pop_df = pop_scenarios['point']\n",
    "    pop_historical = pop_df[pop_df['ds'] <= df['ds'].max()].copy()\n",
    "    df_with_pop = df.merge(pop_historical, on=['unique_id', 'ds'], how='left')\n",
    "    \n",
    "    cv_df = sf.cross_validation(\n",
    "        df=df_with_pop[['unique_id', 'ds', 'y', 'population']],\n",
    "        h=horizon,\n",
    "        n_windows=n_windows,\n",
    "        step_size=config.step_size\n",
    "    )\n",
    "    \n",
    "    # Get metric function\n",
    "    metric_funcs = {'mae': mae, 'mse': mse, 'smape': smape, 'rmse': rmse}\n",
    "    metric_func = metric_funcs.get(metric, mae)\n",
    "    \n",
    "    # Evaluate per cutoff\n",
    "    exclude_cols = ['unique_id', 'ds', 'y', 'cutoff', 'metric', 'population']\n",
    "    model_cols = [col for col in cv_df.columns if col not in exclude_cols]\n",
    "    \n",
    "    cv_results = []\n",
    "    for cutoff in cv_df['cutoff'].unique():\n",
    "        cutoff_data = cv_df[cv_df['cutoff'] == cutoff]\n",
    "        cutoff_eval = evaluate(cutoff_data, metrics=[metric_func], models=model_cols)\n",
    "        cutoff_eval['cutoff'] = cutoff\n",
    "        cutoff_eval['best_model'] = cutoff_eval[model_cols].idxmin(axis=1)\n",
    "        cutoff_eval['best_value'] = cutoff_eval[model_cols].min(axis=1)\n",
    "        cv_results.append(cutoff_eval)\n",
    "        print(f\"   Cutoff {cutoff.strftime('%Y-%m-%d')}: {cutoff_eval['best_model'].value_counts().to_dict()}\")\n",
    "    \n",
    "    eval_cv = pd.concat(cv_results, ignore_index=True)\n",
    "    \n",
    "    # Phase 3: Select Best Model per Series\n",
    "    print(f\"\\nðŸ“ˆ Phase 3: Selecting best model per series...\")\n",
    "    \n",
    "    best_model_selection = []\n",
    "    \n",
    "    for uid in df['unique_id'].unique():\n",
    "        uid_cv = eval_cv[(eval_cv['unique_id'] == uid) & (eval_cv['metric'] == metric)]\n",
    "        \n",
    "        if len(uid_cv) == 0:\n",
    "            continue\n",
    "        \n",
    "        # Count how often each model wins\n",
    "        model_wins = uid_cv['best_model'].value_counts()\n",
    "        best_model = model_wins.index[0]\n",
    "        win_count = model_wins.iloc[0]\n",
    "        total_windows = len(uid_cv)\n",
    "        consistency_ratio = win_count / total_windows\n",
    "        \n",
    "        # Calculate average metric value for best model\n",
    "        avg_metric = uid_cv[best_model].mean()\n",
    "        std_metric = uid_cv[best_model].std()\n",
    "        \n",
    "        # Determine confidence level\n",
    "        if consistency_ratio >= 0.8:\n",
    "            confidence = 'High'\n",
    "        elif consistency_ratio >= consistency_threshold:\n",
    "            confidence = 'Medium'\n",
    "        else:\n",
    "            # If no clear winner, use lowest average metric\n",
    "            avg_metrics = uid_cv[model_cols].mean()\n",
    "            best_model = avg_metrics.idxmin()\n",
    "            avg_metric = avg_metrics.min()\n",
    "            std_metric = uid_cv[best_model].std()\n",
    "            confidence = 'Low'\n",
    "        \n",
    "        best_model_selection.append({\n",
    "            'unique_id': uid,\n",
    "            'best_model': best_model,\n",
    "            'consistency_ratio': consistency_ratio,\n",
    "            'confidence': confidence,\n",
    "            'n_windows': total_windows,\n",
    "            'win_count': win_count,\n",
    "            f'avg_{metric}': avg_metric,\n",
    "            f'std_{metric}': std_metric,\n",
    "        })\n",
    "    \n",
    "    best_model_df = pd.DataFrame(best_model_selection)\n",
    "    \n",
    "    print(f\"\\n   Model Selection Summary:\")\n",
    "    print(f\"   {best_model_df['best_model'].value_counts().to_dict()}\")\n",
    "    print(f\"   Confidence Distribution: {best_model_df['confidence'].value_counts().to_dict()}\")\n",
    "    \n",
    "    # Phase 4: Generate Forecasts for All Scenarios\n",
    "    print(f\"\\nðŸ”® Phase 4: Generating forecasts for all population scenarios...\")\n",
    "    \n",
    "    all_forecasts = []\n",
    "    \n",
    "    for scenario_name in ['low_95', 'point', 'high_95']:\n",
    "        print(f\"   Processing scenario: {scenario_name}\")\n",
    "        pop_scenario = pop_scenarios[scenario_name]\n",
    "        \n",
    "        # Prepare training data with population\n",
    "        pop_hist = pop_scenario[pop_scenario['ds'] <= df['ds'].max()].copy()\n",
    "        df_train = df.merge(pop_hist, on=['unique_id', 'ds'], how='left')\n",
    "        \n",
    "        # Fit model\n",
    "        sf.fit(df=df_train[['unique_id', 'ds', 'y', 'population']])\n",
    "        \n",
    "        # Prepare future exogenous\n",
    "        last_date = df['ds'].max()\n",
    "        future_dates = pd.date_range(\n",
    "            start=last_date + pd.DateOffset(months=3),\n",
    "            periods=horizon,\n",
    "            freq='QS'\n",
    "        )\n",
    "        \n",
    "        future_exog_list = []\n",
    "        for uid in df['unique_id'].unique():\n",
    "            for date in future_dates:\n",
    "                pop_val = pop_scenario[\n",
    "                    (pop_scenario['unique_id'] == uid) & \n",
    "                    (pop_scenario['ds'] == date)\n",
    "                ]['population'].values\n",
    "                if len(pop_val) > 0:\n",
    "                    future_exog_list.append({\n",
    "                        'unique_id': uid,\n",
    "                        'ds': date,\n",
    "                        'population': pop_val[0]\n",
    "                    })\n",
    "        \n",
    "        future_exog_df = pd.DataFrame(future_exog_list)\n",
    "        \n",
    "        # Generate point forecasts (no model prediction intervals needed)\n",
    "        forecasts_df = sf.predict(h=horizon, X_df=future_exog_df)\n",
    "        forecasts_df = forecasts_df.reset_index()\n",
    "        \n",
    "        # Extract best model forecast for each unique_id\n",
    "        for uid in df['unique_id'].unique():\n",
    "            uid_forecast = forecasts_df[forecasts_df['unique_id'] == uid].copy()\n",
    "            uid_best = best_model_df[best_model_df['unique_id'] == uid]\n",
    "            \n",
    "            if len(uid_best) == 0 or len(uid_forecast) == 0:\n",
    "                continue\n",
    "            \n",
    "            best_model = uid_best['best_model'].iloc[0]\n",
    "            \n",
    "            for _, row in uid_forecast.iterrows():\n",
    "                forecast_row = {\n",
    "                    'unique_id': uid,\n",
    "                    'ds': row['ds'],\n",
    "                    'population_scenario': scenario_name,\n",
    "                    'best_model': best_model,\n",
    "                    'forecast': row.get(best_model, np.nan),\n",
    "                    'confidence': uid_best['confidence'].iloc[0],\n",
    "                    'consistency_ratio': uid_best['consistency_ratio'].iloc[0]\n",
    "                }\n",
    "                all_forecasts.append(forecast_row)\n",
    "    \n",
    "    combined_forecasts_df = pd.DataFrame(all_forecasts)\n",
    "    \n",
    "    # Phase 5: Pivot to get low/point/high in columns\n",
    "    print(f\"\\nðŸ“‹ Phase 5: Creating final output format...\")\n",
    "    \n",
    "    final_output = []\n",
    "    \n",
    "    for uid in df['unique_id'].unique():\n",
    "        uid_data = combined_forecasts_df[combined_forecasts_df['unique_id'] == uid]\n",
    "        \n",
    "        for ds in uid_data['ds'].unique():\n",
    "            ds_data = uid_data[uid_data['ds'] == ds]\n",
    "            \n",
    "            point_data = ds_data[ds_data['population_scenario'] == 'point']\n",
    "            low_data = ds_data[ds_data['population_scenario'] == 'low_95']\n",
    "            high_data = ds_data[ds_data['population_scenario'] == 'high_95']\n",
    "            \n",
    "            if len(point_data) == 0:\n",
    "                continue\n",
    "            \n",
    "            output_row = {\n",
    "                'unique_id': uid,\n",
    "                'ds': ds,\n",
    "                'best_model': point_data['best_model'].iloc[0],\n",
    "                'confidence': point_data['confidence'].iloc[0],\n",
    "                'consistency_ratio': point_data['consistency_ratio'].iloc[0],\n",
    "                # Point forecast (using 'population' column as exogenous)\n",
    "                'forecast_point': point_data['forecast'].iloc[0],\n",
    "                # Low population scenario forecast (using 'Forecast_low_95' column as exogenous)\n",
    "                'forecast_low_pop': low_data['forecast'].iloc[0] if len(low_data) > 0 else np.nan,\n",
    "                # High population scenario forecast (using 'Forecast_high_95' column as exogenous)\n",
    "                'forecast_high_pop': high_data['forecast'].iloc[0] if len(high_data) > 0 else np.nan,\n",
    "            }\n",
    "            final_output.append(output_row)\n",
    "    \n",
    "    final_df = pd.DataFrame(final_output)\n",
    "    \n",
    "    # Save to CSV\n",
    "    if save_path:\n",
    "        os.makedirs(os.path.dirname(save_path), exist_ok=True)\n",
    "        final_df.to_csv(save_path, index=False)\n",
    "        print(f\"\\nâœ… Saved: {save_path}\")\n",
    "        \n",
    "        # Also save the model selection summary\n",
    "        selection_path = save_path.replace('.csv', '_model_selection.csv')\n",
    "        best_model_df.to_csv(selection_path, index=False)\n",
    "        print(f\"âœ… Model selection saved: {selection_path}\")\n",
    "    \n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"âœ… BEST MODEL SELECTION COMPLETE!\")\n",
    "    print(f\"   Total series: {final_df['unique_id'].nunique()}\")\n",
    "    print(f\"   Forecast periods: {final_df['ds'].nunique()}\")\n",
    "    print(f\"{'='*80}\")\n",
    "    \n",
    "    return {\n",
    "        'best_model_df': best_model_df,\n",
    "        'combined_forecasts': final_df,\n",
    "        'cv_details': eval_cv,\n",
    "        'historical_data': df\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "plot-function-header",
   "metadata": {},
   "source": [
    "---\n",
    "## NEW FUNCTION 2: Plot Historical Data with Forecast and Intervals\n",
    "\n",
    "This function creates publication-quality plots showing:\n",
    "- Historical data as a solid line\n",
    "- Point forecast as a dashed line\n",
    "- Population scenario range as a shaded band (low to high)\n",
    "- Low and high population scenario forecasts as dotted lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "plot-function",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_forecast_with_intervals(\n",
    "    historical_df: pd.DataFrame,\n",
    "    forecast_df: pd.DataFrame,\n",
    "    unique_id: str,\n",
    "    target_name: str = 'Units Reimbursed',\n",
    "    show_population_scenarios: bool = True,\n",
    "    figsize: Tuple[int, int] = (14, 8),\n",
    "    save_path: Optional[str] = None\n",
    ") -> plt.Figure:\n",
    "    \"\"\"\n",
    "    Plot historical data with point forecast and population scenario forecasts for a specific unique_id.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    historical_df : pd.DataFrame\n",
    "        Historical data with columns ['unique_id', 'ds', 'y']\n",
    "    forecast_df : pd.DataFrame\n",
    "        Forecast data from select_best_model_per_series() with columns:\n",
    "        ['unique_id', 'ds', 'forecast_point', 'forecast_low_pop', 'forecast_high_pop', etc.]\n",
    "    unique_id : str\n",
    "        The series identifier to plot\n",
    "    target_name : str\n",
    "        Name of the target variable for axis labels\n",
    "    show_population_scenarios : bool\n",
    "        Whether to show low/high population scenario forecasts as a band\n",
    "    figsize : Tuple[int, int]\n",
    "        Figure size\n",
    "    save_path : Optional[str]\n",
    "        Path to save the figure\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    matplotlib.figure.Figure\n",
    "    \"\"\"\n",
    "    \n",
    "    # Filter data for the specific unique_id\n",
    "    hist_data = historical_df[historical_df['unique_id'] == unique_id].copy()\n",
    "    fore_data = forecast_df[forecast_df['unique_id'] == unique_id].copy()\n",
    "    \n",
    "    if len(hist_data) == 0:\n",
    "        print(f\"âš ï¸ No historical data found for {unique_id}\")\n",
    "        return None\n",
    "    if len(fore_data) == 0:\n",
    "        print(f\"âš ï¸ No forecast data found for {unique_id}\")\n",
    "        return None\n",
    "    \n",
    "    # Ensure datetime\n",
    "    hist_data['ds'] = pd.to_datetime(hist_data['ds'])\n",
    "    fore_data['ds'] = pd.to_datetime(fore_data['ds'])\n",
    "    \n",
    "    # Sort by date\n",
    "    hist_data = hist_data.sort_values('ds')\n",
    "    fore_data = fore_data.sort_values('ds')\n",
    "    \n",
    "    # Create figure\n",
    "    fig, ax = plt.subplots(figsize=figsize)\n",
    "    \n",
    "    # Determine scale\n",
    "    max_val = max(hist_data['y'].max(), fore_data['forecast_point'].max())\n",
    "    scale = 1e6 if max_val > 1e6 else 1e3 if max_val > 1e3 else 1\n",
    "    scale_label = 'Millions' if scale == 1e6 else 'Thousands' if scale == 1e3 else ''\n",
    "    \n",
    "    # Plot historical data\n",
    "    ax.plot(\n",
    "        hist_data['ds'], \n",
    "        hist_data['y'] / scale,\n",
    "        color=HISTORICAL_COLOR,\n",
    "        linewidth=2.5,\n",
    "        marker='o',\n",
    "        markersize=6,\n",
    "        label='Historical',\n",
    "        zorder=10\n",
    "    )\n",
    "    \n",
    "    # Get last historical point for connection\n",
    "    last_hist = hist_data.iloc[-1]\n",
    "    \n",
    "    # Plot point forecast\n",
    "    ax.plot(\n",
    "        [last_hist['ds'], fore_data['ds'].iloc[0]],\n",
    "        [last_hist['y'] / scale, fore_data['forecast_point'].iloc[0] / scale],\n",
    "        color='#E94F37',\n",
    "        linewidth=2,\n",
    "        linestyle='--',\n",
    "        alpha=0.7\n",
    "    )\n",
    "    ax.plot(\n",
    "        fore_data['ds'],\n",
    "        fore_data['forecast_point'] / scale,\n",
    "        color='#E94F37',\n",
    "        linewidth=2.5,\n",
    "        marker='s',\n",
    "        markersize=6,\n",
    "        linestyle='--',\n",
    "        label='Point Forecast',\n",
    "        zorder=9\n",
    "    )\n",
    "    \n",
    "    # Show population scenario band (fill between low and high pop forecasts)\n",
    "    if show_population_scenarios and 'forecast_low_pop' in fore_data.columns and 'forecast_high_pop' in fore_data.columns:\n",
    "        ax.fill_between(\n",
    "            fore_data['ds'],\n",
    "            fore_data['forecast_low_pop'] / scale,\n",
    "            fore_data['forecast_high_pop'] / scale,\n",
    "            color='#9B59B6',\n",
    "            alpha=0.2,\n",
    "            label='Population Scenario Range',\n",
    "            zorder=5\n",
    "        )\n",
    "        # Also plot the individual lines\n",
    "        ax.plot(\n",
    "            fore_data['ds'],\n",
    "            fore_data['forecast_low_pop'] / scale,\n",
    "            color='#2E86AB',\n",
    "            linewidth=1.5,\n",
    "            linestyle=':',\n",
    "            marker='^',\n",
    "            markersize=4,\n",
    "            label='Low Pop. Scenario',\n",
    "            alpha=0.7,\n",
    "            zorder=8\n",
    "        )\n",
    "        ax.plot(\n",
    "            fore_data['ds'],\n",
    "            fore_data['forecast_high_pop'] / scale,\n",
    "            color='#28A745',\n",
    "            linewidth=1.5,\n",
    "            linestyle=':',\n",
    "            marker='v',\n",
    "            markersize=4,\n",
    "            label='High Pop. Scenario',\n",
    "            alpha=0.7,\n",
    "            zorder=8\n",
    "        )\n",
    "    \n",
    "    # Add vertical line at forecast start\n",
    "    ax.axvline(\n",
    "        x=last_hist['ds'],\n",
    "        color='gray',\n",
    "        linestyle=':',\n",
    "        linewidth=2,\n",
    "        alpha=0.7,\n",
    "        label='Forecast Start'\n",
    "    )\n",
    "    \n",
    "    # Get model info\n",
    "    best_model = fore_data['best_model'].iloc[0] if 'best_model' in fore_data.columns else 'Unknown'\n",
    "    confidence = fore_data['confidence'].iloc[0] if 'confidence' in fore_data.columns else 'N/A'\n",
    "    consistency = fore_data['consistency_ratio'].iloc[0] if 'consistency_ratio' in fore_data.columns else 0\n",
    "    \n",
    "    # Formatting\n",
    "    ax.set_xlabel('Date', fontsize=12)\n",
    "    ax.set_ylabel(f'{target_name} ({scale_label})' if scale_label else target_name, fontsize=12)\n",
    "    ax.set_title(\n",
    "        f'{unique_id}: {target_name}\\n'\n",
    "        f'Best Model: {best_model} | Confidence: {confidence} | Consistency: {consistency:.1%}',\n",
    "        fontsize=14,\n",
    "        fontweight='bold'\n",
    "    )\n",
    "    \n",
    "    # Legend\n",
    "    ax.legend(loc='upper left', fontsize=10, ncol=2)\n",
    "    \n",
    "    # Date formatting\n",
    "    ax.xaxis.set_major_locator(mdates.YearLocator())\n",
    "    ax.xaxis.set_major_formatter(mdates.DateFormatter('%Y'))\n",
    "    ax.xaxis.set_minor_locator(mdates.MonthLocator(bymonth=[4, 7, 10]))\n",
    "    ax.tick_params(axis='x', rotation=45)\n",
    "    \n",
    "    # Grid\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # Save if requested\n",
    "    if save_path:\n",
    "        os.makedirs(os.path.dirname(save_path) if os.path.dirname(save_path) else '.', exist_ok=True)\n",
    "        fig.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "        print(f\"âœ… Saved: {save_path}\")\n",
    "    \n",
    "    #plt.show()\n",
    "    return fig\n",
    "\n",
    "\n",
    "def plot_multiple_forecasts(\n",
    "    historical_df: pd.DataFrame,\n",
    "    forecast_df: pd.DataFrame,\n",
    "    unique_ids: Optional[List[str]] = None,\n",
    "    n_random: int = 6,\n",
    "    target_name: str = 'Units Reimbursed',\n",
    "    show_population_scenarios: bool = False,\n",
    "    figsize: Tuple[int, int] = (18, 12),\n",
    "    save_path: Optional[str] = None\n",
    ") -> plt.Figure:\n",
    "    \"\"\"\n",
    "    Plot forecasts for multiple series in a grid layout.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    historical_df : pd.DataFrame\n",
    "        Historical data\n",
    "    forecast_df : pd.DataFrame\n",
    "        Forecast data from select_best_model_per_series()\n",
    "    unique_ids : Optional[List[str]]\n",
    "        Specific IDs to plot (if None, random selection)\n",
    "    n_random : int\n",
    "        Number of random series to plot if unique_ids is None\n",
    "    target_name : str\n",
    "        Name of target variable\n",
    "    show_population_scenarios : bool\n",
    "        Whether to show population scenario forecasts\n",
    "    figsize : Tuple[int, int]\n",
    "        Figure size\n",
    "    save_path : Optional[str]\n",
    "        Path to save figure\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    matplotlib.figure.Figure\n",
    "    \"\"\"\n",
    "    \n",
    "    if unique_ids is None:\n",
    "        all_ids = forecast_df['unique_id'].unique()\n",
    "        unique_ids = np.random.choice(all_ids, min(n_random, len(all_ids)), replace=False)\n",
    "    \n",
    "    n_plots = len(unique_ids)\n",
    "    n_cols = min(3, n_plots)\n",
    "    n_rows = (n_plots + n_cols - 1) // n_cols\n",
    "    \n",
    "    fig, axes = plt.subplots(n_rows, n_cols, figsize=figsize, squeeze=False)\n",
    "    axes = axes.flatten()\n",
    "    \n",
    "    for idx, uid in enumerate(unique_ids):\n",
    "        ax = axes[idx]\n",
    "        \n",
    "        hist_data = historical_df[historical_df['unique_id'] == uid].copy()\n",
    "        fore_data = forecast_df[forecast_df['unique_id'] == uid].copy()\n",
    "        \n",
    "        if len(hist_data) == 0 or len(fore_data) == 0:\n",
    "            ax.set_visible(False)\n",
    "            continue\n",
    "        \n",
    "        hist_data['ds'] = pd.to_datetime(hist_data['ds'])\n",
    "        fore_data['ds'] = pd.to_datetime(fore_data['ds'])\n",
    "        hist_data = hist_data.sort_values('ds')\n",
    "        fore_data = fore_data.sort_values('ds')\n",
    "        \n",
    "        # Scale\n",
    "        max_val = max(hist_data['y'].max(), fore_data['forecast_point'].max())\n",
    "        scale = 1e6 if max_val > 1e6 else 1e3 if max_val > 1e3 else 1\n",
    "        scale_label = 'M' if scale == 1e6 else 'K' if scale == 1e3 else ''\n",
    "        \n",
    "        # Plot historical\n",
    "        ax.plot(hist_data['ds'], hist_data['y']/scale, color=HISTORICAL_COLOR, \n",
    "                lw=1.5, marker='o', ms=3, label='Historical')\n",
    "        \n",
    "        last_hist = hist_data.iloc[-1]\n",
    "        \n",
    "        # Plot forecast\n",
    "        ax.plot([last_hist['ds'], fore_data['ds'].iloc[0]], \n",
    "                [last_hist['y']/scale, fore_data['forecast_point'].iloc[0]/scale],\n",
    "                color='#E94F37', lw=1.5, ls='--', alpha=0.7)\n",
    "        ax.plot(fore_data['ds'], fore_data['forecast_point']/scale, \n",
    "                color='#E94F37', lw=1.5, marker='s', ms=3, ls='--', label='Forecast')\n",
    "        \n",
    "        # Show population scenario band\n",
    "        if show_population_scenarios and 'forecast_low_pop' in fore_data.columns and 'forecast_high_pop' in fore_data.columns:\n",
    "            ax.fill_between(fore_data['ds'], \n",
    "                          fore_data['forecast_low_pop']/scale,\n",
    "                          fore_data['forecast_high_pop']/scale,\n",
    "                          color='#9B59B6', alpha=0.15)\n",
    "            ax.plot(fore_data['ds'], fore_data['forecast_low_pop']/scale,\n",
    "                   color='#2E86AB', lw=1, ls=':', alpha=0.6)\n",
    "            ax.plot(fore_data['ds'], fore_data['forecast_high_pop']/scale,\n",
    "                   color='#28A745', lw=1, ls=':', alpha=0.6)\n",
    "        \n",
    "        ax.axvline(x=last_hist['ds'], color='gray', ls=':', alpha=0.5)\n",
    "        \n",
    "        # Labels\n",
    "        best_model = fore_data['best_model'].iloc[0] if 'best_model' in fore_data.columns else ''\n",
    "        confidence = fore_data['confidence'].iloc[0] if 'confidence' in fore_data.columns else ''\n",
    "        ax.set_title(f'{uid}\\n{best_model} ({confidence})', fontsize=9, fontweight='bold')\n",
    "        ax.set_ylabel(scale_label, fontsize=8)\n",
    "        ax.tick_params(axis='x', rotation=45, labelsize=7)\n",
    "        ax.tick_params(axis='y', labelsize=7)\n",
    "        ax.grid(True, alpha=0.3)\n",
    "        \n",
    "        if idx == 0:\n",
    "            ax.legend(loc='upper left', fontsize=7)\n",
    "    \n",
    "    # Hide unused subplots\n",
    "    for idx in range(len(unique_ids), len(axes)):\n",
    "        axes[idx].set_visible(False)\n",
    "    \n",
    "    fig.suptitle(f'{target_name} Forecasts with Population Scenarios', fontsize=14, fontweight='bold', y=1.02)\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    if save_path:\n",
    "        fig.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "        print(f\"âœ… Saved: {save_path}\")\n",
    "    \n",
    "    #plt.show()\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "usage-header",
   "metadata": {},
   "source": [
    "---\n",
    "## Usage Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21a58b66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# File paths\n",
    "filepath_withpop = rf\"C:\\Users\\{user}\\OneDrive - purdue.edu\\VS code\\Data\\ATC\\merged_data\\Prebuilt_panels\\P1_withpop.csv\"\n",
    "save_path = rf\"C:\\Users\\{user}\\OneDrive - purdue.edu\\VS code\\Data\\ATC\\Forecast\\TMF\\\\\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "run-best-model",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run best model selection for Units Reimbursed\n",
    "results = select_best_model_per_series(\n",
    "    filepath=filepath_withpop,\n",
    "    target_col='Units Reimbursed',\n",
    "    states=['IL'],  # Filter for Indiana\n",
    "    horizon=8,\n",
    "    n_windows=3,\n",
    "    consistency_threshold=0.5,\n",
    "    metric='mae',\n",
    "    save_path=os.path.join(save_path, 'best_model_forecasts_units.csv')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "view-results",
   "metadata": {},
   "outputs": [],
   "source": [
    "# View the best model selection summary\n",
    "print(\"\\nBest Model Selection Summary:\")\n",
    "print(results['best_model_df'].head(10))\n",
    "\n",
    "print(\"\\n\\nModel Distribution:\")\n",
    "print(results['best_model_df']['best_model'].value_counts())\n",
    "\n",
    "print(\"\\n\\nConfidence Distribution:\")\n",
    "print(results['best_model_df']['confidence'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "plot-single",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot a single series with confidence intervals\n",
    "plot_forecast_with_intervals(\n",
    "    historical_df=results['historical_data'],\n",
    "    forecast_df=results['combined_forecasts'],\n",
    "    unique_id='IN_N06',  # Example: Psychoanaleptics in Indiana\n",
    "    target_name='Units Reimbursed',\n",
    "    show_population_scenarios=True,\n",
    "    save_path=os.path.join(save_path, 'IN_N06_forecast.png')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "plot-multiple",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot multiple series in a grid\n",
    "'''\n",
    "plot_multiple_forecasts(\n",
    "    historical_df=results['historical_data'],\n",
    "    forecast_df=results['combined_forecasts'],\n",
    "    unique_ids=['IN_N06', 'IN_C09', 'IN_A10', 'IN_J01', 'IN_R03', 'IN_N02'],\n",
    "    target_name='Units Reimbursed',\n",
    "    show_population_scenarios=True,\n",
    "    save_path=os.path.join(save_path, 'multi_series_forecast.png')\n",
    ")\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "plot-random",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot random series\n",
    "plot_multiple_forecasts(\n",
    "    historical_df=results['historical_data'],\n",
    "    forecast_df=results['combined_forecasts'],\n",
    "    n_random=9,\n",
    "    target_name='Units Reimbursed',\n",
    "    show_population_scenarios=False,\n",
    "    figsize=(16, 14),\n",
    "    save_path=os.path.join(save_path, 'random_series_forecast.png')\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "prescriptions-header",
   "metadata": {},
   "source": [
    "### Run for Number of Prescriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "run-prescriptions",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run for Number of Prescriptions\n",
    "results_rx = select_best_model_per_series(\n",
    "    filepath=filepath_withpop,\n",
    "    target_col='Number of Prescriptions',\n",
    "    states=['IL'],\n",
    "    horizon=8,\n",
    "    n_windows=3,\n",
    "    consistency_threshold=0.5,\n",
    "    metric='mae',\n",
    "    save_path=os.path.join(save_path, 'best_model_forecasts_prescriptions.csv')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "plot-rx",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot prescriptions forecast\n",
    "plot_forecast_with_intervals(\n",
    "    historical_df=results_rx['historical_data'],\n",
    "    forecast_df=results_rx['combined_forecasts'],\n",
    "    unique_id='IN_N06',\n",
    "    target_name='Number of Prescriptions',\n",
    "    show_population_scenarios=True,\n",
    "    save_path=os.path.join(save_path, 'IN_N06_prescriptions_forecast.png')\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
