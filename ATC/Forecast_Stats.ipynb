{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14de25d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "import seaborn as sns\n",
    "import warnings \n",
    "from utilsforecast.plotting import plot_series\n",
    "from utilsforecast.evaluation import evaluate\n",
    "from utilsforecast.losses import *\n",
    "from statsforecast import StatsForecast\n",
    "from statsforecast.models import (\n",
    "    Naive,WindowAverage, ARIMA, \n",
    "    AutoARIMA,SeasonalNaive,HoltWinters,\n",
    "    CrostonClassic as Croston, HistoricAverage,DynamicOptimizedTheta as DOT,\n",
    "    SeasonalNaive\n",
    ")\n",
    "from dataclasses import dataclass\n",
    "from typing import Optional, List, Dict, Tuple, Union\n",
    "from itertools import product\n",
    "\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")  # To ignore warnings from pandas/numpy\n",
    "\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "plt.rcParams['font.size'] = 10\n",
    "\n",
    "# Color palette for up to 4 models\n",
    "MODEL_COLORS = {\n",
    "    0: '#E94F37',  # Red\n",
    "    1: '#2E86AB',  # Blue\n",
    "    2: '#28A745',  # Green\n",
    "    3: '#9B59B6',  # Purple\n",
    "}\n",
    "HISTORICAL_COLOR = \"#898992\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d75a6c67",
   "metadata": {},
   "outputs": [],
   "source": [
    "user=\"Lilian\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "726f8b35",
   "metadata": {},
   "source": [
    "### Dataclass and Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c1baf5dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class ForecastConfig:\n",
    "    \n",
    "    # Forecast parameters\n",
    "    h: int = 8                          \n",
    "    season_length: int = 4              \n",
    "    \n",
    "    # Cross-validation parameters\n",
    "    n_windows: int = 2                  \n",
    "    step_size: Optional[int] = None     \n",
    "    \n",
    "    # Train-test split parameters\n",
    "    train_size: Optional[int] = None    # Use all available data except test\n",
    "    test_size: Optional[int] = None     # Auto-set to h in __post_init__\n",
    "    \n",
    "    # Plotting parameters\n",
    "    n_samples: int = 4                  # Plot 4 random samples\n",
    "    models_to_plot: Optional[List[str]] = None  # \n",
    "    \n",
    "    # Other settings\n",
    "    confidence_level: int = 95          # 95% confidence intervals\n",
    "    n_jobs: int = -1                    \n",
    "    \n",
    "    def __post_init__(self):\n",
    "        \n",
    "        if self.step_size is None:\n",
    "            self.step_size = self.h\n",
    "        if self.test_size is None:\n",
    "            self.test_size = self.h\n",
    "        if self.models_to_plot is None:\n",
    "            self.models_to_plot = ['Naive', 'ARIMA_manual', 'SARIMA']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93281f08",
   "metadata": {},
   "source": [
    "### SDUD with pop - Statistical Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "74eb21a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defining functions used above but this time for exogenous feature (pop)\n",
    "def load_data_exog(filepath, states=None):\n",
    "\n",
    "    df = pd.read_csv(filepath)\n",
    "    df['ds'] = pd.to_datetime(df['Period'], errors='coerce')\n",
    "    \n",
    "    df = df[(df['ds'] >= '2017-01-01') & (df['ds'] <= '2024-10-01')].copy()\n",
    "    \n",
    "    if states is not None:\n",
    "        if isinstance(states, str):\n",
    "            states = [states]\n",
    "        print(f\"Filtering data for states: {states}\")\n",
    "        df = df[df['State'].isin(states)].copy()\n",
    "        print(f\"Filtered to {len(df)} rows across {df['State'].unique()} state(s)\")\n",
    "        if len(df) == 0:\n",
    "            raise ValueError(\"No data available after filtering by states.\")\n",
    "    \n",
    "    df['unique_id'] = df['State'] + '_' + df['ATC2 Class']\n",
    "    df = df.sort_values(['unique_id','ds']).reset_index(drop=True)\n",
    "\n",
    "    df_units = df[['unique_id', 'ds', 'Units Reimbursed']].copy()\n",
    "    df_units.columns = ['unique_id', 'ds', 'y']\n",
    "    df_units = df_units.dropna(subset=['y'])  \n",
    "\n",
    "    df_prescriptions = df[['unique_id', 'ds', 'Number of Prescriptions']].copy()\n",
    "    df_prescriptions.columns = ['unique_id', 'ds', 'y']\n",
    "    df_prescriptions = df_prescriptions.dropna(subset=['y'])  # â† Only drop NaN in y\n",
    "\n",
    "    return df_units, df_prescriptions, df\n",
    "\n",
    "def pop_scenarios_exog(filepath,states=None):\n",
    "\n",
    "    df = pd.read_csv(filepath)\n",
    "    df['ds'] = pd.to_datetime(df['Period'], errors='coerce')\n",
    "    \n",
    "    if states is not None:\n",
    "        if isinstance(states, str):\n",
    "            states = [states]\n",
    "        df = df[df['State'].isin(states)].copy()\n",
    "    \n",
    "    df['unique_id'] = df['State'] + '_' + df['ATC2 Class']\n",
    "    df = df.sort_values(['unique_id', 'ds']).reset_index(drop=True)\n",
    "    \n",
    "    df_historical = df[df['ds'] <= '2024-10-01'].copy()\n",
    "    df_future = df[df['ds'] > '2024-10-01'].copy()\n",
    "\n",
    "    pop_historical = df_historical[['unique_id', 'ds', 'population']].copy()\n",
    "    pop_historical.columns = ['unique_id', 'ds', 'population']\n",
    "\n",
    "    scenarios={}\n",
    "    pop_future_point = df_future[['unique_id', 'ds', 'population']].copy()\n",
    "    pop_future_point.columns = ['unique_id', 'ds', 'population']\n",
    "    scenarios['point'] = pd.concat([pop_historical, pop_future_point], ignore_index=True)\n",
    "    \n",
    "    # Scenario 2: Lower bound (uses Forecast_low_95 column)\n",
    "    pop_future_low = df_future[['unique_id', 'ds', 'Forecast_low_95']].copy()\n",
    "    pop_future_low.columns = ['unique_id', 'ds', 'population']\n",
    "    scenarios['low_95'] = pd.concat([pop_historical, pop_future_low], ignore_index=True)\n",
    "    \n",
    "    # Scenario 3: Upper bound (uses Forecast_high_95 column)\n",
    "    pop_future_high = df_future[['unique_id', 'ds', 'Forecast_high_95']].copy()\n",
    "    pop_future_high.columns = ['unique_id', 'ds', 'population']\n",
    "    scenarios['high_95'] = pd.concat([pop_historical, pop_future_high], ignore_index=True)\n",
    "    \n",
    "    # Verify we have future data\n",
    "    for scenario_name, scenario_df in scenarios.items():\n",
    "        future_count = len(scenario_df[scenario_df['ds'] > '2024-10-01'])\n",
    "        print(f\"   {scenario_name}: {future_count} future population records\")\n",
    "    \n",
    "    return scenarios\n",
    "\n",
    "def get_models_exog(config, use_exog=True):\n",
    "    \n",
    "    if use_exog:\n",
    "        models = [\n",
    "            # Baseline models (ignore exog)\n",
    "            Naive(),\n",
    "            SeasonalNaive(season_length=config.season_length),\n",
    "            HistoricAverage(),\n",
    "            WindowAverage(window_size=4),\n",
    "            \n",
    "            # Models with exogenous support\n",
    "            AutoARIMA(\n",
    "                seasonal=True, \n",
    "                season_length=config.season_length, \n",
    "                alias=\"SARIMAX\"\n",
    "            ),\n",
    "            AutoARIMA(\n",
    "                seasonal=False,\n",
    "                season_length=config.season_length,\n",
    "                alias=\"ARIMAX\"\n",
    "            ),\n",
    "            # Note: Can add more exog-aware models here\n",
    "        ]\n",
    "    else:\n",
    "        # Standard models without exog\n",
    "        models = [\n",
    "            Naive(),\n",
    "            HistoricAverage(),\n",
    "            WindowAverage(window_size=4),\n",
    "            SeasonalNaive(season_length=config.season_length),\n",
    "            ARIMA(order=(1, 1, 1), alias=\"ARIMA_manual\"),\n",
    "            AutoARIMA(seasonal=True, season_length=config.season_length, alias=\"SARIMA\"),\n",
    "        ]\n",
    "    \n",
    "    return models\n",
    "\n",
    "def evaluate_train_test_exog(df,target_name,config,population_df=None):\n",
    "    \n",
    "    # Split train/test\n",
    "    if config.train_size is None:\n",
    "        train = df.groupby('unique_id').apply(\n",
    "            lambda x: x.iloc[:-config.test_size]\n",
    "        ).reset_index(drop=True)\n",
    "    else:\n",
    "        train = df.groupby('unique_id').apply(\n",
    "            lambda x: x.iloc[-(config.train_size + config.test_size):-config.test_size]\n",
    "        ).reset_index(drop=True)\n",
    "    \n",
    "    test = df.groupby('unique_id').apply(\n",
    "        lambda x: x.iloc[-config.test_size:]\n",
    "    ).reset_index(drop=True)\n",
    "    \n",
    "    # Get models\n",
    "    use_exog = population_df is not None\n",
    "    models = get_models_exog(config, use_exog=use_exog)\n",
    "    \n",
    "    # Initialize StatsForecast\n",
    "    sf = StatsForecast(\n",
    "        models=models,\n",
    "        freq='QS',\n",
    "        n_jobs=config.n_jobs,\n",
    "        fallback_model=SeasonalNaive(season_length=config.season_length)\n",
    "    )\n",
    "    \n",
    "    # Fit and predict with/without exogenous variables\n",
    "    if use_exog:\n",
    "\n",
    "        if 'population' in train.columns:\n",
    "            train = train.drop(columns=['population'])\n",
    "        if 'population' in test.columns:\n",
    "            test = test.drop(columns=['population'])\n",
    "\n",
    "        # Prepare exogenous data for train and test\n",
    "        pop_train = population_df[population_df['ds'].isin(train['ds'])].copy()\n",
    "        pop_test = population_df[population_df['ds'].isin(test['ds'])].copy()\n",
    "        \n",
    "        # Merge population with train data\n",
    "        train_with_pop = train.merge(pop_train, on=['unique_id', 'ds'], how='left')\n",
    "        \n",
    "        # Fit with exogenous\n",
    "        sf.fit(df=train_with_pop[['unique_id', 'ds', 'y', 'population']])\n",
    "        \n",
    "        # Predict with future exogenous\n",
    "        test_with_pop = test.merge(pop_test, on=['unique_id', 'ds'], how='left')\n",
    "        preds = sf.predict(h=config.h, X_df=test_with_pop[['unique_id', 'ds', 'population']])\n",
    "    else:\n",
    "        sf.fit(df=train)\n",
    "        preds = sf.predict(h=config.h)\n",
    "    \n",
    "    # Merge predictions with actuals\n",
    "    preds_df = pd.merge(test, preds.reset_index(), on=['ds', 'unique_id'], how='left')\n",
    "    \n",
    "    # Evaluate\n",
    "    model_cols = [col for col in preds.columns if col not in ['unique_id', 'ds']]\n",
    "    eval_df = evaluate(preds_df, metrics=[mae, mse, smape], models=model_cols)\n",
    "    \n",
    "    # Add best model\n",
    "    mae_df = eval_df[eval_df['metric'] == 'mae'].copy()\n",
    "    mae_df['best_model'] = mae_df[model_cols].idxmin(axis=1)\n",
    "    \n",
    "    exog_label = \" (with population)\" if use_exog else \" (no exog)\"\n",
    "    print(f\"\\nðŸ“ˆ Best Models (Train-Test Split - {target_name}{exog_label}):\")\n",
    "    print(mae_df['best_model'].value_counts())\n",
    "    \n",
    "    return eval_df, preds_df, train, test\n",
    "\n",
    "def CV_with_exog(df,target_name,config,population_df=None):\n",
    "    \n",
    "    use_exog = population_df is not None\n",
    "    models = get_models_exog(config, use_exog=use_exog)\n",
    "    \n",
    "    sf = StatsForecast(\n",
    "        models=models,\n",
    "        freq='QS',\n",
    "        n_jobs=config.n_jobs,\n",
    "        fallback_model=SeasonalNaive(season_length=config.season_length)\n",
    "    )\n",
    "    \n",
    "    print(f\"   Running cross-validation...\")\n",
    "    \n",
    "    # Cross-validation with/without exogenous\n",
    "    if use_exog:\n",
    "\n",
    "        df_for_cv = df.copy()\n",
    "        if 'population' in df_for_cv.columns:\n",
    "            df_for_cv = df_for_cv.drop(columns=['population'])\n",
    "            \n",
    "        df_with_pop = df.merge(population_df, on=['unique_id', 'ds'], how='left')\n",
    "        cv_df = sf.cross_validation(\n",
    "            df=df_with_pop[['unique_id', 'ds', 'y', 'population']],\n",
    "            h=config.h,\n",
    "            n_windows=config.n_windows,\n",
    "            step_size=config.step_size\n",
    "        )\n",
    "    else:\n",
    "        cv_df = sf.cross_validation(\n",
    "            df=df,\n",
    "            h=config.h,\n",
    "            n_windows=config.n_windows,\n",
    "            step_size=config.step_size\n",
    "        )\n",
    "    \n",
    "    # Evaluate per cutoff\n",
    "    exclude_cols = ['unique_id', 'ds', 'y', 'cutoff', 'metric', 'population']\n",
    "    model_cols = [col for col in cv_df.columns if col not in exclude_cols]\n",
    "    \n",
    "    all_results = []\n",
    "    \n",
    "    for cutoff in cv_df['cutoff'].unique():\n",
    "        cutoff_data = cv_df[cv_df['cutoff'] == cutoff]\n",
    "        \n",
    "        cutoff_eval = evaluate(cutoff_data, metrics=[mae, mse, smape], models=model_cols)\n",
    "        cutoff_eval['cutoff'] = cutoff\n",
    "        cutoff_eval['best_model'] = cutoff_eval[model_cols].idxmin(axis=1)\n",
    "        cutoff_eval['best_value'] = cutoff_eval[model_cols].min(axis=1)\n",
    "        \n",
    "        all_results.append(cutoff_eval)\n",
    "        \n",
    "        cutoff_mae = cutoff_eval[cutoff_eval['metric'] == 'mae']\n",
    "        print(f\"\\n   Cutoff {cutoff.strftime('%Y-%m-%d')} (MAE best models):\")\n",
    "        print(f\"   {cutoff_mae['best_model'].value_counts().to_dict()}\")\n",
    "    \n",
    "    eval_df = pd.concat(all_results, ignore_index=True)\n",
    "    \n",
    "    mae_overall = eval_df[eval_df['metric'] == 'mae']\n",
    "    exog_label = \" (with population)\" if use_exog else \"\"\n",
    "    print(f\"\\nðŸ“ˆ Overall Best Models{exog_label}:\")\n",
    "    print(mae_overall['best_model'].value_counts())\n",
    "    \n",
    "    return eval_df, cv_df\n",
    "\n",
    "def generate_future_forecasts(df_historical, target_name, config, population_scenario, horizon=None,save_path=None):\n",
    "    \n",
    "    if horizon is None:\n",
    "        horizon = config.h\n",
    "    use_exog = population_scenario is not None\n",
    "    models = get_models_exog(config, use_exog=use_exog)\n",
    "    \n",
    "    sf = StatsForecast(\n",
    "        models=models,\n",
    "        freq='QS',\n",
    "        n_jobs=config.n_jobs,\n",
    "        fallback_model=SeasonalNaive(season_length=config.season_length)\n",
    "    )\n",
    "    \n",
    "    # Train on full historical data\n",
    "    if use_exog:\n",
    "        # Get historical population\n",
    "        pop_historical = population_scenario[\n",
    "            population_scenario['ds'] <= df_historical['ds'].max()\n",
    "        ].copy()\n",
    "        \n",
    "        df_train = df_historical.merge(pop_historical, on=['unique_id', 'ds'], how='left')\n",
    "        sf.fit(df=df_train[['unique_id', 'ds', 'y', 'population']])\n",
    "        \n",
    "        # Get future population for forecasting\n",
    "        last_date = df_historical['ds'].max()\n",
    "        future_dates = pd.date_range(\n",
    "            start=last_date + pd.DateOffset(months=3),\n",
    "            periods=horizon,\n",
    "            freq='QS'\n",
    "        )\n",
    "        \n",
    "        # Create future exogenous dataframe\n",
    "        future_exog_list = []\n",
    "        for uid in df_historical['unique_id'].unique():\n",
    "            for date in future_dates:\n",
    "                pop_val = population_scenario[\n",
    "                    (population_scenario['unique_id'] == uid) & \n",
    "                    (population_scenario['ds'] == date)\n",
    "                ]['population'].values\n",
    "                \n",
    "                if len(pop_val) > 0:\n",
    "                    future_exog_list.append({\n",
    "                        'unique_id': uid,\n",
    "                        'ds': date,\n",
    "                        'population': pop_val[0]\n",
    "                    })\n",
    "        \n",
    "        future_exog_df = pd.DataFrame(future_exog_list)\n",
    "        forecasts_df = sf.predict(h=horizon, X_df=future_exog_df)\n",
    "    else:\n",
    "        sf.fit(df=df_historical,)\n",
    "        forecasts_df = sf.predict(h=horizon)\n",
    "    \n",
    "    if save_path:\n",
    "        os.makedirs(save_path, exist_ok=True)\n",
    "        filename = os.path.join(\n",
    "            save_path, \n",
    "            f'{target_name.lower().replace(\" \", \"_\")}_future_h{horizon}.csv'\n",
    "        )\n",
    "        forecasts_df.reset_index().to_csv(filename, index=False)\n",
    "        print(f\"âœ… Saved: {filename}\")\n",
    "    \n",
    "    return forecasts_df\n",
    "\n",
    "def forecast_with_population_scenarios(filepath, target_col, states=None, config=None, horizons=None, save_path=None):\n",
    "   \n",
    "    if config is None: config = ForecastConfig()\n",
    "\n",
    "    if horizons is None: horizons = [config.h]\n",
    "\n",
    "    print(f\"\\nFORECASTING: {target_col}, Horizons: {horizons}\")\n",
    "\n",
    "    df_units, df_prescriptions, df_full = load_data_exog(filepath, states)\n",
    "\n",
    "    df = df_units if target_col == 'Units Reimbursed' else df_prescriptions\n",
    "\n",
    "    print(f\"   Unique series: {df['unique_id'].nunique()}, Range: {df['ds'].min()} to {df['ds'].max()}\")\n",
    "    \n",
    "    pop_scenarios = pop_scenarios_exog(filepath, states)\n",
    "    results = {'point': {}, 'low_95': {}, 'high_95': {}}\n",
    "    \n",
    "    for scenario_name, pop_df in pop_scenarios.items():\n",
    "        print(f\"\\n--- SCENARIO: {scenario_name.upper()} ---\")\n",
    "        for h in horizons:\n",
    "            forecasts = generate_future_forecasts(df, target_col, config, pop_df, horizon=h,\n",
    "                                                  save_path=os.path.join(save_path, scenario_name) if save_path else None)\n",
    "            results[scenario_name][f'h{h}'] = {\n",
    "                'forecasts': forecasts,\n",
    "                'df_historical': df.copy()\n",
    "            }\n",
    "    print(\"\\nâœ… COMPLETE!\")\n",
    "    return results\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    return results                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "50b544de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sensitivity_analysis_with_exog(filepath, target_col, states=None, param_grid=None, production_horizons=[4, 8],\n",
    "    population_scenario='point',  # 'point', 'low_95', or 'high_95'\n",
    "    save_path=None):\n",
    "\n",
    "    # Default parameter grid\n",
    "    if param_grid is None:\n",
    "        param_grid = {\n",
    "            'h': [4, 8],\n",
    "            'test_size': [4, 8],\n",
    "            'train_size': [None, 20, 28],\n",
    "            'n_windows': [2, 3, 4],\n",
    "            'step_size': [4],\n",
    "        }\n",
    "    \n",
    "    print(\"=\" * 80); print(f\"SENSITIVITY ANALYSIS WITH EXOGENOUS VARIABLES: {target_col}\")\n",
    "    print(f\"Population Scenario: {population_scenario.upper()}\"); print(f\"Testing {len(list(product(*param_grid.values())))} configurations\")\n",
    "    print(\"=\" * 80); print(\"\\nPhase 1: Loading and preparing data...\")\n",
    "    \n",
    "    df_units, df_prescriptions, df_full = load_data_exog(filepath, states)\n",
    "    df = df_units if target_col == 'Units Reimbursed' else df_prescriptions\n",
    "    target_name = target_col\n",
    "    \n",
    "    print(f\"\\nUnique series: {df['unique_id'].nunique()}\")\n",
    "    print(f\"\\nDate range: {df['ds'].min()} to {df['ds'].max()}\")\n",
    "    print(f\"\\nTotal observations: {len(df)}\")\n",
    "    \n",
    "    # Get population scenarios\n",
    "    pop_scenarios = pop_scenarios_exog(filepath, states)\n",
    "    pop_df = pop_scenarios[population_scenario]\n",
    "    \n",
    "    print(f\"\\nPopulation scenario loaded: {population_scenario}\")\n",
    "    print(f\"\\nPopulation records: {len(pop_df)}\")\n",
    "    \n",
    "    print(\"\\nPhase 2: Running sensitivity analysis...\")\n",
    "    param_names = list(param_grid.keys())\n",
    "    param_values = list(param_grid.values())\n",
    "    combinations = list(product(*param_values))\n",
    "    \n",
    "    all_results = []\n",
    "    all_errors = []  # Simplified error tracking - mean per config\n",
    "    \n",
    "    for i, combo in enumerate(combinations):\n",
    "        params = dict(zip(param_names, combo))\n",
    "        \n",
    "        # Skip invalid combinations\n",
    "        if params.get('test_size') and params.get('h'):\n",
    "            if params['test_size'] < params['h']:\n",
    "                continue\n",
    "        \n",
    "        if params['test_size'] != params['h']:\n",
    "            continue\n",
    "\n",
    "        print(f\"\\n{'â”€' * 80}\"); print(f\"Configuration {i+1}/{len(combinations)}: {params}\"); print('â”€' * 80)\n",
    "        \n",
    "        try:\n",
    "            config = ForecastConfig(\n",
    "                h=params.get('h', 8),\n",
    "                train_size=params.get('train_size'),\n",
    "                test_size=params.get('test_size'),\n",
    "                n_windows=params.get('n_windows', 2),\n",
    "                step_size=params.get('step_size'),\n",
    "                season_length=4,\n",
    "                n_jobs=-1\n",
    "            )\n",
    "            \n",
    "            # Train-Test Evaluation\n",
    "            print(\"\\nRunning train-test evaluation...\")\n",
    "            eval_tt, preds_tt, train_df, test_df = evaluate_train_test_exog(\n",
    "                df, target_name, config, pop_df\n",
    "            )\n",
    "            \n",
    "            # Cross-Validation\n",
    "            print(\"\\nRunning Cross-Validation...\")\n",
    "            eval_cv, cv_df = CV_with_exog(\n",
    "                df, target_name, config, pop_df\n",
    "            )\n",
    "            \n",
    "            exclude_cols = ['unique_id', 'ds', 'y', 'cutoff', 'metric', 'best_model', 'best_value', 'population']\n",
    "            model_cols = [col for col in eval_cv.columns if col not in exclude_cols]\n",
    "            \n",
    "            # Extract MAE results\n",
    "            mae_cv = eval_cv[eval_cv['metric'] == 'mae'].copy()\n",
    "            mae_traintest = eval_tt[eval_tt['metric'] == 'mae'].copy()\n",
    "            \n",
    "            # Add best_model if not present\n",
    "            if 'best_model' not in mae_traintest.columns:\n",
    "                mae_traintest['best_model'] = mae_traintest[model_cols].idxmin(axis=1)\n",
    "            \n",
    "            # Collect Results Per Unique_ID \n",
    "            for uid in df['unique_id'].unique():\n",
    "                uid_cv = mae_cv[mae_cv['unique_id'] == uid]\n",
    "                uid_traintest = mae_traintest[mae_traintest['unique_id'] == uid]\n",
    "                \n",
    "                # CV analysis\n",
    "                cv_best_model = uid_cv['best_model'].mode().iloc[0] if len(uid_cv) > 0 else None\n",
    "                cv_best_count = (uid_cv['best_model'] == cv_best_model).sum()\n",
    "                cv_total = len(uid_cv)\n",
    "                cv_consistency = cv_best_count / cv_total if cv_total > 0 else 0\n",
    "                \n",
    "                # Train-test analysis\n",
    "                traintest_best_model = uid_traintest['best_model'].iloc[0] if len(uid_traintest) > 0 else None\n",
    "                \n",
    "                # Build result row\n",
    "                result_row = {\n",
    "                    'unique_id': uid,\n",
    "                    'config_id': i + 1,\n",
    "                    'population_scenario': population_scenario,\n",
    "                    **params,\n",
    "                    'cv_best_model': cv_best_model,\n",
    "                    'cv_consistency': cv_consistency,\n",
    "                    'traintest_best_model': traintest_best_model,\n",
    "                    'cv_traintest_agree': cv_best_model == traintest_best_model,\n",
    "                }\n",
    "                \n",
    "                # Add MAE values for each model\n",
    "                for model in model_cols:\n",
    "                    cv_mae = uid_cv[model].mean() if len(uid_cv) > 0 else None\n",
    "                    tt_mae = uid_traintest[model].iloc[0] if len(uid_traintest) > 0 and model in uid_traintest.columns else None\n",
    "                    \n",
    "                    result_row[f'{model}_cv_mae'] = cv_mae\n",
    "                    result_row[f'{model}_tt_mae'] = tt_mae\n",
    "                \n",
    "                all_results.append(result_row)\n",
    "                \n",
    "                # One row per unique_id per configuration with MEAN CV MAE and Train-Test MAE\n",
    "                error_row = {\n",
    "                    'config_id': i + 1,\n",
    "                    'unique_id': uid,\n",
    "                    'population_scenario': population_scenario,\n",
    "                    **params,\n",
    "                    'n_cv_windows': cv_total,\n",
    "                }\n",
    "                \n",
    "                # Add mean CV MAE and Train-Test MAE for each model\n",
    "                for model in model_cols:\n",
    "                    # Mean MAE across all CV windows\n",
    "                    cv_mean_mae = uid_cv[model].mean() if len(uid_cv) > 0 else None\n",
    "                    error_row[f'{model}_cv_mean_mae'] = cv_mean_mae\n",
    "                    \n",
    "                    # Train-Test MAE\n",
    "                    tt_mae = uid_traintest[model].iloc[0] if len(uid_traintest) > 0 and model in uid_traintest.columns else None\n",
    "                    error_row[f'{model}_tt_mae'] = tt_mae\n",
    "                \n",
    "                all_errors.append(error_row)\n",
    "            \n",
    "            print(f\"   âœ… Configuration {i+1} completed successfully\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"   âŒ Error in configuration {i+1}: {str(e)}\")\n",
    "            import traceback\n",
    "            traceback.print_exc()\n",
    "            continue\n",
    "    \n",
    "    # Convert to DataFrames\n",
    "    results_df = pd.DataFrame(all_results)\n",
    "    errors_df = pd.DataFrame(all_errors)\n",
    "    \n",
    "    print(f\"\\nâœ… Sensitivity analysis complete!\")\n",
    "    print(f\"\\nTotal configurations tested: {results_df['config_id'].nunique()}\")\n",
    "    print(f\"\\nTotal unique_ids analyzed: {results_df['unique_id'].nunique()}\")\n",
    "    \n",
    "    print(\"\\nPhase 3: Identifying best models per horizon...\")\n",
    "    \n",
    "    recommendations_per_horizon = {}\n",
    "    \n",
    "    for horizon in production_horizons:\n",
    "        print(f\"\\nAnalyzing horizon h={horizon}...\")\n",
    "        \n",
    "        horizon_results = results_df[results_df['h'] == horizon].copy()\n",
    "        \n",
    "        if len(horizon_results) == 0:\n",
    "            print(f\"   âš ï¸ No results for h={horizon}\")\n",
    "            continue\n",
    "        \n",
    "        horizon_recommendations = []\n",
    "        \n",
    "        for uid in horizon_results['unique_id'].unique():\n",
    "            uid_data = horizon_results[horizon_results['unique_id'] == uid]\n",
    "            \n",
    "            # Most frequent CV best model\n",
    "            cv_mode = uid_data['cv_best_model'].mode()\n",
    "            cv_best = cv_mode.iloc[0] if len(cv_mode) > 0 else None\n",
    "            cv_freq = (uid_data['cv_best_model'] == cv_best).sum() / len(uid_data)\n",
    "            \n",
    "            # Most frequent train-test best model\n",
    "            tt_mode = uid_data['traintest_best_model'].mode()\n",
    "            tt_best = tt_mode.iloc[0] if len(tt_mode) > 0 else None\n",
    "            tt_freq = (uid_data['traintest_best_model'] == tt_best).sum() / len(uid_data)\n",
    "            \n",
    "            # Average consistency\n",
    "            avg_consistency = uid_data['cv_consistency'].mean()\n",
    "            \n",
    "            # Determine recommendation\n",
    "            if cv_best == tt_best and cv_freq >= 0.7 and avg_consistency >= 0.7:\n",
    "                confidence = 'High'\n",
    "                recommended_model = cv_best\n",
    "                reason = \"CV and Train-Test agree with high frequency and consistency\"\n",
    "            elif cv_best == tt_best and cv_freq >= 0.5:\n",
    "                confidence = 'Medium-High'\n",
    "                recommended_model = cv_best\n",
    "                reason = \"CV and Train-Test agree with moderate frequency\"\n",
    "            elif cv_freq >= 0.6:\n",
    "                confidence = 'Medium'\n",
    "                recommended_model = cv_best\n",
    "                reason = f\"CV favors {cv_best} ({cv_freq:.0%})\"\n",
    "            elif tt_freq >= 0.6:\n",
    "                confidence = 'Medium'\n",
    "                recommended_model = tt_best\n",
    "                reason = f\"Train-Test favors {tt_best} ({tt_freq:.0%})\"\n",
    "            else:\n",
    "                confidence = 'Low'\n",
    "                # Use lowest average CV MAE\n",
    "                mae_cols = [col for col in uid_data.columns if col.endswith('_cv_mae')]\n",
    "                if mae_cols:\n",
    "                    avg_maes = uid_data[mae_cols].mean()\n",
    "                    recommended_model = avg_maes.idxmin().replace('_cv_mae', '')\n",
    "                else:\n",
    "                    recommended_model = cv_best\n",
    "                reason = \"No clear winner - using lowest average CV MAE\"\n",
    "            \n",
    "            # Get average MAE\n",
    "            rec_mae_col = f'{recommended_model}_cv_mae'\n",
    "            avg_mae = uid_data[rec_mae_col].mean() if rec_mae_col in uid_data.columns else None\n",
    "            \n",
    "            recommendation = {\n",
    "                'unique_id': uid,\n",
    "                'horizon': horizon,\n",
    "                'recommended_model': recommended_model,\n",
    "                'confidence': confidence,\n",
    "                'reason': reason,\n",
    "                'cv_best_model': cv_best,\n",
    "                'cv_frequency': cv_freq,\n",
    "                'cv_consistency': avg_consistency,\n",
    "                'traintest_best_model': tt_best,\n",
    "                'avg_cv_mae': avg_mae,\n",
    "                'population_scenario': population_scenario\n",
    "            }\n",
    "            \n",
    "            horizon_recommendations.append(recommendation)\n",
    "            \n",
    "            mae_display = f\"{avg_mae:,.0f}\" if pd.notna(avg_mae) else \"N/A\"\n",
    "            print(f\"   {uid}: {recommended_model} (confidence: {confidence}, MAE: {mae_display})\")\n",
    "        \n",
    "        recommendations_per_horizon[horizon] = pd.DataFrame(horizon_recommendations)\n",
    "    \n",
    "    print(\"\\nPhase 4: Generating production forecasts...\")\n",
    "    \n",
    "    production_forecasts = {}\n",
    "    \n",
    "    for horizon in production_horizons:\n",
    "        if horizon not in recommendations_per_horizon:\n",
    "            continue\n",
    "        \n",
    "        print(f\"\\nGenerating forecasts for h={horizon}...\")\n",
    "        \n",
    "        recommendations = recommendations_per_horizon[horizon]\n",
    "        \n",
    "        # Configuration for production\n",
    "        config_prod = ForecastConfig(\n",
    "            h=horizon,\n",
    "            season_length=4,\n",
    "            confidence_level=95,\n",
    "            n_jobs=-1\n",
    "        )\n",
    "        \n",
    "        # Train all models on full historical data\n",
    "        models = get_models_exog(config_prod, use_exog=True)\n",
    "        \n",
    "        sf = StatsForecast(\n",
    "            models=models,\n",
    "            freq='QS',\n",
    "            n_jobs=-1,\n",
    "            fallback_model=SeasonalNaive(season_length=4)\n",
    "        )\n",
    "        \n",
    "        # Prepare data with population\n",
    "        pop_historical = pop_df[pop_df['ds'] <= df['ds'].max()].copy()\n",
    "        df_train = df.merge(pop_historical, on=['unique_id', 'ds'], how='left')\n",
    "        \n",
    "        # Fit on historical data\n",
    "        sf.fit(df=df_train[['unique_id', 'ds', 'y', 'population']])\n",
    "        \n",
    "        # Prepare future population\n",
    "        last_date = df['ds'].max()\n",
    "        future_dates = pd.date_range(\n",
    "            start=last_date + pd.DateOffset(months=3),\n",
    "            periods=horizon,\n",
    "            freq='QS'\n",
    "        )\n",
    "        \n",
    "        future_exog_list = []\n",
    "        for uid in df['unique_id'].unique():\n",
    "            for date in future_dates:\n",
    "                pop_val = pop_df[\n",
    "                    (pop_df['unique_id'] == uid) & \n",
    "                    (pop_df['ds'] == date)\n",
    "                ]['population'].values\n",
    "                \n",
    "                if len(pop_val) > 0:\n",
    "                    future_exog_list.append({\n",
    "                        'unique_id': uid,\n",
    "                        'ds': date,\n",
    "                        'population': pop_val[0]\n",
    "                    })\n",
    "        \n",
    "        future_exog_df = pd.DataFrame(future_exog_list)\n",
    "        \n",
    "        # Generate forecasts\n",
    "        forecasts_df = sf.predict(h=horizon, X_df=future_exog_df)\n",
    "        \n",
    "        # Create best model forecasts\n",
    "        best_forecasts = []\n",
    "        \n",
    "        for uid in df['unique_id'].unique():\n",
    "            uid_forecasts = forecasts_df.reset_index()\n",
    "            uid_forecasts = uid_forecasts[uid_forecasts['unique_id'] == uid]\n",
    "            \n",
    "            uid_rec = recommendations[recommendations['unique_id'] == uid]\n",
    "            if len(uid_rec) == 0:\n",
    "                print(f\"   âš ï¸ No recommendation for {uid}, skipping\")\n",
    "                continue\n",
    "            \n",
    "            best_model = uid_rec['recommended_model'].iloc[0]\n",
    "            \n",
    "            for _, row in uid_forecasts.iterrows():\n",
    "                best_row = {\n",
    "                    'unique_id': uid,\n",
    "                    'ds': row['ds'],\n",
    "                    'recommended_model': best_model,\n",
    "                    'forecast': row.get(best_model, np.nan),\n",
    "                    'forecast_lo_95': row.get(f'{best_model}-lo-95', np.nan),\n",
    "                    'forecast_hi_95': row.get(f'{best_model}-hi-95', np.nan),\n",
    "                    'population_scenario': population_scenario\n",
    "                }\n",
    "                best_forecasts.append(best_row)\n",
    "        \n",
    "        best_forecasts_df = pd.DataFrame(best_forecasts)\n",
    "        \n",
    "        production_forecasts[horizon] = {\n",
    "            'all_models': forecasts_df,\n",
    "            'best_model': best_forecasts_df,\n",
    "            'recommendations': recommendations\n",
    "        }\n",
    "        \n",
    "        print(f\"   âœ… Generated {len(best_forecasts_df)} forecast periods\")\n",
    "        print(f\"   âœ… Models used: {recommendations['recommended_model'].value_counts().to_dict()}\")\n",
    "    \n",
    "    print(\"\\nPhase 5: Saving results...\")\n",
    "    \n",
    "    if save_path:\n",
    "        os.makedirs(save_path, exist_ok=True)\n",
    "        \n",
    "        # Save comprehensive results\n",
    "        sensitivity_file = os.path.join(\n",
    "            save_path, \n",
    "            f'{target_name.lower().replace(\" \", \"_\")}_sensitivity_{population_scenario}.xlsx'\n",
    "        )\n",
    "        \n",
    "        with pd.ExcelWriter(sensitivity_file, engine='openpyxl') as writer:\n",
    "            # Sheet 1: All configurations summary\n",
    "            results_df.to_excel(writer, sheet_name='All_Configurations', index=False)\n",
    "            \n",
    "            # Sheet 2: Simplified errors - Mean CV MAE and Train-Test MAE per config\n",
    "            errors_df.to_excel(writer, sheet_name='Model_Errors', index=False)\n",
    "            \n",
    "            # Sheet 3: Recommendations\n",
    "            rec_frames = list(recommendations_per_horizon.values())\n",
    "            if rec_frames:\n",
    "                all_recs = pd.concat(rec_frames, ignore_index=True)\n",
    "                all_recs.to_excel(writer, sheet_name='Recommendations', index=False)\n",
    "            \n",
    "            # Sheet 4: Configuration summary statistics\n",
    "            config_summary = results_df.groupby('config_id').agg({\n",
    "                'cv_traintest_agree': 'mean',\n",
    "                'cv_consistency': 'mean'\n",
    "            }).reset_index()\n",
    "            config_summary.columns = ['config_id', 'avg_cv_tt_agreement', 'avg_cv_consistency']\n",
    "            \n",
    "            # Add parameter details\n",
    "            param_details = results_df.groupby('config_id')[param_names].first().reset_index()\n",
    "            config_summary = config_summary.merge(param_details, on='config_id')\n",
    "            config_summary.to_excel(writer, sheet_name='Config_Summary', index=False)\n",
    "        \n",
    "        print(f\"âœ… Sensitivity analysis saved: {sensitivity_file}\")\n",
    "        \n",
    "        # Save production forecasts\n",
    "        for horizon, forecasts in production_forecasts.items():\n",
    "            horizon_file = os.path.join(\n",
    "                save_path,\n",
    "                f'{target_name.lower().replace(\" \", \"_\")}_production_h{horizon}_{population_scenario}.xlsx'\n",
    "            )\n",
    "            \n",
    "            with pd.ExcelWriter(horizon_file, engine='openpyxl') as writer:\n",
    "                forecasts['all_models'].reset_index().to_excel(\n",
    "                    writer, sheet_name='All_Models', index=False\n",
    "                )\n",
    "                forecasts['best_model'].to_excel(\n",
    "                    writer, sheet_name='Best_Model_Forecast', index=False\n",
    "                )\n",
    "                forecasts['recommendations'].to_excel(\n",
    "                    writer, sheet_name='Model_Selection', index=False\n",
    "                )\n",
    "            \n",
    "            print(f\"âœ… Production forecasts (h={horizon}) saved: {horizon_file}\")\n",
    "    else:\n",
    "        print(\"   âš ï¸ No save_path provided - skipping file export\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"âœ… SENSITIVITY ANALYSIS COMPLETE!\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    return {\n",
    "        'sensitivity_results': results_df,\n",
    "        'model_errors': errors_df,\n",
    "        'production_forecasts': production_forecasts,\n",
    "        'recommendations_per_horizon': recommendations_per_horizon\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "86c7d7b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_top_atc2_forecasts(\n",
    "    df_historical: pd.DataFrame,\n",
    "    df_forecast: pd.DataFrame,\n",
    "    state: str,\n",
    "    target_col: str = 'Units Reimbursed',\n",
    "    model_cols: List[str] = ['SARIMAX', 'Naive'],\n",
    "    top_n: int = 12,\n",
    "    figsize: Tuple[int, int] = (18, 14),\n",
    "    show_ci: bool = True,\n",
    "    save_path: Optional[str] = None\n",
    ") -> plt.Figure:\n",
    "    \"\"\"Plot top N ATC-2 classes with multiple model comparison (max 4).\"\"\"\n",
    "    if len(model_cols) > 4:\n",
    "        model_cols = model_cols[:4]\n",
    "    \n",
    "    df_hist = df_historical.copy()\n",
    "    df_fore = df_forecast.copy()\n",
    "    if 'ds' not in df_fore.columns and 'ds' in df_fore.index.names:\n",
    "        df_fore = df_fore.reset_index()\n",
    "    df_hist['ds'] = pd.to_datetime(df_hist['ds'])\n",
    "    df_fore['ds'] = pd.to_datetime(df_fore['ds'])\n",
    "    df_hist = df_hist[df_hist['unique_id'].str.startswith(f'{state}_')]\n",
    "    df_fore = df_fore[df_fore['unique_id'].str.startswith(f'{state}_')]\n",
    "    \n",
    "    top_classes = df_hist.groupby('unique_id')['y'].sum().sort_values(ascending=False).head(top_n).index.tolist()\n",
    "    n_cols, n_rows = 4, (top_n + 3) // 4\n",
    "    fig, axes = plt.subplots(n_rows, n_cols, figsize=figsize, squeeze=False)\n",
    "    axes = axes.flatten()\n",
    "    \n",
    "    for idx, uid in enumerate(top_classes):\n",
    "        ax = axes[idx]\n",
    "        atc_class = uid.split('_')[1]\n",
    "        hist_data = df_hist[df_hist['unique_id'] == uid].sort_values('ds')\n",
    "        fore_data = df_fore[df_fore['unique_id'] == uid].sort_values('ds')\n",
    "        scale = 1e6 if hist_data['y'].max() > 1e6 else 1e3 if hist_data['y'].max() > 1e3 else 1\n",
    "        scale_label = 'M' if scale == 1e6 else 'K' if scale == 1e3 else ''\n",
    "        \n",
    "        ax.plot(hist_data['ds'], hist_data['y']/scale, color=HISTORICAL_COLOR, lw=1.5, marker='o', ms=2, label='Historical')\n",
    "        last_hist = hist_data.iloc[-1] if len(hist_data) > 0 else None\n",
    "        \n",
    "        for mi, mc in enumerate(model_cols):\n",
    "            if mc not in fore_data.columns or len(fore_data) == 0: continue\n",
    "            color = MODEL_COLORS[mi]\n",
    "            if last_hist is not None:\n",
    "                ax.plot([last_hist['ds'], fore_data['ds'].iloc[0]], [last_hist['y']/scale, fore_data[mc].iloc[0]/scale],\n",
    "                       color=color, lw=1.5, ls='--', alpha=0.7)\n",
    "            ax.plot(fore_data['ds'], fore_data[mc]/scale, color=color, lw=1.5, marker='s', ms=3, ls='--', label=mc)\n",
    "            if show_ci and mi == 0:\n",
    "                lo, hi = f'{mc}-lo-95', f'{mc}-hi-95'\n",
    "                if lo in fore_data.columns and hi in fore_data.columns:\n",
    "                    ax.fill_between(fore_data['ds'], fore_data[lo]/scale, fore_data[hi]/scale, color=color, alpha=0.1)\n",
    "        \n",
    "        if last_hist is not None:\n",
    "            ax.axvline(x=last_hist['ds'], color='gray', ls=':', alpha=0.5)\n",
    "        ax.set_title(f'{atc_class}', fontsize=10, fontweight='bold')\n",
    "        ax.set_ylabel(scale_label)\n",
    "        ax.tick_params(axis='x', rotation=45, labelsize=7)\n",
    "        ax.grid(True, alpha=0.3)\n",
    "        if idx == 0: ax.legend(loc='upper left', fontsize=7)\n",
    "    \n",
    "    for idx in range(len(top_classes), len(axes)):\n",
    "        axes[idx].set_visible(False)\n",
    "    \n",
    "    fig.suptitle(f'{state} - Top {top_n} ATC-2: {target_col}\\nModels: {\", \".join(model_cols)}', fontsize=14, fontweight='bold', y=1.02)\n",
    "    plt.tight_layout()\n",
    "    if save_path:\n",
    "        fig.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "        print(f\"âœ” Saved: {save_path}\")\n",
    "    plt.show()\n",
    "    return fig\n",
    "\n",
    "def plot_single_atc2_forecast(\n",
    "    df_historical: pd.DataFrame,\n",
    "    df_forecast: pd.DataFrame,\n",
    "    state: str,\n",
    "    atc_class: str,\n",
    "    target_col: str = 'Units Reimbursed',\n",
    "    model_cols: List[str] = ['SARIMAX', 'Naive'],\n",
    "    show_ci: bool = True,\n",
    "    figsize: Tuple[int, int] = (14, 7),\n",
    "    save_path: Optional[str] = None\n",
    ") -> plt.Figure:\n",
    "    \"\"\"Detailed plot for single ATC-2 class with multiple models.\"\"\"\n",
    "    if len(model_cols) > 4:\n",
    "        model_cols = model_cols[:4]\n",
    "    \n",
    "    df_hist = df_historical.copy()\n",
    "    df_fore = df_forecast.copy()\n",
    "    if 'ds' not in df_fore.columns and 'ds' in df_fore.index.names:\n",
    "        df_fore = df_fore.reset_index()\n",
    "    df_hist['ds'] = pd.to_datetime(df_hist['ds'])\n",
    "    df_fore['ds'] = pd.to_datetime(df_fore['ds'])\n",
    "    \n",
    "    uid = f'{state}_{atc_class}'\n",
    "    hist_data = df_hist[df_hist['unique_id'] == uid].sort_values('ds')\n",
    "    fore_data = df_fore[df_fore['unique_id'] == uid].sort_values('ds')\n",
    "    \n",
    "    if len(hist_data) == 0:\n",
    "        print(f\"No data for {uid}\")\n",
    "        return None\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=figsize)\n",
    "    scale = 1e6 if hist_data['y'].max() > 1e6 else 1e3 if hist_data['y'].max() > 1e3 else 1\n",
    "    scale_label = 'Millions' if scale == 1e6 else 'Thousands' if scale == 1e3 else ''\n",
    "    \n",
    "    ax.plot(hist_data['ds'], hist_data['y']/scale, color=HISTORICAL_COLOR, lw=2.5, marker='o', ms=5, label='Historical', zorder=10)\n",
    "    last_hist = hist_data.iloc[-1]\n",
    "    \n",
    "    for mi, mc in enumerate(model_cols):\n",
    "        if mc not in fore_data.columns or len(fore_data) == 0:\n",
    "            print(f\"Warning: '{mc}' not found.\")\n",
    "            continue\n",
    "        color = MODEL_COLORS[mi]\n",
    "        ax.plot([last_hist['ds'], fore_data['ds'].iloc[0]], [last_hist['y']/scale, fore_data[mc].iloc[0]/scale],\n",
    "               color=color, lw=2, ls='--', alpha=0.7)\n",
    "        ax.plot(fore_data['ds'], fore_data[mc]/scale, color=color, lw=2, marker='s', ms=6, ls='--', label=mc)\n",
    "        lo, hi = f'{mc}-lo-95', f'{mc}-hi-95'\n",
    "        if show_ci and lo in fore_data.columns and hi in fore_data.columns:\n",
    "            ax.fill_between(fore_data['ds'], fore_data[lo]/scale, fore_data[hi]/scale, color=color, alpha=0.15, label=f'{mc} 95% CI')\n",
    "    \n",
    "    ax.axvline(x=last_hist['ds'], color='gray', ls=':', alpha=0.7, lw=2, label='Forecast Start')\n",
    "    ax.set_xlabel('Year-Quarter', fontsize=12)\n",
    "    ax.set_ylabel(f'{target_col} ({scale_label})', fontsize=12)\n",
    "    ax.set_title(f'{state} - {atc_class}: {target_col}\\nModels: {\", \".join(model_cols)}', fontsize=14, fontweight='bold')\n",
    "    ax.legend(loc='upper left', fontsize=10, ncol=2)\n",
    "    ax.xaxis.set_major_locator(mdates.YearLocator())\n",
    "    ax.xaxis.set_major_formatter(mdates.DateFormatter('%Y'))\n",
    "    ax.tick_params(axis='x', rotation=45)\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    if save_path:\n",
    "        fig.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "        print(f\"âœ” Saved: {save_path}\")\n",
    "    plt.show()\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "21a58b66",
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath_withpop = rf\"C:\\Users\\{user}\\OneDrive - purdue.edu\\VS code\\Data\\ATC\\merged_data\\Prebuilt_panels\\P1_withpop.csv\"\n",
    "save_path = rf\"C:\\Users\\{user}\\OneDrive - purdue.edu\\VS code\\Data\\ATC\\Forecast\\TMF\\\\\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "9a62a5ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n# Configure\\nconfig = ForecastConfig(\\n    h=8,\\n    season_length=4,\\n    n_windows=3,\\n    train_size=None,\\n    test_size=8,  #Setting it to the same h\\n    n_samples=4,\\n    confidence_level=95,\\n    models_to_plot=['Naive', 'SARIMAX']\\n)\\n\\n# Run forecasting for Units Reimbursed with all three population scenarios\\nresults_units = forecast_with_population_scenarios(\\n    filepath=filepath_withpop,\\n    target_col='Units Reimbursed',\\n    states=['IN'],  # Or None for all states\\n    config=config,\\n    horizons=[8],\\n    save_path=save_path\\n)\\n\\n# Run forecasting for Number of Prescriptions\\nresults_prescriptions = forecast_with_population_scenarios(\\n    filepath=filepath_withpop,\\n    target_col='Number of Prescriptions',\\n    states=['IL'],\\n    config=config,\\n    horizons=[8],\\n    save_path=save_path\\n)\\n\""
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "# Configure\n",
    "config = ForecastConfig(\n",
    "    h=8,\n",
    "    season_length=4,\n",
    "    n_windows=3,\n",
    "    train_size=None,\n",
    "    test_size=8,  #Setting it to the same h\n",
    "    n_samples=4,\n",
    "    confidence_level=95,\n",
    "    models_to_plot=['Naive', 'SARIMAX']\n",
    ")\n",
    "\n",
    "# Run forecasting for Units Reimbursed with all three population scenarios\n",
    "results_units = forecast_with_population_scenarios(\n",
    "    filepath=filepath_withpop,\n",
    "    target_col='Units Reimbursed',\n",
    "    states=['IN'],  # Or None for all states\n",
    "    config=config,\n",
    "    horizons=[8],\n",
    "    save_path=save_path\n",
    ")\n",
    "\n",
    "# Run forecasting for Number of Prescriptions\n",
    "results_prescriptions = forecast_with_population_scenarios(\n",
    "    filepath=filepath_withpop,\n",
    "    target_col='Number of Prescriptions',\n",
    "    states=['IL'],\n",
    "    config=config,\n",
    "    horizons=[8],\n",
    "    save_path=save_path\n",
    ")\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "db51035e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "SENSITIVITY ANALYSIS WITH EXOGENOUS VARIABLES: Number of Prescriptions\n",
      "Population Scenario: POINT\n",
      "Testing 4 configurations\n",
      "================================================================================\n",
      "\n",
      "Phase 1: Loading and preparing data...\n",
      "Filtering data for states: ['MI']\n",
      "Filtered to 2663 rows across ['MI'] state(s)\n",
      "\n",
      "Unique series: 84\n",
      "\n",
      "Date range: 2017-01-01 00:00:00 to 2024-10-01 00:00:00\n",
      "\n",
      "Total observations: 2663\n",
      "   point: 672 future population records\n",
      "   low_95: 672 future population records\n",
      "   high_95: 672 future population records\n",
      "\n",
      "Population scenario loaded: point\n",
      "\n",
      "Population records: 3335\n",
      "\n",
      "Phase 2: Running sensitivity analysis...\n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "Configuration 1/4: {'h': 4, 'train_size': None, 'n_windows': 2, 'step_size': 4, 'test_size': 4}\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "\n",
      "Running train-test evaluation...\n",
      "\n",
      "ðŸ“ˆ Best Models (Train-Test Split - Number of Prescriptions (with population)):\n",
      "best_model\n",
      "Naive              29\n",
      "HistoricAverage    20\n",
      "SARIMAX            12\n",
      "SeasonalNaive      10\n",
      "WindowAverage       7\n",
      "ARIMAX              6\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Running Cross-Validation...\n",
      "   Running cross-validation...\n",
      "\n",
      "   Cutoff 2022-10-01 (MAE best models):\n",
      "   {'Naive': 32, 'HistoricAverage': 21, 'SARIMAX': 10, 'WindowAverage': 8, 'SeasonalNaive': 6, 'ARIMAX': 5}\n",
      "\n",
      "   Cutoff 2023-10-01 (MAE best models):\n",
      "   {'Naive': 28, 'HistoricAverage': 20, 'SARIMAX': 12, 'SeasonalNaive': 10, 'ARIMAX': 6, 'WindowAverage': 6}\n",
      "\n",
      "   Cutoff 2020-04-01 (MAE best models):\n",
      "   {'SeasonalNaive': 1}\n",
      "\n",
      "   Cutoff 2021-07-01 (MAE best models):\n",
      "   {'Naive': 1}\n",
      "\n",
      "   Cutoff 2020-10-01 (MAE best models):\n",
      "   {'HistoricAverage': 1}\n",
      "\n",
      "   Cutoff 2021-10-01 (MAE best models):\n",
      "   {'HistoricAverage': 1}\n",
      "\n",
      "ðŸ“ˆ Overall Best Models (with population):\n",
      "best_model\n",
      "Naive              61\n",
      "HistoricAverage    43\n",
      "SARIMAX            22\n",
      "SeasonalNaive      17\n",
      "WindowAverage      14\n",
      "ARIMAX             11\n",
      "Name: count, dtype: int64\n",
      "   âœ… Configuration 1 completed successfully\n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "Configuration 4/4: {'h': 8, 'train_size': None, 'n_windows': 2, 'step_size': 4, 'test_size': 8}\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "\n",
      "Running train-test evaluation...\n",
      "\n",
      "ðŸ“ˆ Best Models (Train-Test Split - Number of Prescriptions (with population)):\n",
      "best_model\n",
      "HistoricAverage    25\n",
      "Naive              24\n",
      "SARIMAX            14\n",
      "WindowAverage      11\n",
      "SeasonalNaive       6\n",
      "ARIMAX              4\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Running Cross-Validation...\n",
      "   Running cross-validation...\n",
      "\n",
      "   Cutoff 2021-10-01 (MAE best models):\n",
      "   {'Naive': 27, 'SARIMAX': 16, 'HistoricAverage': 15, 'WindowAverage': 10, 'SeasonalNaive': 9, 'ARIMAX': 5}\n",
      "\n",
      "   Cutoff 2022-10-01 (MAE best models):\n",
      "   {'HistoricAverage': 24, 'Naive': 23, 'SARIMAX': 14, 'WindowAverage': 11, 'SeasonalNaive': 6, 'ARIMAX': 4}\n",
      "\n",
      "   Cutoff 2019-04-01 (MAE best models):\n",
      "   {'Naive': 1}\n",
      "\n",
      "   Cutoff 2020-04-01 (MAE best models):\n",
      "   {'Naive': 1}\n",
      "\n",
      "   Cutoff 2019-10-01 (MAE best models):\n",
      "   {'ARIMAX': 1}\n",
      "\n",
      "   Cutoff 2020-10-01 (MAE best models):\n",
      "   {'HistoricAverage': 1}\n",
      "\n",
      "ðŸ“ˆ Overall Best Models (with population):\n",
      "best_model\n",
      "Naive              52\n",
      "HistoricAverage    40\n",
      "SARIMAX            30\n",
      "WindowAverage      21\n",
      "SeasonalNaive      15\n",
      "ARIMAX             10\n",
      "Name: count, dtype: int64\n",
      "   âœ… Configuration 4 completed successfully\n",
      "\n",
      "âœ… Sensitivity analysis complete!\n",
      "\n",
      "Total configurations tested: 2\n",
      "\n",
      "Total unique_ids analyzed: 84\n",
      "\n",
      "Phase 3: Identifying best models per horizon...\n",
      "\n",
      "Analyzing horizon h=4...\n",
      "   MI_A01: HistoricAverage (confidence: Medium-High, MAE: 62,124)\n",
      "   MI_A02: Naive (confidence: Medium-High, MAE: 20,809)\n",
      "   MI_A03: HistoricAverage (confidence: Medium, MAE: 1,524)\n",
      "   MI_A04: Naive (confidence: Medium, MAE: 10,353)\n",
      "   MI_A05: Naive (confidence: High, MAE: 64)\n",
      "   MI_A06: ARIMAX (confidence: Medium, MAE: 2,062)\n",
      "   MI_A07: Naive (confidence: Medium, MAE: 24,562)\n",
      "   MI_A08: Naive (confidence: High, MAE: 311)\n",
      "   MI_A09: SARIMAX (confidence: Medium, MAE: 186)\n",
      "   MI_A10: Naive (confidence: Medium, MAE: 18,152)\n",
      "   MI_A11: Naive (confidence: Medium, MAE: 9,302)\n",
      "   MI_A12: ARIMAX (confidence: Medium-High, MAE: 11,059)\n",
      "   MI_A16: HistoricAverage (confidence: Medium-High, MAE: 154)\n",
      "   MI_B01: HistoricAverage (confidence: Medium-High, MAE: 15,056)\n",
      "   MI_B02: HistoricAverage (confidence: Medium-High, MAE: 1,952)\n",
      "   MI_B03: HistoricAverage (confidence: Medium, MAE: 19,602)\n",
      "   MI_B05: ARIMAX (confidence: Medium-High, MAE: 8,892)\n",
      "   MI_B06: HistoricAverage (confidence: High, MAE: 229)\n",
      "   MI_C01: Naive (confidence: Medium-High, MAE: 20,208)\n",
      "   MI_C02: HistoricAverage (confidence: Medium-High, MAE: 8,930)\n",
      "   MI_C03: Naive (confidence: High, MAE: 7,318)\n",
      "   MI_C04: Naive (confidence: Medium, MAE: 44)\n",
      "   MI_C05: HistoricAverage (confidence: Medium, MAE: 7,406)\n",
      "   MI_C07: Naive (confidence: High, MAE: 8,208)\n",
      "   MI_C08: Naive (confidence: High, MAE: 5,450)\n",
      "   MI_C09: Naive (confidence: High, MAE: 16,443)\n",
      "   MI_C10: HistoricAverage (confidence: Medium-High, MAE: 21,461)\n",
      "   MI_D01: HistoricAverage (confidence: Medium-High, MAE: 15,297)\n",
      "   MI_D02: SARIMAX (confidence: High, MAE: 1,322)\n",
      "   MI_D03: Naive (confidence: Medium, MAE: 137)\n",
      "   MI_D04: SARIMAX (confidence: High, MAE: 5,932)\n",
      "   MI_D05: SeasonalNaive (confidence: Medium, MAE: 750)\n",
      "   MI_D06: HistoricAverage (confidence: Medium, MAE: 11,683)\n",
      "   MI_D07: WindowAverage (confidence: High, MAE: 34,851)\n",
      "   MI_D08: Naive (confidence: Medium-High, MAE: 3,640)\n",
      "   MI_D10: ARIMAX (confidence: Medium-High, MAE: 14,493)\n",
      "   MI_D11: ARIMAX (confidence: Medium, MAE: 6,744)\n",
      "   MI_G01: HistoricAverage (confidence: Medium, MAE: 16,623)\n",
      "   MI_G02: HistoricAverage (confidence: Medium, MAE: 28,845)\n",
      "   MI_G03: HistoricAverage (confidence: Medium-High, MAE: 11,973)\n",
      "   MI_G04: HistoricAverage (confidence: Medium-High, MAE: 4,522)\n",
      "   MI_H01: Naive (confidence: Medium-High, MAE: 188)\n",
      "   MI_H02: HistoricAverage (confidence: Medium-High, MAE: 26,311)\n",
      "   MI_H03: Naive (confidence: Medium-High, MAE: 8,215)\n",
      "   MI_H04: SeasonalNaive (confidence: High, MAE: 159)\n",
      "   MI_H05: Naive (confidence: Medium-High, MAE: 59)\n",
      "   MI_J01: Naive (confidence: Medium, MAE: 67,513)\n",
      "   MI_J02: HistoricAverage (confidence: Medium-High, MAE: 13,944)\n",
      "   MI_J04: Naive (confidence: High, MAE: 75)\n",
      "   MI_J05: ARIMAX (confidence: Medium, MAE: 8,509)\n",
      "   MI_J06: ARIMAX (confidence: High, MAE: 455)\n",
      "   MI_J07: HistoricAverage (confidence: Medium, MAE: 907)\n",
      "   MI_L01: WindowAverage (confidence: High, MAE: 1,809)\n",
      "   MI_L02: Naive (confidence: Medium, MAE: 5,717)\n",
      "   MI_L03: Naive (confidence: Medium-High, MAE: 168)\n",
      "   MI_L04: Naive (confidence: High, MAE: 1,243)\n",
      "   MI_M01: HistoricAverage (confidence: Medium, MAE: 23,042)\n",
      "   MI_M02: HistoricAverage (confidence: Medium-High, MAE: 65,020)\n",
      "   MI_M03: HistoricAverage (confidence: Medium-High, MAE: 9,535)\n",
      "   MI_M04: HistoricAverage (confidence: Medium-High, MAE: 1,407)\n",
      "   MI_M05: Naive (confidence: Medium-High, MAE: 441)\n",
      "   MI_M09: Naive (confidence: Medium, MAE: 33)\n",
      "   MI_N01: Naive (confidence: High, MAE: 1,210)\n",
      "   MI_N02: HistoricAverage (confidence: High, MAE: 28,402)\n",
      "   MI_N03: Naive (confidence: Medium-High, MAE: 8,571)\n",
      "   MI_N04: Naive (confidence: High, MAE: 1,616)\n",
      "   MI_N05: Naive (confidence: Medium, MAE: 20,462)\n",
      "   MI_N06: HistoricAverage (confidence: Medium-High, MAE: 66,227)\n",
      "   MI_N07: Naive (confidence: Medium, MAE: 7,080)\n",
      "   MI_P01: HistoricAverage (confidence: Medium, MAE: 6,407)\n",
      "   MI_P02: HistoricAverage (confidence: Medium, MAE: 130)\n",
      "   MI_P03: Naive (confidence: High, MAE: 775)\n",
      "   MI_R01: HistoricAverage (confidence: Medium, MAE: 37,902)\n",
      "   MI_R02: HistoricAverage (confidence: High, MAE: 25,408)\n",
      "   MI_R03: HistoricAverage (confidence: High, MAE: 35,288)\n",
      "   MI_R05: ARIMAX (confidence: Medium-High, MAE: 19,540)\n",
      "   MI_R06: ARIMAX (confidence: Medium-High, MAE: 12,666)\n",
      "   MI_R07: SeasonalNaive (confidence: High, MAE: 28)\n",
      "   MI_S01: HistoricAverage (confidence: Medium, MAE: 21,420)\n",
      "   MI_S02: HistoricAverage (confidence: Medium, MAE: 5,339)\n",
      "   MI_S03: HistoricAverage (confidence: Medium, MAE: 4,895)\n",
      "   MI_V03: ARIMAX (confidence: Medium, MAE: 20,156)\n",
      "   MI_V04: HistoricAverage (confidence: High, MAE: 8,704)\n",
      "   MI_V07: Naive (confidence: High, MAE: 89)\n",
      "\n",
      "Analyzing horizon h=8...\n",
      "   MI_A01: Naive (confidence: Medium-High, MAE: 52,558)\n",
      "   MI_A02: Naive (confidence: Medium, MAE: 31,740)\n",
      "   MI_A03: HistoricAverage (confidence: Medium-High, MAE: 2,736)\n",
      "   MI_A04: Naive (confidence: High, MAE: 13,141)\n",
      "   MI_A05: SARIMAX (confidence: Medium, MAE: 110)\n",
      "   MI_A06: ARIMAX (confidence: Medium-High, MAE: 24,611)\n",
      "   MI_A07: SARIMAX (confidence: Medium-High, MAE: 16,919)\n",
      "   MI_A08: Naive (confidence: Medium-High, MAE: 998)\n",
      "   MI_A09: Naive (confidence: Medium-High, MAE: 142)\n",
      "   MI_A10: Naive (confidence: Medium-High, MAE: 18,346)\n",
      "   MI_A11: Naive (confidence: High, MAE: 8,498)\n",
      "   MI_A12: ARIMAX (confidence: Medium, MAE: 12,014)\n",
      "   MI_A16: Naive (confidence: Medium, MAE: 107)\n",
      "   MI_B01: HistoricAverage (confidence: Medium, MAE: 14,359)\n",
      "   MI_B02: SARIMAX (confidence: Medium-High, MAE: 1,984)\n",
      "   MI_B03: SARIMAX (confidence: Medium, MAE: 13,849)\n",
      "   MI_B05: HistoricAverage (confidence: Medium-High, MAE: 9,652)\n",
      "   MI_B06: HistoricAverage (confidence: Medium-High, MAE: 263)\n",
      "   MI_C01: HistoricAverage (confidence: High, MAE: 15,827)\n",
      "   MI_C02: HistoricAverage (confidence: Medium, MAE: 8,322)\n",
      "   MI_C03: HistoricAverage (confidence: Medium, MAE: 26,737)\n",
      "   MI_C04: Naive (confidence: High, MAE: 53)\n",
      "   MI_C05: HistoricAverage (confidence: Medium-High, MAE: 7,163)\n",
      "   MI_C07: Naive (confidence: High, MAE: 13,450)\n",
      "   MI_C08: Naive (confidence: High, MAE: 10,885)\n",
      "   MI_C09: Naive (confidence: High, MAE: 16,039)\n",
      "   MI_C10: HistoricAverage (confidence: Medium-High, MAE: 25,324)\n",
      "   MI_D01: Naive (confidence: High, MAE: 10,490)\n",
      "   MI_D02: SARIMAX (confidence: High, MAE: 1,312)\n",
      "   MI_D03: Naive (confidence: High, MAE: 212)\n",
      "   MI_D04: SARIMAX (confidence: High, MAE: 4,459)\n",
      "   MI_D05: SARIMAX (confidence: Medium, MAE: 1,070)\n",
      "   MI_D06: HistoricAverage (confidence: High, MAE: 12,944)\n",
      "   MI_D07: SARIMAX (confidence: Medium, MAE: 42,447)\n",
      "   MI_D08: HistoricAverage (confidence: Medium, MAE: 4,351)\n",
      "   MI_D10: SARIMAX (confidence: High, MAE: 12,563)\n",
      "   MI_D11: Naive (confidence: Medium, MAE: 7,379)\n",
      "   MI_G01: HistoricAverage (confidence: High, MAE: 12,528)\n",
      "   MI_G02: HistoricAverage (confidence: Medium-High, MAE: 37,937)\n",
      "   MI_G03: HistoricAverage (confidence: Medium-High, MAE: 14,344)\n",
      "   MI_G04: Naive (confidence: Medium, MAE: 3,626)\n",
      "   MI_H01: HistoricAverage (confidence: High, MAE: 174)\n",
      "   MI_H02: HistoricAverage (confidence: Medium, MAE: 21,044)\n",
      "   MI_H03: Naive (confidence: High, MAE: 8,522)\n",
      "   MI_H04: SARIMAX (confidence: Medium, MAE: 367)\n",
      "   MI_H05: Naive (confidence: Medium, MAE: 57)\n",
      "   MI_J01: Naive (confidence: High, MAE: 56,594)\n",
      "   MI_J02: Naive (confidence: Medium, MAE: 9,562)\n",
      "   MI_J04: Naive (confidence: Medium, MAE: 83)\n",
      "   MI_J05: ARIMAX (confidence: High, MAE: 7,063)\n",
      "   MI_J06: ARIMAX (confidence: Medium-High, MAE: 411)\n",
      "   MI_J07: ARIMAX (confidence: Medium, MAE: 818)\n",
      "   MI_L01: Naive (confidence: High, MAE: 2,490)\n",
      "   MI_L02: Naive (confidence: Medium-High, MAE: 7,154)\n",
      "   MI_L03: Naive (confidence: Medium-High, MAE: 262)\n",
      "   MI_L04: Naive (confidence: Medium, MAE: 3,512)\n",
      "   MI_M01: HistoricAverage (confidence: High, MAE: 21,618)\n",
      "   MI_M02: SARIMAX (confidence: Medium-High, MAE: 74,841)\n",
      "   MI_M03: SARIMAX (confidence: Medium-High, MAE: 9,143)\n",
      "   MI_M04: HistoricAverage (confidence: High, MAE: 1,633)\n",
      "   MI_M05: HistoricAverage (confidence: High, MAE: 332)\n",
      "   MI_M09: ARIMAX (confidence: Medium, MAE: 40)\n",
      "   MI_N01: Naive (confidence: Medium-High, MAE: 1,377)\n",
      "   MI_N02: ARIMAX (confidence: Medium, MAE: 63,286)\n",
      "   MI_N03: HistoricAverage (confidence: Medium-High, MAE: 9,594)\n",
      "   MI_N04: Naive (confidence: Medium-High, MAE: 2,648)\n",
      "   MI_N05: SeasonalNaive (confidence: Medium, MAE: 23,800)\n",
      "   MI_N06: HistoricAverage (confidence: Medium-High, MAE: 79,280)\n",
      "   MI_N07: Naive (confidence: Medium-High, MAE: 10,918)\n",
      "   MI_P01: Naive (confidence: Medium-High, MAE: 5,662)\n",
      "   MI_P02: Naive (confidence: Medium, MAE: 164)\n",
      "   MI_P03: SARIMAX (confidence: Medium-High, MAE: 488)\n",
      "   MI_R01: HistoricAverage (confidence: High, MAE: 43,892)\n",
      "   MI_R02: HistoricAverage (confidence: High, MAE: 27,107)\n",
      "   MI_R03: Naive (confidence: Medium-High, MAE: 38,836)\n",
      "   MI_R05: ARIMAX (confidence: Medium, MAE: 15,736)\n",
      "   MI_R06: SARIMAX (confidence: High, MAE: 15,607)\n",
      "   MI_R07: Naive (confidence: Medium, MAE: 74)\n",
      "   MI_S01: HistoricAverage (confidence: Medium-High, MAE: 29,395)\n",
      "   MI_S02: HistoricAverage (confidence: Medium-High, MAE: 6,237)\n",
      "   MI_S03: HistoricAverage (confidence: High, MAE: 4,564)\n",
      "   MI_V03: ARIMAX (confidence: Medium-High, MAE: 26,431)\n",
      "   MI_V04: HistoricAverage (confidence: Medium-High, MAE: 10,475)\n",
      "   MI_V07: WindowAverage (confidence: High, MAE: 72)\n",
      "\n",
      "Phase 4: Generating production forecasts...\n",
      "\n",
      "Generating forecasts for h=4...\n",
      "   âœ… Generated 336 forecast periods\n",
      "   âœ… Models used: {'HistoricAverage': 34, 'Naive': 32, 'ARIMAX': 10, 'SARIMAX': 3, 'SeasonalNaive': 3, 'WindowAverage': 2}\n",
      "\n",
      "Generating forecasts for h=8...\n",
      "   âœ… Generated 672 forecast periods\n",
      "   âœ… Models used: {'Naive': 32, 'HistoricAverage': 27, 'SARIMAX': 14, 'ARIMAX': 9, 'SeasonalNaive': 1, 'WindowAverage': 1}\n",
      "\n",
      "Phase 5: Saving results...\n",
      "âœ… Sensitivity analysis saved: C:\\Users\\Lilian\\OneDrive - purdue.edu\\VS code\\Data\\ATC\\Forecast\\TMF\\\\number_of_prescriptions_sensitivity_point.xlsx\n",
      "âœ… Production forecasts (h=4) saved: C:\\Users\\Lilian\\OneDrive - purdue.edu\\VS code\\Data\\ATC\\Forecast\\TMF\\\\number_of_prescriptions_production_h4_point.xlsx\n",
      "âœ… Production forecasts (h=8) saved: C:\\Users\\Lilian\\OneDrive - purdue.edu\\VS code\\Data\\ATC\\Forecast\\TMF\\\\number_of_prescriptions_production_h8_point.xlsx\n",
      "\n",
      "================================================================================\n",
      "âœ… SENSITIVITY ANALYSIS COMPLETE!\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "results = sensitivity_analysis_with_exog(\n",
    "    filepath=filepath_withpop,\n",
    "    target_col='Number of Prescriptions',\n",
    "    states=['MI'],\n",
    "    param_grid={\n",
    "        'h': [4, 8],\n",
    "        'train_size': [None], #Training all the dataset for Cross-Validation, otherwise the n_windows will be too small\n",
    "        'n_windows': [2],\n",
    "        'step_size': [4],\n",
    "        'test_size': [4, 8],  #Setting it to the same as h\n",
    "    },\n",
    "    production_horizons=[4, 8],\n",
    "    population_scenario='point',  # 'point' or 'low_95' or 'high_95'\n",
    "    save_path=save_path\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fd84c84",
   "metadata": {},
   "source": [
    "### Visualization and Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d2de9c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set style\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (14, 8)\n",
    "plt.rcParams['font.size'] = 11\n",
    "plt.rcParams['axes.titlesize'] = 14\n",
    "plt.rcParams['axes.labelsize'] = 12\n",
    "\n",
    "# Color palette for statistical models\n",
    "STATS_MODEL_COLORS = {\n",
    "    'SARIMAX': '#2E86AB',\n",
    "    'ARIMAX': '#E94F37',\n",
    "    'AutoARIMA': '#28A745',\n",
    "    'SeasonalNaive': '#9B59B6',\n",
    "    'Naive': '#F39C12',\n",
    "    'HistoricAverage': '#1ABC9C',\n",
    "    'WindowAverage': '#E74C3C',\n",
    "    'DOT': '#3498DB',\n",
    "    'HoltWinters': '#8E44AD',\n",
    "}\n",
    "\n",
    "# Extract results from sensitivity analysis\n",
    "sensitivity_results = results['sensitivity_results']\n",
    "errors_df = results['model_errors']\n",
    "recommendations_per_horizon = results['recommendations_per_horizon']\n",
    "\n",
    "# IMPORTANT: Extract model names from column names\n",
    "# Columns are like: SARIMAX_cv_mean_mae, Naive_tt_mae, etc.\n",
    "cv_mae_cols = [col for col in errors_df.columns if col.endswith('_cv_mean_mae')]\n",
    "tt_mae_cols = [col for col in errors_df.columns if col.endswith('_tt_mae')]\n",
    "\n",
    "# Extract model names\n",
    "stats_model_names = [col.replace('_cv_mean_mae', '') for col in cv_mae_cols]\n",
    "print(f\"\\nâœ“ Detected models: {stats_model_names}\")\n",
    "\n",
    "# Get recommendations for the primary horizon\n",
    "primary_horizon = 8\n",
    "if primary_horizon in recommendations_per_horizon:\n",
    "    stats_recommendations_df = recommendations_per_horizon[primary_horizon]\n",
    "else:\n",
    "    primary_horizon = list(recommendations_per_horizon.keys())[0]\n",
    "    stats_recommendations_df = recommendations_per_horizon[primary_horizon]\n",
    "\n",
    "print(f\"âœ“ Loaded recommendations for horizon={primary_horizon}\")\n",
    "print(f\"âœ“ Total series: {len(stats_recommendations_df)}\")\n",
    "print(f\"âœ“ errors_df shape: {errors_df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c898479",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Calculate mean CV MAE for each model across all series\n",
    "cv_means = {}\n",
    "cv_stds = {}\n",
    "tt_means = {}\n",
    "tt_stds = {}\n",
    "\n",
    "for model in stats_model_names:\n",
    "    cv_col = f'{model}_cv_mean_mae'\n",
    "    tt_col = f'{model}_tt_mae'\n",
    "    \n",
    "    if cv_col in errors_df.columns:\n",
    "        cv_means[model] = errors_df[cv_col].mean()\n",
    "        cv_stds[model] = errors_df[cv_col].std()\n",
    "    \n",
    "    if tt_col in errors_df.columns:\n",
    "        tt_means[model] = errors_df[tt_col].mean()\n",
    "        tt_stds[model] = errors_df[tt_col].std()\n",
    "\n",
    "# Sort by CV MAE\n",
    "cv_sorted = dict(sorted(cv_means.items(), key=lambda x: x[1]))\n",
    "tt_sorted = dict(sorted(tt_means.items(), key=lambda x: x[1]))\n",
    "\n",
    "# CV MAE Chart\n",
    "ax1 = axes[0]\n",
    "models_cv = list(cv_sorted.keys())\n",
    "values_cv = list(cv_sorted.values())\n",
    "errors_cv = [cv_stds[m] for m in models_cv]\n",
    "colors_cv = [STATS_MODEL_COLORS.get(m, '#666666') for m in models_cv]\n",
    "\n",
    "bars1 = ax1.barh(models_cv, values_cv, xerr=errors_cv, color=colors_cv, \n",
    "                  capsize=5, alpha=0.8, edgecolor='white', linewidth=1.5)\n",
    "ax1.set_xlabel('Mean CV MAE')\n",
    "ax1.set_title('Average CV MAE by Model\\n(Lower is Better)', fontweight='bold')\n",
    "ax1.axvline(x=min(values_cv), color='green', linestyle='--', alpha=0.5, \n",
    "            label=f'Best: {min(values_cv):,.0f}')\n",
    "\n",
    "for bar, val in zip(bars1, values_cv):\n",
    "    ax1.text(val + max(errors_cv)*0.1, bar.get_y() + bar.get_height()/2,\n",
    "             f'{val:,.0f}', va='center', fontsize=10)\n",
    "ax1.legend()\n",
    "\n",
    "# Train-Test MAE Chart\n",
    "ax2 = axes[1]\n",
    "models_tt = list(tt_sorted.keys())\n",
    "values_tt = list(tt_sorted.values())\n",
    "errors_tt = [tt_stds[m] for m in models_tt]\n",
    "colors_tt = [STATS_MODEL_COLORS.get(m, '#666666') for m in models_tt]\n",
    "\n",
    "bars2 = ax2.barh(models_tt, values_tt, xerr=errors_tt, color=colors_tt,\n",
    "                  capsize=5, alpha=0.8, edgecolor='white', linewidth=1.5)\n",
    "ax2.set_xlabel('Mean Train-Test MAE')\n",
    "ax2.set_title('Average Train-Test MAE by Model\\n(Lower is Better)', fontweight='bold')\n",
    "ax2.axvline(x=min(values_tt), color='green', linestyle='--', alpha=0.5,\n",
    "            label=f'Best: {min(values_tt):,.0f}')\n",
    "\n",
    "for bar, val in zip(bars2, values_tt):\n",
    "    ax2.text(val + max(errors_tt)*0.1, bar.get_y() + bar.get_height()/2,\n",
    "             f'{val:,.0f}', va='center', fontsize=10)\n",
    "ax2.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(save_path, 'stats_model_performance_overview.png'), dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "print(\"\\nâœ“ Saved: stats_model_performance_overview.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f34eaff",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"STATISTICAL MODEL PERFORMANCE STATISTICS\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Build statistics table\n",
    "stats_data = []\n",
    "for model in stats_model_names:\n",
    "    cv_col = f'{model}_cv_mean_mae'\n",
    "    tt_col = f'{model}_tt_mae'\n",
    "    \n",
    "    row = {'Model': model}\n",
    "    \n",
    "    if cv_col in errors_df.columns:\n",
    "        cv_vals = errors_df[cv_col].dropna()\n",
    "        row['CV_MAE_Mean'] = cv_vals.mean()\n",
    "        row['CV_MAE_Median'] = cv_vals.median()\n",
    "        row['CV_MAE_Std'] = cv_vals.std()\n",
    "        row['CV_MAE_Min'] = cv_vals.min()\n",
    "        row['CV_MAE_Max'] = cv_vals.max()\n",
    "    \n",
    "    if tt_col in errors_df.columns:\n",
    "        tt_vals = errors_df[tt_col].dropna()\n",
    "        row['TT_MAE_Mean'] = tt_vals.mean()\n",
    "        row['TT_MAE_Median'] = tt_vals.median()\n",
    "        row['TT_MAE_Std'] = tt_vals.std()\n",
    "        row['TT_MAE_Min'] = tt_vals.min()\n",
    "        row['TT_MAE_Max'] = tt_vals.max()\n",
    "    \n",
    "    stats_data.append(row)\n",
    "\n",
    "stats_summary = pd.DataFrame(stats_data)\n",
    "\n",
    "print(\"\\nðŸ“Š Cross-Validation MAE Statistics:\")\n",
    "print(\"-\" * 90)\n",
    "print(f\"{'Model':<20} {'Mean':>12} {'Median':>12} {'Std':>12} {'Min':>12} {'Max':>12}\")\n",
    "print(\"-\" * 90)\n",
    "for _, row in stats_summary.sort_values('CV_MAE_Mean').iterrows():\n",
    "    print(f\"{row['Model']:<20} {row['CV_MAE_Mean']:>12,.0f} {row['CV_MAE_Median']:>12,.0f} \"\n",
    "          f\"{row['CV_MAE_Std']:>12,.0f} {row['CV_MAE_Min']:>12,.0f} {row['CV_MAE_Max']:>12,.0f}\")\n",
    "\n",
    "print(\"\\nðŸ“Š Train-Test MAE Statistics:\")\n",
    "print(\"-\" * 90)\n",
    "print(f\"{'Model':<20} {'Mean':>12} {'Median':>12} {'Std':>12} {'Min':>12} {'Max':>12}\")\n",
    "print(\"-\" * 90)\n",
    "for _, row in stats_summary.sort_values('TT_MAE_Mean').iterrows():\n",
    "    print(f\"{row['Model']:<20} {row['TT_MAE_Mean']:>12,.0f} {row['TT_MAE_Median']:>12,.0f} \"\n",
    "          f\"{row['TT_MAE_Std']:>12,.0f} {row['TT_MAE_Min']:>12,.0f} {row['TT_MAE_Max']:>12,.0f}\")\n",
    "\n",
    "stats_summary.to_csv(os.path.join(save_path, 'stats_model_statistics.csv'), index=False)\n",
    "print(\"\\nâœ“ Saved: stats_model_statistics.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dae36a11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape data for box plots (wide to long format)\n",
    "cv_data_long = []\n",
    "tt_data_long = []\n",
    "\n",
    "for model in stats_model_names:\n",
    "    cv_col = f'{model}_cv_mean_mae'\n",
    "    tt_col = f'{model}_tt_mae'\n",
    "    \n",
    "    if cv_col in errors_df.columns:\n",
    "        for val in errors_df[cv_col].dropna():\n",
    "            cv_data_long.append({'Model': model, 'CV_MAE': val})\n",
    "    \n",
    "    if tt_col in errors_df.columns:\n",
    "        for val in errors_df[tt_col].dropna():\n",
    "            tt_data_long.append({'Model': model, 'TT_MAE': val})\n",
    "\n",
    "cv_long_df = pd.DataFrame(cv_data_long)\n",
    "tt_long_df = pd.DataFrame(tt_data_long)\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
    "\n",
    "# Sort by median\n",
    "model_order_cv = cv_long_df.groupby('Model')['CV_MAE'].median().sort_values().index.tolist()\n",
    "model_order_tt = tt_long_df.groupby('Model')['TT_MAE'].median().sort_values().index.tolist()\n",
    "\n",
    "# CV MAE Box Plot\n",
    "ax1 = axes[0]\n",
    "palette_cv = [STATS_MODEL_COLORS.get(m, '#666666') for m in model_order_cv]\n",
    "sns.boxplot(data=cv_long_df, x='Model', y='CV_MAE', order=model_order_cv,\n",
    "            palette=palette_cv, ax=ax1, showfliers=True, flierprops={'alpha': 0.5})\n",
    "ax1.set_title('CV MAE Distribution by Model\\n(Sorted by Median)', fontweight='bold')\n",
    "ax1.set_ylabel('CV MAE')\n",
    "ax1.tick_params(axis='x', rotation=30)\n",
    "\n",
    "# Add median labels\n",
    "medians_cv = cv_long_df.groupby('Model')['CV_MAE'].median()[model_order_cv]\n",
    "for i, (model, median) in enumerate(medians_cv.items()):\n",
    "    ax1.annotate(f'{median:,.0f}', xy=(i, median), xytext=(0, 5),\n",
    "                 textcoords='offset points', ha='center', fontsize=9, fontweight='bold')\n",
    "\n",
    "# Train-Test MAE Box Plot\n",
    "ax2 = axes[1]\n",
    "palette_tt = [STATS_MODEL_COLORS.get(m, '#666666') for m in model_order_tt]\n",
    "sns.boxplot(data=tt_long_df, x='Model', y='TT_MAE', order=model_order_tt,\n",
    "            palette=palette_tt, ax=ax2, showfliers=True, flierprops={'alpha': 0.5})\n",
    "ax2.set_title('Train-Test MAE Distribution by Model\\n(Sorted by Median)', fontweight='bold')\n",
    "ax2.set_ylabel('Train-Test MAE')\n",
    "ax2.tick_params(axis='x', rotation=30)\n",
    "\n",
    "medians_tt = tt_long_df.groupby('Model')['TT_MAE'].median()[model_order_tt]\n",
    "for i, (model, median) in enumerate(medians_tt.items()):\n",
    "    ax2.annotate(f'{median:,.0f}', xy=(i, median), xytext=(0, 5),\n",
    "                 textcoords='offset points', ha='center', fontsize=9, fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(save_path, 'stats_error_distribution_boxplot.png'), dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "print(\"\\nâœ“ Saved: stats_error_distribution_boxplot.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1a46c5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "best_model_counts = stats_recommendations_df['recommended_model'].value_counts()\n",
    "colors_pie = [STATS_MODEL_COLORS.get(m, '#666666') for m in best_model_counts.index]\n",
    "\n",
    "# Pie chart\n",
    "ax1 = axes[0]\n",
    "wedges, texts, autotexts = ax1.pie(\n",
    "    best_model_counts.values,\n",
    "    labels=best_model_counts.index,\n",
    "    autopct='%1.1f%%',\n",
    "    colors=colors_pie,\n",
    "    explode=[0.02] * len(best_model_counts),\n",
    "    startangle=90,\n",
    "    textprops={'fontsize': 10}\n",
    ")\n",
    "ax1.set_title(f'Best Model Distribution (h={primary_horizon})\\n{len(stats_recommendations_df)} Series', fontweight='bold')\n",
    "\n",
    "# Bar chart\n",
    "ax2 = axes[1]\n",
    "bars = ax2.bar(best_model_counts.index, best_model_counts.values, color=colors_pie,\n",
    "               edgecolor='white', linewidth=1.5)\n",
    "ax2.set_ylabel('Number of Series')\n",
    "ax2.set_xlabel('Model')\n",
    "ax2.set_title('Series Count per Best Model', fontweight='bold')\n",
    "ax2.tick_params(axis='x', rotation=30)\n",
    "\n",
    "for bar, count in zip(bars, best_model_counts.values):\n",
    "    ax2.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.3,\n",
    "             str(count), ha='center', va='bottom', fontsize=11, fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(save_path, 'stats_best_model_distribution.png'), dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nðŸ“Š Best Model Distribution (Statistical):\")\n",
    "print(\"-\" * 50)\n",
    "for model, count in best_model_counts.items():\n",
    "    pct = count / len(stats_recommendations_df) * 100\n",
    "    print(f\"   {model:<20}: {count:>3} series ({pct:>5.1f}%)\")\n",
    "print(\"\\nâœ“ Saved: stats_best_model_distribution.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fe0fade",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'confidence' in stats_recommendations_df.columns:\n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "    \n",
    "    confidence_counts = stats_recommendations_df['confidence'].value_counts()\n",
    "    confidence_order = ['High', 'Medium', 'Low']\n",
    "    confidence_colors = {'High': '#28A745', 'Medium': '#F39C12', 'Low': '#E94F37'}\n",
    "    \n",
    "    confidence_counts = confidence_counts.reindex(confidence_order).dropna()\n",
    "    colors_conf = [confidence_colors.get(c, '#666666') for c in confidence_counts.index]\n",
    "    \n",
    "    bars = ax.bar(confidence_counts.index, confidence_counts.values, color=colors_conf,\n",
    "                  edgecolor='white', linewidth=2)\n",
    "    ax.set_ylabel('Number of Series')\n",
    "    ax.set_xlabel('Confidence Level')\n",
    "    ax.set_title('Recommendation Confidence Distribution\\n(Based on MAE margin between best and 2nd best)', \n",
    "                 fontweight='bold')\n",
    "    \n",
    "    for bar, count in zip(bars, confidence_counts.values):\n",
    "        pct = count / len(stats_recommendations_df) * 100\n",
    "        ax.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.5,\n",
    "                f'{count}\\n({pct:.1f}%)', ha='center', va='bottom', fontsize=11)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(save_path, 'stats_confidence_distribution.png'), dpi=150, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"\\nðŸ“Š Confidence Distribution:\")\n",
    "    for conf in ['High', 'Medium', 'Low']:\n",
    "        count = (stats_recommendations_df['confidence'] == conf).sum()\n",
    "        if count > 0:\n",
    "            pct = count / len(stats_recommendations_df) * 100\n",
    "            print(f\"   {conf}: {count} series ({pct:.1f}%)\")\n",
    "    print(\"\\nâœ“ Saved: stats_confidence_distribution.png\")\n",
    "else:\n",
    "    print(\"Note: 'confidence' column not available in recommendations\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79488f4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'cv_traintest_agree' in sensitivity_results.columns:\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "    \n",
    "    # Agreement by model (which CV best model)\n",
    "    ax1 = axes[0]\n",
    "    agreement_by_model = sensitivity_results.groupby('cv_best_model')['cv_traintest_agree'].mean() * 100\n",
    "    agreement_by_model = agreement_by_model.sort_values(ascending=False)\n",
    "    \n",
    "    colors = [STATS_MODEL_COLORS.get(m, '#666666') for m in agreement_by_model.index]\n",
    "    bars = ax1.bar(agreement_by_model.index, agreement_by_model.values, color=colors,\n",
    "                   edgecolor='white', linewidth=1.5)\n",
    "    ax1.set_ylabel('Agreement Rate (%)')\n",
    "    ax1.set_xlabel('Model (CV Best)')\n",
    "    ax1.set_title('CV vs Train-Test Agreement by Model\\n(Higher = More Consistent)', fontweight='bold')\n",
    "    ax1.tick_params(axis='x', rotation=30)\n",
    "    ax1.axhline(y=50, color='red', linestyle='--', alpha=0.5, label='50% baseline')\n",
    "    ax1.legend()\n",
    "    \n",
    "    for bar, val in zip(bars, agreement_by_model.values):\n",
    "        ax1.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 1,\n",
    "                 f'{val:.1f}%', ha='center', va='bottom', fontsize=10)\n",
    "    \n",
    "    # Overall agreement pie\n",
    "    ax2 = axes[1]\n",
    "    agree_count = sensitivity_results['cv_traintest_agree'].sum()\n",
    "    disagree_count = len(sensitivity_results) - agree_count\n",
    "    \n",
    "    ax2.pie([agree_count, disagree_count], \n",
    "            labels=['Agree', 'Disagree'],\n",
    "            autopct='%1.1f%%',\n",
    "            colors=['#28A745', '#E94F37'],\n",
    "            explode=[0.02, 0.02],\n",
    "            startangle=90,\n",
    "            textprops={'fontsize': 12})\n",
    "    ax2.set_title(f'Overall CV vs Train-Test Agreement\\n({agree_count}/{len(sensitivity_results)} series)', \n",
    "                  fontweight='bold')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    #plt.savefig(os.path.join(save_path, 'stats_cv_traintest_agreement.png'), dpi=150, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    overall_agreement = sensitivity_results['cv_traintest_agree'].mean() * 100\n",
    "    print(f\"\\nðŸ“Š Overall CV vs Train-Test Agreement: {overall_agreement:.1f}%\")\n",
    "    print(\"\\nâœ“ Saved: stats_cv_traintest_agreement.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6160551",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate which model ranks best for each series\n",
    "rankings_data = []\n",
    "\n",
    "for idx, row in errors_df.iterrows():\n",
    "    uid = row['unique_id']\n",
    "    \n",
    "    # Get CV MAE values for each model\n",
    "    cv_maes = {}\n",
    "    for model in stats_model_names:\n",
    "        cv_col = f'{model}_cv_mean_mae'\n",
    "        if cv_col in row.index and pd.notna(row[cv_col]):\n",
    "            cv_maes[model] = row[cv_col]\n",
    "    \n",
    "    # Rank models (1 = best)\n",
    "    if cv_maes:\n",
    "        sorted_models = sorted(cv_maes.items(), key=lambda x: x[1])\n",
    "        for rank, (model, mae) in enumerate(sorted_models, 1):\n",
    "            rankings_data.append({'unique_id': uid, 'Model': model, 'Rank': rank})\n",
    "\n",
    "rankings_df = pd.DataFrame(rankings_data)\n",
    "\n",
    "# Count rankings\n",
    "rank_counts = pd.DataFrame(index=stats_model_names, columns=['1st', '2nd', '3rd', '4th', '5th', '6th'])\n",
    "for model in stats_model_names:\n",
    "    model_ranks = rankings_df[rankings_df['Model'] == model]['Rank']\n",
    "    for rank_pos, rank_label in enumerate(['1st', '2nd', '3rd', '4th', '5th', '6th'], 1):\n",
    "        rank_counts.loc[model, rank_label] = (model_ranks == rank_pos).sum()\n",
    "\n",
    "# Keep only columns with data\n",
    "rank_counts = rank_counts.dropna(axis=1, how='all').fillna(0).astype(int)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "sns.heatmap(rank_counts, annot=True, fmt='d', cmap='RdYlGn_r', ax=ax,\n",
    "            cbar_kws={'label': 'Number of Series'}, linewidths=0.5,\n",
    "            annot_kws={'size': 12, 'weight': 'bold'})\n",
    "ax.set_title('Model Rankings Across Series (CV MAE)\\n(How often does each model rank 1st, 2nd, etc.)', \n",
    "             fontweight='bold', pad=20)\n",
    "ax.set_xlabel('Rank Position')\n",
    "ax.set_ylabel('Model')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(save_path, 'stats_model_rankings_heatmap.png'), dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nðŸ“Š Model Ranking Summary:\")\n",
    "print(\"-\" * 60)\n",
    "print(rank_counts.to_string())\n",
    "print(\"\\nâœ“ Saved: stats_model_rankings_heatmap.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6631bfaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'avg_mae' in stats_recommendations_df.columns:\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
    "    \n",
    "    top_n = 10\n",
    "    sorted_by_mae = stats_recommendations_df.sort_values('avg_mae')\n",
    "    \n",
    "    # Best performers\n",
    "    ax1 = axes[0]\n",
    "    top_performers = sorted_by_mae.head(top_n)\n",
    "    colors_best = [STATS_MODEL_COLORS.get(m, '#666666') for m in top_performers['recommended_model']]\n",
    "    \n",
    "    bars1 = ax1.barh(range(len(top_performers)), top_performers['avg_mae'].values, \n",
    "                     color=colors_best, alpha=0.8)\n",
    "    ax1.set_yticks(range(len(top_performers)))\n",
    "    labels = [f\"{row['unique_id'].split('_')[-1][:12]} ({row['recommended_model']})\" \n",
    "              for _, row in top_performers.iterrows()]\n",
    "    ax1.set_yticklabels(labels, fontsize=9)\n",
    "    ax1.set_xlabel('MAE')\n",
    "    ax1.set_title(f'Top {top_n} Best Performing Series\\n(Lowest MAE)', fontweight='bold')\n",
    "    ax1.invert_yaxis()\n",
    "    \n",
    "    # Worst performers\n",
    "    ax2 = axes[1]\n",
    "    bottom_performers = sorted_by_mae.tail(top_n).sort_values('avg_mae', ascending=False)\n",
    "    colors_worst = [STATS_MODEL_COLORS.get(m, '#666666') for m in bottom_performers['recommended_model']]\n",
    "    \n",
    "    bars2 = ax2.barh(range(len(bottom_performers)), bottom_performers['avg_mae'].values,\n",
    "                     color=colors_worst, alpha=0.8)\n",
    "    ax2.set_yticks(range(len(bottom_performers)))\n",
    "    labels = [f\"{row['unique_id'].split('_')[-1][:12]} ({row['recommended_model']})\"\n",
    "              for _, row in bottom_performers.iterrows()]\n",
    "    ax2.set_yticklabels(labels, fontsize=9)\n",
    "    ax2.set_xlabel('MAE')\n",
    "    ax2.set_title(f'Top {top_n} Worst Performing Series\\n(Highest MAE)', fontweight='bold')\n",
    "    ax2.invert_yaxis()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(save_path, 'stats_best_worst_series.png'), dpi=150, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    print(\"\\nâœ“ Saved: stats_best_worst_series.png\")\n",
    "\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# CELL 6.10: Final Summary\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"ðŸ“ˆ STATISTICAL FORECASTING MODEL EVALUATION SUMMARY\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Best overall model by CV MAE\n",
    "best_cv_model = min(cv_means, key=cv_means.get)\n",
    "print(f\"\\nðŸ† Best Overall Model (by Mean CV MAE): {best_cv_model}\")\n",
    "print(f\"   Mean CV MAE: {cv_means[best_cv_model]:,.0f}\")\n",
    "\n",
    "# Most frequently best\n",
    "top_model = stats_recommendations_df['recommended_model'].value_counts().idxmax()\n",
    "top_count = stats_recommendations_df['recommended_model'].value_counts().max()\n",
    "print(f\"\\nðŸ“Š Most Frequently Best Model: {top_model}\")\n",
    "print(f\"   Selected for: {top_count}/{len(stats_recommendations_df)} series ({top_count/len(stats_recommendations_df)*100:.1f}%)\")\n",
    "\n",
    "# Distribution\n",
    "print(f\"\\nðŸ“Š Best Model per Series (h={primary_horizon}):\")\n",
    "for model, count in stats_recommendations_df['recommended_model'].value_counts().items():\n",
    "    pct = count / len(stats_recommendations_df) * 100\n",
    "    print(f\"   {model}: {count} series ({pct:.1f}%)\")\n",
    "\n",
    "# Confidence\n",
    "if 'confidence' in stats_recommendations_df.columns:\n",
    "    print(f\"\\nðŸ“Š Recommendation Confidence:\")\n",
    "    for conf in ['High', 'Medium', 'Low']:\n",
    "        count = (stats_recommendations_df['confidence'] == conf).sum()\n",
    "        if count > 0:\n",
    "            pct = count / len(stats_recommendations_df) * 100\n",
    "            print(f\"   {conf}: {count} series ({pct:.1f}%)\")\n",
    "\n",
    "# Agreement\n",
    "if 'cv_traintest_agree' in sensitivity_results.columns:\n",
    "    agree_pct = sensitivity_results['cv_traintest_agree'].mean() * 100\n",
    "    print(f\"\\nðŸ“Š CV vs Train-Test Agreement: {agree_pct:.1f}%\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"âœ… Section 6 Complete - All visualizations saved!\")\n",
    "print(\"=\" * 80)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
