{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "c2b3e3b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "import shelve\n",
    "import os\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "56f7f271",
   "metadata": {},
   "outputs": [],
   "source": [
    "user=\"lholguin\"\n",
    "#user in personal pc <- \"asus\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "73aebaf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#New changes to the class\n",
    "class NDCATCAnalyzer:\n",
    "\n",
    "    def __init__(self, year, base_path=None):\n",
    "\n",
    "        self.year = year\n",
    "        if base_path is None:\n",
    "            #Lookup the user's base path\n",
    "            self.base_path = rf\"c:\\Users\\{user}\\OneDrive - purdue.edu\\VS code\\Data\"\n",
    "        else:\n",
    "            self.base_path = base_path\n",
    "            \n",
    "        self.df_cleaned = None\n",
    "        self.df_merged = None\n",
    "        self.atc_mapping = None\n",
    "        self.df_faf = None\n",
    "        \n",
    "    def clean_sdud_data(self):\n",
    "        csv_file = os.path.join(self.base_path, f\"SDUD\\\\SDUD{self.year}.csv\")\n",
    "        print(f\"Reading CSV file: {csv_file}\")\n",
    "        \n",
    "        # Read with NDC as string to preserve leading zeros\n",
    "        df = pd.read_csv(csv_file, dtype={'NDC': 'object'})\n",
    "        \n",
    "        print(f\"Total rows in {self.year} before filtering: {len(df)}\")\n",
    "        \n",
    "        # Remove NA values\n",
    "        df_filtered = df.dropna(subset=['Units Reimbursed', 'Number of Prescriptions'])\n",
    "        print(f\"Rows after removing NA: {len(df_filtered)}\")\n",
    "        \n",
    "        # Filter out State='XX'\n",
    "        df_filtered = df_filtered[df_filtered['State'] != 'XX']\n",
    "        print(f\"Rows after filtering State='XX': {len(df_filtered)}\")\n",
    "        print(f\"Unique NDCs: {df_filtered['NDC'].nunique()}\")\n",
    "        \n",
    "        self.df_cleaned = df_filtered\n",
    "        return self.df_cleaned\n",
    "    \n",
    "    #NEW\n",
    "    def adding_key(self):\n",
    "        if self.df_cleaned is None:\n",
    "            raise ValueError(\"Must run clean_sdud_data() first\")\n",
    "        \n",
    "        print(\"Adding record_id column...\")\n",
    "        \n",
    "        # Create record_id column\n",
    "        self.df_cleaned['record_id'] = (\n",
    "            self.df_cleaned['State'].astype(str) + \"_\" +\n",
    "            self.df_cleaned['Year'].astype(str) + \"_\" +\n",
    "            self.df_cleaned['Quarter'].astype(str) + \"_\" +\n",
    "            self.df_cleaned['Utilization Type'].astype(str) + \"_\" +\n",
    "            self.df_cleaned['NDC'].astype(str)\n",
    "        )\n",
    "        \n",
    "        print(f\"Created {len(self.df_cleaned)} record IDs\")\n",
    "        print(f\"Sample record_id: {self.df_cleaned['record_id'].iloc[0]}\")\n",
    "        \n",
    "        return self.df_cleaned\n",
    "    \n",
    "    def generate_ndc_txt(self, output_filename=None):\n",
    "        \"\"\"Step 2: Generate text file with unique NDC values and their record_id keys.\"\"\"\n",
    "        if self.df_cleaned is None:\n",
    "            raise ValueError(\"Must run clean_sdud_data() first\")\n",
    "        \n",
    "        if 'record_id' not in self.df_cleaned.columns:\n",
    "            raise ValueError(\"Must run adding_key() first to create record_id column\")\n",
    "            \n",
    "        if output_filename is None:\n",
    "            output_filename = f\"NDCNEW_{self.year}.txt\"\n",
    "        \n",
    "        output_path = os.path.join(self.base_path, f\"ATC\\\\text_files\\\\{output_filename}\")\n",
    "        \n",
    "        # Get unique combinations of NDC and record_id\n",
    "        unique_pairs = self.df_cleaned[['NDC', 'record_id']].drop_duplicates()\n",
    "        \n",
    "        with open(output_path, 'w') as f:\n",
    "            # Write header\n",
    "            f.write(\"NDC\\trecord_id\\n\")\n",
    "            # Write each unique pair\n",
    "            for _, row in unique_pairs.iterrows():\n",
    "                f.write(f\"{row['NDC']}\\t{row['record_id']}\\n\")\n",
    "        \n",
    "        print(f\"Exported to: {output_path}\")\n",
    "        print(f\"Unique record_id values: {unique_pairs['record_id'].nunique()}\")\n",
    "        return output_path\n",
    "    \n",
    "    def analyze_atc4_mapping(self):\n",
    "        atc4_path = os.path.join(self.base_path, f\"ATC\\\\ATC4_classes\\\\NDCNEW_{self.year}_ATC4_classes.csv\")\n",
    "        \n",
    "        # Read ATC4 mapping\n",
    "        df_atc4 = pd.read_csv(atc4_path, dtype={'NDC': 'object', 'record_id': 'string'})\n",
    "        df_atc4['NDC'] = df_atc4['NDC'].str.zfill(11)\n",
    "\n",
    "        #Print how many unique NDC codes were mapped\n",
    "        print(f\"Total rows in ATC4 mapping file: {len(df_atc4)}\")\n",
    "        print(f\"Unique NDCs in ATC4 mapping file: {df_atc4['NDC'].nunique()}\")\n",
    "\n",
    "        # Ensure consistent data types before merge\n",
    "        self.df_cleaned['record_id'] = self.df_cleaned['record_id'].astype('string')\n",
    "        self.df_cleaned['NDC'] = self.df_cleaned['NDC'].astype('object')  \n",
    "        df_atc4['record_id'] = df_atc4['record_id'].astype('string')\n",
    "        df_atc4['NDC'] = df_atc4['NDC'].astype('object')  \n",
    "\n",
    "        # Merge ATC4 mapping with cleaned data using record_id\n",
    "        if self.df_cleaned is None:\n",
    "            raise ValueError(\"Must run clean_sdud_data() and adding_key() first\")\n",
    "        \n",
    "        if 'record_id' not in self.df_cleaned.columns:\n",
    "            raise ValueError(\"Must run adding_key() first to create record_id column\")\n",
    "        \n",
    "        print(f\"Merging ATC4 mapping with cleaned data using record_id and NDC...\")\n",
    "        \n",
    "        # Merge on BOTH record_id AND NDC\n",
    "        self.atc_mapping = pd.merge(\n",
    "            self.df_cleaned,\n",
    "            df_atc4[['record_id', 'NDC', 'ATC4 Class']],  # Include NDC in the selection\n",
    "            on=['record_id', 'NDC'],  # Merge on both columns\n",
    "            how='left'\n",
    "        )\n",
    "        \n",
    "        # Print rows of the merged dataframe\n",
    "        print(f\"Merged dataframe rows: {len(self.atc_mapping)}\")\n",
    "        #print(self.atc_mapping.head())\n",
    "        total_records = len(self.atc_mapping)\n",
    "        mapped_records = self.atc_mapping['ATC4 Class'].notna().sum()\n",
    "        print(f\"Records with ATC4 mapping: {mapped_records} ({mapped_records/total_records*100:.1f}%)\")\n",
    "\n",
    "        # Identify missing mappings\n",
    "        missing_records = self.atc_mapping[self.atc_mapping['ATC4 Class'].isna()]\n",
    "        if len(missing_records) > 0:\n",
    "            print(f\"\\nRecords without ATC4 mapping: {len(missing_records)}\")\n",
    "            print(f\"Unique NDCs without mapping: {missing_records['NDC'].nunique()}\")\n",
    "        \n",
    "        return self.atc_mapping\n",
    "\n",
    "    def select_one_atc_per_record(self, strategy=\"ndc_mode_then_priority\"):\n",
    "        if self.atc_mapping is None:\n",
    "            raise ValueError(\"Must run analyze_atc4_mapping() first\")\n",
    "\n",
    "        df = self.atc_mapping.copy()\n",
    "        df = df[df['ATC4 Class'].notna()].copy()\n",
    "\n",
    "        # NDC-level ATC4 frequency (mode by NDC)\n",
    "        ndc_atc_counts = (\n",
    "            df.groupby(['NDC','ATC4 Class'])\n",
    "            .size().rename('ndc_atc_count')\n",
    "            .reset_index()\n",
    "        )\n",
    "        df = df.merge(ndc_atc_counts, on=['NDC','ATC4 Class'], how='left')\n",
    "\n",
    "        def atc_priority(atc4):\n",
    "            atc2 = atc4[:3] if isinstance(atc4, str) else \"\"\n",
    "            if atc2.startswith('V03'):  # 'Other therapeutic products'\n",
    "                return 100\n",
    "            if atc2.startswith('V'):    # 'Various'\n",
    "                return 80\n",
    "            # illustrative booster: tune as needed\n",
    "            boosters = {'A':10,'B':15,'C':12,'D':20,'G':18,'H':14,'J':11,'L':16,'M':17,'N':13,'R':19,'S':21}\n",
    "            return boosters.get(atc2[:1], 50)\n",
    "\n",
    "        df['priority_score'] = df['ATC4 Class'].map(atc_priority).fillna(60)\n",
    "\n",
    "        df = df.sort_values(\n",
    "            by=['record_id','ndc_atc_count','priority_score','Units Reimbursed','Number of Prescriptions','ATC4 Class'],\n",
    "            ascending=[True, False, True, False, False, True]\n",
    "        )\n",
    "\n",
    "        df_one = df.drop_duplicates(subset='record_id', keep='first').copy()\n",
    "\n",
    "        # small diagnostic\n",
    "        total_records = self.atc_mapping['record_id'].nunique()\n",
    "        kept = len(df_one)\n",
    "        multi = (self.atc_mapping\n",
    "                .groupby('record_id')['ATC4 Class']\n",
    "                .nunique()\n",
    "                .reset_index(name='n'))\n",
    "        pct_multi = (multi['n']>1).mean()*100\n",
    "\n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(\"SELECT-ONE-ATC PER RECORD_ID (DETERMINISTIC)\")\n",
    "        print(\"=\"*60)\n",
    "        print(f\"Unique record_ids (raw): {total_records:,}\")\n",
    "        print(f\"Kept record_ids (one per id): {kept:,}\")\n",
    "        print(f\"Records with >1 ATC4 candidates: {int((multi['n']>1).sum()):,} ({pct_multi:.1f}%)\")\n",
    "        print(\"Tie-break order: NDC-mode → priority(list) → Units → Prescriptions → alphabetical\")\n",
    "\n",
    "        self.df_selected = df_one\n",
    "        return self.df_selected\n",
    "\n",
    "    def analyze_atc4_distribution(self):\n",
    "\n",
    "        if self.atc_mapping is None:\n",
    "            raise ValueError(\"Must run analyze_atc4_mapping() first\")\n",
    "        \n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(\"ATC4 CLASSES PER RECORD_ID DISTRIBUTION\")\n",
    "        print(f\"{'='*60}\")\n",
    "        \n",
    "        # Count ATC4 classes per record_id (only valid mappings)\n",
    "        records_with_mapping = self.atc_mapping[self.atc_mapping['ATC4 Class'].notna()].copy()\n",
    "        \n",
    "        if len(records_with_mapping) == 0:\n",
    "            print(\"No records with valid ATC4 mappings found.\")\n",
    "            return None\n",
    "        \n",
    "        # Group by record_id and count unique ATC4 classes\n",
    "        atc4_per_record = records_with_mapping.groupby('record_id').agg({\n",
    "            'ATC4 Class': 'nunique',\n",
    "            'NDC': 'first',  # Get the NDC for reference\n",
    "            'State': 'first',  # Get the state for reference\n",
    "            'Year': 'first'    # Get the year for reference\n",
    "        }).reset_index()\n",
    "        \n",
    "        atc4_per_record.columns = ['record_id', 'num_atc4_classes', 'NDC', 'State', 'Year']\n",
    "        \n",
    "        # Distribution analysis\n",
    "        distribution = atc4_per_record['num_atc4_classes'].value_counts().sort_index()\n",
    "        \n",
    "        print(\"Distribution of ATC4 classes per record_id:\")\n",
    "        for classes, count in distribution.items():\n",
    "            pct = (count / len(atc4_per_record)) * 100\n",
    "            print(f\"  {classes} class(es): {count:,} record_ids ({pct:.1f}%)\")\n",
    "        \n",
    "        # Show examples of multi-class records\n",
    "        #multi_class = atc4_per_record[atc4_per_record['num_atc4_classes'] > 1].sort_values('num_atc4_classes', ascending=False)\n",
    "        \n",
    "        #if len(multi_class) > 0:\n",
    "            #print(f\"\\nTop 10 record_ids with most ATC4 classes:\")\n",
    "            #for _, row in multi_class.head(10).iterrows():\n",
    "                #record_classes = records_with_mapping[records_with_mapping['record_id'] == row['record_id']]['ATC4 Class'].unique()\n",
    "                #print(f\"  {row['record_id']}: {row['num_atc4_classes']} classes\")\n",
    "                #print(f\"    NDC: {row['NDC']}, State: {row['State']}, Year: {row['Year']}\")\n",
    "                #print(f\"    Classes: {list(record_classes)}\")\n",
    "                #print()\n",
    "        \n",
    "        #return atc4_per_record\n",
    "\n",
    "    def fetch_atc_names(self, cache_path=None):\n",
    "        \"\"\"Fetch ATC class names (ATC4, ATC3, ATC2) from RxNav API.\"\"\"\n",
    "        if self.atc_mapping is None:\n",
    "            raise ValueError(\"Must run analyze_atc4_mapping() first\")\n",
    "        \n",
    "        if cache_path is None:\n",
    "            cache_path = os.path.join(self.base_path, \"ATC\\\\cache_files\\\\atc_names_cache\")\n",
    "        \n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(\"FETCHING ATC CLASS NAMES\")\n",
    "        print(f\"{'='*60}\")\n",
    "        print(f\"Using cache: {cache_path}\")\n",
    "        \n",
    "        # Get only records with valid ATC4 mappings\n",
    "        df_with_atc = self.atc_mapping[self.atc_mapping['ATC4 Class'].notna()].copy()\n",
    "        \n",
    "        # Create ATC3 and ATC2 columns from ATC4\n",
    "        print(\"\\nCreating ATC3 and ATC2 columns from ATC4...\")\n",
    "        df_with_atc['ATC3 Class'] = df_with_atc['ATC4 Class'].str[:4]\n",
    "        df_with_atc['ATC2 Class'] = df_with_atc['ATC4 Class'].str[:3]\n",
    "        \n",
    "        # Get unique codes for each level\n",
    "        unique_atc4 = df_with_atc['ATC4 Class'].dropna().unique()\n",
    "        unique_atc3 = df_with_atc['ATC3 Class'].dropna().unique()\n",
    "        unique_atc2 = df_with_atc['ATC2 Class'].dropna().unique()\n",
    "        \n",
    "        # Filter out invalid codes\n",
    "        unique_atc4 = [c for c in unique_atc4 if c not in ['No ATC Mapping Found', 'No RxCUI Found', '']]\n",
    "        unique_atc3 = [c for c in unique_atc3 if c not in ['No ATC Mapping Found', 'No RxCUI Found', '', 'No ', 'No']]\n",
    "        unique_atc2 = [c for c in unique_atc2 if c not in ['No ATC Mapping Found', 'No RxCUI Found', '', 'No ', 'No']]\n",
    "        \n",
    "        print(f\"\\nUnique codes to fetch:\")\n",
    "        print(f\"  ATC4: {len(unique_atc4)}\")\n",
    "        print(f\"  ATC3: {len(unique_atc3)}\")\n",
    "        print(f\"  ATC2: {len(unique_atc2)}\")\n",
    "        \n",
    "        # Build mappings\n",
    "        atc4_names = {}\n",
    "        atc3_names = {}\n",
    "        atc2_names = {}\n",
    "        \n",
    "        with shelve.open(cache_path) as cache:\n",
    "            start_time = datetime.now()\n",
    "            \n",
    "            print(\"\\nFetching ATC4 names...\")\n",
    "            for code in unique_atc4:\n",
    "                atc4_names[code] = self._get_atc_name(code, cache)\n",
    "            \n",
    "            print(\"Fetching ATC3 names...\")\n",
    "            for code in unique_atc3:\n",
    "                atc3_names[code] = self._get_atc_name(code, cache)\n",
    "            \n",
    "            print(\"Fetching ATC2 names...\")\n",
    "            for code in unique_atc2:\n",
    "                atc2_names[code] = self._get_atc_name(code, cache)\n",
    "            \n",
    "            print(f\"\\nTotal processing time: {(datetime.now() - start_time).total_seconds()/60:.1f} minutes\")\n",
    "        \n",
    "        # Apply names to all records in atc_mapping\n",
    "        print(\"\\nApplying names to dataframe...\")\n",
    "        self.atc_mapping['ATC3 Class'] = self.atc_mapping['ATC4 Class'].str[:4]\n",
    "        self.atc_mapping['ATC2 Class'] = self.atc_mapping['ATC4 Class'].str[:3]\n",
    "        \n",
    "        self.atc_mapping['ATC4_Name'] = self.atc_mapping['ATC4 Class'].map(atc4_names).fillna('')\n",
    "        self.atc_mapping['ATC3_Name'] = self.atc_mapping['ATC3 Class'].map(atc3_names).fillna('')\n",
    "        self.atc_mapping['ATC2_Name'] = self.atc_mapping['ATC2 Class'].map(atc2_names).fillna('')\n",
    "        \n",
    "        print(f\"\\nATC names added successfully!\")\n",
    "        print(\"\\nSample output:\")\n",
    "        sample = self.atc_mapping[self.atc_mapping['ATC4 Class'].notna()][['NDC', 'record_id', 'ATC4 Class', 'ATC4_Name', 'ATC3 Class', 'ATC3_Name', 'ATC2 Class', 'ATC2_Name']].head(5)\n",
    "        print(sample.to_string())\n",
    "        \n",
    "        return self.atc_mapping\n",
    "    \n",
    "    def prepare_final_dataframe(self):\n",
    "        if not hasattr(self, 'df_selected'):\n",
    "        # ensure selection has run\n",
    "            self.select_one_atc_per_record()\n",
    "\n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(\"PREPARING FINAL DATAFRAME\")\n",
    "        print(\"=\"*60)\n",
    "\n",
    "        self.df_merged = self.df_selected.copy()\n",
    "\n",
    "        return self.df_merged\n",
    "    \n",
    "    def _get_atc_name(self, atc_code, cache):\n",
    "        \"\"\"Get ATC class name from code, using cache.\"\"\"\n",
    "        cache_key = f\"atc_name:{atc_code}\"\n",
    "        if cache_key in cache:\n",
    "            return cache[cache_key]\n",
    "        \n",
    "        try:\n",
    "            url = f\"https://rxnav.nlm.nih.gov/REST/rxclass/class/byId.json?classId={atc_code}\"\n",
    "            response = requests.get(url)\n",
    "            response.raise_for_status()\n",
    "            data = response.json()\n",
    "            \n",
    "            # Get class name\n",
    "            if 'rxclassMinConceptList' in data and 'rxclassMinConcept' in data['rxclassMinConceptList']:\n",
    "                concepts = data['rxclassMinConceptList']['rxclassMinConcept']\n",
    "                if concepts:\n",
    "                    name = concepts[0].get('className', '')\n",
    "                    cache[cache_key] = name\n",
    "                    return name\n",
    "            \n",
    "            cache[cache_key] = ''\n",
    "            return ''\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error retrieving name for {atc_code}: {e}\")\n",
    "            cache[cache_key] = ''\n",
    "            return ''\n",
    "    \n",
    "    def analyze_atc3_distribution(self):\n",
    "\n",
    "        if self.atc_mapping is None:\n",
    "            raise ValueError(\"Must run analyze_atc4_mapping() first\")\n",
    "        \n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(\"ATC3 CLASSES PER RECORD_ID DISTRIBUTION\")\n",
    "        print(f\"{'='*60}\")\n",
    "        \n",
    "        # Create ATC3 classes from ATC4\n",
    "        records_with_mapping = self.atc_mapping[self.atc_mapping['ATC4 Class'].notna()].copy()\n",
    "        \n",
    "        if len(records_with_mapping) == 0:\n",
    "            print(\"No records with valid ATC4 mappings found.\")\n",
    "            return None\n",
    "        \n",
    "        # Create ATC3 class from ATC4 class (first 4 characters)\n",
    "        records_with_mapping['ATC3 Class'] = records_with_mapping['ATC4 Class'].str[:4]\n",
    "        \n",
    "        # Group by record_id and count unique ATC3 classes\n",
    "        atc3_per_record = records_with_mapping.groupby('record_id').agg({\n",
    "            'ATC3 Class': 'nunique',\n",
    "            'NDC': 'first',\n",
    "            'State': 'first',\n",
    "            'Year': 'first'\n",
    "        }).reset_index()\n",
    "        \n",
    "        atc3_per_record.columns = ['record_id', 'num_atc3_classes', 'NDC', 'State', 'Year']\n",
    "        \n",
    "        # Distribution analysis\n",
    "        distribution = atc3_per_record['num_atc3_classes'].value_counts().sort_index()\n",
    "        \n",
    "        print(\"Distribution of ATC3 classes per record_id:\")\n",
    "        for classes, count in distribution.items():\n",
    "            pct = (count / len(atc3_per_record)) * 100\n",
    "            print(f\"  {classes} class(es): {count:,} record_ids ({pct:.1f}%)\")\n",
    "        \n",
    "        # Show examples of multi-class records\n",
    "        #multi_class = atc3_per_record[atc3_per_record['num_atc3_classes'] > 1].sort_values('num_atc3_classes', ascending=False)\n",
    "        \n",
    "        #if len(multi_class) > 0:\n",
    "            #print(f\"\\nTop 10 record_ids with most ATC3 classes:\")\n",
    "            #for _, row in multi_class.head(10).iterrows():\n",
    "                #record_classes = records_with_mapping[records_with_mapping['record_id'] == row['record_id']]['ATC3 Class'].unique()\n",
    "                #print(f\"  {row['record_id']}: {row['num_atc3_classes']} classes\")\n",
    "                #print(f\"    NDC: {row['NDC']}, State: {row['State']}, Year: {row['Year']}\")\n",
    "                #print(f\"    Classes: {list(record_classes)}\")\n",
    "                #print()\n",
    "        \n",
    "        # Summary statistics\n",
    "        #print(f\"\\nATC3 Summary:\")\n",
    "        print(f\"  Total record_ids with ATC3 mapping: {len(atc3_per_record):,}\")\n",
    "        #print(f\"  Average ATC3 classes per record_id: {atc3_per_record['num_atc3_classes'].mean():.2f}\")\n",
    "        #print(f\"  Max ATC3 classes for single record_id: {atc3_per_record['num_atc3_classes'].max()}\")\n",
    "        \n",
    "        return atc3_per_record\n",
    "\n",
    "    def analyze_atc2_distribution(self):\n",
    "\n",
    "        if self.atc_mapping is None:\n",
    "            raise ValueError(\"Must run analyze_atc4_mapping() first\")\n",
    "        \n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(\"ATC2 CLASSES PER RECORD_ID DISTRIBUTION\")\n",
    "        print(f\"{'='*60}\")\n",
    "        \n",
    "        # Create ATC2 classes from ATC4\n",
    "        records_with_mapping = self.atc_mapping[self.atc_mapping['ATC4 Class'].notna()].copy()\n",
    "        \n",
    "        if len(records_with_mapping) == 0:\n",
    "            print(\"No records with valid ATC4 mappings found.\")\n",
    "            return None\n",
    "        \n",
    "        # Create ATC2 class from ATC4 class (first 3 characters)\n",
    "        records_with_mapping['ATC2 Class'] = records_with_mapping['ATC4 Class'].str[:3]\n",
    "        \n",
    "        # Group by record_id and count unique ATC2 classes\n",
    "        atc2_per_record = records_with_mapping.groupby('record_id').agg({\n",
    "            'ATC2 Class': 'nunique',\n",
    "            'NDC': 'first',\n",
    "            'State': 'first',\n",
    "            'Year': 'first'\n",
    "        }).reset_index()\n",
    "        \n",
    "        atc2_per_record.columns = ['record_id', 'num_atc2_classes', 'NDC', 'State', 'Year']\n",
    "        \n",
    "        # Distribution analysis\n",
    "        distribution = atc2_per_record['num_atc2_classes'].value_counts().sort_index()\n",
    "        \n",
    "        print(\"Distribution of ATC2 classes per record_id:\")\n",
    "        for classes, count in distribution.items():\n",
    "            pct = (count / len(atc2_per_record)) * 100\n",
    "            print(f\"  {classes} class(es): {count:,} record_ids ({pct:.1f}%)\")\n",
    "        \n",
    "        # Show examples of multi-class records\n",
    "        #multi_class = atc2_per_record[atc2_per_record['num_atc2_classes'] > 1].sort_values('num_atc2_classes', ascending=False)\n",
    "        \n",
    "        #if len(multi_class) > 0:\n",
    "            #print(f\"\\nTop 10 record_ids with most ATC2 classes:\")\n",
    "            #for _, row in multi_class.head(10).iterrows():\n",
    "                #record_classes = records_with_mapping[records_with_mapping['record_id'] == row['record_id']]['ATC2 Class'].unique()\n",
    "                #print(f\"  {row['record_id']}: {row['num_atc2_classes']} classes\")\n",
    "                #print(f\"    NDC: {row['NDC']}, State: {row['State']}, Year: {row['Year']}\")\n",
    "                #print(f\"    Classes: {list(record_classes)}\")\n",
    "                #print()\n",
    "        \n",
    "        # Summary statistics\n",
    "        print(f\"\\nATC2 Summary:\")\n",
    "        print(f\"  Total record_ids with ATC2 mapping: {len(atc2_per_record):,}\")\n",
    "        print(f\"  Average ATC2 classes per record_id: {atc2_per_record['num_atc2_classes'].mean():.2f}\")\n",
    "        print(f\"  Max ATC2 classes for single record_id: {atc2_per_record['num_atc2_classes'].max()}\")\n",
    "        \n",
    "        return atc2_per_record\n",
    "\n",
    "    def export_merged_data(self, output_filename=None):\n",
    "     \n",
    "        if not hasattr(self, 'df_selected'):\n",
    "            # Ensure we’ve selected one ATC per record deterministically\n",
    "            self.select_one_atc_per_record()\n",
    "\n",
    "        df_final = self.df_selected.copy()\n",
    "\n",
    "        # (Optional) scale here if you prefer the output to be scaled\n",
    "        # If you scale, do the sum check using unscaled copies to avoid rounding issues\n",
    "        # Keep unscaled copies to verify sums:\n",
    "        src_units_sum = self.df_cleaned['Units Reimbursed'].sum()\n",
    "        src_rx_sum    = self.df_cleaned['Number of Prescriptions'].sum()\n",
    "        out_units_sum = df_final['Units Reimbursed'].sum()\n",
    "        out_rx_sum    = df_final['Number of Prescriptions'].sum()\n",
    "\n",
    "        # now scale for the CSV\n",
    "        df_final['Units Reimbursed'] /= 1e9\n",
    "        df_final['Number of Prescriptions'] /= 1e6\n",
    "\n",
    "        if output_filename is None:\n",
    "            output_filename = f\"merged_NEWdata_{self.year}.csv\"\n",
    "        output_path = os.path.join(self.base_path, f\"ATC\\\\merged_data\\\\{output_filename}\")\n",
    "        os.makedirs(os.path.dirname(output_path), exist_ok=True)\n",
    "        df_final.to_csv(output_path, index=False)\n",
    "\n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(\"DATA EXPORT COMPLETE (ONE ATC PER RECORD_ID)\")\n",
    "        print(\"=\"*60)\n",
    "        print(f\"Exported: {output_path}\")\n",
    "        print(f\"Rows exported: {len(df_final):,}\")\n",
    "        print(f\"Sums preserved? Units: {abs(src_units_sum - out_units_sum) < 1e-6}, \"\n",
    "            f\"Prescriptions: {abs(src_rx_sum - out_rx_sum) < 1e-6}\")\n",
    "        return output_path\n",
    "\n",
    "    @staticmethod #ATC distribution analysis across multiple years \n",
    "    def create_multi_year_distribution_analysis_simple(years_list):\n",
    "        \n",
    "        print(\"Creating Multi-Year ATC Distribution Analysis (Percentages Only)...\")\n",
    "        print(\"=\"*70)\n",
    "        \n",
    "        # Dictionary to store only percentage results\n",
    "        results = {\n",
    "            'ATC4_1_class': {},\n",
    "            'ATC4_2_classes': {},\n",
    "            'ATC4_3+_classes': {},\n",
    "            'ATC3_1_class': {},\n",
    "            'ATC3_2_classes': {},\n",
    "            'ATC3_3+_classes': {},\n",
    "            'ATC2_1_class': {},\n",
    "            'ATC2_2_classes': {},\n",
    "            'ATC2_3+_classes': {}\n",
    "        }\n",
    "        \n",
    "        for year in years_list:\n",
    "            print(f\"Processing {year}...\", end=\" \")\n",
    "            \n",
    "            try:\n",
    "                # Create a separate analyzer instance for each year\n",
    "                analyzer = NDCATCAnalyzer(year=year)\n",
    "                analyzer.clean_sdud_data()\n",
    "                analyzer.adding_key()\n",
    "                analyzer.analyze_atc4_mapping()\n",
    "                \n",
    "                # Get records with valid ATC4 mappings\n",
    "                records = analyzer.atc_mapping[analyzer.atc_mapping['ATC4 Class'].notna()].copy()\n",
    "                records['ATC2 Class'] = records['ATC4 Class'].str[:3]\n",
    "                records['ATC3 Class'] = records['ATC4 Class'].str[:4]\n",
    "                \n",
    "                # Calculate distributions\n",
    "                atc4_per_record = records.groupby('record_id')['ATC4 Class'].nunique()\n",
    "                atc3_per_record = records.groupby('record_id')['ATC3 Class'].nunique()\n",
    "                atc2_per_record = records.groupby('record_id')['ATC2 Class'].nunique()\n",
    "                \n",
    "                # ATC4 percentages\n",
    "                atc4_dist = atc4_per_record.value_counts().sort_index()\n",
    "                total_atc4 = len(atc4_per_record)\n",
    "                results['ATC4_1_class'][year] = f\"{(atc4_dist.get(1, 0) / total_atc4 * 100):.1f}%\"\n",
    "                results['ATC4_2_classes'][year] = f\"{(atc4_dist.get(2, 0) / total_atc4 * 100):.1f}%\"\n",
    "                results['ATC4_3+_classes'][year] = f\"{(atc4_dist[atc4_dist.index >= 3].sum() / total_atc4 * 100):.1f}%\"\n",
    "                \n",
    "                # ATC3 percentages\n",
    "                atc3_dist = atc3_per_record.value_counts().sort_index()\n",
    "                total_atc3 = len(atc3_per_record)\n",
    "                results['ATC3_1_class'][year] = f\"{(atc3_dist.get(1, 0) / total_atc3 * 100):.1f}%\"\n",
    "                results['ATC3_2_classes'][year] = f\"{(atc3_dist.get(2, 0) / total_atc3 * 100):.1f}%\"\n",
    "                results['ATC3_3+_classes'][year] = f\"{(atc3_dist[atc3_dist.index >= 3].sum() / total_atc3 * 100):.1f}%\"\n",
    "                \n",
    "                # ATC2 percentages\n",
    "                atc2_dist = atc2_per_record.value_counts().sort_index()\n",
    "                total_atc2 = len(atc2_per_record)\n",
    "                results['ATC2_1_class'][year] = f\"{(atc2_dist.get(1, 0) / total_atc2 * 100):.1f}%\"\n",
    "                results['ATC2_2_classes'][year] = f\"{(atc2_dist.get(2, 0) / total_atc2 * 100):.1f}%\"\n",
    "                results['ATC2_3+_classes'][year] = f\"{(atc2_dist[atc2_dist.index >= 3].sum() / total_atc2 * 100):.1f}%\"\n",
    "                \n",
    "                print(\"✓\")\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"✗ Error: {e}\")\n",
    "                # Fill with N/A for failed years\n",
    "                for key in results.keys():\n",
    "                    results[key][year] = \"N/A\"\n",
    "        \n",
    "        # Create DataFrame (only percentages)\n",
    "        df_percentages = pd.DataFrame(results).T\n",
    "        \n",
    "        print(f\"\\nATC DISTRIBUTION PERCENTAGES ACROSS YEARS\")\n",
    "        print(\"=\"*60)\n",
    "        print(df_percentages)\n",
    "        \n",
    "        return df_percentages\n",
    "    \n",
    "    @staticmethod\n",
    "    def analyze_general_atc2_overview(years_list):\n",
    "        \n",
    "        print(\"Creating ATC2 Overview: Unique NDCs per ATC2 Class Across Years...\")\n",
    "        print(\"=\"*70)\n",
    "        \n",
    "        # Store results for each year\n",
    "        all_year_results = {}\n",
    "        overview_dataframes = {}\n",
    "        \n",
    "        for year in years_list:\n",
    "            print(f\"Processing {year}...\", end=\" \")\n",
    "            \n",
    "            try:\n",
    "                # Create analyzer instance\n",
    "                analyzer = NDCATCAnalyzer(year=year)\n",
    "                analyzer.clean_sdud_data()\n",
    "                analyzer.adding_key()\n",
    "                analyzer.analyze_atc4_mapping()\n",
    "                \n",
    "                # Get records with valid ATC4 mappings\n",
    "                records = analyzer.atc_mapping[analyzer.atc_mapping['ATC4 Class'].notna()].copy()\n",
    "                \n",
    "                if len(records) == 0:\n",
    "                    print(f\"No records with ATC mapping found\")\n",
    "                    all_year_results[year] = pd.DataFrame()\n",
    "                    overview_dataframes[year] = pd.DataFrame()\n",
    "                    continue\n",
    "                \n",
    "                # Create ATC2 class from ATC4\n",
    "                records['ATC2 Class'] = records['ATC4 Class'].str[:3]\n",
    "                \n",
    "                # Remove ATC3 and ATC4 columns (keep only ATC2-level data)\n",
    "                columns_to_keep = [col for col in records.columns \n",
    "                                 if not any(x in col for x in ['ATC3', 'ATC4'])]\n",
    "                \n",
    "                atc2_data = records[columns_to_keep].copy()\n",
    "                \n",
    "                # 1) collapse to distinct (record_id, ATC2) assignments\n",
    "                pairs = atc2_data[['record_id', 'NDC', 'ATC2 Class']].drop_duplicates()\n",
    "\n",
    "                # 2) compute metrics off the deduped pairs:\n",
    "                #    - Unique NDCs per ATC2 (across all records/states/quarters)\n",
    "                #    - Total distinct record_ids per ATC2 (not inflated by multi-ATC4 within the same ATC2)\n",
    "                atc2_ndc_summary = pairs.groupby('ATC2 Class').agg(\n",
    "                    Unique_NDCs=('NDC', 'nunique'),\n",
    "                    Total_Records=('record_id', 'nunique'),\n",
    "                ).sort_values('Unique_NDCs', ascending=False)\n",
    "\n",
    "                # 3) denominator for percentages should be deduped too\n",
    "                total_unique_ndcs = pairs['NDC'].nunique()\n",
    "                atc2_ndc_summary['Percentage_of_NDCs'] = (atc2_ndc_summary['Unique_NDCs'] / total_unique_ndcs * 100).round(1)\n",
    "                                \n",
    "                \n",
    "                # Add percentage of total NDCs\n",
    "                total_unique_ndcs = atc2_data['NDC'].nunique()\n",
    "                atc2_ndc_summary['Percentage_of_NDCs'] = (atc2_ndc_summary['Unique_NDCs'] / total_unique_ndcs * 100).round(1)\n",
    "                \n",
    "                # Sort by number of unique NDCs (descending)\n",
    "                atc2_ndc_summary = atc2_ndc_summary.sort_values('Unique_NDCs', ascending=False)\n",
    "                \n",
    "                # Store results for this year\n",
    "                all_year_results[year] = atc2_ndc_summary\n",
    "                overview_dataframes[year] = atc2_data\n",
    "                \n",
    "                print(f\"✓ ({len(atc2_ndc_summary)} ATC2 classes, {total_unique_ndcs:,} total unique NDCs)\")\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"✗ Error: {e}\")\n",
    "                all_year_results[year] = pd.DataFrame()\n",
    "                overview_dataframes[year] = pd.DataFrame()\n",
    "        \n",
    "        # Display results for each year\n",
    "        print(f\"\\nUNIQUE NDCs PER ATC2 CLASS BY YEAR\")\n",
    "        print(\"=\"*60)\n",
    "        \n",
    "        for year in years_list:\n",
    "            if not all_year_results[year].empty:\n",
    "                print(f\"\\n{year}:\")\n",
    "                print(\"-\" * 40)\n",
    "                print(f\"Total ATC2 Classes: {len(all_year_results[year])}\")\n",
    "                print(f\"Total Unique NDCs: {overview_dataframes[year]['NDC'].nunique():,}\")\n",
    "                print(f\"\\nTop 10 ATC2 Classes by Unique NDCs:\")\n",
    "                print(all_year_results[year].head(10))\n",
    "            else:\n",
    "                print(f\"\\n{year}: No data available\")\n",
    "        \n",
    "        # Create comparison table across years (top ATC2 classes)\n",
    "        print(f\"\\nCOMPARISON: TOP ATC2 CLASSES ACROSS YEARS (by Unique NDCs)\")\n",
    "        print(\"=\"*70)\n",
    "        \n",
    "        # Get all unique ATC2 classes across all years\n",
    "        all_atc2_classes = set()\n",
    "        for year_data in all_year_results.values():\n",
    "            if not year_data.empty:\n",
    "                all_atc2_classes.update(year_data.index.tolist())\n",
    "        \n",
    "        # Create comparison DataFrame\n",
    "        comparison_data = {}\n",
    "        for atc2_class in sorted(all_atc2_classes):\n",
    "            comparison_data[atc2_class] = {}\n",
    "            for year in years_list:\n",
    "                if not all_year_results[year].empty and atc2_class in all_year_results[year].index:\n",
    "                    comparison_data[atc2_class][year] = all_year_results[year].loc[atc2_class, 'Unique_NDCs']\n",
    "                else:\n",
    "                    comparison_data[atc2_class][year] = 0\n",
    "        \n",
    "        df_comparison = pd.DataFrame(comparison_data).T\n",
    "        df_comparison = df_comparison.loc[df_comparison.sum(axis=1).sort_values(ascending=False).index]\n",
    "        \n",
    "        print(\"Top 15 ATC2 Classes by Total Unique NDCs Across All Years:\")\n",
    "        print(df_comparison.head(15))\n",
    "        \n",
    "        return all_year_results, overview_dataframes, df_comparison\n",
    "    \n",
    "    @staticmethod\n",
    "    def get_atc2_ndc_details(year, top_n=10):\n",
    "\n",
    "        try:\n",
    "            analyzer = NDCATCAnalyzer(year=year)\n",
    "            analyzer.clean_sdud_data()\n",
    "            analyzer.adding_key()\n",
    "            analyzer.analyze_atc4_mapping()\n",
    "            \n",
    "            records = analyzer.atc_mapping[analyzer.atc_mapping['ATC4 Class'].notna()].copy()\n",
    "            records['ATC2 Class'] = records['ATC4 Class'].str[:3]\n",
    "            \n",
    "            # Group by ATC2 class and get unique NDCs\n",
    "            atc2_ndc_summary = records.groupby('ATC2 Class').agg({\n",
    "                'NDC': 'nunique',\n",
    "                'record_id': 'count'\n",
    "            }).rename(columns={'NDC': 'Unique_NDCs', 'record_id': 'Total_Records'})\n",
    "            \n",
    "            # Calculate additional metrics\n",
    "            total_unique_ndcs = records['NDC'].nunique()\n",
    "            total_records = len(records)\n",
    "            \n",
    "            atc2_ndc_summary['Percentage_of_NDCs'] = (atc2_ndc_summary['Unique_NDCs'] / total_unique_ndcs * 100).round(1)\n",
    "            atc2_ndc_summary['Percentage_of_Records'] = (atc2_ndc_summary['Total_Records'] / total_records * 100).round(1)\n",
    "            atc2_ndc_summary['Avg_Records_per_NDC'] = (atc2_ndc_summary['Total_Records'] / atc2_ndc_summary['Unique_NDCs']).round(1)\n",
    "            \n",
    "            atc2_ndc_summary = atc2_ndc_summary.sort_values('Unique_NDCs', ascending=False)\n",
    "            \n",
    "            print(f\"DETAILED ATC2-NDC ANALYSIS FOR {year}\")\n",
    "            print(\"=\"*50)\n",
    "            print(f\"Total Unique NDCs: {total_unique_ndcs:,}\")\n",
    "            print(f\"Total ATC2 Classes: {len(atc2_ndc_summary)}\")\n",
    "            print(f\"Total Records: {total_records:,}\")\n",
    "            \n",
    "            print(f\"\\nTop {top_n} ATC2 Classes by Unique NDCs:\")\n",
    "            print(atc2_ndc_summary.head(top_n))\n",
    "            \n",
    "            # Show specific examples\n",
    "            print(f\"\\nSample NDCs for top 3 ATC2 classes:\")\n",
    "            for i, (atc2_class, row) in enumerate(atc2_ndc_summary.head(3).iterrows()):\n",
    "                sample_ndcs = records[records['ATC2 Class'] == atc2_class]['NDC'].unique()[:5]\n",
    "                print(f\"{i+1}. {atc2_class} ({row['Unique_NDCs']} unique NDCs):\")\n",
    "                print(f\"   Sample NDCs: {', '.join(sample_ndcs)}\")\n",
    "            \n",
    "            return atc2_ndc_summary\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error analyzing ATC2-NDC details for {year}: {e}\")\n",
    "            return None\n",
    "    \n",
    "\n",
    "        \"\"\"\n",
    "        Get a detailed summary of all ATC2 classes for a specific year.\n",
    "        Shows unique NDCs and record counts for each ATC2 class.\n",
    "        \"\"\"\n",
    "        import pandas as pd\n",
    "        \n",
    "        try:\n",
    "            analyzer = NDCATCAnalyzer(year=year)\n",
    "            analyzer.clean_sdud_data()\n",
    "            analyzer.adding_key()\n",
    "            analyzer.analyze_atc4_mapping()\n",
    "            \n",
    "            records = analyzer.atc_mapping[analyzer.atc_mapping['ATC4 Class'].notna()].copy()\n",
    "            records['ATC2 Class'] = records['ATC4 Class'].str[:3]\n",
    "            \n",
    "            # Summary by ATC2 class\n",
    "            atc2_summary = records.groupby('ATC2 Class').agg({\n",
    "                'NDC': 'nunique',\n",
    "                'record_id': 'count'\n",
    "            }).rename(columns={'NDC': 'Unique_NDCs', 'record_id': 'Total_Records'})\n",
    "            \n",
    "            # Add percentage of total records\n",
    "            total_records = records['record_id'].count()\n",
    "            atc2_summary['Percentage_of_Records'] = (atc2_summary['Total_Records'] / total_records * 100).round(1)\n",
    "            \n",
    "            atc2_summary = atc2_summary.sort_values('Total_Records', ascending=False)\n",
    "            \n",
    "            print(f\"ATC2 Class Summary for {year}:\")\n",
    "            print(\"=\"*50)\n",
    "            print(f\"Total Records with ATC Mapping: {total_records:,}\")\n",
    "            print(f\"Total Unique NDCs: {records['NDC'].nunique():,}\")\n",
    "            print(f\"Total Unique ATC2 Classes: {records['ATC2 Class'].nunique()}\")\n",
    "            print(\"\\nBreakdown by ATC2 Class:\")\n",
    "            print(atc2_summary)\n",
    "            \n",
    "            return atc2_summary\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error getting ATC2 summary for {year}: {e}\")\n",
    "            return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "workflow_execution",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading CSV file: c:\\Users\\lholguin\\OneDrive - purdue.edu\\VS code\\Data\\SDUD\\SDUD2024.csv\n",
      "Total rows in 2024 before filtering: 5205065\n",
      "Rows after removing NA: 2599748\n",
      "Rows after filtering State='XX': 2362630\n",
      "Unique NDCs: 33397\n",
      "Adding record_id column...\n",
      "Created 2362630 record IDs\n",
      "Sample record_id: AK_2024_4_FFSU_00002143380\n",
      "Total rows in ATC4 mapping file: 4336231\n",
      "Unique NDCs in ATC4 mapping file: 32203\n",
      "Merging ATC4 mapping with cleaned data using record_id and NDC...\n",
      "Merged dataframe rows: 4360194\n",
      "Records with ATC4 mapping: 4336231 (99.5%)\n",
      "\n",
      "Records without ATC4 mapping: 23963\n",
      "Unique NDCs without mapping: 1194\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Utilization Type</th>\n",
       "      <th>State</th>\n",
       "      <th>NDC</th>\n",
       "      <th>Labeler Code</th>\n",
       "      <th>Product Code</th>\n",
       "      <th>Package Size</th>\n",
       "      <th>Year</th>\n",
       "      <th>Quarter</th>\n",
       "      <th>Suppression Used</th>\n",
       "      <th>Product Name</th>\n",
       "      <th>Units Reimbursed</th>\n",
       "      <th>Number of Prescriptions</th>\n",
       "      <th>Total Amount Reimbursed</th>\n",
       "      <th>Medicaid Amount Reimbursed</th>\n",
       "      <th>Non Medicaid Amount Reimbursed</th>\n",
       "      <th>record_id</th>\n",
       "      <th>ATC4 Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>FFSU</td>\n",
       "      <td>AK</td>\n",
       "      <td>00002143380</td>\n",
       "      <td>2</td>\n",
       "      <td>1433</td>\n",
       "      <td>80</td>\n",
       "      <td>2024</td>\n",
       "      <td>4</td>\n",
       "      <td>False</td>\n",
       "      <td>TRULICITY</td>\n",
       "      <td>230.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>108512.57</td>\n",
       "      <td>105868.53</td>\n",
       "      <td>2644.04</td>\n",
       "      <td>AK_2024_4_FFSU_00002143380</td>\n",
       "      <td>A10BJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>FFSU</td>\n",
       "      <td>AK</td>\n",
       "      <td>00002143480</td>\n",
       "      <td>2</td>\n",
       "      <td>1434</td>\n",
       "      <td>80</td>\n",
       "      <td>2024</td>\n",
       "      <td>4</td>\n",
       "      <td>False</td>\n",
       "      <td>TRULICITY</td>\n",
       "      <td>216.0</td>\n",
       "      <td>108.0</td>\n",
       "      <td>102247.58</td>\n",
       "      <td>97153.90</td>\n",
       "      <td>5093.68</td>\n",
       "      <td>AK_2024_4_FFSU_00002143480</td>\n",
       "      <td>A10BJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>FFSU</td>\n",
       "      <td>AK</td>\n",
       "      <td>00002143611</td>\n",
       "      <td>2</td>\n",
       "      <td>1436</td>\n",
       "      <td>11</td>\n",
       "      <td>2024</td>\n",
       "      <td>4</td>\n",
       "      <td>False</td>\n",
       "      <td>EMGALITY P</td>\n",
       "      <td>32.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>22193.94</td>\n",
       "      <td>22193.94</td>\n",
       "      <td>0.00</td>\n",
       "      <td>AK_2024_4_FFSU_00002143611</td>\n",
       "      <td>N02CD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>FFSU</td>\n",
       "      <td>AK</td>\n",
       "      <td>00002144511</td>\n",
       "      <td>2</td>\n",
       "      <td>1445</td>\n",
       "      <td>11</td>\n",
       "      <td>2024</td>\n",
       "      <td>4</td>\n",
       "      <td>False</td>\n",
       "      <td>TALTZ AUTO</td>\n",
       "      <td>38.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>253852.99</td>\n",
       "      <td>226811.15</td>\n",
       "      <td>27041.84</td>\n",
       "      <td>AK_2024_4_FFSU_00002144511</td>\n",
       "      <td>L04AC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>FFSU</td>\n",
       "      <td>AK</td>\n",
       "      <td>00002145780</td>\n",
       "      <td>2</td>\n",
       "      <td>1457</td>\n",
       "      <td>80</td>\n",
       "      <td>2024</td>\n",
       "      <td>4</td>\n",
       "      <td>False</td>\n",
       "      <td>MOUNJARO</td>\n",
       "      <td>182.0</td>\n",
       "      <td>91.0</td>\n",
       "      <td>94241.98</td>\n",
       "      <td>92199.80</td>\n",
       "      <td>2042.18</td>\n",
       "      <td>AK_2024_4_FFSU_00002145780</td>\n",
       "      <td>A10BX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4360189</th>\n",
       "      <td>FFSU</td>\n",
       "      <td>WY</td>\n",
       "      <td>82347050505</td>\n",
       "      <td>82347</td>\n",
       "      <td>505</td>\n",
       "      <td>5</td>\n",
       "      <td>2024</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>LIDOCAINE</td>\n",
       "      <td>1149.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>2587.33</td>\n",
       "      <td>2587.33</td>\n",
       "      <td>0.00</td>\n",
       "      <td>WY_2024_1_FFSU_82347050505</td>\n",
       "      <td>C01BB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4360190</th>\n",
       "      <td>FFSU</td>\n",
       "      <td>WY</td>\n",
       "      <td>82347050505</td>\n",
       "      <td>82347</td>\n",
       "      <td>505</td>\n",
       "      <td>5</td>\n",
       "      <td>2024</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>LIDOCAINE</td>\n",
       "      <td>1149.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>2587.33</td>\n",
       "      <td>2587.33</td>\n",
       "      <td>0.00</td>\n",
       "      <td>WY_2024_1_FFSU_82347050505</td>\n",
       "      <td>N01BB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4360191</th>\n",
       "      <td>FFSU</td>\n",
       "      <td>WY</td>\n",
       "      <td>82347050505</td>\n",
       "      <td>82347</td>\n",
       "      <td>505</td>\n",
       "      <td>5</td>\n",
       "      <td>2024</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>LIDOCAINE</td>\n",
       "      <td>1149.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>2587.33</td>\n",
       "      <td>2587.33</td>\n",
       "      <td>0.00</td>\n",
       "      <td>WY_2024_1_FFSU_82347050505</td>\n",
       "      <td>S02DA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4360192</th>\n",
       "      <td>FFSU</td>\n",
       "      <td>WY</td>\n",
       "      <td>82347050505</td>\n",
       "      <td>82347</td>\n",
       "      <td>505</td>\n",
       "      <td>5</td>\n",
       "      <td>2024</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>LIDOCAINE</td>\n",
       "      <td>1149.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>2587.33</td>\n",
       "      <td>2587.33</td>\n",
       "      <td>0.00</td>\n",
       "      <td>WY_2024_1_FFSU_82347050505</td>\n",
       "      <td>S01HA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4360193</th>\n",
       "      <td>FFSU</td>\n",
       "      <td>WY</td>\n",
       "      <td>82347050505</td>\n",
       "      <td>82347</td>\n",
       "      <td>505</td>\n",
       "      <td>5</td>\n",
       "      <td>2024</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>LIDOCAINE</td>\n",
       "      <td>1149.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>2587.33</td>\n",
       "      <td>2587.33</td>\n",
       "      <td>0.00</td>\n",
       "      <td>WY_2024_1_FFSU_82347050505</td>\n",
       "      <td>C05AD</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4360194 rows × 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Utilization Type State          NDC  Labeler Code  Product Code  \\\n",
       "0                   FFSU    AK  00002143380             2          1433   \n",
       "1                   FFSU    AK  00002143480             2          1434   \n",
       "2                   FFSU    AK  00002143611             2          1436   \n",
       "3                   FFSU    AK  00002144511             2          1445   \n",
       "4                   FFSU    AK  00002145780             2          1457   \n",
       "...                  ...   ...          ...           ...           ...   \n",
       "4360189             FFSU    WY  82347050505         82347           505   \n",
       "4360190             FFSU    WY  82347050505         82347           505   \n",
       "4360191             FFSU    WY  82347050505         82347           505   \n",
       "4360192             FFSU    WY  82347050505         82347           505   \n",
       "4360193             FFSU    WY  82347050505         82347           505   \n",
       "\n",
       "         Package Size  Year  Quarter  Suppression Used Product Name  \\\n",
       "0                  80  2024        4             False   TRULICITY    \n",
       "1                  80  2024        4             False   TRULICITY    \n",
       "2                  11  2024        4             False   EMGALITY P   \n",
       "3                  11  2024        4             False   TALTZ AUTO   \n",
       "4                  80  2024        4             False   MOUNJARO     \n",
       "...               ...   ...      ...               ...          ...   \n",
       "4360189             5  2024        1             False   LIDOCAINE    \n",
       "4360190             5  2024        1             False   LIDOCAINE    \n",
       "4360191             5  2024        1             False   LIDOCAINE    \n",
       "4360192             5  2024        1             False   LIDOCAINE    \n",
       "4360193             5  2024        1             False   LIDOCAINE    \n",
       "\n",
       "         Units Reimbursed  Number of Prescriptions  Total Amount Reimbursed  \\\n",
       "0                   230.0                    110.0                108512.57   \n",
       "1                   216.0                    108.0                102247.58   \n",
       "2                    32.0                     31.0                 22193.94   \n",
       "3                    38.0                     37.0                253852.99   \n",
       "4                   182.0                     91.0                 94241.98   \n",
       "...                   ...                      ...                      ...   \n",
       "4360189            1149.0                     38.0                  2587.33   \n",
       "4360190            1149.0                     38.0                  2587.33   \n",
       "4360191            1149.0                     38.0                  2587.33   \n",
       "4360192            1149.0                     38.0                  2587.33   \n",
       "4360193            1149.0                     38.0                  2587.33   \n",
       "\n",
       "         Medicaid Amount Reimbursed  Non Medicaid Amount Reimbursed  \\\n",
       "0                         105868.53                         2644.04   \n",
       "1                          97153.90                         5093.68   \n",
       "2                          22193.94                            0.00   \n",
       "3                         226811.15                        27041.84   \n",
       "4                          92199.80                         2042.18   \n",
       "...                             ...                             ...   \n",
       "4360189                     2587.33                            0.00   \n",
       "4360190                     2587.33                            0.00   \n",
       "4360191                     2587.33                            0.00   \n",
       "4360192                     2587.33                            0.00   \n",
       "4360193                     2587.33                            0.00   \n",
       "\n",
       "                          record_id ATC4 Class  \n",
       "0        AK_2024_4_FFSU_00002143380      A10BJ  \n",
       "1        AK_2024_4_FFSU_00002143480      A10BJ  \n",
       "2        AK_2024_4_FFSU_00002143611      N02CD  \n",
       "3        AK_2024_4_FFSU_00002144511      L04AC  \n",
       "4        AK_2024_4_FFSU_00002145780      A10BX  \n",
       "...                             ...        ...  \n",
       "4360189  WY_2024_1_FFSU_82347050505      C01BB  \n",
       "4360190  WY_2024_1_FFSU_82347050505      N01BB  \n",
       "4360191  WY_2024_1_FFSU_82347050505      S02DA  \n",
       "4360192  WY_2024_1_FFSU_82347050505      S01HA  \n",
       "4360193  WY_2024_1_FFSU_82347050505      C05AD  \n",
       "\n",
       "[4360194 rows x 17 columns]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analyzer = NDCATCAnalyzer(year=2024)\n",
    "analyzer.clean_sdud_data()           # Clean SDUD data\n",
    "analyzer.adding_key()                # Add record_id key\n",
    "#analyzer.generate_ndc_txt()          # Generate NDC text file\n",
    "analyzer.analyze_atc4_mapping()      # Merge ATC4 by record_id & NDC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "644c005a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "ATC4 CLASSES PER RECORD_ID DISTRIBUTION\n",
      "============================================================\n",
      "Distribution of ATC4 classes per record_id:\n",
      "  1 class(es): 1,623,867 record_ids (69.4%)\n",
      "  2 class(es): 282,747 record_ids (12.1%)\n",
      "  3 class(es): 207,971 record_ids (8.9%)\n",
      "  4 class(es): 60,195 record_ids (2.6%)\n",
      "  5 class(es): 49,616 record_ids (2.1%)\n",
      "  6 class(es): 13,854 record_ids (0.6%)\n",
      "  7 class(es): 24,746 record_ids (1.1%)\n",
      "  8 class(es): 23,866 record_ids (1.0%)\n",
      "  9 class(es): 16,379 record_ids (0.7%)\n",
      "  10 class(es): 578 record_ids (0.0%)\n",
      "  11 class(es): 23,370 record_ids (1.0%)\n",
      "  12 class(es): 2,457 record_ids (0.1%)\n",
      "  13 class(es): 670 record_ids (0.0%)\n",
      "  14 class(es): 3,567 record_ids (0.2%)\n",
      "  15 class(es): 467 record_ids (0.0%)\n",
      "  16 class(es): 1,431 record_ids (0.1%)\n",
      "  17 class(es): 483 record_ids (0.0%)\n",
      "  20 class(es): 1,250 record_ids (0.1%)\n",
      "  21 class(es): 48 record_ids (0.0%)\n",
      "  22 class(es): 1,105 record_ids (0.0%)\n",
      "\n",
      "============================================================\n",
      "ATC3 CLASSES PER RECORD_ID DISTRIBUTION\n",
      "============================================================\n",
      "Distribution of ATC3 classes per record_id:\n",
      "  1 class(es): 1,669,581 record_ids (71.4%)\n",
      "  2 class(es): 269,607 record_ids (11.5%)\n",
      "  3 class(es): 195,911 record_ids (8.4%)\n",
      "  4 class(es): 65,303 record_ids (2.8%)\n",
      "  5 class(es): 42,629 record_ids (1.8%)\n",
      "  6 class(es): 10,620 record_ids (0.5%)\n",
      "  7 class(es): 15,568 record_ids (0.7%)\n",
      "  8 class(es): 18,124 record_ids (0.8%)\n",
      "  9 class(es): 16,436 record_ids (0.7%)\n",
      "  10 class(es): 1,126 record_ids (0.0%)\n",
      "  11 class(es): 22,505 record_ids (1.0%)\n",
      "  12 class(es): 2,297 record_ids (0.1%)\n",
      "  13 class(es): 2,168 record_ids (0.1%)\n",
      "  14 class(es): 2,475 record_ids (0.1%)\n",
      "  15 class(es): 574 record_ids (0.0%)\n",
      "  16 class(es): 1,340 record_ids (0.1%)\n",
      "  18 class(es): 155 record_ids (0.0%)\n",
      "  19 class(es): 1,143 record_ids (0.0%)\n",
      "  20 class(es): 1,105 record_ids (0.0%)\n",
      "  Total record_ids with ATC3 mapping: 2,338,667\n",
      "\n",
      "============================================================\n",
      "ATC2 CLASSES PER RECORD_ID DISTRIBUTION\n",
      "============================================================\n",
      "Distribution of ATC2 classes per record_id:\n",
      "  1 class(es): 1,708,752 record_ids (73.1%)\n",
      "  2 class(es): 325,192 record_ids (13.9%)\n",
      "  3 class(es): 141,450 record_ids (6.0%)\n",
      "  4 class(es): 43,344 record_ids (1.9%)\n",
      "  5 class(es): 32,732 record_ids (1.4%)\n",
      "  6 class(es): 6,275 record_ids (0.3%)\n",
      "  7 class(es): 38,416 record_ids (1.6%)\n",
      "  8 class(es): 7,878 record_ids (0.3%)\n",
      "  9 class(es): 23,952 record_ids (1.0%)\n",
      "  10 class(es): 5,104 record_ids (0.2%)\n",
      "  11 class(es): 1,079 record_ids (0.0%)\n",
      "  12 class(es): 3,342 record_ids (0.1%)\n",
      "  14 class(es): 1,151 record_ids (0.0%)\n",
      "\n",
      "ATC2 Summary:\n",
      "  Total record_ids with ATC2 mapping: 2,338,667\n",
      "  Average ATC2 classes per record_id: 1.64\n",
      "  Max ATC2 classes for single record_id: 14\n"
     ]
    }
   ],
   "source": [
    "# Distribution analyses\n",
    "atc4_dist = analyzer.analyze_atc4_distribution()\n",
    "atc3_dist = analyzer.analyze_atc3_distribution() \n",
    "atc2_dist = analyzer.analyze_atc2_distribution()\n",
    "#different_atc2_records = analyzer.analyze_different_atc2_records()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "524d0ef0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "FETCHING ATC CLASS NAMES\n",
      "============================================================\n",
      "Using cache: c:\\Users\\lholguin\\OneDrive - purdue.edu\\VS code\\Data\\ATC\\cache_files\\atc_names_cache\n",
      "\n",
      "Creating ATC3 and ATC2 columns from ATC4...\n",
      "\n",
      "Unique codes to fetch:\n",
      "  ATC4: 612\n",
      "  ATC3: 212\n",
      "  ATC2: 89\n",
      "\n",
      "Fetching ATC4 names...\n",
      "Fetching ATC3 names...\n",
      "Fetching ATC2 names...\n",
      "\n",
      "Total processing time: 0.0 minutes\n",
      "\n",
      "Applying names to dataframe...\n",
      "\n",
      "ATC names added successfully!\n",
      "\n",
      "Sample output:\n",
      "           NDC                   record_id ATC4 Class                                           ATC4_Name ATC3 Class                                     ATC3_Name ATC2 Class               ATC2_Name\n",
      "0  00002143380  AK_2024_4_FFSU_00002143380      A10BJ           Glucagon-like peptide-1 (GLP-1) analogues       A10B  BLOOD GLUCOSE LOWERING DRUGS, EXCL. INSULINS        A10  DRUGS USED IN DIABETES\n",
      "1  00002143480  AK_2024_4_FFSU_00002143480      A10BJ           Glucagon-like peptide-1 (GLP-1) analogues       A10B  BLOOD GLUCOSE LOWERING DRUGS, EXCL. INSULINS        A10  DRUGS USED IN DIABETES\n",
      "2  00002143611  AK_2024_4_FFSU_00002143611      N02CD  Calcitonin gene-related peptide (CGRP) antagonists       N02C                     ANTIMIGRAINE PREPARATIONS        N02              ANALGESICS\n",
      "3  00002144511  AK_2024_4_FFSU_00002144511      L04AC                              Interleukin inhibitors       L04A                            IMMUNOSUPPRESSANTS        L04      IMMUNOSUPPRESSANTS\n",
      "4  00002145780  AK_2024_4_FFSU_00002145780      A10BX  Other blood glucose lowering drugs, excl. insulins       A10B  BLOOD GLUCOSE LOWERING DRUGS, EXCL. INSULINS        A10  DRUGS USED IN DIABETES\n",
      "\n",
      "============================================================\n",
      "SELECT-ONE-ATC PER RECORD_ID (DETERMINISTIC)\n",
      "============================================================\n",
      "Unique record_ids (raw): 2,362,630\n",
      "Kept record_ids (one per id): 2,338,667\n",
      "Records with >1 ATC4 candidates: 714,800 (30.3%)\n",
      "Tie-break order: NDC-mode → priority(list) → Units → Prescriptions → alphabetical\n",
      "\n",
      "============================================================\n",
      "PREPARING FINAL DATAFRAME\n",
      "============================================================\n",
      "\n",
      "============================================================\n",
      "DATA EXPORT COMPLETE (ONE ATC PER RECORD_ID)\n",
      "============================================================\n",
      "Exported: c:\\Users\\lholguin\\OneDrive - purdue.edu\\VS code\\Data\\ATC\\merged_data\\merged_NEWdata_2024.csv\n",
      "Rows exported: 2,338,667\n",
      "Sums preserved? Units: False, Prescriptions: False\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\lholguin\\\\OneDrive - purdue.edu\\\\VS code\\\\Data\\\\ATC\\\\merged_data\\\\merged_NEWdata_2024.csv'"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analyzer.fetch_atc_names()           \n",
    "analyzer.prepare_final_dataframe()   \n",
    "analyzer.export_merged_data()  \n",
    "# Simple version - only percentages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "2aa7828a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating ATC2 Overview: Unique NDCs per ATC2 Class Across Years...\n",
      "======================================================================\n",
      "Processing 2021... Reading CSV file: c:\\Users\\lholguin\\OneDrive - purdue.edu\\VS code\\Data\\SDUD\\SDUD2021.csv\n",
      "Total rows in 2021 before filtering: 5042532\n",
      "Rows after removing NA: 2575044\n",
      "Rows after filtering State='XX': 2348980\n",
      "Unique NDCs: 32417\n",
      "Adding record_id column...\n",
      "Created 2348980 record IDs\n",
      "Sample record_id: AK_2021_4_FFSU_00002143380\n",
      "Total rows in ATC4 mapping file: 4248026\n",
      "Unique NDCs in ATC4 mapping file: 29275\n",
      "Merging ATC4 mapping with cleaned data using record_id and NDC...\n",
      "Merged dataframe rows: 4309498\n",
      "Records with ATC4 mapping: 4248026 (98.6%)\n",
      "\n",
      "Records without ATC4 mapping: 61472\n",
      "Unique NDCs without mapping: 3142\n",
      "✓ (89 ATC2 classes, 29,275 total unique NDCs)\n",
      "Processing 2022... Reading CSV file: c:\\Users\\lholguin\\OneDrive - purdue.edu\\VS code\\Data\\SDUD\\SDUD2022.csv\n",
      "Total rows in 2022 before filtering: 5164804\n",
      "Rows after removing NA: 2621949\n",
      "Rows after filtering State='XX': 2389418\n",
      "Unique NDCs: 33005\n",
      "Adding record_id column...\n",
      "Created 2389418 record IDs\n",
      "Sample record_id: AK_2022_4_FFSU_00002143380\n",
      "Total rows in ATC4 mapping file: 4385476\n",
      "Unique NDCs in ATC4 mapping file: 30846\n",
      "Merging ATC4 mapping with cleaned data using record_id and NDC...\n",
      "Merged dataframe rows: 4421713\n",
      "Records with ATC4 mapping: 4385476 (99.2%)\n",
      "\n",
      "Records without ATC4 mapping: 36237\n",
      "Unique NDCs without mapping: 2159\n",
      "✓ (89 ATC2 classes, 30,846 total unique NDCs)\n",
      "Processing 2023... Reading CSV file: c:\\Users\\lholguin\\OneDrive - purdue.edu\\VS code\\Data\\SDUD\\SDUD2023.csv\n",
      "Total rows in 2023 before filtering: 5277298\n",
      "Rows after removing NA: 2651527\n",
      "Rows after filtering State='XX': 2413521\n",
      "Unique NDCs: 34439\n",
      "Adding record_id column...\n",
      "Created 2413521 record IDs\n",
      "Sample record_id: AK_2023_4_FFSU_00002143380\n",
      "Total rows in ATC4 mapping file: 4426568\n",
      "Unique NDCs in ATC4 mapping file: 32499\n",
      "Merging ATC4 mapping with cleaned data using record_id and NDC...\n",
      "Merged dataframe rows: 4454193\n",
      "Records with ATC4 mapping: 4426568 (99.4%)\n",
      "\n",
      "Records without ATC4 mapping: 27625\n",
      "Unique NDCs without mapping: 1940\n",
      "✓ (89 ATC2 classes, 32,499 total unique NDCs)\n",
      "Processing 2024... Reading CSV file: c:\\Users\\lholguin\\OneDrive - purdue.edu\\VS code\\Data\\SDUD\\SDUD2024.csv\n",
      "Total rows in 2024 before filtering: 5205065\n",
      "Rows after removing NA: 2599748\n",
      "Rows after filtering State='XX': 2362630\n",
      "Unique NDCs: 33397\n",
      "Adding record_id column...\n",
      "Created 2362630 record IDs\n",
      "Sample record_id: AK_2024_4_FFSU_00002143380\n",
      "Total rows in ATC4 mapping file: 4336231\n",
      "Unique NDCs in ATC4 mapping file: 32203\n",
      "Merging ATC4 mapping with cleaned data using record_id and NDC...\n",
      "Merged dataframe rows: 4360194\n",
      "Records with ATC4 mapping: 4336231 (99.5%)\n",
      "\n",
      "Records without ATC4 mapping: 23963\n",
      "Unique NDCs without mapping: 1194\n",
      "✓ (89 ATC2 classes, 32,203 total unique NDCs)\n",
      "\n",
      "UNIQUE NDCs PER ATC2 CLASS BY YEAR\n",
      "============================================================\n",
      "\n",
      "2021:\n",
      "----------------------------------------\n",
      "Total ATC2 Classes: 89\n",
      "Total Unique NDCs: 29,275\n",
      "\n",
      "Top 10 ATC2 Classes by Unique NDCs:\n",
      "            Unique_NDCs  Total_Records  Percentage_of_NDCs\n",
      "ATC2 Class                                                \n",
      "S01                3359         225028                11.5\n",
      "J01                2346         174808                 8.0\n",
      "N06                2310         237634                 7.9\n",
      "N02                2058         166620                 7.0\n",
      "N05                2021         207865                 6.9\n",
      "C05                1511          97341                 5.2\n",
      "D07                1340         110577                 4.6\n",
      "A01                1204          95815                 4.1\n",
      "R01                1189          93863                 4.1\n",
      "C01                1151          57852                 3.9\n",
      "\n",
      "2022:\n",
      "----------------------------------------\n",
      "Total ATC2 Classes: 89\n",
      "Total Unique NDCs: 30,846\n",
      "\n",
      "Top 10 ATC2 Classes by Unique NDCs:\n",
      "            Unique_NDCs  Total_Records  Percentage_of_NDCs\n",
      "ATC2 Class                                                \n",
      "S01                3590         232741                11.6\n",
      "N06                2497         247458                 8.1\n",
      "J01                2444         178022                 7.9\n",
      "N05                2096         207271                 6.8\n",
      "N02                2092         167860                 6.8\n",
      "C05                1590          99755                 5.2\n",
      "D07                1390         115597                 4.5\n",
      "R01                1306          99991                 4.2\n",
      "A01                1259          98847                 4.1\n",
      "C01                1231          60294                 4.0\n",
      "\n",
      "2023:\n",
      "----------------------------------------\n",
      "Total ATC2 Classes: 89\n",
      "Total Unique NDCs: 32,499\n",
      "\n",
      "Top 10 ATC2 Classes by Unique NDCs:\n",
      "            Unique_NDCs  Total_Records  Percentage_of_NDCs\n",
      "ATC2 Class                                                \n",
      "S01                3742         236590                11.5\n",
      "N06                2692         255174                 8.3\n",
      "J01                2506         182159                 7.7\n",
      "N05                2239         212710                 6.9\n",
      "N02                2138         162821                 6.6\n",
      "C05                1640         101637                 5.0\n",
      "D07                1360         116342                 4.2\n",
      "R01                1356         102963                 4.2\n",
      "C01                1317          59523                 4.1\n",
      "L01                1284          53261                 4.0\n",
      "\n",
      "2024:\n",
      "----------------------------------------\n",
      "Total ATC2 Classes: 89\n",
      "Total Unique NDCs: 32,203\n",
      "\n",
      "Top 10 ATC2 Classes by Unique NDCs:\n",
      "            Unique_NDCs  Total_Records  Percentage_of_NDCs\n",
      "ATC2 Class                                                \n",
      "S01                3742         234021                11.6\n",
      "N06                2657         255424                 8.3\n",
      "J01                2389         174155                 7.4\n",
      "N05                2250         210375                 7.0\n",
      "N02                2024         157759                 6.3\n",
      "C05                1669         100291                 5.2\n",
      "R01                1337         102328                 4.2\n",
      "C01                1317          58872                 4.1\n",
      "D07                1316         112703                 4.1\n",
      "L01                1306          49483                 4.1\n",
      "\n",
      "COMPARISON: TOP ATC2 CLASSES ACROSS YEARS (by Unique NDCs)\n",
      "======================================================================\n",
      "Top 15 ATC2 Classes by Total Unique NDCs Across All Years:\n",
      "     2021  2022  2023  2024\n",
      "S01  3359  3590  3742  3742\n",
      "N06  2310  2497  2692  2657\n",
      "J01  2346  2444  2506  2389\n",
      "N05  2021  2096  2239  2250\n",
      "N02  2058  2092  2138  2024\n",
      "C05  1511  1590  1640  1669\n",
      "D07  1340  1390  1360  1316\n",
      "R01  1189  1306  1356  1337\n",
      "C01  1151  1231  1317  1317\n",
      "A01  1204  1259  1268  1248\n",
      "L01  1108  1193  1284  1306\n",
      "N03   999  1100  1250  1236\n",
      "A07  1024  1069  1088  1085\n",
      "C09  1072  1035  1086  1032\n",
      "S02   985  1033  1040  1058\n",
      "Comparison table:\n",
      "     2021  2022  2023  2024\n",
      "S01  3359  3590  3742  3742\n",
      "N06  2310  2497  2692  2657\n",
      "J01  2346  2444  2506  2389\n",
      "N05  2021  2096  2239  2250\n",
      "N02  2058  2092  2138  2024\n",
      "..    ...   ...   ...   ...\n",
      "R07    11     9    11    11\n",
      "M09     8     8     8     9\n",
      "A14     5     4     5     1\n",
      "V01     1     2     6     6\n",
      "V10     2     1     3     1\n",
      "\n",
      "[89 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "years_to_analyze = [2021, 2022, 2023, 2024]\n",
    "yearly_results, overview_data, comparison_table = NDCATCAnalyzer.analyze_general_atc2_overview(years_to_analyze)\n",
    "\n",
    "# The comparison_table shows unique NDCs per ATC2 class across years\n",
    "print(\"Comparison table:\")\n",
    "print(comparison_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "b26b2a79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Summary of Each File ===\n",
      "                                File  Total rows  Unique NDCs  Mapped NDCs (non-null ATC)\n",
      " With key (NDCNEW_2024_ATC4_classes)     4426568        32499                     4426568\n",
      "Without key (NDCf_2024_ATC4_classes)       62105        32499                       62105\n",
      "\n",
      "=== NDC Overlap Comparison ===\n",
      "                  Metric   Value\n",
      "            Overlap NDCs 32499.0\n",
      "Only in without-key file     0.0\n",
      "   Only in with-key file     0.0\n",
      "         Percent overlap   100.0\n"
     ]
    }
   ],
   "source": [
    "nokey_path=rf'C:\\Users\\{user}\\OneDrive - purdue.edu\\VS code\\Data\\ATC\\ATC4_classes\\Classes_notgood\\NDCf_2023_ATC4_classes.csv'\n",
    "keyed_path=rf'C:\\Users\\{user}\\OneDrive - purdue.edu\\VS code\\Data\\ATC\\ATC4_classes\\NDCNEW_2023_ATC4_classes.csv'\n",
    "\n",
    "# Load them\n",
    "keyed = pd.read_csv(keyed_path, dtype=str)\n",
    "nokey = pd.read_csv(nokey_path, dtype=str)\n",
    "\n",
    "# Normalize NDCs (remove hyphens, pad to 11 digits)\n",
    "for df in [keyed, nokey]:\n",
    "    df[\"NDC\"] = df[\"NDC\"].str.replace(\"-\", \"\", regex=False).str.zfill(11)\n",
    "\n",
    "# --- Summary stats ---\n",
    "summary = {\n",
    "    \"File\": [\"With key (NDCNEW_2024_ATC4_classes)\", \"Without key (NDCf_2024_ATC4_classes)\"],\n",
    "    \"Total rows\": [len(keyed), len(nokey)],\n",
    "    \"Unique NDCs\": [keyed[\"NDC\"].nunique(), nokey[\"NDC\"].nunique()],\n",
    "    \"Mapped NDCs (non-null ATC)\": [\n",
    "        keyed[\"ATC4 Class\"].notna().sum(),\n",
    "        nokey[\"ATC4 Class\"].notna().sum(),\n",
    "    ],\n",
    "}\n",
    "summary_df = pd.DataFrame(summary)\n",
    "\n",
    "# --- Compare overlap of unique NDCs ---\n",
    "ndc_keyed = set(keyed[\"NDC\"].unique())\n",
    "ndc_nokey = set(nokey[\"NDC\"].unique())\n",
    "\n",
    "overlap_ndcs = len(ndc_keyed & ndc_nokey)\n",
    "only_in_nokey = len(ndc_nokey - ndc_keyed)\n",
    "only_in_keyed = len(ndc_keyed - ndc_nokey)\n",
    "\n",
    "comparison = pd.DataFrame({\n",
    "    \"Metric\": [\"Overlap NDCs\", \"Only in without-key file\", \"Only in with-key file\", \"Percent overlap\"],\n",
    "    \"Value\": [overlap_ndcs, only_in_nokey, only_in_keyed, overlap_ndcs / len(ndc_nokey) * 100]\n",
    "})\n",
    "\n",
    "print(\"\\n=== Summary of Each File ===\")\n",
    "print(summary_df.to_string(index=False))\n",
    "\n",
    "print(\"\\n=== NDC Overlap Comparison ===\")\n",
    "print(comparison.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0887c17",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
