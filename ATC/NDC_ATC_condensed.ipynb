{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c2b3e3b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "import shelve\n",
    "import os\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "56f7f271",
   "metadata": {},
   "outputs": [],
   "source": [
    "user=\"lholguin\"\n",
    "#user in personal pc <- \"asus\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73aebaf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Class with new methods for NDC-ATC analysis\n",
    "class NDCATCAnalyzer:\n",
    "\n",
    "    def __init__(self, year, base_path=None):\n",
    "\n",
    "        self.year = year\n",
    "        if base_path is None:\n",
    "            #Lookup the user's base path\n",
    "            self.base_path = rf\"c:\\Users\\{user}\\OneDrive - purdue.edu\\VS code\\Data\"\n",
    "        else:\n",
    "            self.base_path = base_path\n",
    "            \n",
    "        self.df_cleaned = None\n",
    "        self.df_merged = None\n",
    "        self.atc_mapping = None\n",
    "        self.df_faf = None\n",
    "        \n",
    "    def clean_sdud_data(self):\n",
    "        csv_file = os.path.join(self.base_path, f\"SDUD\\\\SDUD{self.year}.csv\")\n",
    "        print(f\"Reading CSV file: {csv_file}\")\n",
    "        \n",
    "        # Read with NDC as string to preserve leading zeros\n",
    "        df = pd.read_csv(csv_file, dtype={'NDC': 'object'})\n",
    "        \n",
    "        print(f\"Total rows in {self.year} before filtering: {len(df)}\")\n",
    "        \n",
    "        # Remove NA values\n",
    "        df_filtered = df.dropna(subset=['Units Reimbursed', 'Number of Prescriptions'])\n",
    "        print(f\"Rows after removing NA: {len(df_filtered)}\")\n",
    "        \n",
    "        # Filter out State='XX'\n",
    "        df_filtered = df_filtered[df_filtered['State'] != 'XX']\n",
    "        print(f\"Rows after filtering State='XX': {len(df_filtered)}\")\n",
    "        print(f\"Unique NDCs: {df_filtered['NDC'].nunique()}\")\n",
    "        \n",
    "        self.df_cleaned = df_filtered\n",
    "        return self.df_cleaned\n",
    "    \n",
    "    #NEW\n",
    "    def adding_key(self):\n",
    "        if self.df_cleaned is None:\n",
    "            raise ValueError(\"Must run clean_sdud_data() first\")\n",
    "        \n",
    "        print(\"Adding record_id column...\")\n",
    "        \n",
    "        # Create record_id column\n",
    "        self.df_cleaned['record_id'] = (\n",
    "            self.df_cleaned['State'].astype(str) + \"_\" +\n",
    "            self.df_cleaned['Year'].astype(str) + \"_\" +\n",
    "            self.df_cleaned['Quarter'].astype(str) + \"_\" +\n",
    "            self.df_cleaned['Utilization Type'].astype(str) + \"_\" +\n",
    "            self.df_cleaned['NDC'].astype(str)\n",
    "        )\n",
    "        \n",
    "        print(f\"Created {len(self.df_cleaned)} record IDs\")\n",
    "        print(f\"Sample record_id: {self.df_cleaned['record_id'].iloc[0]}\")\n",
    "        \n",
    "        return self.df_cleaned\n",
    "    \n",
    "    def generate_ndc_txt(self, output_filename=None):\n",
    "        \"\"\"Step 2: Generate text file with unique NDC values and their record_id keys.\"\"\"\n",
    "        if self.df_cleaned is None:\n",
    "            raise ValueError(\"Must run clean_sdud_data() first\")\n",
    "        \n",
    "        if 'record_id' not in self.df_cleaned.columns:\n",
    "            raise ValueError(\"Must run adding_key() first to create record_id column\")\n",
    "            \n",
    "        if output_filename is None:\n",
    "            output_filename = f\"NDCNEW_{self.year}.txt\"\n",
    "        \n",
    "        output_path = os.path.join(self.base_path, f\"ATC\\\\text_files\\\\{output_filename}\")\n",
    "        \n",
    "        # Get unique combinations of NDC and record_id\n",
    "        unique_pairs = self.df_cleaned[['NDC', 'record_id']].drop_duplicates()\n",
    "        \n",
    "        with open(output_path, 'w') as f:\n",
    "            # Write header\n",
    "            f.write(\"NDC\\trecord_id\\n\")\n",
    "            # Write each unique pair\n",
    "            for _, row in unique_pairs.iterrows():\n",
    "                f.write(f\"{row['NDC']}\\t{row['record_id']}\\n\")\n",
    "        \n",
    "        print(f\"Exported to: {output_path}\")\n",
    "        print(f\"Unique record_id values: {unique_pairs['record_id'].nunique()}\")\n",
    "        return output_path\n",
    "    \n",
    "    def analyze_atc4_mapping(self):\n",
    "        atc4_path = os.path.join(self.base_path, f\"ATC\\\\ATC4_classes\\\\NDCNEW_{self.year}_ATC4_classes.csv\")\n",
    "        \n",
    "        # Read ATC4 mapping\n",
    "        df_atc4 = pd.read_csv(atc4_path, dtype={'NDC': 'object', 'record_id': 'string'})\n",
    "        df_atc4['NDC'] = df_atc4['NDC'].str.zfill(11)\n",
    "\n",
    "        #Print how many unique NDC codes were mapped\n",
    "        print(f\"Total rows in ATC4 mapping file: {len(df_atc4)}\")\n",
    "        print(f\"Unique NDCs in ATC4 mapping file: {df_atc4['NDC'].nunique()}\")\n",
    "\n",
    "        # Ensure consistent data types before merge\n",
    "        self.df_cleaned['record_id'] = self.df_cleaned['record_id'].astype('string')\n",
    "        self.df_cleaned['NDC'] = self.df_cleaned['NDC'].astype('object')  \n",
    "        df_atc4['record_id'] = df_atc4['record_id'].astype('string')\n",
    "        df_atc4['NDC'] = df_atc4['NDC'].astype('object')  \n",
    "\n",
    "        # Merge ATC4 mapping with cleaned data using record_id\n",
    "        if self.df_cleaned is None:\n",
    "            raise ValueError(\"Must run clean_sdud_data() and adding_key() first\")\n",
    "        \n",
    "        if 'record_id' not in self.df_cleaned.columns:\n",
    "            raise ValueError(\"Must run adding_key() first to create record_id column\")\n",
    "        \n",
    "        print(f\"Merging ATC4 mapping with cleaned data using record_id and NDC...\")\n",
    "        \n",
    "        # Merge on BOTH record_id AND NDC\n",
    "        self.atc_mapping = pd.merge(\n",
    "            self.df_cleaned,\n",
    "            df_atc4[['record_id', 'NDC', 'ATC4 Class']],  # Include NDC in the selection\n",
    "            on=['record_id', 'NDC'],  # Merge on both columns\n",
    "            how='left'\n",
    "        )\n",
    "        \n",
    "        # Print rows of the merged dataframe\n",
    "        print(f\"Merged dataframe rows: {len(self.atc_mapping)}\")\n",
    "        #print(self.atc_mapping.head())\n",
    "        total_records = len(self.atc_mapping)\n",
    "        mapped_records = self.atc_mapping['ATC4 Class'].notna().sum()\n",
    "        print(f\"Records with ATC4 mapping: {mapped_records} ({mapped_records/total_records*100:.1f}%)\")\n",
    "\n",
    "        # Identify missing mappings\n",
    "        missing_records = self.atc_mapping[self.atc_mapping['ATC4 Class'].isna()]\n",
    "        if len(missing_records) > 0:\n",
    "            print(f\"\\nRecords without ATC4 mapping: {len(missing_records)}\")\n",
    "            print(f\"Unique NDCs without mapping: {missing_records['NDC'].nunique()}\")\n",
    "        \n",
    "        return self.atc_mapping\n",
    "\n",
    "    def select_one_atc_per_record(self, strategy=\"ndc_mode_then_priority\"):\n",
    "        if self.atc_mapping is None:\n",
    "            raise ValueError(\"Must run analyze_atc4_mapping() first\")\n",
    "\n",
    "        df = self.atc_mapping.copy()\n",
    "        df = df[df['ATC4 Class'].notna()].copy()\n",
    "\n",
    "        # NDC-level ATC4 frequency (mode by NDC)\n",
    "        ndc_atc_counts = (\n",
    "            df.groupby(['NDC','ATC4 Class'])\n",
    "            .size().rename('ndc_atc_count')\n",
    "            .reset_index()\n",
    "        )\n",
    "        df = df.merge(ndc_atc_counts, on=['NDC','ATC4 Class'], how='left')\n",
    "\n",
    "        def atc_priority(atc4):\n",
    "            atc2 = atc4[:3] if isinstance(atc4, str) else \"\"\n",
    "            if atc2.startswith('V03'):  # 'Other therapeutic products'\n",
    "                return 100\n",
    "            if atc2.startswith('V'):    # 'Various'\n",
    "                return 80\n",
    "            # illustrative booster: tune as needed\n",
    "            boosters = {'A':10,'B':15,'C':12,'D':20,'G':18,'H':14,'J':11,'L':16,'M':17,'N':13,'R':19,'S':21}\n",
    "            return boosters.get(atc2[:1], 50)\n",
    "\n",
    "        df['priority_score'] = df['ATC4 Class'].map(atc_priority).fillna(60)\n",
    "\n",
    "        df = df.sort_values(\n",
    "            by=['record_id','ndc_atc_count','priority_score','Units Reimbursed','Number of Prescriptions','ATC4 Class'],\n",
    "            ascending=[True, False, True, False, False, True]\n",
    "        )\n",
    "\n",
    "        df_one = df.drop_duplicates(subset='record_id', keep='first').copy()\n",
    "\n",
    "        # small diagnostic\n",
    "        total_records = self.atc_mapping['record_id'].nunique()\n",
    "        kept = len(df_one)\n",
    "        multi = (self.atc_mapping\n",
    "                .groupby('record_id')['ATC4 Class']\n",
    "                .nunique()\n",
    "                .reset_index(name='n'))\n",
    "        pct_multi = (multi['n']>1).mean()*100\n",
    "\n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(\"SELECT-ONE-ATC PER RECORD_ID (DETERMINISTIC)\")\n",
    "        print(\"=\"*60)\n",
    "        print(f\"Unique record_ids (raw): {total_records:,}\")\n",
    "        print(f\"Kept record_ids (one per id): {kept:,}\")\n",
    "        print(f\"Records with >1 ATC4 candidates: {int((multi['n']>1).sum()):,} ({pct_multi:.1f}%)\")\n",
    "        print(\"Tie-break order: NDC-mode → priority(list) → Units → Prescriptions → alphabetical\")\n",
    "\n",
    "        self.df_selected = df_one\n",
    "        return self.df_selected\n",
    "\n",
    "    def analyze_atc4_distribution(self):\n",
    "\n",
    "        if self.atc_mapping is None:\n",
    "            raise ValueError(\"Must run analyze_atc4_mapping() first\")\n",
    "        \n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(\"ATC4 CLASSES PER RECORD_ID DISTRIBUTION\")\n",
    "        print(f\"{'='*60}\")\n",
    "        \n",
    "        # Count ATC4 classes per record_id (only valid mappings)\n",
    "        records_with_mapping = self.atc_mapping[self.atc_mapping['ATC4 Class'].notna()].copy()\n",
    "        \n",
    "        if len(records_with_mapping) == 0:\n",
    "            print(\"No records with valid ATC4 mappings found.\")\n",
    "            return None\n",
    "        \n",
    "        # Group by record_id and count unique ATC4 classes\n",
    "        atc4_per_record = records_with_mapping.groupby('record_id').agg({\n",
    "            'ATC4 Class': 'nunique',\n",
    "            'NDC': 'first',  # Get the NDC for reference\n",
    "            'State': 'first',  # Get the state for reference\n",
    "            'Year': 'first'    # Get the year for reference\n",
    "        }).reset_index()\n",
    "        \n",
    "        atc4_per_record.columns = ['record_id', 'num_atc4_classes', 'NDC', 'State', 'Year']\n",
    "        \n",
    "        # Distribution analysis\n",
    "        distribution = atc4_per_record['num_atc4_classes'].value_counts().sort_index()\n",
    "        \n",
    "        print(\"Distribution of ATC4 classes per record_id:\")\n",
    "        for classes, count in distribution.items():\n",
    "            pct = (count / len(atc4_per_record)) * 100\n",
    "            print(f\"  {classes} class(es): {count:,} record_ids ({pct:.1f}%)\")\n",
    "        \n",
    "        # Show examples of multi-class records\n",
    "        #multi_class = atc4_per_record[atc4_per_record['num_atc4_classes'] > 1].sort_values('num_atc4_classes', ascending=False)\n",
    "        \n",
    "        #if len(multi_class) > 0:\n",
    "            #print(f\"\\nTop 10 record_ids with most ATC4 classes:\")\n",
    "            #for _, row in multi_class.head(10).iterrows():\n",
    "                #record_classes = records_with_mapping[records_with_mapping['record_id'] == row['record_id']]['ATC4 Class'].unique()\n",
    "                #print(f\"  {row['record_id']}: {row['num_atc4_classes']} classes\")\n",
    "                #print(f\"    NDC: {row['NDC']}, State: {row['State']}, Year: {row['Year']}\")\n",
    "                #print(f\"    Classes: {list(record_classes)}\")\n",
    "                #print()\n",
    "        \n",
    "        #return atc4_per_record\n",
    "\n",
    "    def fetch_atc_names(self, cache_path=None):\n",
    "        \"\"\"Fetch ATC class names (ATC4, ATC3, ATC2) from RxNav API.\"\"\"\n",
    "        if self.atc_mapping is None:\n",
    "            raise ValueError(\"Must run analyze_atc4_mapping() first\")\n",
    "        \n",
    "        if cache_path is None:\n",
    "            cache_path = os.path.join(self.base_path, \"ATC\\\\cache_files\\\\atc_names_cache\")\n",
    "        \n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(\"FETCHING ATC CLASS NAMES\")\n",
    "        print(f\"{'='*60}\")\n",
    "        print(f\"Using cache: {cache_path}\")\n",
    "        \n",
    "        # Get only records with valid ATC4 mappings\n",
    "        df_with_atc = self.atc_mapping[self.atc_mapping['ATC4 Class'].notna()].copy()\n",
    "        \n",
    "        # Create ATC3 and ATC2 columns from ATC4\n",
    "        print(\"\\nCreating ATC3 and ATC2 columns from ATC4...\")\n",
    "        df_with_atc['ATC3 Class'] = df_with_atc['ATC4 Class'].str[:4]\n",
    "        df_with_atc['ATC2 Class'] = df_with_atc['ATC4 Class'].str[:3]\n",
    "        \n",
    "        # Get unique codes for each level\n",
    "        unique_atc4 = df_with_atc['ATC4 Class'].dropna().unique()\n",
    "        unique_atc3 = df_with_atc['ATC3 Class'].dropna().unique()\n",
    "        unique_atc2 = df_with_atc['ATC2 Class'].dropna().unique()\n",
    "        \n",
    "        # Filter out invalid codes\n",
    "        unique_atc4 = [c for c in unique_atc4 if c not in ['No ATC Mapping Found', 'No RxCUI Found', '']]\n",
    "        unique_atc3 = [c for c in unique_atc3 if c not in ['No ATC Mapping Found', 'No RxCUI Found', '', 'No ', 'No']]\n",
    "        unique_atc2 = [c for c in unique_atc2 if c not in ['No ATC Mapping Found', 'No RxCUI Found', '', 'No ', 'No']]\n",
    "        \n",
    "        print(f\"\\nUnique codes to fetch:\")\n",
    "        print(f\"  ATC4: {len(unique_atc4)}\")\n",
    "        print(f\"  ATC3: {len(unique_atc3)}\")\n",
    "        print(f\"  ATC2: {len(unique_atc2)}\")\n",
    "        \n",
    "        # Build mappings\n",
    "        atc4_names = {}\n",
    "        atc3_names = {}\n",
    "        atc2_names = {}\n",
    "        \n",
    "        with shelve.open(cache_path) as cache:\n",
    "            start_time = datetime.now()\n",
    "            \n",
    "            print(\"\\nFetching ATC4 names...\")\n",
    "            for code in unique_atc4:\n",
    "                atc4_names[code] = self._get_atc_name(code, cache)\n",
    "            \n",
    "            print(\"Fetching ATC3 names...\")\n",
    "            for code in unique_atc3:\n",
    "                atc3_names[code] = self._get_atc_name(code, cache)\n",
    "            \n",
    "            print(\"Fetching ATC2 names...\")\n",
    "            for code in unique_atc2:\n",
    "                atc2_names[code] = self._get_atc_name(code, cache)\n",
    "            \n",
    "            print(f\"\\nTotal processing time: {(datetime.now() - start_time).total_seconds()/60:.1f} minutes\")\n",
    "        \n",
    "        # Apply names to all records in atc_mapping\n",
    "        print(\"\\nApplying names to dataframe...\")\n",
    "        self.atc_mapping['ATC3 Class'] = self.atc_mapping['ATC4 Class'].str[:4]\n",
    "        self.atc_mapping['ATC2 Class'] = self.atc_mapping['ATC4 Class'].str[:3]\n",
    "        \n",
    "        self.atc_mapping['ATC4_Name'] = self.atc_mapping['ATC4 Class'].map(atc4_names).fillna('')\n",
    "        self.atc_mapping['ATC3_Name'] = self.atc_mapping['ATC3 Class'].map(atc3_names).fillna('')\n",
    "        self.atc_mapping['ATC2_Name'] = self.atc_mapping['ATC2 Class'].map(atc2_names).fillna('')\n",
    "        \n",
    "        print(f\"\\nATC names added successfully!\")\n",
    "        print(\"\\nSample output:\")\n",
    "        sample = self.atc_mapping[self.atc_mapping['ATC4 Class'].notna()][['NDC', 'record_id', 'ATC4 Class', 'ATC4_Name', 'ATC3 Class', 'ATC3_Name', 'ATC2 Class', 'ATC2_Name']].head(5)\n",
    "        print(sample.to_string())\n",
    "        \n",
    "        return self.atc_mapping\n",
    "    \n",
    "    def prepare_final_dataframe(self):\n",
    "        if not hasattr(self, 'df_selected'):\n",
    "        # ensure selection has run\n",
    "            self.select_one_atc_per_record()\n",
    "\n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(\"PREPARING FINAL DATAFRAME\")\n",
    "        print(\"=\"*60)\n",
    "\n",
    "        self.df_merged = self.df_selected.copy()\n",
    "\n",
    "        return self.df_merged\n",
    "    \n",
    "    def _get_atc_name(self, atc_code, cache):\n",
    "        \"\"\"Get ATC class name from code, using cache.\"\"\"\n",
    "        cache_key = f\"atc_name:{atc_code}\"\n",
    "        if cache_key in cache:\n",
    "            return cache[cache_key]\n",
    "        \n",
    "        try:\n",
    "            url = f\"https://rxnav.nlm.nih.gov/REST/rxclass/class/byId.json?classId={atc_code}\"\n",
    "            response = requests.get(url)\n",
    "            response.raise_for_status()\n",
    "            data = response.json()\n",
    "            \n",
    "            # Get class name\n",
    "            if 'rxclassMinConceptList' in data and 'rxclassMinConcept' in data['rxclassMinConceptList']:\n",
    "                concepts = data['rxclassMinConceptList']['rxclassMinConcept']\n",
    "                if concepts:\n",
    "                    name = concepts[0].get('className', '')\n",
    "                    cache[cache_key] = name\n",
    "                    return name\n",
    "            \n",
    "            cache[cache_key] = ''\n",
    "            return ''\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error retrieving name for {atc_code}: {e}\")\n",
    "            cache[cache_key] = ''\n",
    "            return ''\n",
    "    \n",
    "    def analyze_atc3_distribution(self):\n",
    "\n",
    "        if self.atc_mapping is None:\n",
    "            raise ValueError(\"Must run analyze_atc4_mapping() first\")\n",
    "        \n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(\"ATC3 CLASSES PER RECORD_ID DISTRIBUTION\")\n",
    "        print(f\"{'='*60}\")\n",
    "        \n",
    "        # Create ATC3 classes from ATC4\n",
    "        records_with_mapping = self.atc_mapping[self.atc_mapping['ATC4 Class'].notna()].copy()\n",
    "        \n",
    "        if len(records_with_mapping) == 0:\n",
    "            print(\"No records with valid ATC4 mappings found.\")\n",
    "            return None\n",
    "        \n",
    "        # Create ATC3 class from ATC4 class (first 4 characters)\n",
    "        records_with_mapping['ATC3 Class'] = records_with_mapping['ATC4 Class'].str[:4]\n",
    "        \n",
    "        # Group by record_id and count unique ATC3 classes\n",
    "        atc3_per_record = records_with_mapping.groupby('record_id').agg({\n",
    "            'ATC3 Class': 'nunique',\n",
    "            'NDC': 'first',\n",
    "            'State': 'first',\n",
    "            'Year': 'first'\n",
    "        }).reset_index()\n",
    "        \n",
    "        atc3_per_record.columns = ['record_id', 'num_atc3_classes', 'NDC', 'State', 'Year']\n",
    "        \n",
    "        # Distribution analysis\n",
    "        distribution = atc3_per_record['num_atc3_classes'].value_counts().sort_index()\n",
    "        \n",
    "        print(\"Distribution of ATC3 classes per record_id:\")\n",
    "        for classes, count in distribution.items():\n",
    "            pct = (count / len(atc3_per_record)) * 100\n",
    "            print(f\"  {classes} class(es): {count:,} record_ids ({pct:.1f}%)\")\n",
    "        \n",
    "        # Show examples of multi-class records\n",
    "        #multi_class = atc3_per_record[atc3_per_record['num_atc3_classes'] > 1].sort_values('num_atc3_classes', ascending=False)\n",
    "        \n",
    "        #if len(multi_class) > 0:\n",
    "            #print(f\"\\nTop 10 record_ids with most ATC3 classes:\")\n",
    "            #for _, row in multi_class.head(10).iterrows():\n",
    "                #record_classes = records_with_mapping[records_with_mapping['record_id'] == row['record_id']]['ATC3 Class'].unique()\n",
    "                #print(f\"  {row['record_id']}: {row['num_atc3_classes']} classes\")\n",
    "                #print(f\"    NDC: {row['NDC']}, State: {row['State']}, Year: {row['Year']}\")\n",
    "                #print(f\"    Classes: {list(record_classes)}\")\n",
    "                #print()\n",
    "        \n",
    "        # Summary statistics\n",
    "        #print(f\"\\nATC3 Summary:\")\n",
    "        print(f\"  Total record_ids with ATC3 mapping: {len(atc3_per_record):,}\")\n",
    "        #print(f\"  Average ATC3 classes per record_id: {atc3_per_record['num_atc3_classes'].mean():.2f}\")\n",
    "        #print(f\"  Max ATC3 classes for single record_id: {atc3_per_record['num_atc3_classes'].max()}\")\n",
    "        \n",
    "        return atc3_per_record\n",
    "\n",
    "    def analyze_atc2_distribution(self):\n",
    "\n",
    "        if self.atc_mapping is None:\n",
    "            raise ValueError(\"Must run analyze_atc4_mapping() first\")\n",
    "        \n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(\"ATC2 CLASSES PER RECORD_ID DISTRIBUTION\")\n",
    "        print(f\"{'='*60}\")\n",
    "        \n",
    "        # Create ATC2 classes from ATC4\n",
    "        records_with_mapping = self.atc_mapping[self.atc_mapping['ATC4 Class'].notna()].copy()\n",
    "        \n",
    "        if len(records_with_mapping) == 0:\n",
    "            print(\"No records with valid ATC4 mappings found.\")\n",
    "            return None\n",
    "        \n",
    "        # Create ATC2 class from ATC4 class (first 3 characters)\n",
    "        records_with_mapping['ATC2 Class'] = records_with_mapping['ATC4 Class'].str[:3]\n",
    "        \n",
    "        # Group by record_id and count unique ATC2 classes\n",
    "        atc2_per_record = records_with_mapping.groupby('record_id').agg({\n",
    "            'ATC2 Class': 'nunique',\n",
    "            'NDC': 'first',\n",
    "            'State': 'first',\n",
    "            'Year': 'first'\n",
    "        }).reset_index()\n",
    "        \n",
    "        atc2_per_record.columns = ['record_id', 'num_atc2_classes', 'NDC', 'State', 'Year']\n",
    "        \n",
    "        # Distribution analysis\n",
    "        distribution = atc2_per_record['num_atc2_classes'].value_counts().sort_index()\n",
    "        \n",
    "        print(\"Distribution of ATC2 classes per record_id:\")\n",
    "        for classes, count in distribution.items():\n",
    "            pct = (count / len(atc2_per_record)) * 100\n",
    "            print(f\"  {classes} class(es): {count:,} record_ids ({pct:.1f}%)\")\n",
    "        \n",
    "        # Show examples of multi-class records\n",
    "        #multi_class = atc2_per_record[atc2_per_record['num_atc2_classes'] > 1].sort_values('num_atc2_classes', ascending=False)\n",
    "        \n",
    "        #if len(multi_class) > 0:\n",
    "            #print(f\"\\nTop 10 record_ids with most ATC2 classes:\")\n",
    "            #for _, row in multi_class.head(10).iterrows():\n",
    "                #record_classes = records_with_mapping[records_with_mapping['record_id'] == row['record_id']]['ATC2 Class'].unique()\n",
    "                #print(f\"  {row['record_id']}: {row['num_atc2_classes']} classes\")\n",
    "                #print(f\"    NDC: {row['NDC']}, State: {row['State']}, Year: {row['Year']}\")\n",
    "                #print(f\"    Classes: {list(record_classes)}\")\n",
    "                #print()\n",
    "        \n",
    "        # Summary statistics\n",
    "        print(f\"\\nATC2 Summary:\")\n",
    "        print(f\"  Total record_ids with ATC2 mapping: {len(atc2_per_record):,}\")\n",
    "        print(f\"  Average ATC2 classes per record_id: {atc2_per_record['num_atc2_classes'].mean():.2f}\")\n",
    "        print(f\"  Max ATC2 classes for single record_id: {atc2_per_record['num_atc2_classes'].max()}\")\n",
    "        \n",
    "        return atc2_per_record\n",
    "\n",
    "    def export_merged_data(self, output_filename=None):\n",
    "     \n",
    "        if not hasattr(self, 'df_selected'):\n",
    "            # Ensure we’ve selected one ATC per record deterministically\n",
    "            self.select_one_atc_per_record()\n",
    "\n",
    "        df_final = self.df_selected.copy()\n",
    "\n",
    "        # (Optional) scale here if you prefer the output to be scaled\n",
    "        # If you scale, do the sum check using unscaled copies to avoid rounding issues\n",
    "        # Keep unscaled copies to verify sums:\n",
    "        src_units_sum = self.df_cleaned['Units Reimbursed'].sum()\n",
    "        src_rx_sum    = self.df_cleaned['Number of Prescriptions'].sum()\n",
    "        out_units_sum = df_final['Units Reimbursed'].sum()\n",
    "        out_rx_sum    = df_final['Number of Prescriptions'].sum()\n",
    "\n",
    "        # now scale for the CSV\n",
    "        df_final['Units Reimbursed'] /= 1e9\n",
    "        df_final['Number of Prescriptions'] /= 1e6\n",
    "\n",
    "        if output_filename is None:\n",
    "            output_filename = f\"merged_NEWdata_{self.year}.csv\"\n",
    "        output_path = os.path.join(self.base_path, f\"ATC\\\\merged_data\\\\{output_filename}\")\n",
    "        os.makedirs(os.path.dirname(output_path), exist_ok=True)\n",
    "        df_final.to_csv(output_path, index=False)\n",
    "\n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(\"DATA EXPORT COMPLETE (ONE ATC PER RECORD_ID)\")\n",
    "        print(\"=\"*60)\n",
    "        print(f\"Exported: {output_path}\")\n",
    "        print(f\"Rows exported: {len(df_final):,}\")\n",
    "        print(f\"Sums preserved? Units: {abs(src_units_sum - out_units_sum) < 1e-6}, \"\n",
    "            f\"Prescriptions: {abs(src_rx_sum - out_rx_sum) < 1e-6}\")\n",
    "        return output_path\n",
    "\n",
    "    @staticmethod #ATC distribution analysis across multiple years \n",
    "    def create_multi_year_distribution_analysis_simple(years_list):\n",
    "        \n",
    "        print(\"Creating Multi-Year ATC Distribution Analysis (Percentages Only)...\")\n",
    "        print(\"=\"*70)\n",
    "        \n",
    "        # Dictionary to store only percentage results\n",
    "        results = {\n",
    "            'ATC4_1_class': {},'ATC4_2_classes': {},'ATC4_3+_classes': {},\n",
    "            'ATC3_1_class': {},'ATC3_2_classes': {},'ATC3_3+_classes': {},\n",
    "            'ATC2_1_class': {},'ATC2_2_classes': {},'ATC2_3+_classes': {}\n",
    "        }\n",
    "        \n",
    "        for year in years_list:\n",
    "            print(f\"Processing {year}...\", end=\" \")\n",
    "            \n",
    "            try:\n",
    "                # Create a separate analyzer instance for each year\n",
    "                analyzer = NDCATCAnalyzer(year=year)\n",
    "                analyzer.clean_sdud_data()\n",
    "                analyzer.adding_key()\n",
    "                analyzer.analyze_atc4_mapping()\n",
    "                \n",
    "                # Get records with valid ATC4 mappings\n",
    "                records = analyzer.atc_mapping[analyzer.atc_mapping['ATC4 Class'].notna()].copy()\n",
    "                records['ATC2 Class'] = records['ATC4 Class'].str[:3]\n",
    "                records['ATC3 Class'] = records['ATC4 Class'].str[:4]\n",
    "                \n",
    "                # Calculate distributions\n",
    "                atc4_per_record = records.groupby('record_id')['ATC4 Class'].nunique()\n",
    "                atc3_per_record = records.groupby('record_id')['ATC3 Class'].nunique()\n",
    "                atc2_per_record = records.groupby('record_id')['ATC2 Class'].nunique()\n",
    "                \n",
    "                # ATC4 percentages\n",
    "                atc4_dist = atc4_per_record.value_counts().sort_index()\n",
    "                total_atc4 = len(atc4_per_record)\n",
    "                results['ATC4_1_class'][year] = f\"{(atc4_dist.get(1, 0) / total_atc4 * 100):.1f}%\"\n",
    "                results['ATC4_2_classes'][year] = f\"{(atc4_dist.get(2, 0) / total_atc4 * 100):.1f}%\"\n",
    "                results['ATC4_3+_classes'][year] = f\"{(atc4_dist[atc4_dist.index >= 3].sum() / total_atc4 * 100):.1f}%\"\n",
    "                \n",
    "                # ATC3 percentages\n",
    "                atc3_dist = atc3_per_record.value_counts().sort_index()\n",
    "                total_atc3 = len(atc3_per_record)\n",
    "                results['ATC3_1_class'][year] = f\"{(atc3_dist.get(1, 0) / total_atc3 * 100):.1f}%\"\n",
    "                results['ATC3_2_classes'][year] = f\"{(atc3_dist.get(2, 0) / total_atc3 * 100):.1f}%\"\n",
    "                results['ATC3_3+_classes'][year] = f\"{(atc3_dist[atc3_dist.index >= 3].sum() / total_atc3 * 100):.1f}%\"\n",
    "                \n",
    "                # ATC2 percentages\n",
    "                atc2_dist = atc2_per_record.value_counts().sort_index()\n",
    "                total_atc2 = len(atc2_per_record)\n",
    "                results['ATC2_1_class'][year] = f\"{(atc2_dist.get(1, 0) / total_atc2 * 100):.1f}%\"\n",
    "                results['ATC2_2_classes'][year] = f\"{(atc2_dist.get(2, 0) / total_atc2 * 100):.1f}%\"\n",
    "                results['ATC2_3+_classes'][year] = f\"{(atc2_dist[atc2_dist.index >= 3].sum() / total_atc2 * 100):.1f}%\"\n",
    "                \n",
    "                print(\"✓\")\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"✗ Error: {e}\")\n",
    "                # Fill with N/A for failed years\n",
    "                for key in results.keys():\n",
    "                    results[key][year] = \"N/A\"\n",
    "        \n",
    "        # Create DataFrame (only percentages)\n",
    "        df_percentages = pd.DataFrame(results).T\n",
    "        \n",
    "        print(f\"\\nATC DISTRIBUTION PERCENTAGES ACROSS YEARS\")\n",
    "        print(\"=\"*60)\n",
    "        print(df_percentages)\n",
    "        \n",
    "        return df_percentages\n",
    "    \n",
    "    @staticmethod\n",
    "    def analyze_general_atc_overview(years_list):\n",
    "\n",
    "        print(\"Creating ATC2 & ATC3 Overview: Unique NDCs per Class Across Years...\")\n",
    "        print(\"=\"*78)\n",
    "\n",
    "        # Per-year summary tables (ATC2 & ATC3)\n",
    "        atc2_year_results = {}\n",
    "        atc3_year_results = {}\n",
    "\n",
    "        # Keep the per-year “clean” dataframes if you want to inspect / reuse\n",
    "        overview_dataframes_atc2 = {}\n",
    "        overview_dataframes_atc3 = {}\n",
    "\n",
    "        for year in years_list:\n",
    "            print(f\"Processing {year}...\", end=\" \")\n",
    "            try:\n",
    "                analyzer = NDCATCAnalyzer(year=year)\n",
    "                analyzer.clean_sdud_data()\n",
    "                analyzer.adding_key()\n",
    "                analyzer.analyze_atc4_mapping()\n",
    "\n",
    "                # Keep only mapped rows\n",
    "                records = analyzer.atc_mapping[analyzer.atc_mapping['ATC4 Class'].notna()].copy()\n",
    "                if records.empty:\n",
    "                    print(\"No records with ATC mapping found\")\n",
    "                    atc2_year_results[year] = pd.DataFrame()\n",
    "                    atc3_year_results[year] = pd.DataFrame()\n",
    "                    overview_dataframes_atc2[year] = pd.DataFrame()\n",
    "                    overview_dataframes_atc3[year] = pd.DataFrame()\n",
    "                    continue\n",
    "\n",
    "                # Derive ATC2/ATC3 from ATC4\n",
    "                records['ATC2 Class'] = records['ATC4 Class'].str[:3]\n",
    "                records['ATC3 Class'] = records['ATC4 Class'].str[:4]\n",
    "\n",
    "                # --- ATC2 ---\n",
    "                pairs2 = records[['record_id', 'NDC', 'ATC2 Class']].drop_duplicates()\n",
    "                atc2_summary = (\n",
    "                    pairs2.groupby('ATC2 Class')\n",
    "                        .agg(Unique_NDCs=('NDC', 'nunique'),\n",
    "                            Total_Records=('record_id', 'nunique'))\n",
    "                        .sort_values('Unique_NDCs', ascending=False)\n",
    "                )\n",
    "                total_unique_ndcs2 = pairs2['NDC'].nunique()\n",
    "                atc2_summary['Percentage_of_NDCs'] = (\n",
    "                    atc2_summary['Unique_NDCs'] / total_unique_ndcs2 * 100\n",
    "                ).round(1)\n",
    "\n",
    "                # --- ATC3 ---\n",
    "                pairs3 = records[['record_id', 'NDC', 'ATC3 Class']].drop_duplicates()\n",
    "                atc3_summary = (\n",
    "                    pairs3.groupby('ATC3 Class')\n",
    "                        .agg(Unique_NDCs=('NDC', 'nunique'),\n",
    "                            Total_Records=('record_id', 'nunique'))\n",
    "                        .sort_values('Unique_NDCs', ascending=False)\n",
    "                )\n",
    "                total_unique_ndcs3 = pairs3['NDC'].nunique()\n",
    "                atc3_summary['Percentage_of_NDCs'] = (\n",
    "                    atc3_summary['Unique_NDCs'] / total_unique_ndcs3 * 100\n",
    "                ).round(1)\n",
    "\n",
    "                # Store per-year tables\n",
    "                atc2_year_results[year] = atc2_summary\n",
    "                atc3_year_results[year] = atc3_summary\n",
    "                overview_dataframes_atc2[year] = pairs2\n",
    "                overview_dataframes_atc3[year] = pairs3\n",
    "\n",
    "                print(f\"✓ (ATC2: {len(atc2_summary)} classes, {total_unique_ndcs2:,} unique NDCs; \"\n",
    "                    f\"ATC3: {len(atc3_summary)} classes, {total_unique_ndcs3:,} unique NDCs)\")\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"✗ Error: {e}\")\n",
    "                atc2_year_results[year] = pd.DataFrame()\n",
    "                atc3_year_results[year] = pd.DataFrame()\n",
    "                overview_dataframes_atc2[year] = pd.DataFrame()\n",
    "                overview_dataframes_atc3[year] = pd.DataFrame()\n",
    "\n",
    "        # ---- Pretty print per-year (optional) ----\n",
    "        print(\"\\nUNIQUE NDCs PER ATC2 CLASS BY YEAR\")\n",
    "        print(\"=\"*60)\n",
    "        for year in years_list:\n",
    "            if not atc2_year_results[year].empty:\n",
    "                print(f\"\\n{year}:\")\n",
    "                print(\"-\"*40)\n",
    "                print(f\"Total ATC2 Classes: {len(atc2_year_results[year])}\")\n",
    "                print(f\"Total Unique NDCs: {overview_dataframes_atc2[year]['NDC'].nunique():,}\")\n",
    "                print(\"\\nTop 10 ATC2 Classes by Unique NDCs:\")\n",
    "                print(atc2_year_results[year].head(10))\n",
    "            else:\n",
    "                print(f\"\\n{year}: No ATC2 data available\")\n",
    "\n",
    "        print(\"\\nUNIQUE NDCs PER ATC3 CLASS BY YEAR\")\n",
    "        print(\"=\"*60)\n",
    "        for year in years_list:\n",
    "            if not atc3_year_results[year].empty:\n",
    "                print(f\"\\n{year}:\")\n",
    "                print(\"-\"*40)\n",
    "                print(f\"Total ATC3 Classes: {len(atc3_year_results[year])}\")\n",
    "                print(f\"Total Unique NDCs: {overview_dataframes_atc3[year]['NDC'].nunique():,}\")\n",
    "                print(\"\\nTop 10 ATC3 Classes by Unique NDCs:\")\n",
    "                print(atc3_year_results[year].head(10))\n",
    "            else:\n",
    "                print(f\"\\n{year}: No ATC3 data available\")\n",
    "\n",
    "        # ---- Build comparison tables (rows = classes, cols = years, values = Unique_NDCs) ----\n",
    "        def build_comparison(year_tables):\n",
    "            all_classes = set()\n",
    "            for tbl in year_tables.values():\n",
    "                if not tbl.empty:\n",
    "                    all_classes.update(tbl.index.tolist())\n",
    "            comp = {}\n",
    "            for cls in sorted(all_classes):\n",
    "                comp[cls] = {}\n",
    "                for y in years_list:\n",
    "                    if not year_tables[y].empty and cls in year_tables[y].index:\n",
    "                        comp[cls][y] = int(year_tables[y].loc[cls, 'Unique_NDCs'])\n",
    "                    else:\n",
    "                        comp[cls][y] = 0\n",
    "            dfc = pd.DataFrame(comp).T\n",
    "            return dfc.loc[dfc.sum(axis=1).sort_values(ascending=False).index]\n",
    "\n",
    "        atc2_comparison = build_comparison(atc2_year_results)\n",
    "        atc3_comparison = build_comparison(atc3_year_results)\n",
    "\n",
    "        print(\"\\nTop 15 ATC2 Classes by Total Unique NDCs Across All Years:\")\n",
    "        print(atc2_comparison.head(15))\n",
    "        print(\"\\nTop 15 ATC3 Classes by Total Unique NDCs Across All Years:\")\n",
    "        print(atc3_comparison.head(15))\n",
    "\n",
    "        return atc2_year_results, atc3_year_results, atc2_comparison, atc3_comparison\n",
    "    \n",
    "    @staticmethod\n",
    "    def get_atc_ndc_details(year, top_n=10):\n",
    "        \n",
    "    \n",
    "        print(f\"\\nDETAILED ATC2 & ATC3 ANALYSIS FOR {year}\")\n",
    "        print(\"=\" * 70)\n",
    "\n",
    "        try:\n",
    "            analyzer = NDCATCAnalyzer(year=year)\n",
    "            analyzer.clean_sdud_data()\n",
    "            analyzer.adding_key()\n",
    "            analyzer.analyze_atc4_mapping()\n",
    "\n",
    "            df = analyzer.atc_mapping[analyzer.atc_mapping['ATC4 Class'].notna()].copy()\n",
    "            if df.empty:\n",
    "                print(\"No valid ATC mappings found.\")\n",
    "                return pd.DataFrame(), pd.DataFrame()\n",
    "\n",
    "            # Derive ATC3 & ATC2 from ATC4\n",
    "            df['ATC3 Class'] = df['ATC4 Class'].str[:4]\n",
    "            df['ATC2 Class'] = df['ATC4 Class'].str[:3]\n",
    "\n",
    "            # --- Deduplicate to avoid inflated counts ---\n",
    "            pairs2 = df[['record_id', 'NDC', 'ATC2 Class']].drop_duplicates()\n",
    "            pairs3 = df[['record_id', 'NDC', 'ATC3 Class']].drop_duplicates()\n",
    "\n",
    "            # === Compute denominators ===\n",
    "            total_unique_ndcs = df['NDC'].nunique()\n",
    "            total_records = len(df)\n",
    "            print(f\"Total records analyzed: {total_records:,}\")\n",
    "            print(f\"Total unique NDCs mapped: {total_unique_ndcs:,}\")\n",
    "\n",
    "            # === ATC2 Summary ===\n",
    "            atc2_summary = (\n",
    "                pairs2.groupby('ATC2 Class')\n",
    "                    .agg(Unique_NDCs=('NDC', 'nunique'),\n",
    "                        Total_Records=('record_id', 'nunique'))\n",
    "            )\n",
    "            atc2_summary['Percentage_of_NDCs'] = (\n",
    "                atc2_summary['Unique_NDCs'] / total_unique_ndcs * 100\n",
    "            ).round(1)\n",
    "            atc2_summary['Avg_Records_per_NDC'] = (\n",
    "                atc2_summary['Total_Records'] / atc2_summary['Unique_NDCs']\n",
    "            ).round(1)\n",
    "            atc2_summary = atc2_summary.sort_values('Unique_NDCs', ascending=False)\n",
    "\n",
    "            # === ATC3 Summary ===\n",
    "            atc3_summary = (\n",
    "                pairs3.groupby('ATC3 Class')\n",
    "                    .agg(Unique_NDCs=('NDC', 'nunique'),\n",
    "                        Total_Records=('record_id', 'nunique'))\n",
    "            )\n",
    "            atc3_summary['Percentage_of_NDCs'] = (\n",
    "                atc3_summary['Unique_NDCs'] / total_unique_ndcs * 100\n",
    "            ).round(1)\n",
    "            atc3_summary['Avg_Records_per_NDC'] = (\n",
    "                atc3_summary['Total_Records'] / atc3_summary['Unique_NDCs']\n",
    "            ).round(1)\n",
    "            atc3_summary = atc3_summary.sort_values('Unique_NDCs', ascending=False)\n",
    "\n",
    "            # === Display ===\n",
    "            print(f\"\\nTOP {top_n} ATC2 CLASSES BY UNIQUE NDCs\")\n",
    "            print(atc2_summary.head(top_n))\n",
    "            print(f\"\\nTOP {top_n} ATC3 CLASSES BY UNIQUE NDCs\")\n",
    "            print(atc3_summary.head(top_n))\n",
    "\n",
    "            # === Sample NDCs ===\n",
    "            print(\"\\nSample NDCs for top 3 ATC2 classes:\")\n",
    "            for i, atc2 in enumerate(atc2_summary.head(3).index, start=1):\n",
    "                sample = df[df['ATC2 Class'] == atc2]['NDC'].drop_duplicates().head(5).tolist()\n",
    "                print(f\"{i}. {atc2} ({atc2_summary.loc[atc2, 'Unique_NDCs']} NDCs): {', '.join(sample)}\")\n",
    "\n",
    "            print(\"\\nSample NDCs for top 3 ATC3 classes:\")\n",
    "            for i, atc3 in enumerate(atc3_summary.head(3).index, start=1):\n",
    "                sample = df[df['ATC3 Class'] == atc3]['NDC'].drop_duplicates().head(5).tolist()\n",
    "                print(f\"{i}. {atc3} ({atc3_summary.loc[atc3, 'Unique_NDCs']} NDCs): {', '.join(sample)}\")\n",
    "\n",
    "            return atc2_summary, atc3_summary\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error analyzing ATC2/ATC3 details for {year}: {e}\")\n",
    "            return pd.DataFrame(), pd.DataFrame()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "workflow_execution",
   "metadata": {},
   "outputs": [],
   "source": [
    "analyzer = NDCATCAnalyzer(year=2024)\n",
    "analyzer.clean_sdud_data()           # Clean SDUD data\n",
    "analyzer.adding_key()                # Add record_id key\n",
    "#analyzer.generate_ndc_txt()          # Generate NDC text file\n",
    "analyzer.analyze_atc4_mapping()      # Merge ATC4 by record_id & NDC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "644c005a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution analyses\n",
    "atc4_dist = analyzer.analyze_atc4_distribution()\n",
    "atc3_dist = analyzer.analyze_atc3_distribution() \n",
    "atc2_dist = analyzer.analyze_atc2_distribution()\n",
    "#different_atc2_records = analyzer.analyze_different_atc2_records()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "524d0ef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "analyzer.fetch_atc_names()           \n",
    "analyzer.prepare_final_dataframe()   \n",
    "analyzer.export_merged_data()  \n",
    "# Simple version - only percentages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2aa7828a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating ATC2 & ATC3 Overview: Unique NDCs per Class Across Years...\n",
      "==============================================================================\n",
      "Processing 2020... Reading CSV file: c:\\Users\\lholguin\\OneDrive - purdue.edu\\VS code\\Data\\SDUD\\SDUD2020.csv\n",
      "Total rows in 2020 before filtering: 4922728\n",
      "Rows after removing NA: 2508077\n",
      "Rows after filtering State='XX': 2284815\n",
      "Unique NDCs: 32220\n",
      "Adding record_id column...\n",
      "Created 2284815 record IDs\n",
      "Sample record_id: AK_2020_4_FFSU_00002143380\n",
      "Total rows in ATC4 mapping file: 4011219\n",
      "Unique NDCs in ATC4 mapping file: 27661\n",
      "Merging ATC4 mapping with cleaned data using record_id and NDC...\n",
      "Merged dataframe rows: 4122259\n",
      "Records with ATC4 mapping: 4011219 (97.3%)\n",
      "\n",
      "Records without ATC4 mapping: 111040\n",
      "Unique NDCs without mapping: 4559\n",
      "✓ (ATC2: 90 classes, 27,661 unique NDCs; ATC3: 212 classes, 27,661 unique NDCs)\n",
      "Processing 2021... Reading CSV file: c:\\Users\\lholguin\\OneDrive - purdue.edu\\VS code\\Data\\SDUD\\SDUD2021.csv\n",
      "Total rows in 2021 before filtering: 5042532\n",
      "Rows after removing NA: 2575044\n",
      "Rows after filtering State='XX': 2348980\n",
      "Unique NDCs: 32417\n",
      "Adding record_id column...\n",
      "Created 2348980 record IDs\n",
      "Sample record_id: AK_2021_4_FFSU_00002143380\n",
      "Total rows in ATC4 mapping file: 4248026\n",
      "Unique NDCs in ATC4 mapping file: 29275\n",
      "Merging ATC4 mapping with cleaned data using record_id and NDC...\n",
      "Merged dataframe rows: 4309498\n",
      "Records with ATC4 mapping: 4248026 (98.6%)\n",
      "\n",
      "Records without ATC4 mapping: 61472\n",
      "Unique NDCs without mapping: 3142\n",
      "✓ (ATC2: 89 classes, 29,275 unique NDCs; ATC3: 211 classes, 29,275 unique NDCs)\n",
      "Processing 2022... Reading CSV file: c:\\Users\\lholguin\\OneDrive - purdue.edu\\VS code\\Data\\SDUD\\SDUD2022.csv\n",
      "Total rows in 2022 before filtering: 5164804\n",
      "Rows after removing NA: 2621949\n",
      "Rows after filtering State='XX': 2389418\n",
      "Unique NDCs: 33005\n",
      "Adding record_id column...\n",
      "Created 2389418 record IDs\n",
      "Sample record_id: AK_2022_4_FFSU_00002143380\n",
      "Total rows in ATC4 mapping file: 4385476\n",
      "Unique NDCs in ATC4 mapping file: 30846\n",
      "Merging ATC4 mapping with cleaned data using record_id and NDC...\n",
      "Merged dataframe rows: 4421713\n",
      "Records with ATC4 mapping: 4385476 (99.2%)\n",
      "\n",
      "Records without ATC4 mapping: 36237\n",
      "Unique NDCs without mapping: 2159\n",
      "✓ (ATC2: 89 classes, 30,846 unique NDCs; ATC3: 209 classes, 30,846 unique NDCs)\n",
      "Processing 2023... Reading CSV file: c:\\Users\\lholguin\\OneDrive - purdue.edu\\VS code\\Data\\SDUD\\SDUD2023.csv\n",
      "Total rows in 2023 before filtering: 5277298\n",
      "Rows after removing NA: 2651527\n",
      "Rows after filtering State='XX': 2413521\n",
      "Unique NDCs: 34439\n",
      "Adding record_id column...\n",
      "Created 2413521 record IDs\n",
      "Sample record_id: AK_2023_4_FFSU_00002143380\n",
      "Total rows in ATC4 mapping file: 4426568\n",
      "Unique NDCs in ATC4 mapping file: 32499\n",
      "Merging ATC4 mapping with cleaned data using record_id and NDC...\n",
      "Merged dataframe rows: 4454193\n",
      "Records with ATC4 mapping: 4426568 (99.4%)\n",
      "\n",
      "Records without ATC4 mapping: 27625\n",
      "Unique NDCs without mapping: 1940\n",
      "✓ (ATC2: 89 classes, 32,499 unique NDCs; ATC3: 211 classes, 32,499 unique NDCs)\n",
      "Processing 2024... Reading CSV file: c:\\Users\\lholguin\\OneDrive - purdue.edu\\VS code\\Data\\SDUD\\SDUD2024.csv\n",
      "Total rows in 2024 before filtering: 5205065\n",
      "Rows after removing NA: 2599748\n",
      "Rows after filtering State='XX': 2362630\n",
      "Unique NDCs: 33397\n",
      "Adding record_id column...\n",
      "Created 2362630 record IDs\n",
      "Sample record_id: AK_2024_4_FFSU_00002143380\n",
      "Total rows in ATC4 mapping file: 4336231\n",
      "Unique NDCs in ATC4 mapping file: 32203\n",
      "Merging ATC4 mapping with cleaned data using record_id and NDC...\n",
      "Merged dataframe rows: 4360194\n",
      "Records with ATC4 mapping: 4336231 (99.5%)\n",
      "\n",
      "Records without ATC4 mapping: 23963\n",
      "Unique NDCs without mapping: 1194\n",
      "✓ (ATC2: 89 classes, 32,203 unique NDCs; ATC3: 212 classes, 32,203 unique NDCs)\n",
      "\n",
      "UNIQUE NDCs PER ATC2 CLASS BY YEAR\n",
      "============================================================\n",
      "\n",
      "2020:\n",
      "----------------------------------------\n",
      "Total ATC2 Classes: 90\n",
      "Total Unique NDCs: 27,661\n",
      "\n",
      "Top 10 ATC2 Classes by Unique NDCs:\n",
      "            Unique_NDCs  Total_Records  Percentage_of_NDCs\n",
      "ATC2 Class                                                \n",
      "S01                3093         206868                11.2\n",
      "J01                2260         165325                 8.2\n",
      "N06                2176         229231                 7.9\n",
      "N02                1999         160920                 7.2\n",
      "N05                1920         197370                 6.9\n",
      "C05                1409          89240                 5.1\n",
      "D07                1241         101528                 4.5\n",
      "C09                1166          65773                 4.2\n",
      "A01                1104          89432                 4.0\n",
      "R01                1095          85513                 4.0\n",
      "\n",
      "2021:\n",
      "----------------------------------------\n",
      "Total ATC2 Classes: 89\n",
      "Total Unique NDCs: 29,275\n",
      "\n",
      "Top 10 ATC2 Classes by Unique NDCs:\n",
      "            Unique_NDCs  Total_Records  Percentage_of_NDCs\n",
      "ATC2 Class                                                \n",
      "S01                3359         225028                11.5\n",
      "J01                2346         174808                 8.0\n",
      "N06                2310         237634                 7.9\n",
      "N02                2058         166620                 7.0\n",
      "N05                2021         207865                 6.9\n",
      "C05                1511          97341                 5.2\n",
      "D07                1340         110577                 4.6\n",
      "A01                1204          95815                 4.1\n",
      "R01                1189          93863                 4.1\n",
      "C01                1151          57852                 3.9\n",
      "\n",
      "2022:\n",
      "----------------------------------------\n",
      "Total ATC2 Classes: 89\n",
      "Total Unique NDCs: 30,846\n",
      "\n",
      "Top 10 ATC2 Classes by Unique NDCs:\n",
      "            Unique_NDCs  Total_Records  Percentage_of_NDCs\n",
      "ATC2 Class                                                \n",
      "S01                3590         232741                11.6\n",
      "N06                2497         247458                 8.1\n",
      "J01                2444         178022                 7.9\n",
      "N05                2096         207271                 6.8\n",
      "N02                2092         167860                 6.8\n",
      "C05                1590          99755                 5.2\n",
      "D07                1390         115597                 4.5\n",
      "R01                1306          99991                 4.2\n",
      "A01                1259          98847                 4.1\n",
      "C01                1231          60294                 4.0\n",
      "\n",
      "2023:\n",
      "----------------------------------------\n",
      "Total ATC2 Classes: 89\n",
      "Total Unique NDCs: 32,499\n",
      "\n",
      "Top 10 ATC2 Classes by Unique NDCs:\n",
      "            Unique_NDCs  Total_Records  Percentage_of_NDCs\n",
      "ATC2 Class                                                \n",
      "S01                3742         236590                11.5\n",
      "N06                2692         255174                 8.3\n",
      "J01                2506         182159                 7.7\n",
      "N05                2239         212710                 6.9\n",
      "N02                2138         162821                 6.6\n",
      "C05                1640         101637                 5.0\n",
      "D07                1360         116342                 4.2\n",
      "R01                1356         102963                 4.2\n",
      "C01                1317          59523                 4.1\n",
      "L01                1284          53261                 4.0\n",
      "\n",
      "2024:\n",
      "----------------------------------------\n",
      "Total ATC2 Classes: 89\n",
      "Total Unique NDCs: 32,203\n",
      "\n",
      "Top 10 ATC2 Classes by Unique NDCs:\n",
      "            Unique_NDCs  Total_Records  Percentage_of_NDCs\n",
      "ATC2 Class                                                \n",
      "S01                3742         234021                11.6\n",
      "N06                2657         255424                 8.3\n",
      "J01                2389         174155                 7.4\n",
      "N05                2250         210375                 7.0\n",
      "N02                2024         157759                 6.3\n",
      "C05                1669         100291                 5.2\n",
      "R01                1337         102328                 4.2\n",
      "C01                1317          58872                 4.1\n",
      "D07                1316         112703                 4.1\n",
      "L01                1306          49483                 4.1\n",
      "\n",
      "UNIQUE NDCs PER ATC3 CLASS BY YEAR\n",
      "============================================================\n",
      "\n",
      "2020:\n",
      "----------------------------------------\n",
      "Total ATC3 Classes: 212\n",
      "Total Unique NDCs: 27,661\n",
      "\n",
      "Top 10 ATC3 Classes by Unique NDCs:\n",
      "            Unique_NDCs  Total_Records  Percentage_of_NDCs\n",
      "ATC3 Class                                                \n",
      "N06A               1330         145400                 4.8\n",
      "C05A               1258          85161                 4.5\n",
      "D07A               1241         101528                 4.5\n",
      "N05A               1163         121498                 4.2\n",
      "N02B               1133          90442                 4.1\n",
      "A01A               1104          89432                 4.0\n",
      "R01A                970          81513                 3.5\n",
      "S01A                967          59450                 3.5\n",
      "N03A                929         100640                 3.4\n",
      "N02A                877          70570                 3.2\n",
      "\n",
      "2021:\n",
      "----------------------------------------\n",
      "Total ATC3 Classes: 211\n",
      "Total Unique NDCs: 29,275\n",
      "\n",
      "Top 10 ATC3 Classes by Unique NDCs:\n",
      "            Unique_NDCs  Total_Records  Percentage_of_NDCs\n",
      "ATC3 Class                                                \n",
      "N06A               1424         151501                 4.9\n",
      "C05A               1342          92441                 4.6\n",
      "D07A               1340         110577                 4.6\n",
      "A01A               1204          95815                 4.1\n",
      "N05A               1202         124177                 4.1\n",
      "N02B               1165          92919                 4.0\n",
      "R01A               1054          89300                 3.6\n",
      "S01A               1021          63084                 3.5\n",
      "N03A                999         104701                 3.4\n",
      "S01B                935          83537                 3.2\n",
      "\n",
      "2022:\n",
      "----------------------------------------\n",
      "Total ATC3 Classes: 209\n",
      "Total Unique NDCs: 30,846\n",
      "\n",
      "Top 10 ATC3 Classes by Unique NDCs:\n",
      "            Unique_NDCs  Total_Records  Percentage_of_NDCs\n",
      "ATC3 Class                                                \n",
      "N06A               1557         156785                 5.0\n",
      "C05A               1419          95139                 4.6\n",
      "D07A               1390         115597                 4.5\n",
      "A01A               1259          98847                 4.1\n",
      "N05A               1259         122264                 4.1\n",
      "N02B               1181          93175                 3.8\n",
      "R01A               1163          95298                 3.8\n",
      "N03A               1100         110969                 3.6\n",
      "S01A               1035          63759                 3.4\n",
      "S01B                999          87954                 3.2\n",
      "\n",
      "2023:\n",
      "----------------------------------------\n",
      "Total ATC3 Classes: 211\n",
      "Total Unique NDCs: 32,499\n",
      "\n",
      "Top 10 ATC3 Classes by Unique NDCs:\n",
      "            Unique_NDCs  Total_Records  Percentage_of_NDCs\n",
      "ATC3 Class                                                \n",
      "N06A               1654         163424                 5.1\n",
      "C05A               1464          97438                 4.5\n",
      "D07A               1360         116342                 4.2\n",
      "N05A               1359         130811                 4.2\n",
      "A01A               1268         102184                 3.9\n",
      "N03A               1250         115876                 3.8\n",
      "N02B               1223          88664                 3.8\n",
      "R01A               1218          98749                 3.7\n",
      "S01A               1056          63853                 3.2\n",
      "S01B               1018          91665                 3.1\n",
      "\n",
      "2024:\n",
      "----------------------------------------\n",
      "Total ATC3 Classes: 212\n",
      "Total Unique NDCs: 32,203\n",
      "\n",
      "Top 10 ATC3 Classes by Unique NDCs:\n",
      "            Unique_NDCs  Total_Records  Percentage_of_NDCs\n",
      "ATC3 Class                                                \n",
      "N06A               1630         159664                 5.1\n",
      "C05A               1485          96365                 4.6\n",
      "N05A               1376         130476                 4.3\n",
      "D07A               1316         112703                 4.1\n",
      "A01A               1248         101603                 3.9\n",
      "N03A               1236         116844                 3.8\n",
      "R01A               1206          98484                 3.7\n",
      "N02B               1163          85159                 3.6\n",
      "S01B               1059          92145                 3.3\n",
      "S01A               1040          61710                 3.2\n",
      "\n",
      "Top 15 ATC2 Classes by Total Unique NDCs Across All Years:\n",
      "     2020  2021  2022  2023  2024\n",
      "S01  3093  3359  3590  3742  3742\n",
      "N06  2176  2310  2497  2692  2657\n",
      "J01  2260  2346  2444  2506  2389\n",
      "N05  1920  2021  2096  2239  2250\n",
      "N02  1999  2058  2092  2138  2024\n",
      "C05  1409  1511  1590  1640  1669\n",
      "D07  1241  1340  1390  1360  1316\n",
      "R01  1095  1189  1306  1356  1337\n",
      "C01  1072  1151  1231  1317  1317\n",
      "A01  1104  1204  1259  1268  1248\n",
      "L01  1007  1108  1193  1284  1306\n",
      "N03   929   999  1100  1250  1236\n",
      "C09  1166  1072  1035  1086  1032\n",
      "A07   935  1024  1069  1088  1085\n",
      "S02   901   985  1033  1040  1058\n",
      "\n",
      "Top 15 ATC3 Classes by Total Unique NDCs Across All Years:\n",
      "      2020  2021  2022  2023  2024\n",
      "N06A  1330  1424  1557  1654  1630\n",
      "C05A  1258  1342  1419  1464  1485\n",
      "D07A  1241  1340  1390  1360  1316\n",
      "N05A  1163  1202  1259  1359  1376\n",
      "A01A  1104  1204  1259  1268  1248\n",
      "N02B  1133  1165  1181  1223  1163\n",
      "R01A   970  1054  1163  1218  1206\n",
      "N03A   929   999  1100  1250  1236\n",
      "S01A   967  1021  1035  1056  1040\n",
      "S01B   873   935   999  1018  1059\n",
      "C10A   795   840   891   922   937\n",
      "N02A   877   891   885   884   808\n",
      "H02A   732   800   866   878   902\n",
      "M01A   775   800   820   884   883\n",
      "C07A   690   770   865   898   867\n",
      "\n",
      "DETAILED ATC2 & ATC3 ANALYSIS FOR 2024\n",
      "======================================================================\n",
      "Reading CSV file: c:\\Users\\lholguin\\OneDrive - purdue.edu\\VS code\\Data\\SDUD\\SDUD2024.csv\n",
      "Total rows in 2024 before filtering: 5205065\n",
      "Rows after removing NA: 2599748\n",
      "Rows after filtering State='XX': 2362630\n",
      "Unique NDCs: 33397\n",
      "Adding record_id column...\n",
      "Created 2362630 record IDs\n",
      "Sample record_id: AK_2024_4_FFSU_00002143380\n",
      "Total rows in ATC4 mapping file: 4336231\n",
      "Unique NDCs in ATC4 mapping file: 32203\n",
      "Merging ATC4 mapping with cleaned data using record_id and NDC...\n",
      "Merged dataframe rows: 4360194\n",
      "Records with ATC4 mapping: 4336231 (99.5%)\n",
      "\n",
      "Records without ATC4 mapping: 23963\n",
      "Unique NDCs without mapping: 1194\n",
      "Total records analyzed: 4,336,231\n",
      "Total unique NDCs mapped: 32,203\n",
      "\n",
      "TOP 10 ATC2 CLASSES BY UNIQUE NDCs\n",
      "            Unique_NDCs  Total_Records  Percentage_of_NDCs  \\\n",
      "ATC2 Class                                                   \n",
      "S01                3742         234021                11.6   \n",
      "N06                2657         255424                 8.3   \n",
      "J01                2389         174155                 7.4   \n",
      "N05                2250         210375                 7.0   \n",
      "N02                2024         157759                 6.3   \n",
      "C05                1669         100291                 5.2   \n",
      "R01                1337         102328                 4.2   \n",
      "C01                1317          58872                 4.1   \n",
      "D07                1316         112703                 4.1   \n",
      "L01                1306          49483                 4.1   \n",
      "\n",
      "            Avg_Records_per_NDC  \n",
      "ATC2 Class                       \n",
      "S01                        62.5  \n",
      "N06                        96.1  \n",
      "J01                        72.9  \n",
      "N05                        93.5  \n",
      "N02                        77.9  \n",
      "C05                        60.1  \n",
      "R01                        76.5  \n",
      "C01                        44.7  \n",
      "D07                        85.6  \n",
      "L01                        37.9  \n",
      "\n",
      "TOP 10 ATC3 CLASSES BY UNIQUE NDCs\n",
      "            Unique_NDCs  Total_Records  Percentage_of_NDCs  \\\n",
      "ATC3 Class                                                   \n",
      "N06A               1630         159664                 5.1   \n",
      "C05A               1485          96365                 4.6   \n",
      "N05A               1376         130476                 4.3   \n",
      "D07A               1316         112703                 4.1   \n",
      "A01A               1248         101603                 3.9   \n",
      "N03A               1236         116844                 3.8   \n",
      "R01A               1206          98484                 3.7   \n",
      "N02B               1163          85159                 3.6   \n",
      "S01B               1059          92145                 3.3   \n",
      "S01A               1040          61710                 3.2   \n",
      "\n",
      "            Avg_Records_per_NDC  \n",
      "ATC3 Class                       \n",
      "N06A                       98.0  \n",
      "C05A                       64.9  \n",
      "N05A                       94.8  \n",
      "D07A                       85.6  \n",
      "A01A                       81.4  \n",
      "N03A                       94.5  \n",
      "R01A                       81.7  \n",
      "N02B                       73.2  \n",
      "S01B                       87.0  \n",
      "S01A                       59.3  \n",
      "\n",
      "Sample NDCs for top 3 ATC2 classes:\n",
      "1. S01 (3742 NDCs): 00003029305, 00003029328, 00003049420, 00009001103, 00009001104\n",
      "2. N06 (2657 NDCs): 00002327030, 00054040013, 00054040022, 00054040122, 00054060313\n",
      "3. J01 (2389 NDCs): 00069312019, 00069314019, 00078079975, 00078087601, 00093117201\n",
      "\n",
      "Sample NDCs for top 3 ATC3 classes:\n",
      "1. N06A (1630 NDCs): 00002327030, 00054040013, 00054040022, 00054040122, 00054060313\n",
      "2. C05A (1485 NDCs): 00003029305, 00003029328, 00003049420, 00009001103, 00009001104\n",
      "3. N05A (1376 NDCs): 00054002025, 00054002125, 00054002129, 00054252625, 00054252731\n"
     ]
    }
   ],
   "source": [
    "#seeing unique NDC for unique ATC2 and ATC3 across years\n",
    "years = [2020, 2021, 2022, 2023, 2024]\n",
    "#NDCATCAnalyzer.create_multi_year_distribution_analysis_simple(years)\n",
    "NDCATCAnalyzer.analyze_general_atc_overview(years)\n",
    "# Detailed ATC2 & ATC3 analysis for a specific year\n",
    "atc2_2023, atc3_2023 = NDCATCAnalyzer.get_atc_ndc_details(year=2024, top_n=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b26b2a79",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Just checking overlap between files with and without key\n",
    "nokey_path=rf'C:\\Users\\{user}\\OneDrive - purdue.edu\\VS code\\Data\\ATC\\ATC4_classes\\Classes_notgood\\NDCf_2023_ATC4_classes.csv'\n",
    "keyed_path=rf'C:\\Users\\{user}\\OneDrive - purdue.edu\\VS code\\Data\\ATC\\ATC4_classes\\NDCNEW_2023_ATC4_classes.csv'\n",
    "\n",
    "# Load them\n",
    "keyed = pd.read_csv(keyed_path, dtype=str)\n",
    "nokey = pd.read_csv(nokey_path, dtype=str)\n",
    "\n",
    "# Normalize NDCs (remove hyphens, pad to 11 digits)\n",
    "for df in [keyed, nokey]:\n",
    "    df[\"NDC\"] = df[\"NDC\"].str.replace(\"-\", \"\", regex=False).str.zfill(11)\n",
    "\n",
    "# --- Summary stats ---\n",
    "summary = {\n",
    "    \"File\": [\"With key (NDCNEW_2024_ATC4_classes)\", \"Without key (NDCf_2024_ATC4_classes)\"],\n",
    "    \"Total rows\": [len(keyed), len(nokey)],\n",
    "    \"Unique NDCs\": [keyed[\"NDC\"].nunique(), nokey[\"NDC\"].nunique()],\n",
    "    \"Mapped NDCs (non-null ATC)\": [\n",
    "        keyed[\"ATC4 Class\"].notna().sum(),\n",
    "        nokey[\"ATC4 Class\"].notna().sum(),\n",
    "    ],\n",
    "}\n",
    "summary_df = pd.DataFrame(summary)\n",
    "\n",
    "# --- Compare overlap of unique NDCs ---\n",
    "ndc_keyed = set(keyed[\"NDC\"].unique())\n",
    "ndc_nokey = set(nokey[\"NDC\"].unique())\n",
    "\n",
    "overlap_ndcs = len(ndc_keyed & ndc_nokey)\n",
    "only_in_nokey = len(ndc_nokey - ndc_keyed)\n",
    "only_in_keyed = len(ndc_keyed - ndc_nokey)\n",
    "\n",
    "comparison = pd.DataFrame({\n",
    "    \"Metric\": [\"Overlap NDCs\", \"Only in without-key file\", \"Only in with-key file\", \"Percent overlap\"],\n",
    "    \"Value\": [overlap_ndcs, only_in_nokey, only_in_keyed, overlap_ndcs / len(ndc_nokey) * 100]\n",
    "})\n",
    "\n",
    "print(\"\\n=== Summary of Each File ===\")\n",
    "print(summary_df.to_string(index=False))\n",
    "\n",
    "print(\"\\n=== NDC Overlap Comparison ===\")\n",
    "print(comparison.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0887c17",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
