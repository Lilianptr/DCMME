{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import json\n",
    "from typing import Iterable, Dict, Any, List, Optional\n",
    "import requests\n",
    "import networkx as nx\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "def _props_dict(item):\n",
    "    props = {}\n",
    "    plist = (item.get(\"propertyConceptList\") or {}).get(\"propertyConcept\") or []\n",
    "    for p in plist:\n",
    "        k = (p.get(\"propName\") or \"\").strip()\n",
    "        v = (p.get(\"propValue\") or \"\").strip()\n",
    "        if k:\n",
    "            props[k.upper()] = v\n",
    "    return props\n",
    "\n",
    "def _first_match(props, *keys_or_contains):\n",
    "    for key in keys_or_contains:\n",
    "        if key in props:\n",
    "            return props[key]\n",
    "    for key in props:\n",
    "        for needle in keys_or_contains:\n",
    "            if needle in key:\n",
    "                return props[key]\n",
    "    return None\n",
    "\n",
    "def _rxnorm_names_from_rxcui(rxcui):\n",
    "    base = \"https://rxnav.nlm.nih.gov/REST\"\n",
    "    url = f\"{base}/rxcui/{rxcui}/allProperties.json\"\n",
    "    resp = requests.get(url, params={\"prop\": \"names\"}, timeout=10)\n",
    "    resp.raise_for_status()\n",
    "    data = resp.json() or {}\n",
    "    props = (data.get(\"propConceptGroup\") or {}).get(\"propConcept\") or []\n",
    "    names = [(p.get(\"propName\"), p.get(\"propValue\")) for p in props]\n",
    "\n",
    "    brand = None\n",
    "    for code, val in names:\n",
    "        if (code or \"\").upper() in (\"BN\", \"SBD\", \"SBDF\", \"SBDG\") and val:\n",
    "            brand = val\n",
    "            break\n",
    "\n",
    "    generic = None\n",
    "    for code, val in names:\n",
    "        if (code or \"\").upper() in (\"IN\", \"SCD\", \"SCDF\", \"SCDC\") and val:\n",
    "            generic = val\n",
    "            break\n",
    "\n",
    "    if generic is None:\n",
    "        url2 = f\"{base}/rxcui/{rxcui}/property.json\"\n",
    "        r2 = requests.get(url2, params={\"propName\": \"RxNorm Name\"}, timeout=10)\n",
    "        if r2.ok:\n",
    "            dd = r2.json() or {}\n",
    "            generic = (dd.get(\"propConceptGroup\") or {}).get(\"propConcept\", [{}])[0].get(\"propValue\")\n",
    "\n",
    "    return brand, generic\n",
    "\n",
    "def get_names_for_ndc(ndc_code, ndcstatus=\"ALL\"):\n",
    "    \"\"\"\n",
    "    Returns a dict with:\n",
    "      - ndc11\n",
    "      - brand_name\n",
    "      - product_type\n",
    "      - generic_name\n",
    "      - labeler\n",
    "      - rxcui\n",
    "    Uses RxCUI fallbacks to fill brand/generic when missing in NDC properties.\n",
    "    \"\"\"\n",
    "    ndc_url = \"https://rxnav.nlm.nih.gov/REST/ndcproperties.json\"\n",
    "    r = requests.get(ndc_url, params={\"id\": ndc_code, \"ndcstatus\": ndcstatus}, timeout=10)\n",
    "    r.raise_for_status()\n",
    "    data = r.json() or {}\n",
    "    items = (data.get(\"ndcPropertyList\") or {}).get(\"ndcProperty\") or []\n",
    "    if not items:\n",
    "        return {\n",
    "            \"ndc11\": None,\n",
    "            \"brand_name\": None,\n",
    "            \"product_type\": None,\n",
    "            \"generic_name\": None,\n",
    "            \"labeler\": None,\n",
    "            \"rxcui\": None,\n",
    "        }\n",
    "\n",
    "    # pick richest item (prefer one with explicit proprietary/nonproprietary if present)\n",
    "    best = None\n",
    "    for it in items:\n",
    "        props = _props_dict(it)\n",
    "        if \"PROPRIETARYNAME\" in props or \"NONPROPRIETARYNAME\" in props:\n",
    "            best = it\n",
    "            break\n",
    "    if best is None:\n",
    "        best = items[0]\n",
    "\n",
    "    props = _props_dict(best)\n",
    "    rxcui = best.get(\"rxcui\")\n",
    "    ndc11 = best.get(\"ndcItem\")  # RxNavâ€™s NDC11 field\n",
    "\n",
    "    # direct reads\n",
    "    brand = _first_match(props, \"PROPRIETARYNAME\", \"PROPRIETARY NAME\", \"PROPRIETARY\")\n",
    "    generic = _first_match(props, \"NONPROPRIETARYNAME\", \"NONPROPRIETARY NAME\", \"NONPROPRIETARY\")\n",
    "    product_type = _first_match(props, \"PRODUCTTYPENAME\", \"PRODUCT TYPE\")\n",
    "    labeler = _first_match(props, \"LABELER\", \"LABELERNAME\", \"LABELER NAME\")\n",
    "\n",
    "    # fallbacks via RxCUI\n",
    "    if (not brand or not generic) and rxcui:\n",
    "        rx_brand, rx_generic = _rxnorm_names_from_rxcui(rxcui)\n",
    "        brand = brand or rx_brand\n",
    "        generic = generic or rx_generic\n",
    "\n",
    "    return {\n",
    "        \"ndc11\": ndc11,\n",
    "        \"brand_name\": brand,\n",
    "        \"product_type\": product_type,   # e.g., HUMAN PRESCRIPTION DRUG\n",
    "        \"generic_name\": generic,\n",
    "        \"labeler\": labeler,\n",
    "        \"rxcui\": rxcui,\n",
    "    }\n",
    "\n",
    "# ---- Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    summary = get_names_for_ndc(\"00003-0894\", ndcstatus=\"ALL\")\n",
    "\n",
    "print(\"NDC11:\", summary[\"ndc11\"])\n",
    "print(\"Brand name:\", summary[\"brand_name\"])\n",
    "print(\"Product type:\", summary[\"product_type\"])\n",
    "print(\"Generic name:\", summary[\"generic_name\"])\n",
    "print(\"Labeler:\", summary[\"labeler\"])\n",
    "print(\"RxCUI:\", summary[\"rxcui\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading and exploring drug utilization data \n",
    "df = pd.read_csv('SDUD2017.csv')\n",
    "print(len(df))\n",
    "df=df.dropna(subset=['State', 'NDC', 'Units Reimbursed', 'Number of Prescriptions'])\n",
    "print(len(df))\n",
    "\n",
    "#PC_idx=np.arange(len(df[\"NDC\"].unique()))\n",
    "#print(len(PC_idx))\n",
    "# Too many unique NDC codes to handle all of them in a matrix like FAF dataset. \n",
    "\n",
    "# Remove invalid state code 'XX'\n",
    "df = df[df['State'] != 'XX']\n",
    "print(len(df))\n",
    "\n",
    "# Grouping by 'State' and summing 'Units Reimbursed' and 'Number of Prescriptions'\n",
    "state_summary = df.groupby('State')[['Units Reimbursed', 'Number of Prescriptions']].sum()\n",
    "print(state_summary)\n",
    "\n",
    "total_units = state_summary['Units Reimbursed'].sum()\n",
    "total_prescriptions = state_summary['Number of Prescriptions'].sum()\n",
    "print(\"\\nTotal Units Reimbursed across all states:\", total_units)\n",
    "print(\"Total Number of Prescriptions across all states:\", total_prescriptions)\n",
    "\n",
    "# Sorting by 'Units Reimbursed' in descending order and displaying the top 10 states\n",
    "top_states_units = state_summary.sort_values(by='Units Reimbursed', ascending=False).head(10)\n",
    "print(\"\\nTop 10 States by Units Reimbursed:\")\n",
    "print(top_states_units)\n",
    "\n",
    "# Sorting by 'Number of Prescriptions' in descending order and displaying the top 10 states\n",
    "top_states_prescriptions = state_summary.sort_values(by='Number of Prescriptions', ascending=False).head(10)\n",
    "print(\"\\nTop 10 States by Number of Prescriptions:\")\n",
    "print(top_states_prescriptions)\n",
    "\n",
    "# print(df_xx)\n",
    "print(len(df_xx))\n",
    "\n",
    "wp = df_xx.groupby('State')[['Units Reimbursed', 'Number of Prescriptions']].sum()\n",
    "print(wp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Trying a function to encapsulate the above logic for reusability\n",
    "\n",
    "def preliminar(file_path):\n",
    "    \"\"\"\n",
    "    Reads a CSV file, drops NA in key columns, processes the drug utilization data, and prints summaries with the year.\n",
    "    \"\"\"\n",
    "    year = file_path[4:8]\n",
    "\n",
    "    df = pd.read_csv(file_path)\n",
    "    required_cols = ['State', 'NDC', 'Units Reimbursed', 'Number of Prescriptions']\n",
    "    existing = [c for c in required_cols if c in df.columns]\n",
    "    if existing:\n",
    "        before = len(df)\n",
    "        df = df.dropna(subset=existing)\n",
    "        dropped = before - len(df)\n",
    "        print(f\"Year {year}: Dropped {dropped} rows with NA in {existing}\")\n",
    "    else:\n",
    "        print(f\"Year {year}: Required columns missing, skip NA drop\")\n",
    "\n",
    "    print(f\"Year {year}: Total rows after NA drop: {len(df)}\")\n",
    "\n",
    "    df_xx = df[df['State'] == 'XX']\n",
    "    print(f\"Year {year}: Rows with invalid state code 'XX': {len(df_xx)}\")\n",
    "\n",
    "    df = df[df['State'] != 'XX']\n",
    "    print(f\"Year {year}: Rows after removing invalid state code 'XX': {len(df)}\")\n",
    "\n",
    "    state_summary = df.groupby('State')[['Units Reimbursed', 'Number of Prescriptions']].sum()\n",
    "    #print(f\"\\nYear {year}: State Summary:\")\n",
    "    #print(state_summary)\n",
    "\n",
    "    total_units = state_summary['Units Reimbursed'].sum()\n",
    "    total_prescriptions = state_summary['Number of Prescriptions'].sum()\n",
    "    print(f\"\\nYear {year}: Total Units Reimbursed across all states: {total_units}\")\n",
    "    print(f\"Year {year}: Total Number of Prescriptions across all states: {total_prescriptions}\")\n",
    "\n",
    "    top_states_units = state_summary.sort_values(by='Units Reimbursed', ascending=False).head(10)\n",
    "    print(f\"\\nYear {year}: Top 10 States by Units Reimbursed:\")\n",
    "    print(top_states_units)\n",
    "\n",
    "    top_states_prescriptions = state_summary.sort_values(by='Number of Prescriptions', ascending=False).head(10)\n",
    "    print(f\"\\nYear {year}: Top 10 States by Number of Prescriptions:\")\n",
    "    print(top_states_prescriptions)\n",
    "\n",
    "    wp = df_xx.groupby('State')[['Units Reimbursed', 'Number of Prescriptions']].sum()\n",
    "    print(f\"\\nYear {year}: Summary for rows with invalid state code 'XX':\")\n",
    "    print(wp)\n",
    "\n",
    "    if not wp.empty:\n",
    "        xx_units = wp['Units Reimbursed'].iloc[0]\n",
    "        xx_prescriptions = wp['Number of Prescriptions'].iloc[0]\n",
    "        units_difference_percentage = ((total_units - xx_units) / xx_units) * 100\n",
    "        prescriptions_difference_percentage = ((total_prescriptions - xx_prescriptions) / xx_prescriptions) * 100\n",
    "        print(f\"\\nYear {year}: Comparison with 'XX':\")\n",
    "        print(f\"Percentage difference in Units Reimbursed: {units_difference_percentage:.2f}%\")\n",
    "        print(f\"Percentage difference in Number of Prescriptions: {prescriptions_difference_percentage:.2f}%\")\n",
    "    else:\n",
    "        print(f\"\\nYear {year}: No data available for state code 'XX'.\")\n",
    "\n",
    "    correlation = state_summary['Units Reimbursed'].corr(state_summary['Number of Prescriptions'])\n",
    "    print(f\"\\nYear {year}: Correlation between 'Units Reimbursed' and 'Number of Prescriptions': {correlation:.2f}\")\n",
    "\n",
    "# Inputs for multiple years (datasets)\n",
    "preliminar('SDUD2010.csv')\n",
    "preliminar('SDUD2011.csv')\n",
    "preliminar('SDUD2012.csv')\n",
    "preliminar('SDUD2013.csv')\n",
    "preliminar('SDUD2014.csv')\n",
    "preliminar('SDUD2015.csv')\n",
    "preliminar('SDUD2016.csv')\n",
    "preliminar('SDUD2017.csv')\n",
    "preliminar('SDUD2018.csv')\n",
    "preliminar('SDUD2019.csv')\n",
    "preliminar('SDUD2020.csv')\n",
    "preliminar('SDUD2021.csv')\n",
    "preliminar('SDUD2022.csv')\n",
    "preliminar('SDUD2023.csv')\n",
    "preliminar('SDUD2024.csv')\n",
    "\n",
    "# Counting frequency of states in the top-ten lists across years\n",
    "from collections import Counter\n",
    "top_states_counter_units = Counter()\n",
    "top_states_counter_prescriptions = Counter()\n",
    "years = [str(y) for y in range(2010, 2025)]\n",
    "for year in years:\n",
    "    state_summary = df.groupby('State')[['Units Reimbursed', 'Number of Prescriptions']].sum()\n",
    "    top_states_units = state_summary.sort_values(by='Units Reimbursed', ascending=False).head(10)\n",
    "    top_states_prescriptions = state_summary.sort_values(by='Number of Prescriptions', ascending=False).head(10)\n",
    "    top_states_counter_units.update(top_states_units.index)\n",
    "    top_states_counter_prescriptions.update(top_states_prescriptions.index)\n",
    "print(\"\\nFrequency of States in Top 10 by Units Reimbursed across years:\")\n",
    "print(top_states_counter_units)\n",
    "print(\"\\nFrequency of States in Top 10 by Number of Prescriptions across years:\")\n",
    "print(top_states_counter_prescriptions)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
